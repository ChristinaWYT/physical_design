Tue Jul 22 06:14:34 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-22 06:14:34,960 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-22 06:14:34,961 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-22 06:14:34,961 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-22 06:14:35,182 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-22 06:14:35,182 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-22 06:14:35,182 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-22 06:14:35,182 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-22 06:14:35,182 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-22 06:14:35,182 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 54774 22
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-22 06:14:35,183 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-22 06:14:35,184 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-22 06:14:35,184 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 54774 9.1.143.59 22
2014-07-22 06:14:35,184 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-22 06:14:35,184 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-22 06:14:35,184 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-22 06:14:35,186 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-22 06:14:35,186 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-22 06:14:35,186 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=271
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-22 06:14:35,187 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-22 06:14:35,190 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-22 06:14:35,190 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-22 06:14:35,403 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-22 06:14:35,764 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-22 06:14:35,850 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-22 06:14:35,862 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-22 06:14:35,924 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-22 06:14:35,925 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-22 06:14:35,925 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-22 06:14:35,930 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-22 06:14:35,934 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-22 06:14:36,021 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-22 06:14:36,021 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-22 06:14:36,025 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-22 06:14:36,027 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-22 06:14:36,094 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-22 06:14:36,148 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-22 06:14:36,157 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-22 06:14:36,158 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-22 06:14:36,158 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-22 06:14:36,158 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-22 06:14:36,477 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-22 06:14:36,538 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-22 06:14:36,540 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-22 06:14:36,541 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-22 06:14:36,541 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-22 06:14:36,542 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-22 06:14:36,564 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-22 06:14:36,567 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-22 06:14:36,571 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-22 06:14:36,590 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x475e35978f0000, negotiated timeout = 90000
2014-07-22 06:15:06,704 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0xba6ceb, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-22 06:15:06,705 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0xba6ceb connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-22 06:15:06,706 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-22 06:15:06,707 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-22 06:15:06,740 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x475e35978f0001, negotiated timeout = 90000
2014-07-22 06:15:07,001 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4fa3fd6d
2014-07-22 06:15:07,005 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-22 06:15:07,011 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-22 06:15:07,027 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-22 06:15:07,056 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-22 06:15:07,061 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-22 06:15:07,065 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-22 06:15:07,084 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1406034875762 with port=60020, startcode=1406034875944
2014-07-22 06:15:07,433 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-22 06:15:07,433 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-22 06:15:07,434 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-22 06:15:07,460 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-22 06:15:07,468 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944
2014-07-22 06:15:07,506 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-22 06:15:07,519 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-22 06:15:07,614 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034907525
2014-07-22 06:15:07,628 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-22 06:15:07,633 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-22 06:15:07,636 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-22 06:15:07,641 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-22 06:15:07,643 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-22 06:15:07,643 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-22 06:15:07,644 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-22 06:15:07,644 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-22 06:15:07,644 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-22 06:15:07,651 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1406034877632, slave1,60020,1406034875944] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1406034877632, slave1,60020,1406034875944]
2014-07-22 06:15:07,673 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-22 06:15:07,676 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x6806da29, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-22 06:15:07,676 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6806da29 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-22 06:15:07,677 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-22 06:15:07,677 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-22 06:15:07,680 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x1475e3590bf0004, negotiated timeout = 90000
2014-07-22 06:15:07,687 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-22 06:15:07,687 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-22 06:15:07,729 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1406034875944, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x475e35978f0000
2014-07-22 06:15:07,729 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1406034875944 starting
2014-07-22 06:15:07,729 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-22 06:15:07,729 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1406034875944
2014-07-22 06:15:07,729 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1406034875944'
2014-07-22 06:15:07,730 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-22 06:15:07,732 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-22 06:15:07,733 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-22 06:15:12,645 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-22 06:15:12,753 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:12,785 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:12,785 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944
2014-07-22 06:15:12,787 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-22 06:15:12,825 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034912792.meta
2014-07-22 06:15:12,846 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-22 06:15:12,867 DEBUG [RS_OPEN_META-slave1:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-22 06:15:12,875 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-22 06:15:12,878 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-22 06:15:12,883 INFO  [RS_OPEN_META-slave1:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-22 06:15:12,883 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-22 06:15:12,883 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-22 06:15:12,952 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:12,989 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-22 06:15:13,036 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for 978f1f75944e480386cb1ba96e016133
2014-07-22 06:15:13,037 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/978f1f75944e480386cb1ba96e016133, isReference=false, isBulkLoadResult=false, seqid=7439, majorCompaction=false
2014-07-22 06:15:13,063 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/e0012f71f4a34951895edd9d70b0aa5b, isReference=false, isBulkLoadResult=false, seqid=7413, majorCompaction=true
2014-07-22 06:15:13,097 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-22 06:15:13,102 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=7440
2014-07-22 06:15:13,103 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-22 06:15:13,107 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-22 06:15:13,108 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as slave1,60020,1406034875944
2014-07-22 06:15:13,118 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-22 06:15:13,119 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:13,127 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:13,127 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:13,128 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on slave1,60020,1406034875944
2014-07-22 06:15:13,477 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:13,503 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:13,504 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d5ed6c6bc1f29770a0ea714c5e8e25d6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,505 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:13,505 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b56ece888c92e20684625b0b0795278c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,506 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:13,507 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4fb364c259e9d660d17f31cbb7c7479c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,507 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-22 06:15:13,515 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:13,520 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d5ed6c6bc1f29770a0ea714c5e8e25d6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,521 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => d5ed6c6bc1f29770a0ea714c5e8e25d6, NAME => 'usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-22 06:15:13,523 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d5ed6c6bc1f29770a0ea714c5e8e25d6
2014-07-22 06:15:13,524 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:13,526 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b56ece888c92e20684625b0b0795278c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,527 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4fb364c259e9d660d17f31cbb7c7479c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,527 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => b56ece888c92e20684625b0b0795278c, NAME => 'usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-22 06:15:13,528 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 4fb364c259e9d660d17f31cbb7c7479c, NAME => 'usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-22 06:15:13,529 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable b56ece888c92e20684625b0b0795278c
2014-07-22 06:15:13,529 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 4fb364c259e9d660d17f31cbb7c7479c
2014-07-22 06:15:13,529 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:13,530 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:13,565 INFO  [RS_OPEN_REGION-slave1:60020-0] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-22 06:15:13,569 INFO  [RS_OPEN_REGION-slave1:60020-0] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-22 06:15:13,573 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-22 06:15:13,573 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-22 06:15:13,573 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-22 06:15:13,589 INFO  [StoreOpener-d5ed6c6bc1f29770a0ea714c5e8e25d6-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:13,590 INFO  [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:13,594 INFO  [StoreOpener-b56ece888c92e20684625b0b0795278c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:13,599 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d5ed6c6bc1f29770a0ea714c5e8e25d6
2014-07-22 06:15:13,603 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined d5ed6c6bc1f29770a0ea714c5e8e25d6; next sequenceid=1
2014-07-22 06:15:13,604 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d5ed6c6bc1f29770a0ea714c5e8e25d6
2014-07-22 06:15:13,607 INFO  [PostOpenDeployTasks:d5ed6c6bc1f29770a0ea714c5e8e25d6] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:13,651 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-22 06:15:13,651 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-22 06:15:13,655 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/01a05a2a1ef84cdba4945e07a5c5dae7, isReference=false, isBulkLoadResult=false, seqid=17458, majorCompaction=false
2014-07-22 06:15:13,657 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/153fa9b2738f4cb08abaee12419f4eae, isReference=false, isBulkLoadResult=false, seqid=9273, majorCompaction=false
2014-07-22 06:15:13,683 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/1a6ad96eef59402d93edfcd7aa1caefc, isReference=false, isBulkLoadResult=false, seqid=8826, majorCompaction=false
2014-07-22 06:15:13,687 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/1a104894726c416ba2f33e06b7ffd2e7, isReference=false, isBulkLoadResult=false, seqid=4861, majorCompaction=false
2014-07-22 06:15:13,701 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/20608902dc2b4130b85e5039d3967947, isReference=false, isBulkLoadResult=false, seqid=7971, majorCompaction=false
2014-07-22 06:15:13,711 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/36a61530632846df9cef19cdf1b83b7e, isReference=false, isBulkLoadResult=false, seqid=12946, majorCompaction=false
2014-07-22 06:15:13,718 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/3046dfc45cde4cb8ad7f8a8949f5a575, isReference=false, isBulkLoadResult=false, seqid=9600, majorCompaction=false
2014-07-22 06:15:13,737 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/62d4892fe70342ceb9b28ccc08808774, isReference=false, isBulkLoadResult=false, seqid=7771, majorCompaction=false
2014-07-22 06:15:13,745 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/36e47539af144daa9ab760d41a622296, isReference=false, isBulkLoadResult=false, seqid=5287, majorCompaction=false
2014-07-22 06:15:13,746 INFO  [PostOpenDeployTasks:d5ed6c6bc1f29770a0ea714c5e8e25d6] catalog.MetaEditor: Updated row usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6. with server=slave1,60020,1406034875944
2014-07-22 06:15:13,746 INFO  [PostOpenDeployTasks:d5ed6c6bc1f29770a0ea714c5e8e25d6] regionserver.HRegionServer: Finished post open deploy task for usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:13,747 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d5ed6c6bc1f29770a0ea714c5e8e25d6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:13,753 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d5ed6c6bc1f29770a0ea714c5e8e25d6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:13,753 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned d5ed6c6bc1f29770a0ea714c5e8e25d6 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:13,754 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6. on slave1,60020,1406034875944
2014-07-22 06:15:13,754 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dc91d22c1394d601b468f4b04df159ef from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,759 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dc91d22c1394d601b468f4b04df159ef from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:13,760 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => dc91d22c1394d601b468f4b04df159ef, NAME => 'usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-22 06:15:13,760 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable dc91d22c1394d601b468f4b04df159ef
2014-07-22 06:15:13,760 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:13,762 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/446457c9dfa04b479c91f188241bb537, isReference=false, isBulkLoadResult=false, seqid=18459, majorCompaction=false
2014-07-22 06:15:13,769 INFO  [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:13,790 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/586f3be75cb54b1eb729aea808186a77, isReference=false, isBulkLoadResult=false, seqid=19263, majorCompaction=false
2014-07-22 06:15:13,791 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/79c22d2c6a85408ea27b0a5223add061, isReference=false, isBulkLoadResult=false, seqid=3475, majorCompaction=false
2014-07-22 06:15:13,811 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/016135a7cd0d4937a2c4fca607138ae4, isReference=false, isBulkLoadResult=false, seqid=6423, majorCompaction=false
2014-07-22 06:15:13,826 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/049da0768d2a457997b569008aa9d8a1, isReference=false, isBulkLoadResult=false, seqid=9601, majorCompaction=false
2014-07-22 06:15:13,830 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/7cbf17d9bd904fef81305a9341f67e94, isReference=false, isBulkLoadResult=false, seqid=7120, majorCompaction=false
2014-07-22 06:15:13,833 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/66aacc17c1b44dab87a56e969d32c024, isReference=false, isBulkLoadResult=false, seqid=12526, majorCompaction=false
2014-07-22 06:15:13,849 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/0ea9a0ee36134f61a270a7f81054a291, isReference=false, isBulkLoadResult=false, seqid=4722, majorCompaction=false
2014-07-22 06:15:13,857 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/702b559f0d654c02955c0721223aebe6, isReference=false, isBulkLoadResult=false, seqid=18871, majorCompaction=false
2014-07-22 06:15:13,862 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/ace1b2df25b348519a633e563b5d2266, isReference=false, isBulkLoadResult=false, seqid=5087, majorCompaction=false
2014-07-22 06:15:13,869 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/10d19554397840eea47fc8c06a9eff21, isReference=false, isBulkLoadResult=false, seqid=8161, majorCompaction=false
2014-07-22 06:15:13,884 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/b300730730c1480db09aac4e6b1bfc17, isReference=false, isBulkLoadResult=false, seqid=7624, majorCompaction=false
2014-07-22 06:15:13,884 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/188362f85f2c4c64a6ec874692ac1122, isReference=false, isBulkLoadResult=false, seqid=8011, majorCompaction=false
2014-07-22 06:15:13,935 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/1d821be19f1c4711aafa4925b5121d61, isReference=false, isBulkLoadResult=false, seqid=7563, majorCompaction=false
2014-07-22 06:15:13,941 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/8cf30c839bc74a95ac2c85deebc7a002, isReference=false, isBulkLoadResult=false, seqid=16771, majorCompaction=false
2014-07-22 06:15:13,962 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/ce98572738d1494aa3cdef66a1e94fdd, isReference=false, isBulkLoadResult=false, seqid=3288, majorCompaction=false
2014-07-22 06:15:13,966 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/20081a5367074941989915c4498d1f01, isReference=false, isBulkLoadResult=false, seqid=7714, majorCompaction=false
2014-07-22 06:15:13,987 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/94c0bf2165154a5ca1aa6a0727a6dba9, isReference=false, isBulkLoadResult=false, seqid=4438, majorCompaction=true
2014-07-22 06:15:13,990 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/34a2864df03f48f8907bda5d579f5a0e, isReference=false, isBulkLoadResult=false, seqid=7864, majorCompaction=false
2014-07-22 06:15:13,991 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/d0df99451d4b46608037f6220fb1d3e3, isReference=false, isBulkLoadResult=false, seqid=7425, majorCompaction=false
2014-07-22 06:15:14,003 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/9f9e4dde69334e4898013a74f471de20, isReference=false, isBulkLoadResult=false, seqid=20325, majorCompaction=false
2014-07-22 06:15:14,009 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/390564a18e4547b6a640321ce237471a, isReference=false, isBulkLoadResult=false, seqid=9131, majorCompaction=false
2014-07-22 06:15:14,018 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/c16892f8d6e8413580467f5ee819b8c6, isReference=false, isBulkLoadResult=false, seqid=18038, majorCompaction=false
2014-07-22 06:15:14,026 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/dd3772129a38425fbb9aec60c3ab4f37, isReference=false, isBulkLoadResult=false, seqid=6819, majorCompaction=false
2014-07-22 06:15:14,032 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/d2efc9d000e34cd79dbf0f9bee4e9812, isReference=false, isBulkLoadResult=false, seqid=21910, majorCompaction=false
2014-07-22 06:15:14,035 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/4b80673820314763bf3e7e23b57bd63b, isReference=false, isBulkLoadResult=false, seqid=4322, majorCompaction=false
2014-07-22 06:15:14,050 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/e62ded6863d84c51905e68b59c8bd5f7, isReference=false, isBulkLoadResult=false, seqid=19547, majorCompaction=false
2014-07-22 06:15:14,058 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/4f1b0f530a3c4ee189f73dd083b39368, isReference=false, isBulkLoadResult=false, seqid=4467, majorCompaction=false
2014-07-22 06:15:14,063 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/e40084e1d35a446c99d0fadb3b251691, isReference=false, isBulkLoadResult=false, seqid=6973, majorCompaction=false
2014-07-22 06:15:14,074 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/efa1825e86be47b8a3a7f95ac098b618, isReference=false, isBulkLoadResult=false, seqid=21272, majorCompaction=false
2014-07-22 06:15:14,084 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/7562db8bda6a4f0286bd1e250176245e, isReference=false, isBulkLoadResult=false, seqid=7064, majorCompaction=false
2014-07-22 06:15:14,093 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/e68c8f7395574cb3abfe7c26f8944d4a, isReference=false, isBulkLoadResult=false, seqid=7266, majorCompaction=false
2014-07-22 06:15:14,099 DEBUG [StoreOpener-4fb364c259e9d660d17f31cbb7c7479c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/f48128b0994b4e4a87245426171cda4e, isReference=false, isBulkLoadResult=false, seqid=17184, majorCompaction=false
2014-07-22 06:15:14,104 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c
2014-07-22 06:15:14,108 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 4fb364c259e9d660d17f31cbb7c7479c; next sequenceid=21911
2014-07-22 06:15:14,108 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 4fb364c259e9d660d17f31cbb7c7479c
2014-07-22 06:15:14,111 INFO  [PostOpenDeployTasks:4fb364c259e9d660d17f31cbb7c7479c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:14,114 DEBUG [PostOpenDeployTasks:4fb364c259e9d660d17f31cbb7c7479c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:15:14,115 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 2000 blocking
2014-07-22 06:15:14,118 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/e7848ae4e09b4e4c81b02bbbe671d6c6, isReference=false, isBulkLoadResult=false, seqid=8118, majorCompaction=false
2014-07-22 06:15:14,122 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1137692485 starting at candidate #6 after considering 84 permutations with 53 in ratio
2014-07-22 06:15:14,124 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 4fb364c259e9d660d17f31cbb7c7479c - family: Initiating minor compaction
2014-07-22 06:15:14,126 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:14,126 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/.tmp, totalSize=1.1g
2014-07-22 06:15:14,127 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/7b83b3bbeb2c43cc8e322f5975df968b, isReference=false, isBulkLoadResult=false, seqid=2747, majorCompaction=true
2014-07-22 06:15:14,128 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/f48128b0994b4e4a87245426171cda4e, keycount=94013, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=17184
2014-07-22 06:15:14,128 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/01a05a2a1ef84cdba4945e07a5c5dae7, keycount=94301, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=17458
2014-07-22 06:15:14,129 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/c16892f8d6e8413580467f5ee819b8c6, keycount=130471, bloomtype=ROW, size=93.0m, encoding=NONE, seqNum=18038
2014-07-22 06:15:14,129 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/446457c9dfa04b479c91f188241bb537, keycount=94547, bloomtype=ROW, size=67.4m, encoding=NONE, seqNum=18459
2014-07-22 06:15:14,130 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/702b559f0d654c02955c0721223aebe6, keycount=123165, bloomtype=ROW, size=87.7m, encoding=NONE, seqNum=18871
2014-07-22 06:15:14,131 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/586f3be75cb54b1eb729aea808186a77, keycount=103412, bloomtype=ROW, size=73.7m, encoding=NONE, seqNum=19263
2014-07-22 06:15:14,131 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/e62ded6863d84c51905e68b59c8bd5f7, keycount=97443, bloomtype=ROW, size=69.4m, encoding=NONE, seqNum=19547
2014-07-22 06:15:14,131 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/9f9e4dde69334e4898013a74f471de20, keycount=347745, bloomtype=ROW, size=247.5m, encoding=NONE, seqNum=20325
2014-07-22 06:15:14,131 INFO  [PostOpenDeployTasks:4fb364c259e9d660d17f31cbb7c7479c] catalog.MetaEditor: Updated row usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c. with server=slave1,60020,1406034875944
2014-07-22 06:15:14,132 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/efa1825e86be47b8a3a7f95ac098b618, keycount=316626, bloomtype=ROW, size=225.4m, encoding=NONE, seqNum=21272
2014-07-22 06:15:14,132 INFO  [PostOpenDeployTasks:4fb364c259e9d660d17f31cbb7c7479c] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:14,132 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4fb364c259e9d660d17f31cbb7c7479c/family/d2efc9d000e34cd79dbf0f9bee4e9812, keycount=121853, bloomtype=ROW, size=86.8m, encoding=NONE, seqNum=21910
2014-07-22 06:15:14,133 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4fb364c259e9d660d17f31cbb7c7479c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,141 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4fb364c259e9d660d17f31cbb7c7479c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,141 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 4fb364c259e9d660d17f31cbb7c7479c to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:14,141 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c. on slave1,60020,1406034875944
2014-07-22 06:15:14,142 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:14,147 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:14,148 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-22 06:15:14,149 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-22 06:15:14,149 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-22 06:15:14,149 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/e9f9c929519945ffbf96dea19a95e088, isReference=false, isBulkLoadResult=false, seqid=1664, majorCompaction=true
2014-07-22 06:15:14,159 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:14,160 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/7f6aec52a6ce4a5ab9c16cad6dd65116, isReference=false, isBulkLoadResult=false, seqid=6761, majorCompaction=false
2014-07-22 06:15:14,169 DEBUG [StoreOpener-b56ece888c92e20684625b0b0795278c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c/family/ee1a6a73a9d242c68994f6bebadb5b80, isReference=false, isBulkLoadResult=false, seqid=8302, majorCompaction=false
2014-07-22 06:15:14,172 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/b56ece888c92e20684625b0b0795278c
2014-07-22 06:15:14,176 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined b56ece888c92e20684625b0b0795278c; next sequenceid=9601
2014-07-22 06:15:14,176 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node b56ece888c92e20684625b0b0795278c
2014-07-22 06:15:14,178 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/95acd6659acc4f02ba5c7b856f654c37, isReference=false, isBulkLoadResult=false, seqid=8532, majorCompaction=false
2014-07-22 06:15:14,179 INFO  [PostOpenDeployTasks:b56ece888c92e20684625b0b0795278c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:14,180 DEBUG [PostOpenDeployTasks:b56ece888c92e20684625b0b0795278c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-22 06:15:14,189 INFO  [PostOpenDeployTasks:b56ece888c92e20684625b0b0795278c] catalog.MetaEditor: Updated row usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c. with server=slave1,60020,1406034875944
2014-07-22 06:15:14,189 INFO  [PostOpenDeployTasks:b56ece888c92e20684625b0b0795278c] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:14,190 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b56ece888c92e20684625b0b0795278c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,200 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b56ece888c92e20684625b0b0795278c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,200 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned b56ece888c92e20684625b0b0795278c to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:14,200 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c. on slave1,60020,1406034875944
2014-07-22 06:15:14,201 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1dd62601dc1d239750a111cfb301723b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:14,204 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-22 06:15:14,206 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1dd62601dc1d239750a111cfb301723b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:15:14,207 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 1dd62601dc1d239750a111cfb301723b, NAME => 'usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-22 06:15:14,208 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 1dd62601dc1d239750a111cfb301723b
2014-07-22 06:15:14,208 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-22 06:15:14,209 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:14,212 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-22 06:15:14,212 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-22 06:15:14,215 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-22 06:15:14,219 INFO  [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:15:14,224 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1406034875944
2014-07-22 06:15:14,224 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-22 06:15:14,225 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,232 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,232 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:14,232 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1406034875944
2014-07-22 06:15:14,238 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/b81933d89c6145c2b36d0b0dd1ef4a6f, isReference=false, isBulkLoadResult=false, seqid=7209, majorCompaction=false
2014-07-22 06:15:14,279 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/03e5a62f62b749b888e65bc7920ff8b7, isReference=false, isBulkLoadResult=false, seqid=8010, majorCompaction=false
2014-07-22 06:15:14,294 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/bb1c2b2826194654815484118520c3a6, isReference=false, isBulkLoadResult=false, seqid=6614, majorCompaction=false
2014-07-22 06:15:14,312 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/be675c2a539942e39565a3b55d7fa7b7, isReference=false, isBulkLoadResult=false, seqid=7416, majorCompaction=false
2014-07-22 06:15:14,317 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/10728c432159457db95ad5387d068067, isReference=false, isBulkLoadResult=false, seqid=2590, majorCompaction=false
2014-07-22 06:15:14,320 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:15:14,341 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/17f1d595926246c3aa0b7abec97915dc, isReference=false, isBulkLoadResult=false, seqid=7714, majorCompaction=false
2014-07-22 06:15:14,344 DEBUG [StoreOpener-dc91d22c1394d601b468f4b04df159ef-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef/family/ca5013e5ad67477a9907d78d896501bf, isReference=false, isBulkLoadResult=false, seqid=6907, majorCompaction=false
2014-07-22 06:15:14,348 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/dc91d22c1394d601b468f4b04df159ef
2014-07-22 06:15:14,351 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined dc91d22c1394d601b468f4b04df159ef; next sequenceid=9602
2014-07-22 06:15:14,351 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node dc91d22c1394d601b468f4b04df159ef
2014-07-22 06:15:14,354 INFO  [PostOpenDeployTasks:dc91d22c1394d601b468f4b04df159ef] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:14,355 DEBUG [PostOpenDeployTasks:dc91d22c1394d601b468f4b04df159ef] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-22 06:15:14,363 INFO  [PostOpenDeployTasks:dc91d22c1394d601b468f4b04df159ef] catalog.MetaEditor: Updated row usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef. with server=slave1,60020,1406034875944
2014-07-22 06:15:14,363 INFO  [PostOpenDeployTasks:dc91d22c1394d601b468f4b04df159ef] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:14,363 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dc91d22c1394d601b468f4b04df159ef from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,368 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dc91d22c1394d601b468f4b04df159ef from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,368 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned dc91d22c1394d601b468f4b04df159ef to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:14,368 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef. on slave1,60020,1406034875944
2014-07-22 06:15:14,403 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/2fc1654a352a4e87b4abe2a451ebe5c8, isReference=false, isBulkLoadResult=false, seqid=2288, majorCompaction=true
2014-07-22 06:15:14,423 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/422b8cfdb16747528f6787e05f91e29e, isReference=false, isBulkLoadResult=false, seqid=8161, majorCompaction=false
2014-07-22 06:15:14,469 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/534e0de7c0d547e297413009fc56c056, isReference=false, isBulkLoadResult=false, seqid=8491, majorCompaction=false
2014-07-22 06:15:14,495 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/667a7090dd444d3190a00978b6776612, isReference=false, isBulkLoadResult=false, seqid=7562, majorCompaction=false
2014-07-22 06:15:14,521 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/7caadd44681143538812a11658ca4483, isReference=false, isBulkLoadResult=false, seqid=2444, majorCompaction=false
2014-07-22 06:15:14,536 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/89ab81e3469e416aa7e5d7b6763f5771, isReference=false, isBulkLoadResult=false, seqid=9601, majorCompaction=false
2014-07-22 06:15:14,547 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/a230f5372ddd4cb799953da3c3b4f606, isReference=false, isBulkLoadResult=false, seqid=9533, majorCompaction=false
2014-07-22 06:15:14,573 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/a4f6ae0a5e9c4d2c91872ca818bb543a, isReference=false, isBulkLoadResult=false, seqid=7416, majorCompaction=false
2014-07-22 06:15:14,591 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/ab1528ee77464e648c331ca3569e6575, isReference=false, isBulkLoadResult=false, seqid=9021, majorCompaction=false
2014-07-22 06:15:14,607 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/c3c6901c6af74664967a9af200fe8d35, isReference=false, isBulkLoadResult=false, seqid=7864, majorCompaction=false
2014-07-22 06:15:14,634 DEBUG [StoreOpener-1dd62601dc1d239750a111cfb301723b-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b/family/d0763a6698ae42f8b54c6ff0c786f265, isReference=false, isBulkLoadResult=false, seqid=7209, majorCompaction=false
2014-07-22 06:15:14,639 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/1dd62601dc1d239750a111cfb301723b
2014-07-22 06:15:14,643 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 1dd62601dc1d239750a111cfb301723b; next sequenceid=9602
2014-07-22 06:15:14,643 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1dd62601dc1d239750a111cfb301723b
2014-07-22 06:15:14,646 INFO  [PostOpenDeployTasks:1dd62601dc1d239750a111cfb301723b] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:14,646 DEBUG [PostOpenDeployTasks:1dd62601dc1d239750a111cfb301723b] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-22 06:15:14,657 INFO  [PostOpenDeployTasks:1dd62601dc1d239750a111cfb301723b] catalog.MetaEditor: Updated row usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b. with server=slave1,60020,1406034875944
2014-07-22 06:15:14,657 INFO  [PostOpenDeployTasks:1dd62601dc1d239750a111cfb301723b] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:14,658 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1dd62601dc1d239750a111cfb301723b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,664 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1dd62601dc1d239750a111cfb301723b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:15:14,665 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 1dd62601dc1d239750a111cfb301723b to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:15:14,665 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b. on slave1,60020,1406034875944
2014-07-22 06:15:17,647 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-22 06:15:17,647 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-22 06:15:17,648 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-22 06:15:17,648 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-22 06:15:42,977 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close b56ece888c92e20684625b0b0795278c, via zk=yes, znode version=0, on null
2014-07-22 06:15:42,978 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close dc91d22c1394d601b468f4b04df159ef, via zk=yes, znode version=0, on null
2014-07-22 06:15:42,980 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 1dd62601dc1d239750a111cfb301723b, via zk=yes, znode version=0, on null
2014-07-22 06:15:42,981 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:42,982 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close d5ed6c6bc1f29770a0ea714c5e8e25d6, via zk=yes, znode version=0, on null
2014-07-22 06:15:42,982 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Close 4fb364c259e9d660d17f31cbb7c7479c, via zk=yes, znode version=0, on null
2014-07-22 06:15:42,983 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:42,984 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:42,987 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.: disabling compactions & flushes
2014-07-22 06:15:42,987 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:42,988 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.: disabling compactions & flushes
2014-07-22 06:15:42,988 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:42,989 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.: disabling compactions & flushes
2014-07-22 06:15:42,989 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:43,257 INFO  [StoreCloserThread-usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.-1] regionserver.HStore: Closed family
2014-07-22 06:15:43,260 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:43,260 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1dd62601dc1d239750a111cfb301723b from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,266 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1dd62601dc1d239750a111cfb301723b from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,266 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b. on slave1,60020,1406034875944
2014-07-22 06:15:43,266 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b.
2014-07-22 06:15:43,266 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:43,269 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.: disabling compactions & flushes
2014-07-22 06:15:43,269 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:43,269 INFO  [StoreCloserThread-usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.-1] regionserver.HStore: Closed family
2014-07-22 06:15:43,270 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:43,270 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d5ed6c6bc1f29770a0ea714c5e8e25d6 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,277 INFO  [StoreCloserThread-usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.-1] regionserver.HStore: Closed family
2014-07-22 06:15:43,277 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:43,278 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning b56ece888c92e20684625b0b0795278c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,278 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d5ed6c6bc1f29770a0ea714c5e8e25d6 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,278 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6. on slave1,60020,1406034875944
2014-07-22 06:15:43,278 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,,1406021312005.d5ed6c6bc1f29770a0ea714c5e8e25d6.
2014-07-22 06:15:43,278 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:43,280 INFO  [StoreCloserThread-usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.-1] regionserver.HStore: Closed family
2014-07-22 06:15:43,280 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:43,281 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning dc91d22c1394d601b468f4b04df159ef from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,281 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.: disabling compactions & flushes
2014-07-22 06:15:43,281 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: waiting for 1 compactions to complete for region usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:43,284 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node b56ece888c92e20684625b0b0795278c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,284 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c. on slave1,60020,1406034875944
2014-07-22 06:15:43,284 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c.
2014-07-22 06:15:43,288 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node dc91d22c1394d601b468f4b04df159ef from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,288 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef. on slave1,60020,1406034875944
2014-07-22 06:15:43,288 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef.
2014-07-22 06:15:43,787 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: compaction interrupted
java.io.InterruptedIOException: Aborting compaction of store family in region usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c. because it was interrupted.
	at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:81)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:109)
	at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1086)
	at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1481)
	at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:475)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-22 06:15:43,788 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:43,795 INFO  [StoreCloserThread-usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.-1] regionserver.HStore: Closed family
2014-07-22 06:15:43,796 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:43,796 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4fb364c259e9d660d17f31cbb7c7479c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,797 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Aborted compaction: Request = regionName=usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c., storeName=family, fileCount=10, fileSize=1.1g, priority=1984, time=131894514231661; duration=29sec
2014-07-22 06:15:43,797 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b. because compaction request was cancelled
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user3,1406021312006.1dd62601dc1d239750a111cfb301723b. because compaction request was cancelled
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef. because compaction request was cancelled
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c. because compaction request was cancelled
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user4,1406021312006.dc91d22c1394d601b468f4b04df159ef. because compaction request was cancelled
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c. because compaction request was cancelled
2014-07-22 06:15:43,798 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user7,1406021312006.b56ece888c92e20684625b0b0795278c. because compaction request was cancelled
2014-07-22 06:15:43,802 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4fb364c259e9d660d17f31cbb7c7479c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-22 06:15:43,802 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c. on slave1,60020,1406034875944
2014-07-22 06:15:43,802 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user8,1406021312007.4fb364c259e9d660d17f31cbb7c7479c.
2014-07-22 06:15:45,670 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Compacting hbase:meta,,1.1588230740
2014-07-22 06:15:45,671 DEBUG [Priority.RpcServer.handler=4,port=60020] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 2000 blocking
2014-07-22 06:15:45,671 DEBUG [Priority.RpcServer.handler=4,port=60020] regionserver.HStore: 1588230740 - info: Initiating major compaction
2014-07-22 06:15:45,672 DEBUG [Priority.RpcServer.handler=4,port=60020] regionserver.CompactSplitThread: Small Compaction requested: org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext@7bd16a52; Because: User-triggered major compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:15:45,672 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-07-22 06:15:45,673 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=19.3k
2014-07-22 06:15:45,674 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/e0012f71f4a34951895edd9d70b0aa5b, keycount=101, bloomtype=NONE, size=12.3k, encoding=NONE, seqNum=7413, earliestPutTs=1402645258588
2014-07-22 06:15:45,674 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/978f1f75944e480386cb1ba96e016133, keycount=53, bloomtype=NONE, size=7.0k, encoding=NONE, seqNum=7439, earliestPutTs=1406020967232
2014-07-22 06:15:45,679 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:15:45,715 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/19068afc2462472490f5fe058af742f4 as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/19068afc2462472490f5fe058af742f4
2014-07-22 06:15:45,737 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:15:45,751 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/e0012f71f4a34951895edd9d70b0aa5b, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/e0012f71f4a34951895edd9d70b0aa5b
2014-07-22 06:15:45,754 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/978f1f75944e480386cb1ba96e016133, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/978f1f75944e480386cb1ba96e016133
2014-07-22 06:15:45,754 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into 19068afc2462472490f5fe058af742f4(size=8.8k), total size for store is 8.8k. This selection was in queue for 0sec, and took 0sec to execute.
2014-07-22 06:15:45,754 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=19.3k, priority=1, time=131926062136900; duration=0sec
2014-07-22 06:15:45,755 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:19:36,037 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=7297, hits=78, hitRatio=1.06%, , cachingAccesses=80, cachingHits=75, cachingHitsRatio=93.75%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:20:53,321 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:20:53,334 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:20:53,334 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 753f5973e99ebd3e7e2bc45781eaf616 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,335 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:20:53,335 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a1bcd7cee994fe8eb603588f61ee109e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,336 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964.
2014-07-22 06:20:53,336 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 86ea69fe85336d05b86e4198e206c41d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,336 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:20:53,348 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 753f5973e99ebd3e7e2bc45781eaf616 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,349 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a1bcd7cee994fe8eb603588f61ee109e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,349 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 753f5973e99ebd3e7e2bc45781eaf616, NAME => 'usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-22 06:20:53,349 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 86ea69fe85336d05b86e4198e206c41d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,349 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => a1bcd7cee994fe8eb603588f61ee109e, NAME => 'usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-22 06:20:53,350 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 86ea69fe85336d05b86e4198e206c41d, NAME => 'usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-22 06:20:53,350 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 753f5973e99ebd3e7e2bc45781eaf616
2014-07-22 06:20:53,350 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 06:20:53,350 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:20:53,350 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:20:53,350 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 86ea69fe85336d05b86e4198e206c41d
2014-07-22 06:20:53,351 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:20:53,363 INFO  [StoreOpener-86ea69fe85336d05b86e4198e206c41d-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:20:53,363 INFO  [StoreOpener-753f5973e99ebd3e7e2bc45781eaf616-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:20:53,368 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d
2014-07-22 06:20:53,369 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616
2014-07-22 06:20:53,372 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 86ea69fe85336d05b86e4198e206c41d; next sequenceid=1
2014-07-22 06:20:53,372 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 86ea69fe85336d05b86e4198e206c41d
2014-07-22 06:20:53,373 INFO  [StoreOpener-a1bcd7cee994fe8eb603588f61ee109e-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:20:53,374 INFO  [PostOpenDeployTasks:86ea69fe85336d05b86e4198e206c41d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:20:53,374 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 753f5973e99ebd3e7e2bc45781eaf616; next sequenceid=1
2014-07-22 06:20:53,374 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 753f5973e99ebd3e7e2bc45781eaf616
2014-07-22 06:20:53,377 INFO  [PostOpenDeployTasks:753f5973e99ebd3e7e2bc45781eaf616] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:20:53,388 INFO  [PostOpenDeployTasks:86ea69fe85336d05b86e4198e206c41d] catalog.MetaEditor: Updated row usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. with server=slave1,60020,1406034875944
2014-07-22 06:20:53,388 INFO  [PostOpenDeployTasks:86ea69fe85336d05b86e4198e206c41d] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:20:53,390 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 86ea69fe85336d05b86e4198e206c41d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,390 INFO  [PostOpenDeployTasks:753f5973e99ebd3e7e2bc45781eaf616] catalog.MetaEditor: Updated row usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. with server=slave1,60020,1406034875944
2014-07-22 06:20:53,390 INFO  [PostOpenDeployTasks:753f5973e99ebd3e7e2bc45781eaf616] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:20:53,391 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 753f5973e99ebd3e7e2bc45781eaf616 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,394 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 86ea69fe85336d05b86e4198e206c41d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,394 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 86ea69fe85336d05b86e4198e206c41d to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:20:53,394 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. on slave1,60020,1406034875944
2014-07-22 06:20:53,395 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0faeca82b5910c2fe2cd27ba8cde6964 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,396 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 753f5973e99ebd3e7e2bc45781eaf616 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,396 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 753f5973e99ebd3e7e2bc45781eaf616 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:20:53,396 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. on slave1,60020,1406034875944
2014-07-22 06:20:53,396 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6a9abfa0046dd16d723f3fe367c1c68f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,399 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0faeca82b5910c2fe2cd27ba8cde6964 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,400 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 0faeca82b5910c2fe2cd27ba8cde6964, NAME => 'usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-22 06:20:53,401 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0faeca82b5910c2fe2cd27ba8cde6964
2014-07-22 06:20:53,401 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964.
2014-07-22 06:20:53,402 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6a9abfa0046dd16d723f3fe367c1c68f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:20:53,402 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 6a9abfa0046dd16d723f3fe367c1c68f, NAME => 'usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-22 06:20:53,404 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 6a9abfa0046dd16d723f3fe367c1c68f
2014-07-22 06:20:53,404 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:20:53,405 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 06:20:53,408 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined a1bcd7cee994fe8eb603588f61ee109e; next sequenceid=1
2014-07-22 06:20:53,408 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 06:20:53,409 INFO  [StoreOpener-0faeca82b5910c2fe2cd27ba8cde6964-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:20:53,414 INFO  [StoreOpener-6a9abfa0046dd16d723f3fe367c1c68f-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:20:53,414 INFO  [PostOpenDeployTasks:a1bcd7cee994fe8eb603588f61ee109e] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:20:53,416 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0faeca82b5910c2fe2cd27ba8cde6964
2014-07-22 06:20:53,420 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f
2014-07-22 06:20:53,421 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 0faeca82b5910c2fe2cd27ba8cde6964; next sequenceid=1
2014-07-22 06:20:53,421 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0faeca82b5910c2fe2cd27ba8cde6964
2014-07-22 06:20:53,423 INFO  [PostOpenDeployTasks:a1bcd7cee994fe8eb603588f61ee109e] catalog.MetaEditor: Updated row usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. with server=slave1,60020,1406034875944
2014-07-22 06:20:53,423 INFO  [PostOpenDeployTasks:a1bcd7cee994fe8eb603588f61ee109e] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:20:53,425 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a1bcd7cee994fe8eb603588f61ee109e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,426 INFO  [PostOpenDeployTasks:0faeca82b5910c2fe2cd27ba8cde6964] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964.
2014-07-22 06:20:53,430 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a1bcd7cee994fe8eb603588f61ee109e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,430 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned a1bcd7cee994fe8eb603588f61ee109e to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:20:53,430 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. on slave1,60020,1406034875944
2014-07-22 06:20:53,434 INFO  [PostOpenDeployTasks:0faeca82b5910c2fe2cd27ba8cde6964] catalog.MetaEditor: Updated row usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964. with server=slave1,60020,1406034875944
2014-07-22 06:20:53,434 INFO  [PostOpenDeployTasks:0faeca82b5910c2fe2cd27ba8cde6964] regionserver.HRegionServer: Finished post open deploy task for usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964.
2014-07-22 06:20:53,435 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0faeca82b5910c2fe2cd27ba8cde6964 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,441 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0faeca82b5910c2fe2cd27ba8cde6964 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,441 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 0faeca82b5910c2fe2cd27ba8cde6964 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:20:53,441 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,,1406035254793.0faeca82b5910c2fe2cd27ba8cde6964. on slave1,60020,1406034875944
2014-07-22 06:20:53,459 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 6a9abfa0046dd16d723f3fe367c1c68f; next sequenceid=1
2014-07-22 06:20:53,459 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 6a9abfa0046dd16d723f3fe367c1c68f
2014-07-22 06:20:53,461 INFO  [PostOpenDeployTasks:6a9abfa0046dd16d723f3fe367c1c68f] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:20:53,468 INFO  [PostOpenDeployTasks:6a9abfa0046dd16d723f3fe367c1c68f] catalog.MetaEditor: Updated row usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. with server=slave1,60020,1406034875944
2014-07-22 06:20:53,468 INFO  [PostOpenDeployTasks:6a9abfa0046dd16d723f3fe367c1c68f] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:20:53,470 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6a9abfa0046dd16d723f3fe367c1c68f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,474 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6a9abfa0046dd16d723f3fe367c1c68f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:20:53,474 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 6a9abfa0046dd16d723f3fe367c1c68f to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:20:53,474 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. on slave1,60020,1406034875944
2014-07-22 06:21:11,551 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:21:11,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 92 synced till here 88
2014-07-22 06:21:11,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034907525 with entries=92, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035271552
2014-07-22 06:21:48,831 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:21:48,864 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035271552 with entries=88, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035308831
2014-07-22 06:22:01,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:22:01,447 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 267 synced till here 266
2014-07-22 06:22:01,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035308831 with entries=87, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035321424
2014-07-22 06:22:15,977 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9840ms
No GCs detected
2014-07-22 06:22:43,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:22:43,362 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 357 synced till here 355
2014-07-22 06:22:43,638 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035321424 with entries=90, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035363279
2014-07-22 06:22:48,228 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:22:48,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 448 synced till here 446
2014-07-22 06:22:48,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035363279 with entries=91, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035368228
2014-07-22 06:22:52,237 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:22:52,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 537 synced till here 536
2014-07-22 06:22:52,437 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035368228 with entries=89, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035372238
2014-07-22 06:23:24,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:24,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 625 synced till here 624
2014-07-22 06:23:24,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035372238 with entries=88, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035404302
2014-07-22 06:23:25,642 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:23:25,648 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.4m
2014-07-22 06:23:26,141 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:23:26,141 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.0m
2014-07-22 06:23:26,167 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:23:26,687 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:23:26,755 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:23:27,130 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-22 06:23:28,407 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:28,519 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035404302 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035408407
2014-07-22 06:23:31,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:31,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 804 synced till here 795
2014-07-22 06:23:31,937 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035408407 with entries=91, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035411814
2014-07-22 06:23:34,405 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:34,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 899 synced till here 895
2014-07-22 06:23:34,923 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035411814 with entries=95, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035414406
2014-07-22 06:23:40,267 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1296ms
GC pool 'ParNew' had collection(s): count=1 time=1683ms
2014-07-22 06:23:40,856 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:41,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1010 synced till here 1002
2014-07-22 06:23:41,851 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035414406 with entries=111, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035420857
2014-07-22 06:23:51,619 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:52,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1139 synced till here 1128
2014-07-22 06:23:52,301 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=167, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/ee2859f9e2894b8a890a6d9adde50719
2014-07-22 06:23:52,322 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/ee2859f9e2894b8a890a6d9adde50719 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ee2859f9e2894b8a890a6d9adde50719
2014-07-22 06:23:52,351 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ee2859f9e2894b8a890a6d9adde50719, entries=933730, sequenceid=167, filesize=66.5m
2014-07-22 06:23:52,352 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268906560, currentsize=195.8m/205291120 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 26704ms, sequenceid=167, compaction requested=false
2014-07-22 06:23:52,355 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 438.7m
2014-07-22 06:23:52,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035420857 with entries=129, filesize=93.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035431619
2014-07-22 06:23:53,188 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=167, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/400b2add85f34231bea24287687b428e
2014-07-22 06:23:53,232 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/400b2add85f34231bea24287687b428e as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/400b2add85f34231bea24287687b428e
2014-07-22 06:23:53,380 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/400b2add85f34231bea24287687b428e, entries=932180, sequenceid=167, filesize=66.4m
2014-07-22 06:23:53,381 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.0m/268462960, currentsize=195.5m/205010480 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 27240ms, sequenceid=167, compaction requested=false
2014-07-22 06:23:53,964 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:23:55,031 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:55,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1236 synced till here 1234
2014-07-22 06:23:55,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035431619 with entries=97, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035435032
2014-07-22 06:23:58,115 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:23:58,115 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.4m
2014-07-22 06:23:58,354 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:23:58,514 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:23:58,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1327 synced till here 1325
2014-07-22 06:23:58,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035435032 with entries=91, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035438499
2014-07-22 06:23:58,743 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:24:02,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:02,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1420 synced till here 1414
2014-07-22 06:24:02,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035438499 with entries=93, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035442871
2014-07-22 06:24:08,236 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:08,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1509 synced till here 1506
2014-07-22 06:24:08,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035442871 with entries=89, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035448237
2014-07-22 06:24:10,754 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:10,795 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1597 synced till here 1596
2014-07-22 06:24:10,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035448237 with entries=88, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035450754
2014-07-22 06:24:13,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:13,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035450754 with entries=89, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035453607
2014-07-22 06:24:16,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:16,677 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=334, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/664392e0cf254ebfb655902e8437bb62
2014-07-22 06:24:16,735 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/664392e0cf254ebfb655902e8437bb62 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664392e0cf254ebfb655902e8437bb62
2014-07-22 06:24:17,194 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035453607 with entries=110, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035456166
2014-07-22 06:24:17,265 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664392e0cf254ebfb655902e8437bb62, entries=939140, sequenceid=334, filesize=66.9m
2014-07-22 06:24:17,265 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.9m/270463760, currentsize=183.4m/192335360 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 19150ms, sequenceid=334, compaction requested=false
2014-07-22 06:24:17,266 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 441.6m
2014-07-22 06:24:17,563 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:24:20,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:20,194 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1885 synced till here 1884
2014-07-22 06:24:20,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035456166 with entries=89, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035460147
2014-07-22 06:24:22,297 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:24:22,330 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:22,351 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1975 synced till here 1971
2014-07-22 06:24:22,477 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035460147 with entries=90, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035462331
2014-07-22 06:24:24,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:24,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035462331 with entries=90, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035464652
2014-07-22 06:24:25,466 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=293, memsize=451.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/5cf6fa316d494134bdbc399e82d31174
2014-07-22 06:24:25,485 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/5cf6fa316d494134bdbc399e82d31174 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5cf6fa316d494134bdbc399e82d31174
2014-07-22 06:24:25,501 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5cf6fa316d494134bdbc399e82d31174, entries=1642840, sequenceid=293, filesize=117.0m
2014-07-22 06:24:25,501 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~451.2m/473127920, currentsize=365.8m/383538640 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 33146ms, sequenceid=293, compaction requested=false
2014-07-22 06:24:25,502 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 304.3m
2014-07-22 06:24:25,581 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:24:25,880 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:24:36,076 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=7694, hits=474, hitRatio=6.16%, , cachingAccesses=477, cachingHits=471, cachingHitsRatio=98.74%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:24:36,334 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:36,367 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2154 synced till here 2152
2014-07-22 06:24:36,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035464652 with entries=89, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035476335
2014-07-22 06:24:38,021 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=531, memsize=304.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/94d0ef3ae10b475195697b8d415a748b
2014-07-22 06:24:38,035 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/94d0ef3ae10b475195697b8d415a748b as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/94d0ef3ae10b475195697b8d415a748b
2014-07-22 06:24:38,047 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/94d0ef3ae10b475195697b8d415a748b, entries=1108030, sequenceid=531, filesize=78.9m
2014-07-22 06:24:38,047 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~304.3m/319104720, currentsize=34.5m/36142960 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 12545ms, sequenceid=531, compaction requested=true
2014-07-22 06:24:38,048 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 2000 blocking
2014-07-22 06:24:38,048 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:24:38,048 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 222610024 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-22 06:24:38,049 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating major compaction
2014-07-22 06:24:38,049 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 401.7m
2014-07-22 06:24:38,049 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:24:38,049 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=212.3m
2014-07-22 06:24:38,050 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ee2859f9e2894b8a890a6d9adde50719, keycount=93373, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=167, earliestPutTs=1406035268880
2014-07-22 06:24:38,101 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664392e0cf254ebfb655902e8437bb62, keycount=93914, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=334, earliestPutTs=1406035406137
2014-07-22 06:24:38,101 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/94d0ef3ae10b475195697b8d415a748b, keycount=110803, bloomtype=ROW, size=78.9m, encoding=NONE, seqNum=531, earliestPutTs=1406035438129
2014-07-22 06:24:38,121 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:24:38,160 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:24:38,475 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:24:38,493 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-22 06:24:38,493 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-22 06:24:38,493 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=452, memsize=441.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/803d51d65517430b927fb56dbc62de13
2014-07-22 06:24:38,513 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/803d51d65517430b927fb56dbc62de13 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/803d51d65517430b927fb56dbc62de13
2014-07-22 06:24:38,526 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/803d51d65517430b927fb56dbc62de13, entries=1607820, sequenceid=452, filesize=114.5m
2014-07-22 06:24:38,526 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~441.6m/463040720, currentsize=156.5m/164087920 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 21260ms, sequenceid=452, compaction requested=false
2014-07-22 06:24:38,527 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.8m
2014-07-22 06:24:39,194 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:24:39,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:39,862 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035476335 with entries=96, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035479675
2014-07-22 06:24:43,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:24:43,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035479675 with entries=88, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035483034
2014-07-22 06:24:49,499 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=552, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/3ce5be53f6f3495f9df46b407eec410a
2014-07-22 06:24:49,516 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/3ce5be53f6f3495f9df46b407eec410a as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3ce5be53f6f3495f9df46b407eec410a
2014-07-22 06:24:49,525 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3ce5be53f6f3495f9df46b407eec410a, entries=936940, sequenceid=552, filesize=66.7m
2014-07-22 06:24:49,525 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269813440, currentsize=17.1m/17912160 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10998ms, sequenceid=552, compaction requested=false
2014-07-22 06:24:54,467 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=552, memsize=401.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f0f87a72f7234b7d895651b348cb2aa8
2014-07-22 06:24:54,485 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f0f87a72f7234b7d895651b348cb2aa8 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f0f87a72f7234b7d895651b348cb2aa8
2014-07-22 06:24:54,496 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f0f87a72f7234b7d895651b348cb2aa8, entries=1462740, sequenceid=552, filesize=104.1m
2014-07-22 06:24:54,496 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~401.7m/421254320, currentsize=58.9m/61733040 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 16447ms, sequenceid=552, compaction requested=false
2014-07-22 06:25:08,926 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:25:08,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035483034 with entries=87, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035508926
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034907525
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035271552
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035308831
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035321424
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035363279
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035368228
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035372238
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035404302
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035408407
2014-07-22 06:25:08,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035411814
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035414406
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035420857
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035431619
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035435032
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035438499
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035442871
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035448237
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035450754
2014-07-22 06:25:08,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035453607
2014-07-22 06:25:10,919 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:25:10,920 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.1m
2014-07-22 06:25:11,482 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:25:12,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:25:12,540 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2519 synced till here 2515
2014-07-22 06:25:13,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035508926 with entries=94, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035512035
2014-07-22 06:25:13,701 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/c6ab0c99802847d094c3c4db9c2952c2 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6ab0c99802847d094c3c4db9c2952c2
2014-07-22 06:25:13,722 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:25:13,731 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ee2859f9e2894b8a890a6d9adde50719, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ee2859f9e2894b8a890a6d9adde50719
2014-07-22 06:25:13,733 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664392e0cf254ebfb655902e8437bb62, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664392e0cf254ebfb655902e8437bb62
2014-07-22 06:25:13,737 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/94d0ef3ae10b475195697b8d415a748b, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/94d0ef3ae10b475195697b8d415a748b
2014-07-22 06:25:13,738 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into c6ab0c99802847d094c3c4db9c2952c2(size=212.1m), total size for store is 212.1m. This selection was in queue for 0sec, and took 35sec to execute.
2014-07-22 06:25:13,739 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=3, fileSize=212.3m, priority=1997, time=132458439402265; duration=35sec
2014-07-22 06:25:13,739 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:25:20,200 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=621, memsize=260.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/dce80915771c496081a4f36f4849711d
2014-07-22 06:25:20,231 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/dce80915771c496081a4f36f4849711d as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dce80915771c496081a4f36f4849711d
2014-07-22 06:25:20,277 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dce80915771c496081a4f36f4849711d, entries=947850, sequenceid=621, filesize=67.5m
2014-07-22 06:25:20,277 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.3m/272971360, currentsize=28.1m/29475840 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9357ms, sequenceid=621, compaction requested=true
2014-07-22 06:25:20,278 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:25:20,278 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 2000 blocking
2014-07-22 06:25:20,279 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 260432978 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-22 06:25:20,279 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating major compaction
2014-07-22 06:25:20,279 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:25:20,280 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=248.4m
2014-07-22 06:25:20,280 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/400b2add85f34231bea24287687b428e, keycount=93218, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=167, earliestPutTs=1406035270409
2014-07-22 06:25:20,280 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/803d51d65517430b927fb56dbc62de13, keycount=160782, bloomtype=ROW, size=114.5m, encoding=NONE, seqNum=452, earliestPutTs=1406035406690
2014-07-22 06:25:20,280 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dce80915771c496081a4f36f4849711d, keycount=94785, bloomtype=ROW, size=67.5m, encoding=NONE, seqNum=621, earliestPutTs=1406035457800
2014-07-22 06:25:20,293 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:25:25,452 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:25:25,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2610 synced till here 2604
2014-07-22 06:25:25,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035512035 with entries=91, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035525452
2014-07-22 06:25:25,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035456166
2014-07-22 06:25:25,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035460147
2014-07-22 06:25:25,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035462331
2014-07-22 06:25:30,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:25:30,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035525452 with entries=88, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035530184
2014-07-22 06:25:56,618 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b56579cb3d9043b8845e67e56ac203cb as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b56579cb3d9043b8845e67e56ac203cb
2014-07-22 06:25:56,634 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:25:56,645 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/400b2add85f34231bea24287687b428e, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/400b2add85f34231bea24287687b428e
2014-07-22 06:25:56,648 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/803d51d65517430b927fb56dbc62de13, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/803d51d65517430b927fb56dbc62de13
2014-07-22 06:25:56,651 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dce80915771c496081a4f36f4849711d, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dce80915771c496081a4f36f4849711d
2014-07-22 06:25:56,652 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into b56579cb3d9043b8845e67e56ac203cb(size=248.1m), total size for store is 248.1m. This selection was in queue for 0sec, and took 36sec to execute.
2014-07-22 06:25:56,652 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=3, fileSize=248.4m, priority=1997, time=132500669661456; duration=36sec
2014-07-22 06:25:56,652 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:25:58,353 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:25:58,353 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 257.2m
2014-07-22 06:25:58,631 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:25:58,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:25:58,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2788 synced till here 2787
2014-07-22 06:25:58,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035530184 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035558843
2014-07-22 06:26:01,729 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:26:01,730 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.4m
2014-07-22 06:26:01,939 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:26:02,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:26:02,795 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035558843 with entries=87, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035562769
2014-07-22 06:26:04,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:26:05,076 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035562769 with entries=98, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035564727
2014-07-22 06:26:07,928 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=699, memsize=258.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/6da12f6ecbc941a697e912fe2c36195d
2014-07-22 06:26:07,944 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/6da12f6ecbc941a697e912fe2c36195d as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6da12f6ecbc941a697e912fe2c36195d
2014-07-22 06:26:07,958 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6da12f6ecbc941a697e912fe2c36195d, entries=942090, sequenceid=699, filesize=67.1m
2014-07-22 06:26:07,958 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.7m/271314080, currentsize=82.0m/86023520 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9605ms, sequenceid=699, compaction requested=false
2014-07-22 06:26:12,070 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=719, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/b0a7c72ef9a3421bb57053f6bc3fd22e
2014-07-22 06:26:12,081 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/b0a7c72ef9a3421bb57053f6bc3fd22e as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b0a7c72ef9a3421bb57053f6bc3fd22e
2014-07-22 06:26:12,092 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b0a7c72ef9a3421bb57053f6bc3fd22e, entries=937250, sequenceid=719, filesize=66.8m
2014-07-22 06:26:12,092 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269919760, currentsize=52.8m/55412320 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10362ms, sequenceid=719, compaction requested=true
2014-07-22 06:26:12,093 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:26:12,093 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 2000 blocking
2014-07-22 06:26:12,093 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 301917272 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-22 06:26:12,093 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating major compaction
2014-07-22 06:26:12,093 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:26:12,094 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=287.9m
2014-07-22 06:26:12,094 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5cf6fa316d494134bdbc399e82d31174, keycount=164284, bloomtype=ROW, size=117.0m, encoding=NONE, seqNum=293, earliestPutTs=1406035269695
2014-07-22 06:26:12,094 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f0f87a72f7234b7d895651b348cb2aa8, keycount=146274, bloomtype=ROW, size=104.1m, encoding=NONE, seqNum=552, earliestPutTs=1406035432371
2014-07-22 06:26:12,094 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b0a7c72ef9a3421bb57053f6bc3fd22e, keycount=93725, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=719, earliestPutTs=1406035478258
2014-07-22 06:26:12,110 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:26:18,251 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:26:18,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035564727 with entries=87, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035578251
2014-07-22 06:26:18,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035464652
2014-07-22 06:26:20,235 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:26:20,236 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.5m
2014-07-22 06:26:20,461 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:26:21,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:26:21,565 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035578251 with entries=87, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035581494
2014-07-22 06:26:28,083 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=788, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/2acff46355ed4bc88465e9f366c1029e
2014-07-22 06:26:28,099 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/2acff46355ed4bc88465e9f366c1029e as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/2acff46355ed4bc88465e9f366c1029e
2014-07-22 06:26:28,110 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/2acff46355ed4bc88465e9f366c1029e, entries=934040, sequenceid=788, filesize=66.6m
2014-07-22 06:26:28,111 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268994400, currentsize=9.4m/9808880 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 7875ms, sequenceid=788, compaction requested=false
2014-07-22 06:26:52,380 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/eb1047791abf4576931cc1689dccf7e5 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/eb1047791abf4576931cc1689dccf7e5
2014-07-22 06:26:52,398 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:26:52,406 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5cf6fa316d494134bdbc399e82d31174, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5cf6fa316d494134bdbc399e82d31174
2014-07-22 06:26:52,412 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f0f87a72f7234b7d895651b348cb2aa8, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f0f87a72f7234b7d895651b348cb2aa8
2014-07-22 06:26:52,420 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b0a7c72ef9a3421bb57053f6bc3fd22e, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b0a7c72ef9a3421bb57053f6bc3fd22e
2014-07-22 06:26:52,420 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into eb1047791abf4576931cc1689dccf7e5(size=287.6m), total size for store is 287.6m. This selection was in queue for 0sec, and took 40sec to execute.
2014-07-22 06:26:52,421 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=3, fileSize=287.9m, priority=1997, time=132552484036838; duration=40sec
2014-07-22 06:26:52,421 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:27:18,163 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:18,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035581494 with entries=88, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035638163
2014-07-22 06:27:20,490 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:20,512 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3322 synced till here 3320
2014-07-22 06:27:20,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035638163 with entries=87, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035640491
2014-07-22 06:27:26,454 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:26,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035640491 with entries=87, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035646454
2014-07-22 06:27:29,548 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:27:29,548 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 257.3m
2014-07-22 06:27:29,695 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:27:31,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:31,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3498 synced till here 3495
2014-07-22 06:27:31,106 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035646454 with entries=89, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035651048
2014-07-22 06:27:32,435 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:27:32,435 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.9m
2014-07-22 06:27:32,810 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:27:33,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:33,803 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3586 synced till here 3584
2014-07-22 06:27:33,851 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035651048 with entries=88, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035653787
2014-07-22 06:27:39,350 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=866, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7b079d89a378488b9e187ce8ecf0bd49
2014-07-22 06:27:39,374 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7b079d89a378488b9e187ce8ecf0bd49 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7b079d89a378488b9e187ce8ecf0bd49
2014-07-22 06:27:39,400 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7b079d89a378488b9e187ce8ecf0bd49, entries=936870, sequenceid=866, filesize=66.7m
2014-07-22 06:27:39,401 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269811120, currentsize=80.8m/84701360 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9852ms, sequenceid=866, compaction requested=true
2014-07-22 06:27:39,401 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:27:39,401 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 2000 blocking
2014-07-22 06:27:39,402 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-22 06:27:39,402 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-22 06:27:39,402 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. because compaction request was cancelled
2014-07-22 06:27:41,221 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=887, memsize=258.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/4e11f3adf3684a93899c722650de802f
2014-07-22 06:27:41,236 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/4e11f3adf3684a93899c722650de802f as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4e11f3adf3684a93899c722650de802f
2014-07-22 06:27:41,253 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4e11f3adf3684a93899c722650de802f, entries=940930, sequenceid=887, filesize=67.0m
2014-07-22 06:27:41,254 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.4m/270979840, currentsize=46.9m/49209280 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8818ms, sequenceid=887, compaction requested=false
2014-07-22 06:27:55,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:55,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3674 synced till here 3673
2014-07-22 06:27:55,729 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035653787 with entries=88, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035675604
2014-07-22 06:27:57,717 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:27:57,820 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3765 synced till here 3760
2014-07-22 06:27:58,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035675604 with entries=91, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035677718
2014-07-22 06:27:58,502 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:27:58,503 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.8m
2014-07-22 06:27:58,791 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:28:00,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:00,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035677718 with entries=89, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035680302
2014-07-22 06:28:07,527 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=955, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/632ab96551834f478ed1c7859441ac68
2014-07-22 06:28:07,739 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/632ab96551834f478ed1c7859441ac68 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/632ab96551834f478ed1c7859441ac68
2014-07-22 06:28:07,757 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/632ab96551834f478ed1c7859441ac68, entries=940580, sequenceid=955, filesize=67.0m
2014-07-22 06:28:07,757 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.3m/270881600, currentsize=35.4m/37128320 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9254ms, sequenceid=955, compaction requested=true
2014-07-22 06:28:07,758 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:28:07,758 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 2000 blocking
2014-07-22 06:28:07,758 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 1 permutations with 0 in ratio
2014-07-22 06:28:07,758 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-22 06:28:07,758 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. because compaction request was cancelled
2014-07-22 06:28:29,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:29,269 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035680302 with entries=89, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035709223
2014-07-22 06:28:32,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:32,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4038 synced till here 4037
2014-07-22 06:28:32,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035709223 with entries=95, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035712203
2014-07-22 06:28:34,664 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:28:34,666 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:28:35,096 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:28:35,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:35,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4125 synced till here 4124
2014-07-22 06:28:35,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035712203 with entries=87, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035715263
2014-07-22 06:28:36,913 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:28:36,913 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.4m
2014-07-22 06:28:37,264 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:28:37,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:37,346 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035715263 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035717279
2014-07-22 06:28:40,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:40,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4301 synced till here 4300
2014-07-22 06:28:40,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035717279 with entries=88, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035720924
2014-07-22 06:28:43,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:43,625 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:28:43,630 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4403 synced till here 4402
2014-07-22 06:28:43,650 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035720924 with entries=102, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035723449
2014-07-22 06:28:45,293 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:28:45,797 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1034, memsize=259.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/4e4f3b7d1fe34361826ba3874f625909
2014-07-22 06:28:45,810 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/4e4f3b7d1fe34361826ba3874f625909 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4e4f3b7d1fe34361826ba3874f625909
2014-07-22 06:28:45,822 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4e4f3b7d1fe34361826ba3874f625909, entries=945280, sequenceid=1034, filesize=67.4m
2014-07-22 06:28:45,823 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.6m/272232640, currentsize=145.9m/152995600 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 11157ms, sequenceid=1034, compaction requested=true
2014-07-22 06:28:45,823 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-22 06:28:45,823 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:28:45,823 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 433419947 starting at candidate #0 after considering 3 permutations with 2 in ratio
2014-07-22 06:28:45,823 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 266.6m
2014-07-22 06:28:45,824 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating major compaction
2014-07-22 06:28:45,824 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:28:45,824 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=413.3m
2014-07-22 06:28:45,824 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6ab0c99802847d094c3c4db9c2952c2, keycount=298090, bloomtype=ROW, size=212.1m, encoding=NONE, seqNum=531, earliestPutTs=1406035268880
2014-07-22 06:28:45,824 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6da12f6ecbc941a697e912fe2c36195d, keycount=94209, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=699, earliestPutTs=1406035465673
2014-07-22 06:28:45,824 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7b079d89a378488b9e187ce8ecf0bd49, keycount=93687, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=866, earliestPutTs=1406035558439
2014-07-22 06:28:45,824 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4e4f3b7d1fe34361826ba3874f625909, keycount=94528, bloomtype=ROW, size=67.4m, encoding=NONE, seqNum=1034, earliestPutTs=1406035649584
2014-07-22 06:28:45,940 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:28:46,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:28:46,084 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:28:46,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4496 synced till here 4494
2014-07-22 06:28:46,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035723449 with entries=93, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035726035
2014-07-22 06:28:47,592 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1055, memsize=259.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/9526edcf54bc4e6d9046715f288fa785
2014-07-22 06:28:47,661 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/9526edcf54bc4e6d9046715f288fa785 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9526edcf54bc4e6d9046715f288fa785
2014-07-22 06:28:47,683 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9526edcf54bc4e6d9046715f288fa785, entries=942870, sequenceid=1055, filesize=67.2m
2014-07-22 06:28:47,683 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.0m/271540080, currentsize=122.7m/128675120 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10770ms, sequenceid=1055, compaction requested=true
2014-07-22 06:28:47,683 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-22 06:28:47,684 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 277.7m
2014-07-22 06:28:47,882 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:28:54,563 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1123, memsize=266.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/30e97a8e8973423f9ed1795adeaf266c
2014-07-22 06:28:54,580 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/30e97a8e8973423f9ed1795adeaf266c as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30e97a8e8973423f9ed1795adeaf266c
2014-07-22 06:28:54,593 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30e97a8e8973423f9ed1795adeaf266c, entries=970660, sequenceid=1123, filesize=69.1m
2014-07-22 06:28:54,593 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~266.6m/279524320, currentsize=4.8m/5010960 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 8770ms, sequenceid=1123, compaction requested=false
2014-07-22 06:28:56,082 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1135, memsize=277.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/33f2423bbef44742b7cbd8e366447518
2014-07-22 06:28:56,095 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/33f2423bbef44742b7cbd8e366447518 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/33f2423bbef44742b7cbd8e366447518
2014-07-22 06:28:56,107 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/33f2423bbef44742b7cbd8e366447518, entries=1010940, sequenceid=1135, filesize=72.0m
2014-07-22 06:28:56,107 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~277.7m/291145520, currentsize=4.7m/4898560 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8424ms, sequenceid=1135, compaction requested=true
2014-07-22 06:28:56,108 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-22 06:29:25,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:25,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4590 synced till here 4587
2014-07-22 06:29:25,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035726035 with entries=94, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035765072
2014-07-22 06:29:25,279 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035476335
2014-07-22 06:29:25,279 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035479675
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035483034
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035508926
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035512035
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035525452
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035530184
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035558843
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035562769
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035564727
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035578251
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035581494
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035638163
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035640491
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035646454
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035651048
2014-07-22 06:29:25,280 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035653787
2014-07-22 06:29:25,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035675604
2014-07-22 06:29:25,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035677718
2014-07-22 06:29:25,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035680302
2014-07-22 06:29:25,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035709223
2014-07-22 06:29:30,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:31,102 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035765072 with entries=89, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035770854
2014-07-22 06:29:34,056 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:29:34,056 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.2m
2014-07-22 06:29:34,206 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:34,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4768 synced till here 4767
2014-07-22 06:29:34,277 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:29:34,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035770854 with entries=89, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035774207
2014-07-22 06:29:36,064 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=45362, hits=1339, hitRatio=2.95%, , cachingAccesses=1342, cachingHits=1336, cachingHitsRatio=99.55%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:29:36,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:36,420 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:29:36,421 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.2m
2014-07-22 06:29:36,803 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:29:36,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4882 synced till here 4881
2014-07-22 06:29:36,987 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035774207 with entries=114, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035776420
2014-07-22 06:29:40,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:40,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4970 synced till here 4969
2014-07-22 06:29:40,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035776420 with entries=88, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035780359
2014-07-22 06:29:43,897 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1200, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/9872a5840069450fa6bc4d2c3e6ef031
2014-07-22 06:29:43,912 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/9872a5840069450fa6bc4d2c3e6ef031 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9872a5840069450fa6bc4d2c3e6ef031
2014-07-22 06:29:43,922 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9872a5840069450fa6bc4d2c3e6ef031, entries=932780, sequenceid=1200, filesize=66.5m
2014-07-22 06:29:43,922 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.2m/268633280, currentsize=97.7m/102435920 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9866ms, sequenceid=1200, compaction requested=false
2014-07-22 06:29:45,218 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/58a5b7d841514b91b82a084d99f76a39 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/58a5b7d841514b91b82a084d99f76a39
2014-07-22 06:29:45,233 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:29:45,241 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6ab0c99802847d094c3c4db9c2952c2, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6ab0c99802847d094c3c4db9c2952c2
2014-07-22 06:29:45,243 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6da12f6ecbc941a697e912fe2c36195d, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6da12f6ecbc941a697e912fe2c36195d
2014-07-22 06:29:45,246 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7b079d89a378488b9e187ce8ecf0bd49, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7b079d89a378488b9e187ce8ecf0bd49
2014-07-22 06:29:45,249 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4e4f3b7d1fe34361826ba3874f625909, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4e4f3b7d1fe34361826ba3874f625909
2014-07-22 06:29:45,249 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into 58a5b7d841514b91b82a084d99f76a39(size=413.1m), total size for store is 479.5m. This selection was in queue for 0sec, and took 59sec to execute.
2014-07-22 06:29:45,249 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=4, fileSize=413.3m, priority=1996, time=132706214371916; duration=59sec
2014-07-22 06:29:45,249 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-22 06:29:45,249 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:29:45,250 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 215555137 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-22 06:29:45,250 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating minor compaction
2014-07-22 06:29:45,250 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:29:45,250 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=205.6m
2014-07-22 06:29:45,250 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/2acff46355ed4bc88465e9f366c1029e, keycount=93404, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=788
2014-07-22 06:29:45,250 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/632ab96551834f478ed1c7859441ac68, keycount=94058, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=955
2014-07-22 06:29:45,250 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/33f2423bbef44742b7cbd8e366447518, keycount=101094, bloomtype=ROW, size=72.0m, encoding=NONE, seqNum=1135
2014-07-22 06:29:45,279 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:29:45,684 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1222, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3066cdef10894a04bb5ad9b4c23565fd
2014-07-22 06:29:45,698 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3066cdef10894a04bb5ad9b4c23565fd as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3066cdef10894a04bb5ad9b4c23565fd
2014-07-22 06:29:45,877 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3066cdef10894a04bb5ad9b4c23565fd, entries=938310, sequenceid=1222, filesize=66.9m
2014-07-22 06:29:45,878 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.7m/270226880, currentsize=62.4m/65390800 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9457ms, sequenceid=1222, compaction requested=true
2014-07-22 06:29:45,878 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-22 06:29:47,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:47,776 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035780359 with entries=91, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035787682
2014-07-22 06:29:47,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035712203
2014-07-22 06:29:47,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035715263
2014-07-22 06:29:47,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035717279
2014-07-22 06:29:47,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035720924
2014-07-22 06:29:49,667 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:29:49,713 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035787682 with entries=89, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035789668
2014-07-22 06:29:50,929 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:29:50,929 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.2m
2014-07-22 06:29:51,115 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:29:59,170 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1301, memsize=257.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/0b6366441fc7404bb1de71e0b396d91d
2014-07-22 06:29:59,195 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/0b6366441fc7404bb1de71e0b396d91d as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0b6366441fc7404bb1de71e0b396d91d
2014-07-22 06:29:59,224 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0b6366441fc7404bb1de71e0b396d91d, entries=936520, sequenceid=1301, filesize=66.7m
2014-07-22 06:29:59,225 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.2m/269708640, currentsize=6.2m/6465440 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8296ms, sequenceid=1301, compaction requested=false
2014-07-22 06:30:10,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:10,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035789668 with entries=87, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035810660
2014-07-22 06:30:14,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:14,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5324 synced till here 5322
2014-07-22 06:30:14,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035810660 with entries=87, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035814275
2014-07-22 06:30:16,873 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/369226b83e2d44b090045de94a239f7a as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/369226b83e2d44b090045de94a239f7a
2014-07-22 06:30:16,899 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:30:16,907 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/2acff46355ed4bc88465e9f366c1029e, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/2acff46355ed4bc88465e9f366c1029e
2014-07-22 06:30:16,912 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/632ab96551834f478ed1c7859441ac68, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/632ab96551834f478ed1c7859441ac68
2014-07-22 06:30:16,920 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/33f2423bbef44742b7cbd8e366447518, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/33f2423bbef44742b7cbd8e366447518
2014-07-22 06:30:16,920 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into 369226b83e2d44b090045de94a239f7a(size=205.5m), total size for store is 520.3m. This selection was in queue for 0sec, and took 31sec to execute.
2014-07-22 06:30:16,920 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=3, fileSize=205.6m, priority=1996, time=132765640432370; duration=31sec
2014-07-22 06:30:16,921 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-22 06:30:16,921 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:30:16,921 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 210884014 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-22 06:30:16,921 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating minor compaction
2014-07-22 06:30:16,921 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:30:16,922 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=201.1m
2014-07-22 06:30:16,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4e11f3adf3684a93899c722650de802f, keycount=94093, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=887
2014-07-22 06:30:16,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9526edcf54bc4e6d9046715f288fa785, keycount=94287, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=1055
2014-07-22 06:30:16,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3066cdef10894a04bb5ad9b4c23565fd, keycount=93831, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=1222
2014-07-22 06:30:16,935 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:30:17,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:17,548 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035814275 with entries=89, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035817521
2014-07-22 06:30:19,364 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:30:19,365 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.3m
2014-07-22 06:30:19,878 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:30:21,504 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:21,542 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035817521 with entries=86, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035821504
2014-07-22 06:30:21,958 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:30:21,958 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.0m
2014-07-22 06:30:22,407 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:30:23,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:23,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5588 synced till here 5585
2014-07-22 06:30:23,785 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035821504 with entries=89, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035823670
2014-07-22 06:30:29,252 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1368, memsize=257.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/0bb6ea13421b49b49ca2c84d130e15db
2014-07-22 06:30:29,267 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/0bb6ea13421b49b49ca2c84d130e15db as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0bb6ea13421b49b49ca2c84d130e15db
2014-07-22 06:30:29,277 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0bb6ea13421b49b49ca2c84d130e15db, entries=938810, sequenceid=1368, filesize=66.9m
2014-07-22 06:30:29,277 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.8m/270369360, currentsize=71.7m/75132080 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9913ms, sequenceid=1368, compaction requested=true
2014-07-22 06:30:29,278 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-22 06:30:31,452 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1389, memsize=258.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/721a863b19ec4f0aaa2c3d78b279bb72
2014-07-22 06:30:31,471 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/721a863b19ec4f0aaa2c3d78b279bb72 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/721a863b19ec4f0aaa2c3d78b279bb72
2014-07-22 06:30:31,488 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/721a863b19ec4f0aaa2c3d78b279bb72, entries=941500, sequenceid=1389, filesize=67.1m
2014-07-22 06:30:31,489 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.6m/271143760, currentsize=35.5m/37263120 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9530ms, sequenceid=1389, compaction requested=false
2014-07-22 06:30:34,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:34,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035823670 with entries=89, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035834176
2014-07-22 06:30:37,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:37,464 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5764 synced till here 5763
2014-07-22 06:30:37,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035834176 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035837444
2014-07-22 06:30:39,173 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:30:39,174 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.0m
2014-07-22 06:30:39,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:39,489 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:30:39,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5866 synced till here 5865
2014-07-22 06:30:39,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035837444 with entries=102, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035839444
2014-07-22 06:30:41,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:30:41,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5955 synced till here 5953
2014-07-22 06:30:41,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035839444 with entries=89, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035841738
2014-07-22 06:30:48,933 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1470, memsize=259.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/01ed25b22fb9462da52d1c474f7cca9f
2014-07-22 06:30:48,955 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/01ed25b22fb9462da52d1c474f7cca9f as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/01ed25b22fb9462da52d1c474f7cca9f
2014-07-22 06:30:49,104 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/01ed25b22fb9462da52d1c474f7cca9f, entries=943540, sequenceid=1470, filesize=67.2m
2014-07-22 06:30:49,105 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.1m/271731120, currentsize=77.4m/81207200 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9931ms, sequenceid=1470, compaction requested=true
2014-07-22 06:30:49,105 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-22 06:30:50,817 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/aabd48dfd8d342f8b20b8eb2aea4a1da as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aabd48dfd8d342f8b20b8eb2aea4a1da
2014-07-22 06:30:50,839 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:30:50,848 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4e11f3adf3684a93899c722650de802f, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4e11f3adf3684a93899c722650de802f
2014-07-22 06:30:50,852 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9526edcf54bc4e6d9046715f288fa785, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9526edcf54bc4e6d9046715f288fa785
2014-07-22 06:30:50,861 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3066cdef10894a04bb5ad9b4c23565fd, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3066cdef10894a04bb5ad9b4c23565fd
2014-07-22 06:30:50,861 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into aabd48dfd8d342f8b20b8eb2aea4a1da(size=201.0m), total size for store is 555.8m. This selection was in queue for 0sec, and took 33sec to execute.
2014-07-22 06:30:50,862 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=3, fileSize=201.1m, priority=1996, time=132797311818279; duration=33sec
2014-07-22 06:30:50,862 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-22 06:30:50,862 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:30:50,862 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 616102910 starting at candidate #0 after considering 3 permutations with 2 in ratio
2014-07-22 06:30:50,862 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating major compaction
2014-07-22 06:30:50,862 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:30:50,863 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=587.6m
2014-07-22 06:30:50,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b56579cb3d9043b8845e67e56ac203cb, keycount=348785, bloomtype=ROW, size=248.1m, encoding=NONE, seqNum=621, earliestPutTs=1406035270409
2014-07-22 06:30:50,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/369226b83e2d44b090045de94a239f7a, keycount=288556, bloomtype=ROW, size=205.5m, encoding=NONE, seqNum=1135, earliestPutTs=1406035511043
2014-07-22 06:30:50,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0b6366441fc7404bb1de71e0b396d91d, keycount=93652, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=1301, earliestPutTs=1406035728868
2014-07-22 06:30:50,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/01ed25b22fb9462da52d1c474f7cca9f, keycount=94354, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=1470, earliestPutTs=1406035791215
2014-07-22 06:30:50,889 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:31:02,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:31:02,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035841738 with entries=90, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035862112
2014-07-22 06:31:03,613 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:31:03,613 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.6m
2014-07-22 06:31:03,948 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:31:04,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:31:05,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035862112 with entries=110, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035864620
2014-07-22 06:31:05,952 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:31:05,952 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.4m
2014-07-22 06:31:06,302 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:31:07,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:31:07,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6242 synced till here 6241
2014-07-22 06:31:07,900 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035864620 with entries=87, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035867870
2014-07-22 06:31:12,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:31:13,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6349 synced till here 6348
2014-07-22 06:31:13,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035867870 with entries=107, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035872352
2014-07-22 06:31:15,060 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1535, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/cc011a3a348f4a10a532a436b5840276
2014-07-22 06:31:15,073 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/cc011a3a348f4a10a532a436b5840276 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cc011a3a348f4a10a532a436b5840276
2014-07-22 06:31:15,084 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cc011a3a348f4a10a532a436b5840276, entries=939870, sequenceid=1535, filesize=66.9m
2014-07-22 06:31:15,084 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270675920, currentsize=105.6m/110729440 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 11471ms, sequenceid=1535, compaction requested=true
2014-07-22 06:31:15,084 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-22 06:31:16,113 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1558, memsize=259.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/4ea6cf36ce084ff0a57e851abe5d345b
2014-07-22 06:31:16,128 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/4ea6cf36ce084ff0a57e851abe5d345b as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4ea6cf36ce084ff0a57e851abe5d345b
2014-07-22 06:31:16,138 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4ea6cf36ce084ff0a57e851abe5d345b, entries=942920, sequenceid=1558, filesize=67.1m
2014-07-22 06:31:16,139 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.0m/271551280, currentsize=68.4m/71707440 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10186ms, sequenceid=1558, compaction requested=true
2014-07-22 06:31:16,139 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-22 06:31:37,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:31:38,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035872352 with entries=103, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035897800
2014-07-22 06:31:40,378 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:31:40,379 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.4m
2014-07-22 06:31:40,605 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:31:41,286 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:31:41,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035897800 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035901287
2014-07-22 06:31:48,299 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1637, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/a64930d3d51d4dc78f539a7eb8203c56
2014-07-22 06:31:48,318 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/a64930d3d51d4dc78f539a7eb8203c56 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a64930d3d51d4dc78f539a7eb8203c56
2014-07-22 06:31:48,332 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a64930d3d51d4dc78f539a7eb8203c56, entries=937180, sequenceid=1637, filesize=66.8m
2014-07-22 06:31:48,333 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.4m/269899280, currentsize=15.6m/16323600 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 7955ms, sequenceid=1637, compaction requested=false
2014-07-22 06:32:14,676 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/f03246c5131a4e9291f1abd54136d6e7 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03246c5131a4e9291f1abd54136d6e7
2014-07-22 06:32:14,689 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:32:14,695 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b56579cb3d9043b8845e67e56ac203cb, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b56579cb3d9043b8845e67e56ac203cb
2014-07-22 06:32:14,697 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/369226b83e2d44b090045de94a239f7a, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/369226b83e2d44b090045de94a239f7a
2014-07-22 06:32:14,776 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0b6366441fc7404bb1de71e0b396d91d, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0b6366441fc7404bb1de71e0b396d91d
2014-07-22 06:32:14,781 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/01ed25b22fb9462da52d1c474f7cca9f, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/01ed25b22fb9462da52d1c474f7cca9f
2014-07-22 06:32:14,781 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into f03246c5131a4e9291f1abd54136d6e7(size=587.4m), total size for store is 654.2m. This selection was in queue for 0sec, and took 1mins, 23sec to execute.
2014-07-22 06:32:14,782 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=4, fileSize=587.6m, priority=1996, time=132831252938669; duration=1mins, 23sec
2014-07-22 06:32:14,782 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-22 06:32:14,782 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:32:14,782 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 209999251 starting at candidate #1 after considering 3 permutations with 1 in ratio
2014-07-22 06:32:14,782 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating minor compaction
2014-07-22 06:32:14,782 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:32:14,783 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=200.3m
2014-07-22 06:32:14,783 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9872a5840069450fa6bc4d2c3e6ef031, keycount=93278, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=1200
2014-07-22 06:32:14,783 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0bb6ea13421b49b49ca2c84d130e15db, keycount=93881, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=1368
2014-07-22 06:32:14,783 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cc011a3a348f4a10a532a436b5840276, keycount=93987, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=1535
2014-07-22 06:32:14,837 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:32:14,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:14,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035901287 with entries=88, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035934854
2014-07-22 06:32:16,111 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:32:16,112 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.1m
2014-07-22 06:32:16,559 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:32:16,702 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:16,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6725 synced till here 6723
2014-07-22 06:32:16,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035934854 with entries=98, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035936703
2014-07-22 06:32:17,584 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:32:17,584 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.1m
2014-07-22 06:32:17,822 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:32:18,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:18,926 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035936703 with entries=88, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035938896
2014-07-22 06:32:19,882 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:32:21,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:21,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6921 synced till here 6916
2014-07-22 06:32:22,026 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035938896 with entries=108, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035941454
2014-07-22 06:32:27,062 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1672, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/30b688e734e14bd7a34cf50a88d1b282
2014-07-22 06:32:27,086 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/30b688e734e14bd7a34cf50a88d1b282 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30b688e734e14bd7a34cf50a88d1b282
2014-07-22 06:32:27,106 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30b688e734e14bd7a34cf50a88d1b282, entries=932600, sequenceid=1672, filesize=66.4m
2014-07-22 06:32:27,107 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268564080, currentsize=36.5m/38320480 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10995ms, sequenceid=1672, compaction requested=true
2014-07-22 06:32:27,107 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-22 06:32:27,107 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 309.9m
2014-07-22 06:32:27,280 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:32:27,673 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1701, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7428030c92d84efdb002b43166d70d98
2014-07-22 06:32:27,686 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7428030c92d84efdb002b43166d70d98 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7428030c92d84efdb002b43166d70d98
2014-07-22 06:32:27,696 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7428030c92d84efdb002b43166d70d98, entries=932490, sequenceid=1701, filesize=66.4m
2014-07-22 06:32:27,696 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.1m/268549360, currentsize=90.3m/94717760 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10112ms, sequenceid=1701, compaction requested=false
2014-07-22 06:32:31,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:31,533 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035941454 with entries=89, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035951502
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035723449
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035726035
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035765072
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035770854
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035774207
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035776420
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035780359
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035787682
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035789668
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035810660
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035814275
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035817521
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035821504
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035823670
2014-07-22 06:32:31,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035834176
2014-07-22 06:32:31,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035837444
2014-07-22 06:32:31,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035839444
2014-07-22 06:32:31,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035841738
2014-07-22 06:32:31,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035862112
2014-07-22 06:32:33,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:33,652 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7106 synced till here 7105
2014-07-22 06:32:33,666 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035951502 with entries=96, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035953399
2014-07-22 06:32:35,089 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:32:35,090 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.7m
2014-07-22 06:32:35,370 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:32:35,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:32:35,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035953399 with entries=88, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035955595
2014-07-22 06:32:38,466 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1758, memsize=309.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/12273d344c8b4ecca177f79e93303456
2014-07-22 06:32:38,490 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/12273d344c8b4ecca177f79e93303456 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/12273d344c8b4ecca177f79e93303456
2014-07-22 06:32:38,512 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/12273d344c8b4ecca177f79e93303456, entries=1128280, sequenceid=1758, filesize=80.4m
2014-07-22 06:32:38,512 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~309.9m/324934880, currentsize=93.1m/97609840 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 11405ms, sequenceid=1758, compaction requested=true
2014-07-22 06:32:38,513 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-22 06:32:43,488 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1805, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b0afe7c65e084af9b0f4ef42bc6deaa4
2014-07-22 06:32:43,502 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b0afe7c65e084af9b0f4ef42bc6deaa4 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b0afe7c65e084af9b0f4ef42bc6deaa4
2014-07-22 06:32:43,562 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b0afe7c65e084af9b0f4ef42bc6deaa4, entries=940470, sequenceid=1805, filesize=67.0m
2014-07-22 06:32:43,562 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.3m/270847600, currentsize=23.3m/24407680 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8472ms, sequenceid=1805, compaction requested=true
2014-07-22 06:32:43,562 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-22 06:32:46,333 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/d686e1db60a74a5e8a995b4fe68ae2ef as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/d686e1db60a74a5e8a995b4fe68ae2ef
2014-07-22 06:32:46,346 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:32:46,355 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9872a5840069450fa6bc4d2c3e6ef031, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9872a5840069450fa6bc4d2c3e6ef031
2014-07-22 06:32:46,362 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0bb6ea13421b49b49ca2c84d130e15db, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0bb6ea13421b49b49ca2c84d130e15db
2014-07-22 06:32:46,370 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cc011a3a348f4a10a532a436b5840276, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cc011a3a348f4a10a532a436b5840276
2014-07-22 06:32:46,370 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into d686e1db60a74a5e8a995b4fe68ae2ef(size=200.2m), total size for store is 679.7m. This selection was in queue for 0sec, and took 31sec to execute.
2014-07-22 06:32:46,370 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=3, fileSize=200.3m, priority=1996, time=132915172997389; duration=31sec
2014-07-22 06:32:46,370 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-22 06:32:46,371 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 2000 blocking
2014-07-22 06:32:46,371 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 737434436 starting at candidate #0 after considering 6 permutations with 5 in ratio
2014-07-22 06:32:46,371 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating major compaction
2014-07-22 06:32:46,371 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:32:46,371 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=703.3m
2014-07-22 06:32:46,371 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/eb1047791abf4576931cc1689dccf7e5, keycount=404283, bloomtype=ROW, size=287.6m, encoding=NONE, seqNum=719, earliestPutTs=1406035269695
2014-07-22 06:32:46,372 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aabd48dfd8d342f8b20b8eb2aea4a1da, keycount=282211, bloomtype=ROW, size=201.0m, encoding=NONE, seqNum=1222, earliestPutTs=1406035562376
2014-07-22 06:32:46,372 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/721a863b19ec4f0aaa2c3d78b279bb72, keycount=94150, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=1389, earliestPutTs=1406035776431
2014-07-22 06:32:46,372 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4ea6cf36ce084ff0a57e851abe5d345b, keycount=94292, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=1558, earliestPutTs=1406035821976
2014-07-22 06:32:46,372 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/12273d344c8b4ecca177f79e93303456, keycount=112828, bloomtype=ROW, size=80.4m, encoding=NONE, seqNum=1758, earliestPutTs=1406035866035
2014-07-22 06:32:46,419 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:33:17,689 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:17,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7283 synced till here 7282
2014-07-22 06:33:17,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035955595 with entries=89, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035997689
2014-07-22 06:33:17,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035864620
2014-07-22 06:33:17,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035867870
2014-07-22 06:33:17,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035872352
2014-07-22 06:33:17,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035897800
2014-07-22 06:33:17,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035901287
2014-07-22 06:33:19,752 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:19,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7370 synced till here 7368
2014-07-22 06:33:19,784 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035997689 with entries=87, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035999752
2014-07-22 06:33:20,627 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:33:20,628 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.7m
2014-07-22 06:33:20,872 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:33:21,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:21,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7461 synced till here 7458
2014-07-22 06:33:21,706 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035999752 with entries=91, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036001630
2014-07-22 06:33:26,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:26,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036001630 with entries=91, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036006463
2014-07-22 06:33:29,669 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1868, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/fabdaf4e06c14e04b63ba273a8125fb0
2014-07-22 06:33:29,681 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/fabdaf4e06c14e04b63ba273a8125fb0 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/fabdaf4e06c14e04b63ba273a8125fb0
2014-07-22 06:33:29,690 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/fabdaf4e06c14e04b63ba273a8125fb0, entries=934620, sequenceid=1868, filesize=66.6m
2014-07-22 06:33:29,690 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269161680, currentsize=51.4m/53947040 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9062ms, sequenceid=1868, compaction requested=true
2014-07-22 06:33:29,690 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-22 06:33:33,543 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:33,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7639 synced till here 7638
2014-07-22 06:33:33,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036006463 with entries=87, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036013543
2014-07-22 06:33:34,007 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:33:34,007 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.3m
2014-07-22 06:33:34,268 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:33:41,850 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1924, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/0dd5a0be17874cc88fa10d2c480372ac
2014-07-22 06:33:41,881 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/0dd5a0be17874cc88fa10d2c480372ac as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/0dd5a0be17874cc88fa10d2c480372ac
2014-07-22 06:33:41,900 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/0dd5a0be17874cc88fa10d2c480372ac, entries=933210, sequenceid=1924, filesize=66.5m
2014-07-22 06:33:41,900 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268758320, currentsize=9.4m/9852240 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 7893ms, sequenceid=1924, compaction requested=false
2014-07-22 06:33:52,760 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:52,946 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036013543 with entries=96, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036032761
2014-07-22 06:33:55,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:55,615 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7825 synced till here 7824
2014-07-22 06:33:55,713 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036032761 with entries=90, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036035582
2014-07-22 06:33:55,896 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:33:55,896 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.2m
2014-07-22 06:33:56,200 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:33:59,775 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:33:59,793 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7915 synced till here 7913
2014-07-22 06:33:59,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036035582 with entries=90, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036039776
2014-07-22 06:34:05,199 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1972, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/505b94b3549a47768bbf76f7abe39455
2014-07-22 06:34:05,252 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/505b94b3549a47768bbf76f7abe39455 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/505b94b3549a47768bbf76f7abe39455
2014-07-22 06:34:05,280 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/505b94b3549a47768bbf76f7abe39455, entries=938420, sequenceid=1972, filesize=66.9m
2014-07-22 06:34:05,281 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270260000, currentsize=54.5m/57195200 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9384ms, sequenceid=1972, compaction requested=true
2014-07-22 06:34:05,281 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-22 06:34:06,869 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:34:07,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036039776 with entries=98, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036046870
2014-07-22 06:34:17,195 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:34:17,196 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 257.5m
2014-07-22 06:34:17,433 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:34:18,331 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:34:18,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036046870 with entries=90, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036058331
2014-07-22 06:34:20,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:34:20,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8192 synced till here 8190
2014-07-22 06:34:20,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036058331 with entries=89, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036060516
2014-07-22 06:34:26,245 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2035, memsize=257.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/b9596934ec0941d2903bd7c020cfba16
2014-07-22 06:34:26,271 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/b9596934ec0941d2903bd7c020cfba16 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b9596934ec0941d2903bd7c020cfba16
2014-07-22 06:34:26,302 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b9596934ec0941d2903bd7c020cfba16, entries=937530, sequenceid=2035, filesize=66.8m
2014-07-22 06:34:26,303 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.5m/270001680, currentsize=69.9m/73311840 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9107ms, sequenceid=2035, compaction requested=true
2014-07-22 06:34:26,303 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-22 06:34:28,034 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/aaa11ac208e84af09cee264ac5e4c3df as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aaa11ac208e84af09cee264ac5e4c3df
2014-07-22 06:34:28,049 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:34:28,067 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/eb1047791abf4576931cc1689dccf7e5, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/eb1047791abf4576931cc1689dccf7e5
2014-07-22 06:34:28,076 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aabd48dfd8d342f8b20b8eb2aea4a1da, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aabd48dfd8d342f8b20b8eb2aea4a1da
2014-07-22 06:34:28,081 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/721a863b19ec4f0aaa2c3d78b279bb72, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/721a863b19ec4f0aaa2c3d78b279bb72
2014-07-22 06:34:28,086 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4ea6cf36ce084ff0a57e851abe5d345b, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4ea6cf36ce084ff0a57e851abe5d345b
2014-07-22 06:34:28,088 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/12273d344c8b4ecca177f79e93303456, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/12273d344c8b4ecca177f79e93303456
2014-07-22 06:34:28,088 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into aaa11ac208e84af09cee264ac5e4c3df(size=703.1m), total size for store is 769.6m. This selection was in queue for 0sec, and took 1mins, 41sec to execute.
2014-07-22 06:34:28,088 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=5, fileSize=703.3m, priority=1995, time=132946761753576; duration=1mins, 41sec
2014-07-22 06:34:28,089 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-22 06:34:28,089 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 2000 blocking
2014-07-22 06:34:28,089 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 852706169 starting at candidate #0 after considering 6 permutations with 3 in ratio
2014-07-22 06:34:28,089 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating major compaction
2014-07-22 06:34:28,089 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:34:28,090 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=813.2m
2014-07-22 06:34:28,090 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/58a5b7d841514b91b82a084d99f76a39, keycount=580514, bloomtype=ROW, size=413.1m, encoding=NONE, seqNum=1034, earliestPutTs=1406035268880
2014-07-22 06:34:28,090 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/d686e1db60a74a5e8a995b4fe68ae2ef, keycount=281146, bloomtype=ROW, size=200.2m, encoding=NONE, seqNum=1535, earliestPutTs=1406035714701
2014-07-22 06:34:28,090 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7428030c92d84efdb002b43166d70d98, keycount=93249, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=1701, earliestPutTs=1406035863668
2014-07-22 06:34:28,090 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/fabdaf4e06c14e04b63ba273a8125fb0, keycount=93462, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=1868, earliestPutTs=1406035937615
2014-07-22 06:34:28,090 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b9596934ec0941d2903bd7c020cfba16, keycount=93753, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=2035, earliestPutTs=1406036000640
2014-07-22 06:34:28,113 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:34:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=113225, hits=2053, hitRatio=1.81%, , cachingAccesses=2056, cachingHits=2050, cachingHitsRatio=99.70%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:34:46,719 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:34:46,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036060516 with entries=90, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036086719
2014-07-22 06:34:48,546 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:34:48,547 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.3m
2014-07-22 06:34:48,698 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:34:50,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:34:50,316 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8371 synced till here 8369
2014-07-22 06:34:50,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036086719 with entries=89, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036090266
2014-07-22 06:34:56,916 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2092, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f1f563f21b424222be9daf42ecbe8b79
2014-07-22 06:34:56,958 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f1f563f21b424222be9daf42ecbe8b79 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f1f563f21b424222be9daf42ecbe8b79
2014-07-22 06:34:56,979 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f1f563f21b424222be9daf42ecbe8b79, entries=936860, sequenceid=2092, filesize=66.8m
2014-07-22 06:34:56,980 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269808240, currentsize=40.7m/42631520 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8432ms, sequenceid=2092, compaction requested=true
2014-07-22 06:34:56,980 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-22 06:35:00,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:00,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8460 synced till here 8459
2014-07-22 06:35:00,352 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036090266 with entries=89, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036100321
2014-07-22 06:35:01,444 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:35:01,445 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.6m
2014-07-22 06:35:01,903 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:35:02,268 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:02,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8550 synced till here 8549
2014-07-22 06:35:02,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036100321 with entries=90, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036102269
2014-07-22 06:35:04,122 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:04,139 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8639 synced till here 8637
2014-07-22 06:35:04,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036102269 with entries=89, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036104122
2014-07-22 06:35:10,862 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2141, memsize=261.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/71cd6c6578a4487f96caee75274414e3
2014-07-22 06:35:10,882 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/71cd6c6578a4487f96caee75274414e3 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/71cd6c6578a4487f96caee75274414e3
2014-07-22 06:35:10,907 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/71cd6c6578a4487f96caee75274414e3, entries=951220, sequenceid=2141, filesize=67.8m
2014-07-22 06:35:10,907 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.3m/273945040, currentsize=56.1m/58873840 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9462ms, sequenceid=2141, compaction requested=true
2014-07-22 06:35:10,907 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-22 06:35:34,640 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:34,670 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8727 synced till here 8726
2014-07-22 06:35:34,779 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036104122 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036134640
2014-07-22 06:35:34,982 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:35:34,983 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.7m
2014-07-22 06:35:35,324 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:35:39,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:39,302 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036134640 with entries=88, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036139277
2014-07-22 06:35:40,701 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:35:40,701 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.4m
2014-07-22 06:35:41,019 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:41,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8904 synced till here 8903
2014-07-22 06:35:41,061 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:35:41,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036139277 with entries=89, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036141019
2014-07-22 06:35:42,529 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:35:43,033 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:43,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8994 synced till here 8993
2014-07-22 06:35:43,090 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036141019 with entries=90, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036143033
2014-07-22 06:35:45,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:35:45,092 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9084 synced till here 9082
2014-07-22 06:35:45,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036143033 with entries=90, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036145030
2014-07-22 06:35:46,220 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2202, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/137b8eecc3ad4f5e80bad749de1f329b
2014-07-22 06:35:46,236 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/137b8eecc3ad4f5e80bad749de1f329b as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/137b8eecc3ad4f5e80bad749de1f329b
2014-07-22 06:35:46,252 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/137b8eecc3ad4f5e80bad749de1f329b, entries=940380, sequenceid=2202, filesize=67.0m
2014-07-22 06:35:46,253 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.3m/270822560, currentsize=145.9m/153023760 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 11270ms, sequenceid=2202, compaction requested=false
2014-07-22 06:35:46,253 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 313.0m
2014-07-22 06:35:46,447 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:35:50,776 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2222, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/1a3868de3c9c47cdaba4fe11f96abd80
2014-07-22 06:35:50,796 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/1a3868de3c9c47cdaba4fe11f96abd80 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/1a3868de3c9c47cdaba4fe11f96abd80
2014-07-22 06:35:50,811 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/1a3868de3c9c47cdaba4fe11f96abd80, entries=935360, sequenceid=2222, filesize=66.7m
2014-07-22 06:35:50,812 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.9m/269358960, currentsize=33.3m/34875760 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10111ms, sequenceid=2222, compaction requested=true
2014-07-22 06:35:50,812 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-22 06:35:55,838 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2295, memsize=314.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/d74b51bd25e8459886b82943aba34b8e
2014-07-22 06:35:55,870 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/d74b51bd25e8459886b82943aba34b8e as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/d74b51bd25e8459886b82943aba34b8e
2014-07-22 06:35:55,895 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/d74b51bd25e8459886b82943aba34b8e, entries=1145230, sequenceid=2295, filesize=81.6m
2014-07-22 06:35:55,895 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~314.5m/329817600, currentsize=13.8m/14494320 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9642ms, sequenceid=2295, compaction requested=true
2014-07-22 06:35:55,896 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-22 06:36:03,045 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:03,053 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:36:03,053 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.8m
2014-07-22 06:36:03,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9174 synced till here 9173
2014-07-22 06:36:03,077 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036145030 with entries=90, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036163045
2014-07-22 06:36:03,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035934854
2014-07-22 06:36:03,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035936703
2014-07-22 06:36:03,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035938896
2014-07-22 06:36:03,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035941454
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035951502
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035953399
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035955595
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035997689
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406035999752
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036001630
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036006463
2014-07-22 06:36:03,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036013543
2014-07-22 06:36:03,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036032761
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036035582
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036039776
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036046870
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036058331
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036060516
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036086719
2014-07-22 06:36:03,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036090266
2014-07-22 06:36:03,297 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:36:05,764 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:05,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9269 synced till here 9268
2014-07-22 06:36:06,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036163045 with entries=95, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036165765
2014-07-22 06:36:12,190 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2308, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/34a4d41f15684ee38e11561b25d174e3
2014-07-22 06:36:12,213 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/34a4d41f15684ee38e11561b25d174e3 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/34a4d41f15684ee38e11561b25d174e3
2014-07-22 06:36:12,227 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/34a4d41f15684ee38e11561b25d174e3, entries=940480, sequenceid=2308, filesize=67.0m
2014-07-22 06:36:12,228 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.3m/270849040, currentsize=69.6m/73008640 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9175ms, sequenceid=2308, compaction requested=true
2014-07-22 06:36:12,228 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-22 06:36:14,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:14,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036165765 with entries=88, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036174772
2014-07-22 06:36:14,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036100321
2014-07-22 06:36:14,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036102269
2014-07-22 06:36:14,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036104122
2014-07-22 06:36:23,136 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/c34badbb0973457db38551c5c56578a7 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c34badbb0973457db38551c5c56578a7
2014-07-22 06:36:23,180 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:36:23,196 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/58a5b7d841514b91b82a084d99f76a39, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/58a5b7d841514b91b82a084d99f76a39
2014-07-22 06:36:23,198 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/d686e1db60a74a5e8a995b4fe68ae2ef, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/d686e1db60a74a5e8a995b4fe68ae2ef
2014-07-22 06:36:23,201 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7428030c92d84efdb002b43166d70d98, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7428030c92d84efdb002b43166d70d98
2014-07-22 06:36:23,204 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/fabdaf4e06c14e04b63ba273a8125fb0, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/fabdaf4e06c14e04b63ba273a8125fb0
2014-07-22 06:36:23,211 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b9596934ec0941d2903bd7c020cfba16, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b9596934ec0941d2903bd7c020cfba16
2014-07-22 06:36:23,211 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into c34badbb0973457db38551c5c56578a7(size=813.0m), total size for store is 880.0m. This selection was in queue for 0sec, and took 1mins, 55sec to execute.
2014-07-22 06:36:23,212 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=5, fileSize=813.2m, priority=1995, time=133048480038821; duration=1mins, 55sec
2014-07-22 06:36:23,212 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-22 06:36:23,212 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 2000 blocking
2014-07-22 06:36:23,213 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 351778008 starting at candidate #1 after considering 10 permutations with 6 in ratio
2014-07-22 06:36:23,213 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating minor compaction
2014-07-22 06:36:23,213 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:36:23,214 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=335.5m
2014-07-22 06:36:23,214 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a64930d3d51d4dc78f539a7eb8203c56, keycount=93718, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=1637
2014-07-22 06:36:23,214 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b0afe7c65e084af9b0f4ef42bc6deaa4, keycount=94047, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=1805
2014-07-22 06:36:23,214 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/505b94b3549a47768bbf76f7abe39455, keycount=93842, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=1972
2014-07-22 06:36:23,215 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/71cd6c6578a4487f96caee75274414e3, keycount=95122, bloomtype=ROW, size=67.8m, encoding=NONE, seqNum=2141
2014-07-22 06:36:23,215 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/34a4d41f15684ee38e11561b25d174e3, keycount=94048, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=2308
2014-07-22 06:36:23,247 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:36:27,384 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:36:27,385 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.3m
2014-07-22 06:36:27,544 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:36:28,703 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:28,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9452 synced till here 9449
2014-07-22 06:36:28,924 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036174772 with entries=95, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036188704
2014-07-22 06:36:30,757 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:30,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9544 synced till here 9539
2014-07-22 06:36:30,890 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036188704 with entries=92, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036190758
2014-07-22 06:36:32,816 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:32,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9632 synced till here 9631
2014-07-22 06:36:32,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036190758 with entries=88, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036192817
2014-07-22 06:36:37,476 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2370, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/0e45f810af4546f8bd6b87c06d2cc874
2014-07-22 06:36:37,496 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/0e45f810af4546f8bd6b87c06d2cc874 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0e45f810af4546f8bd6b87c06d2cc874
2014-07-22 06:36:37,519 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0e45f810af4546f8bd6b87c06d2cc874, entries=938960, sequenceid=2370, filesize=66.9m
2014-07-22 06:36:37,519 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.9m/270412720, currentsize=100.2m/105085920 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10135ms, sequenceid=2370, compaction requested=true
2014-07-22 06:36:37,519 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-22 06:36:53,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:53,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036192817 with entries=88, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036213233
2014-07-22 06:36:53,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036134640
2014-07-22 06:36:56,027 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:36:56,027 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.5m
2014-07-22 06:36:56,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:36:56,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9808 synced till here 9805
2014-07-22 06:36:56,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036213233 with entries=88, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036216326
2014-07-22 06:36:56,471 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:36:56,983 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:36:56,983 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.3m
2014-07-22 06:36:57,300 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:37:04,336 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2463, memsize=259.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/70674ba77a2e429f88cc28674fdc0cef
2014-07-22 06:37:04,357 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/70674ba77a2e429f88cc28674fdc0cef as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/70674ba77a2e429f88cc28674fdc0cef
2014-07-22 06:37:04,402 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/70674ba77a2e429f88cc28674fdc0cef, entries=943280, sequenceid=2463, filesize=67.2m
2014-07-22 06:37:04,402 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.1m/271655360, currentsize=37.5m/39368560 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8375ms, sequenceid=2463, compaction requested=true
2014-07-22 06:37:04,402 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-22 06:37:05,166 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2475, memsize=257.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/7b76a9b44f244df595e604d5e8558e28
2014-07-22 06:37:05,183 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/7b76a9b44f244df595e604d5e8558e28 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b76a9b44f244df595e604d5e8558e28
2014-07-22 06:37:05,428 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b76a9b44f244df595e604d5e8558e28, entries=938640, sequenceid=2475, filesize=66.9m
2014-07-22 06:37:05,429 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.8m/270319440, currentsize=20.2m/21190400 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8446ms, sequenceid=2475, compaction requested=false
2014-07-22 06:37:05,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:05,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036216326 with entries=87, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036225633
2014-07-22 06:37:11,998 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/dbb0a2efcc524fd08b6b6e104d1bfeaa as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dbb0a2efcc524fd08b6b6e104d1bfeaa
2014-07-22 06:37:12,023 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:37:12,045 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a64930d3d51d4dc78f539a7eb8203c56, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a64930d3d51d4dc78f539a7eb8203c56
2014-07-22 06:37:12,049 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b0afe7c65e084af9b0f4ef42bc6deaa4, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b0afe7c65e084af9b0f4ef42bc6deaa4
2014-07-22 06:37:12,053 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/505b94b3549a47768bbf76f7abe39455, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/505b94b3549a47768bbf76f7abe39455
2014-07-22 06:37:12,061 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/71cd6c6578a4487f96caee75274414e3, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/71cd6c6578a4487f96caee75274414e3
2014-07-22 06:37:12,067 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/34a4d41f15684ee38e11561b25d174e3, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/34a4d41f15684ee38e11561b25d174e3
2014-07-22 06:37:12,067 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 5 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into dbb0a2efcc524fd08b6b6e104d1bfeaa(size=335.3m), total size for store is 989.6m. This selection was in queue for 0sec, and took 48sec to execute.
2014-07-22 06:37:12,067 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=5, fileSize=335.5m, priority=1994, time=133163603725542; duration=48sec
2014-07-22 06:37:12,068 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-22 06:37:12,068 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 2000 blocking
2014-07-22 06:37:12,068 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 295725820 starting at candidate #1 after considering 6 permutations with 3 in ratio
2014-07-22 06:37:12,068 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating minor compaction
2014-07-22 06:37:12,069 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:37:12,069 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=282.0m
2014-07-22 06:37:12,069 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/0dd5a0be17874cc88fa10d2c480372ac, keycount=93321, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=1924
2014-07-22 06:37:12,069 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f1f563f21b424222be9daf42ecbe8b79, keycount=93686, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=2092
2014-07-22 06:37:12,069 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/d74b51bd25e8459886b82943aba34b8e, keycount=114523, bloomtype=ROW, size=81.6m, encoding=NONE, seqNum=2295
2014-07-22 06:37:12,069 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/70674ba77a2e429f88cc28674fdc0cef, keycount=94328, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=2463
2014-07-22 06:37:12,091 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:37:21,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:21,408 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9986 synced till here 9982
2014-07-22 06:37:21,490 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036225633 with entries=91, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036241265
2014-07-22 06:37:31,257 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:37:31,258 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:37:31,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:31,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10075 synced till here 10074
2014-07-22 06:37:31,469 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036241265 with entries=89, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036251433
2014-07-22 06:37:31,625 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:37:33,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:33,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10165 synced till here 10161
2014-07-22 06:37:33,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036251433 with entries=90, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036253279
2014-07-22 06:37:35,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:35,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10252 synced till here 10251
2014-07-22 06:37:35,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036253279 with entries=87, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036255293
2014-07-22 06:37:37,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:37,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10342 synced till here 10341
2014-07-22 06:37:37,645 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036255293 with entries=90, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036257554
2014-07-22 06:37:41,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:41,511 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036257554 with entries=87, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036261485
2014-07-22 06:37:42,363 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:37:42,364 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.5m
2014-07-22 06:37:42,733 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:37:43,731 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2537, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/0b9fc05993b5446eb153ab91056a5310
2014-07-22 06:37:43,745 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/0b9fc05993b5446eb153ab91056a5310 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0b9fc05993b5446eb153ab91056a5310
2014-07-22 06:37:43,758 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0b9fc05993b5446eb153ab91056a5310, entries=939520, sequenceid=2537, filesize=67.0m
2014-07-22 06:37:43,759 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.0m/270575120, currentsize=164.6m/172602560 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 12501ms, sequenceid=2537, compaction requested=true
2014-07-22 06:37:43,759 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-22 06:37:43,859 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:37:43,860 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.7m
2014-07-22 06:37:44,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:44,373 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:37:44,374 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10521 synced till here 10518
2014-07-22 06:37:44,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036261485 with entries=92, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036264252
2014-07-22 06:37:47,070 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:47,098 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10611 synced till here 10609
2014-07-22 06:37:47,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036264252 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036267070
2014-07-22 06:37:49,114 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:49,249 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10706 synced till here 10702
2014-07-22 06:37:49,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036267070 with entries=95, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036269114
2014-07-22 06:37:49,849 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:37:51,752 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:37:51,772 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10795 synced till here 10793
2014-07-22 06:37:51,789 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036269114 with entries=89, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036271753
2014-07-22 06:37:55,206 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2630, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/ea6a456ca43a4c4d9079d4020faffcac
2014-07-22 06:37:55,229 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/ea6a456ca43a4c4d9079d4020faffcac as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ea6a456ca43a4c4d9079d4020faffcac
2014-07-22 06:37:55,255 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ea6a456ca43a4c4d9079d4020faffcac, entries=939730, sequenceid=2630, filesize=67.0m
2014-07-22 06:37:55,256 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270635120, currentsize=144.4m/151432960 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 12893ms, sequenceid=2630, compaction requested=false
2014-07-22 06:37:55,256 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 291.9m
2014-07-22 06:37:55,450 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:37:56,317 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2643, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/642d28c4d31047c0a93da5be3000f089
2014-07-22 06:37:56,343 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/642d28c4d31047c0a93da5be3000f089 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/642d28c4d31047c0a93da5be3000f089
2014-07-22 06:37:56,360 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/642d28c4d31047c0a93da5be3000f089, entries=940610, sequenceid=2643, filesize=67.0m
2014-07-22 06:37:56,361 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.3m/270887600, currentsize=127.2m/133415520 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 12501ms, sequenceid=2643, compaction requested=true
2014-07-22 06:37:56,361 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-22 06:38:00,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:38:00,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10885 synced till here 10883
2014-07-22 06:38:00,840 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036271753 with entries=90, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036280694
2014-07-22 06:38:01,338 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/b27daa587548446d868b35cb03f0528b as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b27daa587548446d868b35cb03f0528b
2014-07-22 06:38:01,484 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:38:01,492 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/0dd5a0be17874cc88fa10d2c480372ac, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/0dd5a0be17874cc88fa10d2c480372ac
2014-07-22 06:38:01,494 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f1f563f21b424222be9daf42ecbe8b79, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f1f563f21b424222be9daf42ecbe8b79
2014-07-22 06:38:01,500 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/d74b51bd25e8459886b82943aba34b8e, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/d74b51bd25e8459886b82943aba34b8e
2014-07-22 06:38:01,502 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/70674ba77a2e429f88cc28674fdc0cef, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/70674ba77a2e429f88cc28674fdc0cef
2014-07-22 06:38:01,503 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into b27daa587548446d868b35cb03f0528b(size=282.0m), total size for store is 1.0g. This selection was in queue for 0sec, and took 49sec to execute.
2014-07-22 06:38:01,503 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=4, fileSize=282.0m, priority=1995, time=133212459049485; duration=49sec
2014-07-22 06:38:01,503 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-22 06:38:01,503 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:38:01,503 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 3 permutations with 0 in ratio
2014-07-22 06:38:01,503 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-22 06:38:01,504 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Not compacting usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. because compaction request was cancelled
2014-07-22 06:38:01,504 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 2000 blocking
2014-07-22 06:38:01,504 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 281948641 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-22 06:38:01,504 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: a1bcd7cee994fe8eb603588f61ee109e - family: Initiating major compaction
2014-07-22 06:38:01,504 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:38:01,504 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp, totalSize=268.9m
2014-07-22 06:38:01,504 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3ce5be53f6f3495f9df46b407eec410a, keycount=93694, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=552, earliestPutTs=1406035270536
2014-07-22 06:38:01,505 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30e97a8e8973423f9ed1795adeaf266c, keycount=97066, bloomtype=ROW, size=69.1m, encoding=NONE, seqNum=1123, earliestPutTs=1406035479167
2014-07-22 06:38:01,505 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30b688e734e14bd7a34cf50a88d1b282, keycount=93260, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=1672, earliestPutTs=1406035726025
2014-07-22 06:38:01,505 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/1a3868de3c9c47cdaba4fe11f96abd80, keycount=93536, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=2222, earliestPutTs=1406035936242
2014-07-22 06:38:01,614 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:38:02,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:38:02,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036280694 with entries=91, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036282760
2014-07-22 06:38:06,065 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2726, memsize=291.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/eca0523ee5a84a6ab89a873045905a3b
2014-07-22 06:38:06,092 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/eca0523ee5a84a6ab89a873045905a3b as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/eca0523ee5a84a6ab89a873045905a3b
2014-07-22 06:38:06,117 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/eca0523ee5a84a6ab89a873045905a3b, entries=1062660, sequenceid=2726, filesize=75.7m
2014-07-22 06:38:06,117 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~291.9m/306037200, currentsize=67.1m/70396400 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10861ms, sequenceid=2726, compaction requested=true
2014-07-22 06:38:06,117 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-22 06:38:29,771 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:38:29,797 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036282760 with entries=88, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036309772
2014-07-22 06:38:30,243 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:38:30,243 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.4m
2014-07-22 06:38:30,518 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:38:37,800 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/fdf38541936c4a42937a072f45a0569d as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/fdf38541936c4a42937a072f45a0569d
2014-07-22 06:38:37,832 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:38:37,844 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3ce5be53f6f3495f9df46b407eec410a, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3ce5be53f6f3495f9df46b407eec410a
2014-07-22 06:38:37,848 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30e97a8e8973423f9ed1795adeaf266c, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30e97a8e8973423f9ed1795adeaf266c
2014-07-22 06:38:37,851 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30b688e734e14bd7a34cf50a88d1b282, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/30b688e734e14bd7a34cf50a88d1b282
2014-07-22 06:38:37,862 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/1a3868de3c9c47cdaba4fe11f96abd80, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/1a3868de3c9c47cdaba4fe11f96abd80
2014-07-22 06:38:37,862 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. into fdf38541936c4a42937a072f45a0569d(size=268.8m), total size for store is 268.8m. This selection was in queue for 0sec, and took 36sec to execute.
2014-07-22 06:38:37,862 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., storeName=family, fileCount=4, fileSize=268.9m, priority=1996, time=133261894644167; duration=36sec
2014-07-22 06:38:37,862 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-22 06:38:37,862 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 2000 blocking
2014-07-22 06:38:37,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 290074184 starting at candidate #1 after considering 6 permutations with 3 in ratio
2014-07-22 06:38:37,863 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating minor compaction
2014-07-22 06:38:37,863 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:38:37,863 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=276.6m
2014-07-22 06:38:37,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/137b8eecc3ad4f5e80bad749de1f329b, keycount=94038, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=2202
2014-07-22 06:38:37,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0e45f810af4546f8bd6b87c06d2cc874, keycount=93896, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=2370
2014-07-22 06:38:37,863 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0b9fc05993b5446eb153ab91056a5310, keycount=93952, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=2537
2014-07-22 06:38:37,864 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/eca0523ee5a84a6ab89a873045905a3b, keycount=106266, bloomtype=ROW, size=75.7m, encoding=NONE, seqNum=2726
2014-07-22 06:38:37,878 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:38:38,299 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2772, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/667d406c8e1e4e089001843b7c25742e
2014-07-22 06:38:38,312 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/667d406c8e1e4e089001843b7c25742e as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/667d406c8e1e4e089001843b7c25742e
2014-07-22 06:38:38,323 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/667d406c8e1e4e089001843b7c25742e, entries=935020, sequenceid=2772, filesize=66.6m
2014-07-22 06:38:38,323 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.8m/269259360, currentsize=1.9m/1978320 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 8080ms, sequenceid=2772, compaction requested=false
2014-07-22 06:38:51,083 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:38:51,084 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.4m
2014-07-22 06:38:51,221 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:38:52,268 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:38:52,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11155 synced till here 11154
2014-07-22 06:38:52,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036309772 with entries=91, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036332269
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036139277
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036141019
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036143033
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036145030
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036163045
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036165765
2014-07-22 06:38:52,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036174772
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036188704
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036190758
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036192817
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036213233
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036216326
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036225633
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036241265
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036251433
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036253279
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036255293
2014-07-22 06:38:52,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036257554
2014-07-22 06:38:52,661 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:38:52,661 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.0m
2014-07-22 06:38:52,849 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:38:59,639 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2797, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/a49a4970cf4f4b16882131409568d4f8
2014-07-22 06:38:59,656 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/a49a4970cf4f4b16882131409568d4f8 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/a49a4970cf4f4b16882131409568d4f8
2014-07-22 06:38:59,703 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/a49a4970cf4f4b16882131409568d4f8, entries=933410, sequenceid=2797, filesize=66.5m
2014-07-22 06:38:59,703 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268815920, currentsize=40.1m/42061680 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8620ms, sequenceid=2797, compaction requested=true
2014-07-22 06:38:59,704 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-22 06:39:00,626 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2809, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/6f202830b9c34fe6918fd03740dec2f5
2014-07-22 06:39:00,641 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/6f202830b9c34fe6918fd03740dec2f5 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6f202830b9c34fe6918fd03740dec2f5
2014-07-22 06:39:00,664 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6f202830b9c34fe6918fd03740dec2f5, entries=932210, sequenceid=2809, filesize=66.5m
2014-07-22 06:39:00,664 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.0m/268471200, currentsize=23.2m/24375600 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8003ms, sequenceid=2809, compaction requested=true
2014-07-22 06:39:00,664 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-22 06:39:06,578 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:39:06,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11243 synced till here 11242
2014-07-22 06:39:06,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036332269 with entries=88, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036346578
2014-07-22 06:39:06,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036261485
2014-07-22 06:39:06,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036264252
2014-07-22 06:39:06,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036267070
2014-07-22 06:39:06,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036269114
2014-07-22 06:39:09,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:39:09,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036346578 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036349175
2014-07-22 06:39:11,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:39:11,955 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036349175 with entries=86, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036351924
2014-07-22 06:39:17,275 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/bae72755f5e24ff4b71effc1f3caaf80 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bae72755f5e24ff4b71effc1f3caaf80
2014-07-22 06:39:17,292 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:39:17,300 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/137b8eecc3ad4f5e80bad749de1f329b, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/137b8eecc3ad4f5e80bad749de1f329b
2014-07-22 06:39:17,302 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0e45f810af4546f8bd6b87c06d2cc874, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0e45f810af4546f8bd6b87c06d2cc874
2014-07-22 06:39:17,305 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0b9fc05993b5446eb153ab91056a5310, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/0b9fc05993b5446eb153ab91056a5310
2014-07-22 06:39:17,309 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/eca0523ee5a84a6ab89a873045905a3b, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/eca0523ee5a84a6ab89a873045905a3b
2014-07-22 06:39:17,309 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into bae72755f5e24ff4b71effc1f3caaf80(size=276.5m), total size for store is 1.1g. This selection was in queue for 0sec, and took 39sec to execute.
2014-07-22 06:39:17,309 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=4, fileSize=276.6m, priority=1995, time=133298253465874; duration=39sec
2014-07-22 06:39:17,310 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-22 06:39:17,310 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 2000 blocking
2014-07-22 06:39:17,310 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 1177648528 starting at candidate #0 after considering 6 permutations with 2 in ratio
2014-07-22 06:39:17,310 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating major compaction
2014-07-22 06:39:17,311 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:39:17,311 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=1.1g
2014-07-22 06:39:17,311 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03246c5131a4e9291f1abd54136d6e7, keycount=825347, bloomtype=ROW, size=587.4m, encoding=NONE, seqNum=1470, earliestPutTs=1406035270409
2014-07-22 06:39:17,311 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dbb0a2efcc524fd08b6b6e104d1bfeaa, keycount=470777, bloomtype=ROW, size=335.3m, encoding=NONE, seqNum=2308, earliestPutTs=1406035839259
2014-07-22 06:39:17,312 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b76a9b44f244df595e604d5e8558e28, keycount=93864, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=2475, earliestPutTs=1406036163067
2014-07-22 06:39:17,312 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/642d28c4d31047c0a93da5be3000f089, keycount=94061, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=2643, earliestPutTs=1406036217234
2014-07-22 06:39:17,312 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6f202830b9c34fe6918fd03740dec2f5, keycount=93221, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=2809, earliestPutTs=1406036263913
2014-07-22 06:39:17,352 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:39:29,279 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:39:29,280 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:39:29,537 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:39:29,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:39:29,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11505 synced till here 11504
2014-07-22 06:39:29,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036351924 with entries=89, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036369691
2014-07-22 06:39:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=182297, hits=2885, hitRatio=1.58%, , cachingAccesses=2888, cachingHits=2882, cachingHitsRatio=99.79%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:39:37,484 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2893, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/664007390947402d8e65ecbcb0ea5b06
2014-07-22 06:39:37,505 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/664007390947402d8e65ecbcb0ea5b06 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664007390947402d8e65ecbcb0ea5b06
2014-07-22 06:39:37,524 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664007390947402d8e65ecbcb0ea5b06, entries=933860, sequenceid=2893, filesize=66.6m
2014-07-22 06:39:37,524 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268943520, currentsize=21.5m/22529600 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8244ms, sequenceid=2893, compaction requested=true
2014-07-22 06:39:37,524 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-22 06:39:57,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:39:57,514 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036369691 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036397463
2014-07-22 06:39:57,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036271753
2014-07-22 06:39:57,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036280694
2014-07-22 06:39:57,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036282760
2014-07-22 06:40:00,030 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:00,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11681 synced till here 11680
2014-07-22 06:40:00,249 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036397463 with entries=89, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036400031
2014-07-22 06:40:02,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:02,875 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.1m
2014-07-22 06:40:02,877 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:40:03,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11783 synced till here 11782
2014-07-22 06:40:03,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036400031 with entries=102, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036402542
2014-07-22 06:40:03,130 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:40:04,967 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:40:04,967 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.3m
2014-07-22 06:40:05,172 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:40:07,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:07,314 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11870 synced till here 11869
2014-07-22 06:40:07,326 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036402542 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036407292
2014-07-22 06:40:09,507 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:10,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11993 synced till here 11991
2014-07-22 06:40:10,090 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036407292 with entries=123, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036409507
2014-07-22 06:40:11,820 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:11,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12080 synced till here 12079
2014-07-22 06:40:11,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036409507 with entries=87, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036411821
2014-07-22 06:40:13,514 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:40:13,527 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2963, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/ac9739a28f1e4373970ab5992e4b8cb6
2014-07-22 06:40:13,539 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/ac9739a28f1e4373970ab5992e4b8cb6 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ac9739a28f1e4373970ab5992e4b8cb6
2014-07-22 06:40:13,644 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ac9739a28f1e4373970ab5992e4b8cb6, entries=932620, sequenceid=2963, filesize=66.5m
2014-07-22 06:40:13,644 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268587840, currentsize=144.2m/151236720 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10769ms, sequenceid=2963, compaction requested=true
2014-07-22 06:40:13,645 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-22 06:40:13,645 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.3m
2014-07-22 06:40:13,969 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:40:13,977 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:14,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12180 synced till here 12179
2014-07-22 06:40:14,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036411821 with entries=100, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036413978
2014-07-22 06:40:16,074 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2975, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/fcc2a0292d884efcb6a7ffdd761becb6
2014-07-22 06:40:16,101 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/fcc2a0292d884efcb6a7ffdd761becb6 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fcc2a0292d884efcb6a7ffdd761becb6
2014-07-22 06:40:16,141 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fcc2a0292d884efcb6a7ffdd761becb6, entries=933200, sequenceid=2975, filesize=66.5m
2014-07-22 06:40:16,142 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268754560, currentsize=141.3m/148148800 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 11175ms, sequenceid=2975, compaction requested=false
2014-07-22 06:40:22,802 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3060, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/40876b1a92334cd1af7ecba46efa63de
2014-07-22 06:40:22,832 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/40876b1a92334cd1af7ecba46efa63de as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/40876b1a92334cd1af7ecba46efa63de
2014-07-22 06:40:22,853 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/40876b1a92334cd1af7ecba46efa63de, entries=938930, sequenceid=3060, filesize=66.9m
2014-07-22 06:40:22,853 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.9m/270403680, currentsize=42.2m/44238160 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9208ms, sequenceid=3060, compaction requested=true
2014-07-22 06:40:22,853 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:16), split_queue=0, merge_queue=0
2014-07-22 06:40:23,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:23,919 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036413978 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036423886
2014-07-22 06:40:32,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:32,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12355 synced till here 12354
2014-07-22 06:40:32,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036423886 with entries=88, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036432557
2014-07-22 06:40:35,238 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:40:35,239 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.6m
2014-07-22 06:40:35,371 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:35,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036432557 with entries=87, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036435371
2014-07-22 06:40:35,476 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:40:39,072 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:40:39,072 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.4m
2014-07-22 06:40:39,486 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:40:39,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:39,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12530 synced till here 12528
2014-07-22 06:40:39,985 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036435371 with entries=88, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036439932
2014-07-22 06:40:41,986 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:42,032 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036439932 with entries=88, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036441986
2014-07-22 06:40:44,985 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3129, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3a89ecfbb7f946dfbd46775b656af846
2014-07-22 06:40:45,001 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3a89ecfbb7f946dfbd46775b656af846 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3a89ecfbb7f946dfbd46775b656af846
2014-07-22 06:40:45,019 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3a89ecfbb7f946dfbd46775b656af846, entries=934300, sequenceid=3129, filesize=66.6m
2014-07-22 06:40:45,019 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.6m/269071440, currentsize=69.9m/73304800 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9780ms, sequenceid=3129, compaction requested=true
2014-07-22 06:40:45,020 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:17), split_queue=0, merge_queue=0
2014-07-22 06:40:48,624 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3142, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/f359601075364e12acb2a691e86db611
2014-07-22 06:40:48,635 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/f359601075364e12acb2a691e86db611 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f359601075364e12acb2a691e86db611
2014-07-22 06:40:48,644 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f359601075364e12acb2a691e86db611, entries=939200, sequenceid=3142, filesize=66.9m
2014-07-22 06:40:48,645 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.0m/270481760, currentsize=61.9m/64895600 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9573ms, sequenceid=3142, compaction requested=false
2014-07-22 06:40:52,863 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:52,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12706 synced till here 12705
2014-07-22 06:40:52,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036441986 with entries=88, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036452864
2014-07-22 06:40:54,763 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:40:55,085 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036452864 with entries=102, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036454763
2014-07-22 06:40:55,662 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:40:55,663 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.8m
2014-07-22 06:40:55,891 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:41:03,954 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3226, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/bd596bf42bea4c2cbd5c99f6cc603301
2014-07-22 06:41:03,971 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/bd596bf42bea4c2cbd5c99f6cc603301 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bd596bf42bea4c2cbd5c99f6cc603301
2014-07-22 06:41:03,991 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bd596bf42bea4c2cbd5c99f6cc603301, entries=934920, sequenceid=3226, filesize=66.6m
2014-07-22 06:41:03,991 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.8m/269249120, currentsize=22.9m/24036320 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8328ms, sequenceid=3226, compaction requested=true
2014-07-22 06:41:03,992 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-22 06:41:14,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:41:15,251 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12906 synced till here 12904
2014-07-22 06:41:15,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036454763 with entries=98, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036474959
2014-07-22 06:41:17,260 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:41:17,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12997 synced till here 12994
2014-07-22 06:41:17,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036474959 with entries=91, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036477261
2014-07-22 06:41:21,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:41:21,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13086 synced till here 13085
2014-07-22 06:41:21,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036477261 with entries=89, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036481392
2014-07-22 06:41:21,999 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:41:21,999 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.2m
2014-07-22 06:41:22,417 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:41:30,159 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3300, memsize=264.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/60a1d87491e44e3b888a30f6d07fce32
2014-07-22 06:41:30,175 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/60a1d87491e44e3b888a30f6d07fce32 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/60a1d87491e44e3b888a30f6d07fce32
2014-07-22 06:41:30,195 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/60a1d87491e44e3b888a30f6d07fce32, entries=961250, sequenceid=3300, filesize=68.5m
2014-07-22 06:41:30,196 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.0m/276830880, currentsize=7.9m/8288400 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8197ms, sequenceid=3300, compaction requested=true
2014-07-22 06:41:30,196 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-22 06:41:43,577 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:41:43,578 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.4m
2014-07-22 06:41:43,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:41:43,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13176 synced till here 13174
2014-07-22 06:41:43,915 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036481392 with entries=90, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036503875
2014-07-22 06:41:44,046 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:41:45,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:41:45,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13265 synced till here 13264
2014-07-22 06:41:45,754 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036503875 with entries=89, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036505653
2014-07-22 06:41:45,918 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:41:45,918 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.3m
2014-07-22 06:41:46,144 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:41:49,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:41:49,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13353 synced till here 13352
2014-07-22 06:41:49,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036505653 with entries=88, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036509336
2014-07-22 06:41:53,452 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3311, memsize=260.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/7b5960e54d6f458bb787b7d3dd4ea50e
2014-07-22 06:41:53,473 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/7b5960e54d6f458bb787b7d3dd4ea50e as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b5960e54d6f458bb787b7d3dd4ea50e
2014-07-22 06:41:53,499 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b5960e54d6f458bb787b7d3dd4ea50e, entries=948200, sequenceid=3311, filesize=67.6m
2014-07-22 06:41:53,499 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.4m/273072160, currentsize=97.9m/102676800 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9922ms, sequenceid=3311, compaction requested=true
2014-07-22 06:41:53,500 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:20), split_queue=0, merge_queue=0
2014-07-22 06:41:54,794 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3322, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/3d347eb654eb45a0b609aaec2070814e
2014-07-22 06:41:54,816 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/3d347eb654eb45a0b609aaec2070814e as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3d347eb654eb45a0b609aaec2070814e
2014-07-22 06:41:54,843 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3d347eb654eb45a0b609aaec2070814e, entries=933070, sequenceid=3322, filesize=66.5m
2014-07-22 06:41:54,843 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268700960, currentsize=16.9m/17692480 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 8925ms, sequenceid=3322, compaction requested=true
2014-07-22 06:41:54,844 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-22 06:42:00,888 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/f03256958e7a426b8917f597c5cd468e as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03256958e7a426b8917f597c5cd468e
2014-07-22 06:42:00,920 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:42:00,937 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03246c5131a4e9291f1abd54136d6e7, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03246c5131a4e9291f1abd54136d6e7
2014-07-22 06:42:00,940 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dbb0a2efcc524fd08b6b6e104d1bfeaa, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/dbb0a2efcc524fd08b6b6e104d1bfeaa
2014-07-22 06:42:00,944 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b76a9b44f244df595e604d5e8558e28, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b76a9b44f244df595e604d5e8558e28
2014-07-22 06:42:00,948 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/642d28c4d31047c0a93da5be3000f089, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/642d28c4d31047c0a93da5be3000f089
2014-07-22 06:42:00,950 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6f202830b9c34fe6918fd03740dec2f5, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6f202830b9c34fe6918fd03740dec2f5
2014-07-22 06:42:00,951 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into f03256958e7a426b8917f597c5cd468e(size=1.1g), total size for store is 1.3g. This selection was in queue for 0sec, and took 2mins, 43sec to execute.
2014-07-22 06:42:00,951 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=5, fileSize=1.1g, priority=1995, time=133337701241404; duration=2mins, 43sec
2014-07-22 06:42:00,951 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-22 06:42:00,952 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 2000 blocking
2014-07-22 06:42:00,953 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 7 files of size 1384248559 starting at candidate #0 after considering 15 permutations with 9 in ratio
2014-07-22 06:42:00,953 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating major compaction
2014-07-22 06:42:00,953 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:42:00,954 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 7 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=1.3g
2014-07-22 06:42:00,954 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aaa11ac208e84af09cee264ac5e4c3df, keycount=987764, bloomtype=ROW, size=703.1m, encoding=NONE, seqNum=1758, earliestPutTs=1406035269695
2014-07-22 06:42:00,954 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b27daa587548446d868b35cb03f0528b, keycount=395858, bloomtype=ROW, size=282.0m, encoding=NONE, seqNum=2463, earliestPutTs=1406035950115
2014-07-22 06:42:00,954 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ea6a456ca43a4c4d9079d4020faffcac, keycount=93973, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=2630, earliestPutTs=1406036216038
2014-07-22 06:42:00,955 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/a49a4970cf4f4b16882131409568d4f8, keycount=93341, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=2797, earliestPutTs=1406036262485
2014-07-22 06:42:00,955 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ac9739a28f1e4373970ab5992e4b8cb6, keycount=93262, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=2963, earliestPutTs=1406036331511
2014-07-22 06:42:00,955 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3a89ecfbb7f946dfbd46775b656af846, keycount=93430, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=3129, earliestPutTs=1406036403028
2014-07-22 06:42:00,955 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/60a1d87491e44e3b888a30f6d07fce32, keycount=96125, bloomtype=ROW, size=68.5m, encoding=NONE, seqNum=3300, earliestPutTs=1406036435514
2014-07-22 06:42:01,030 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:42:16,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:16,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13442 synced till here 13440
2014-07-22 06:42:16,256 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036509336 with entries=89, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036536224
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036309772
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036332269
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036346578
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036349175
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036351924
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036369691
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036397463
2014-07-22 06:42:16,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036400031
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036402542
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036407292
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036409507
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036411821
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036413978
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036423886
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036432557
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036435371
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036439932
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036441986
2014-07-22 06:42:16,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036452864
2014-07-22 06:42:16,763 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:42:16,763 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.4m
2014-07-22 06:42:16,997 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:42:24,371 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3392, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/2073ea8f0cfb46938ef4af8811b6b681
2014-07-22 06:42:24,398 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/2073ea8f0cfb46938ef4af8811b6b681 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2073ea8f0cfb46938ef4af8811b6b681
2014-07-22 06:42:24,414 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2073ea8f0cfb46938ef4af8811b6b681, entries=933450, sequenceid=3392, filesize=66.5m
2014-07-22 06:42:24,415 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.4m/268827040, currentsize=16.8m/17630880 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 7652ms, sequenceid=3392, compaction requested=true
2014-07-22 06:42:24,415 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-22 06:42:30,497 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:30,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13552 synced till here 13551
2014-07-22 06:42:30,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036536224 with entries=110, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036550498
2014-07-22 06:42:30,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036454763
2014-07-22 06:42:30,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036474959
2014-07-22 06:42:30,897 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036477261
2014-07-22 06:42:33,570 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:33,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036550498 with entries=89, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036553571
2014-07-22 06:42:44,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:44,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13730 synced till here 13728
2014-07-22 06:42:44,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036553571 with entries=89, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036564012
2014-07-22 06:42:45,178 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:42:45,179 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.3m
2014-07-22 06:42:45,623 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:42:45,954 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:45,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13818 synced till here 13817
2014-07-22 06:42:45,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036564012 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036565955
2014-07-22 06:42:46,095 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:42:46,096 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.4m
2014-07-22 06:42:46,325 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:42:47,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:47,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13919 synced till here 13916
2014-07-22 06:42:48,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036565955 with entries=101, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036567695
2014-07-22 06:42:49,585 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:49,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14012 synced till here 14009
2014-07-22 06:42:49,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036567695 with entries=93, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036569585
2014-07-22 06:42:51,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:42:51,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036569585 with entries=89, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036571322
2014-07-22 06:42:52,290 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:42:56,562 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3467, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3163119de88448bfb7ff8f51c32cd6ad
2014-07-22 06:42:56,574 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3163119de88448bfb7ff8f51c32cd6ad as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3163119de88448bfb7ff8f51c32cd6ad
2014-07-22 06:42:56,585 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3163119de88448bfb7ff8f51c32cd6ad, entries=938860, sequenceid=3467, filesize=66.9m
2014-07-22 06:42:56,586 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.9m/270383600, currentsize=152.3m/159665520 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 11407ms, sequenceid=3467, compaction requested=false
2014-07-22 06:42:56,586 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 271.1m
2014-07-22 06:42:56,744 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:42:57,201 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3478, memsize=256.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/1014f6c94f824b938cc4dc5c0cd9633e
2014-07-22 06:42:57,211 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/1014f6c94f824b938cc4dc5c0cd9633e as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1014f6c94f824b938cc4dc5c0cd9633e
2014-07-22 06:42:57,219 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1014f6c94f824b938cc4dc5c0cd9633e, entries=933460, sequenceid=3478, filesize=66.5m
2014-07-22 06:42:57,219 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.4m/268828400, currentsize=140.4m/147236320 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 11123ms, sequenceid=3478, compaction requested=true
2014-07-22 06:42:57,220 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-22 06:43:04,690 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3568, memsize=271.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/2717071f15434eb2a82219a79409ee84
2014-07-22 06:43:04,713 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/2717071f15434eb2a82219a79409ee84 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2717071f15434eb2a82219a79409ee84
2014-07-22 06:43:04,740 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2717071f15434eb2a82219a79409ee84, entries=987150, sequenceid=3568, filesize=70.3m
2014-07-22 06:43:04,741 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~271.1m/284291520, currentsize=1.6m/1641520 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8154ms, sequenceid=3568, compaction requested=true
2014-07-22 06:43:04,741 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:23), split_queue=0, merge_queue=0
2014-07-22 06:43:13,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:13,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036571322 with entries=87, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036593560
2014-07-22 06:43:13,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036481392
2014-07-22 06:43:13,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036503875
2014-07-22 06:43:16,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:16,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14278 synced till here 14276
2014-07-22 06:43:16,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036593560 with entries=90, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036596034
2014-07-22 06:43:18,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:18,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14366 synced till here 14365
2014-07-22 06:43:18,367 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036596034 with entries=88, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036598322
2014-07-22 06:43:29,932 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:43:29,933 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.6m
2014-07-22 06:43:30,137 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:30,177 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:43:30,178 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036598322 with entries=88, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036610138
2014-07-22 06:43:31,047 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:43:31,048 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.8m
2014-07-22 06:43:31,397 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:43:32,159 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:32,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036610138 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036612159
2014-07-22 06:43:37,966 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:38,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14633 synced till here 14630
2014-07-22 06:43:38,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036612159 with entries=92, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036617966
2014-07-22 06:43:40,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:43:40,108 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14722 synced till here 14721
2014-07-22 06:43:40,123 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036617966 with entries=89, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036620027
2014-07-22 06:43:40,197 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3634, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/e317c6f8491f4836961520a2cbf3021c
2014-07-22 06:43:40,218 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/e317c6f8491f4836961520a2cbf3021c as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/e317c6f8491f4836961520a2cbf3021c
2014-07-22 06:43:40,239 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/e317c6f8491f4836961520a2cbf3021c, entries=939750, sequenceid=3634, filesize=67.0m
2014-07-22 06:43:40,240 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270639840, currentsize=106.8m/112009200 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10307ms, sequenceid=3634, compaction requested=false
2014-07-22 06:43:40,962 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3645, memsize=258.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/0c8330b0261141af8063d49197c2bcf5
2014-07-22 06:43:40,977 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/0c8330b0261141af8063d49197c2bcf5 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0c8330b0261141af8063d49197c2bcf5
2014-07-22 06:43:40,989 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0c8330b0261141af8063d49197c2bcf5, entries=940720, sequenceid=3645, filesize=67.0m
2014-07-22 06:43:40,989 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.4m/270922000, currentsize=97.9m/102614800 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9941ms, sequenceid=3645, compaction requested=true
2014-07-22 06:43:40,989 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:24), split_queue=0, merge_queue=0
2014-07-22 06:44:06,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:07,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14813 synced till here 14812
2014-07-22 06:44:07,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036620027 with entries=91, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036646843
2014-07-22 06:44:07,351 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:44:07,352 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.6m
2014-07-22 06:44:07,585 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:44:15,168 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3734, memsize=256.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/cf85ec511e0a4f9eae319c46f5ac3d74
2014-07-22 06:44:15,183 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/cf85ec511e0a4f9eae319c46f5ac3d74 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cf85ec511e0a4f9eae319c46f5ac3d74
2014-07-22 06:44:15,194 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cf85ec511e0a4f9eae319c46f5ac3d74, entries=934420, sequenceid=3734, filesize=66.6m
2014-07-22 06:44:15,194 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.6m/269105040, currentsize=9.3m/9702400 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 7843ms, sequenceid=3734, compaction requested=true
2014-07-22 06:44:15,194 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:25), split_queue=0, merge_queue=0
2014-07-22 06:44:19,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:19,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036646843 with entries=89, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036659311
2014-07-22 06:44:21,121 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:21,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14992 synced till here 14987
2014-07-22 06:44:21,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036659311 with entries=90, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036661121
2014-07-22 06:44:30,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:30,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15084 synced till here 15082
2014-07-22 06:44:30,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036661121 with entries=92, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036670318
2014-07-22 06:44:30,867 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.4m
2014-07-22 06:44:30,867 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:44:31,267 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:44:31,497 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:44:31,498 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.0m
2014-07-22 06:44:31,763 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:44:32,076 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:32,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15183 synced till here 15181
2014-07-22 06:44:32,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036670318 with entries=99, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036672076
2014-07-22 06:44:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=251085, hits=3706, hitRatio=1.47%, , cachingAccesses=3709, cachingHits=3703, cachingHitsRatio=99.83%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:44:39,185 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3803, memsize=260.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/940cccf80b434ae1acc1a4c2f2994729
2014-07-22 06:44:39,197 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/940cccf80b434ae1acc1a4c2f2994729 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/940cccf80b434ae1acc1a4c2f2994729
2014-07-22 06:44:39,206 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/940cccf80b434ae1acc1a4c2f2994729, entries=948090, sequenceid=3803, filesize=67.5m
2014-07-22 06:44:39,206 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.4m/273043280, currentsize=32.8m/34354560 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8339ms, sequenceid=3803, compaction requested=true
2014-07-22 06:44:39,206 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-22 06:44:39,479 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3811, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/84b46c4ebe0b40fe9c014f47562f9be0
2014-07-22 06:44:39,498 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/84b46c4ebe0b40fe9c014f47562f9be0 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/84b46c4ebe0b40fe9c014f47562f9be0
2014-07-22 06:44:39,514 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/84b46c4ebe0b40fe9c014f47562f9be0, entries=932160, sequenceid=3811, filesize=66.4m
2014-07-22 06:44:39,515 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.0m/268456560, currentsize=23.4m/24496720 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8017ms, sequenceid=3811, compaction requested=true
2014-07-22 06:44:39,515 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-22 06:44:44,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:44,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15273 synced till here 15272
2014-07-22 06:44:44,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036672076 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036684082
2014-07-22 06:44:45,909 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:44:46,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15391 synced till here 15389
2014-07-22 06:44:46,496 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036684082 with entries=118, filesize=83.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036685910
2014-07-22 06:45:09,679 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:45:09,679 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.1m
2014-07-22 06:45:10,044 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:45:10,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:45:10,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15482 synced till here 15481
2014-07-22 06:45:10,984 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036685910 with entries=91, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036710896
2014-07-22 06:45:11,189 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:45:11,189 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.0m
2014-07-22 06:45:11,557 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:45:12,664 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:45:12,680 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15570 synced till here 15569
2014-07-22 06:45:12,761 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036710896 with entries=88, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036712665
2014-07-22 06:45:13,664 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/28931cb45de747878da6b1cd2f208884 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/28931cb45de747878da6b1cd2f208884
2014-07-22 06:45:13,768 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:45:13,777 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aaa11ac208e84af09cee264ac5e4c3df, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/aaa11ac208e84af09cee264ac5e4c3df
2014-07-22 06:45:13,788 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b27daa587548446d868b35cb03f0528b, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b27daa587548446d868b35cb03f0528b
2014-07-22 06:45:13,793 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ea6a456ca43a4c4d9079d4020faffcac, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ea6a456ca43a4c4d9079d4020faffcac
2014-07-22 06:45:13,799 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/a49a4970cf4f4b16882131409568d4f8, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/a49a4970cf4f4b16882131409568d4f8
2014-07-22 06:45:13,802 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ac9739a28f1e4373970ab5992e4b8cb6, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/ac9739a28f1e4373970ab5992e4b8cb6
2014-07-22 06:45:13,805 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3a89ecfbb7f946dfbd46775b656af846, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3a89ecfbb7f946dfbd46775b656af846
2014-07-22 06:45:13,808 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/60a1d87491e44e3b888a30f6d07fce32, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/60a1d87491e44e3b888a30f6d07fce32
2014-07-22 06:45:13,808 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 7 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into 28931cb45de747878da6b1cd2f208884(size=1.3g), total size for store is 1.5g. This selection was in queue for 0sec, and took 3mins, 12sec to execute.
2014-07-22 06:45:13,809 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=7, fileSize=1.3g, priority=1993, time=133501343520363; duration=3mins, 12sec
2014-07-22 06:45:13,809 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-22 06:45:13,809 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 2000 blocking
2014-07-22 06:45:13,810 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 8 files of size 1565477655 starting at candidate #0 after considering 21 permutations with 14 in ratio
2014-07-22 06:45:13,810 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating major compaction
2014-07-22 06:45:13,810 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:45:13,810 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 8 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=1.5g
2014-07-22 06:45:13,810 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c34badbb0973457db38551c5c56578a7, keycount=1142124, bloomtype=ROW, size=813.0m, encoding=NONE, seqNum=2035, earliestPutTs=1406035268880
2014-07-22 06:45:13,810 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bae72755f5e24ff4b71effc1f3caaf80, keycount=388152, bloomtype=ROW, size=276.5m, encoding=NONE, seqNum=2726, earliestPutTs=1406036057930
2014-07-22 06:45:13,811 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664007390947402d8e65ecbcb0ea5b06, keycount=93386, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=2893, earliestPutTs=1406036278374
2014-07-22 06:45:13,811 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/40876b1a92334cd1af7ecba46efa63de, keycount=93893, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=3060, earliestPutTs=1406036369286
2014-07-22 06:45:13,811 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bd596bf42bea4c2cbd5c99f6cc603301, keycount=93492, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=3226, earliestPutTs=1406036413680
2014-07-22 06:45:13,811 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2073ea8f0cfb46938ef4af8811b6b681, keycount=93345, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=3392, earliestPutTs=1406036455759
2014-07-22 06:45:13,811 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2717071f15434eb2a82219a79409ee84, keycount=98715, bloomtype=ROW, size=70.3m, encoding=NONE, seqNum=3568, earliestPutTs=1406036536936
2014-07-22 06:45:13,811 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cf85ec511e0a4f9eae319c46f5ac3d74, keycount=93442, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=3734, earliestPutTs=1406036576735
2014-07-22 06:45:13,991 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:45:14,836 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:45:14,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15660 synced till here 15658
2014-07-22 06:45:14,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036712665 with entries=90, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036714836
2014-07-22 06:45:16,688 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:45:16,741 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15753 synced till here 15748
2014-07-22 06:45:16,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036714836 with entries=93, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036716690
2014-07-22 06:45:17,375 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:45:18,061 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:45:20,468 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3871, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/934cb24d58fe48e29ad7f65bd377cd20
2014-07-22 06:45:20,490 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/934cb24d58fe48e29ad7f65bd377cd20 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/934cb24d58fe48e29ad7f65bd377cd20
2014-07-22 06:45:20,517 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/934cb24d58fe48e29ad7f65bd377cd20, entries=932370, sequenceid=3871, filesize=66.4m
2014-07-22 06:45:20,517 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268498240, currentsize=43.1m/45228000 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10838ms, sequenceid=3871, compaction requested=true
2014-07-22 06:45:20,518 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-22 06:45:20,518 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 275.4m
2014-07-22 06:45:20,682 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:45:21,889 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3901, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/30a967f05f264fa19e88f4f3548ffb25
2014-07-22 06:45:21,906 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/30a967f05f264fa19e88f4f3548ffb25 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/30a967f05f264fa19e88f4f3548ffb25
2014-07-22 06:45:21,926 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/30a967f05f264fa19e88f4f3548ffb25, entries=938120, sequenceid=3901, filesize=66.8m
2014-07-22 06:45:21,926 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270171360, currentsize=127.1m/133222080 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10737ms, sequenceid=3901, compaction requested=false
2014-07-22 06:45:21,927 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 266.3m
2014-07-22 06:45:22,138 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:45:28,455 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3982, memsize=275.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/861eccb04c9c40e3be3d9aca6e5a412e
2014-07-22 06:45:28,477 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/861eccb04c9c40e3be3d9aca6e5a412e as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/861eccb04c9c40e3be3d9aca6e5a412e
2014-07-22 06:45:28,496 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/861eccb04c9c40e3be3d9aca6e5a412e, entries=1002710, sequenceid=3982, filesize=71.4m
2014-07-22 06:45:28,496 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~275.4m/288772960, currentsize=0.0/0 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 7978ms, sequenceid=3982, compaction requested=true
2014-07-22 06:45:28,496 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:28), split_queue=0, merge_queue=0
2014-07-22 06:45:29,776 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3983, memsize=266.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/a8c756b3ff3c4e3c91e5a87499136a6d
2014-07-22 06:45:29,789 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/a8c756b3ff3c4e3c91e5a87499136a6d as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a8c756b3ff3c4e3c91e5a87499136a6d
2014-07-22 06:45:29,800 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a8c756b3ff3c4e3c91e5a87499136a6d, entries=969690, sequenceid=3983, filesize=69.0m
2014-07-22 06:45:29,800 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~266.3m/279262240, currentsize=0.0/0 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 7873ms, sequenceid=3983, compaction requested=true
2014-07-22 06:45:29,801 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:29), split_queue=0, merge_queue=0
2014-07-22 06:46:20,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:20,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15843 synced till here 15842
2014-07-22 06:46:20,117 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036716690 with entries=90, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036780081
2014-07-22 06:46:20,117 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036505653
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036509336
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036536224
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036550498
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036553571
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036564012
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036565955
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036567695
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036569585
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036571322
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036593560
2014-07-22 06:46:20,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036596034
2014-07-22 06:46:20,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036598322
2014-07-22 06:46:20,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036610138
2014-07-22 06:46:20,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036612159
2014-07-22 06:46:20,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036617966
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036620027
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036646843
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036659311
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036661121
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036670318
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036672076
2014-07-22 06:46:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036684082
2014-07-22 06:46:22,000 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:22,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15932 synced till here 15931
2014-07-22 06:46:22,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036780081 with entries=89, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036782000
2014-07-22 06:46:23,754 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:23,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036782000 with entries=89, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036783754
2014-07-22 06:46:25,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:26,494 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16143 synced till here 16142
2014-07-22 06:46:26,614 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036783754 with entries=122, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036785803
2014-07-22 06:46:27,275 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:46:27,275 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.1m
2014-07-22 06:46:27,695 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:46:28,724 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:28,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036785803 with entries=88, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036788725
2014-07-22 06:46:31,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:31,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036788725 with entries=89, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036791542
2014-07-22 06:46:36,156 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4068, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/1e325298a47c4f15b3808508244ba266
2014-07-22 06:46:36,169 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/1e325298a47c4f15b3808508244ba266 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1e325298a47c4f15b3808508244ba266
2014-07-22 06:46:36,179 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1e325298a47c4f15b3808508244ba266, entries=938460, sequenceid=4068, filesize=66.9m
2014-07-22 06:46:36,180 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.7m/270267680, currentsize=60.3m/63277280 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8905ms, sequenceid=4068, compaction requested=false
2014-07-22 06:46:40,522 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:40,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16416 synced till here 16412
2014-07-22 06:46:40,913 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036791542 with entries=96, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036800522
2014-07-22 06:46:42,523 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:46:42,523 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.8m
2014-07-22 06:46:42,680 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:46:42,680 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.3m
2014-07-22 06:46:42,796 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:46:42,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:42,936 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:46:42,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036800522 with entries=88, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036802925
2014-07-22 06:46:50,684 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4148, memsize=256.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8c142c73626f487d85d3ed963aed50c5
2014-07-22 06:46:50,689 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4150, memsize=257.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/3c6a34fd17684f0989b9d9bff011cd0a
2014-07-22 06:46:50,743 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8c142c73626f487d85d3ed963aed50c5 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8c142c73626f487d85d3ed963aed50c5
2014-07-22 06:46:50,744 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/3c6a34fd17684f0989b9d9bff011cd0a as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/3c6a34fd17684f0989b9d9bff011cd0a
2014-07-22 06:46:50,804 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8c142c73626f487d85d3ed963aed50c5, entries=934890, sequenceid=4148, filesize=66.6m
2014-07-22 06:46:50,805 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.8m/269240160, currentsize=21.4m/22477600 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8282ms, sequenceid=4148, compaction requested=true
2014-07-22 06:46:50,805 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-22 06:46:50,806 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/3c6a34fd17684f0989b9d9bff011cd0a, entries=938750, sequenceid=4150, filesize=66.9m
2014-07-22 06:46:50,806 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.8m/270350880, currentsize=20.0m/20960000 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8126ms, sequenceid=4150, compaction requested=true
2014-07-22 06:46:50,806 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:31), split_queue=0, merge_queue=0
2014-07-22 06:46:53,072 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:53,090 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16594 synced till here 16591
2014-07-22 06:46:53,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036802925 with entries=90, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036813073
2014-07-22 06:46:54,934 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:54,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16684 synced till here 16683
2014-07-22 06:46:55,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036813073 with entries=90, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036814935
2014-07-22 06:46:57,086 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:46:57,250 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16778 synced till here 16773
2014-07-22 06:46:57,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036814935 with entries=94, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036817086
2014-07-22 06:46:59,679 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:46:59,679 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:46:59,895 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:47:07,478 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4234, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/87b026b8d9d64b0fb0948e35a899e5d5
2014-07-22 06:47:07,517 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/87b026b8d9d64b0fb0948e35a899e5d5 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/87b026b8d9d64b0fb0948e35a899e5d5
2014-07-22 06:47:07,550 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/87b026b8d9d64b0fb0948e35a899e5d5, entries=934070, sequenceid=4234, filesize=66.5m
2014-07-22 06:47:07,551 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/269005280, currentsize=10.7m/11269120 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 7872ms, sequenceid=4234, compaction requested=true
2014-07-22 06:47:07,551 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:32), split_queue=0, merge_queue=0
2014-07-22 06:47:10,472 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:47:10,494 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16870 synced till here 16868
2014-07-22 06:47:10,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036817086 with entries=92, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036830472
2014-07-22 06:47:12,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:47:12,400 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16962 synced till here 16960
2014-07-22 06:47:12,437 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036830472 with entries=92, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036832279
2014-07-22 06:47:14,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:47:14,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17052 synced till here 17049
2014-07-22 06:47:14,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036832279 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036834018
2014-07-22 06:47:17,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:47:17,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17141 synced till here 17139
2014-07-22 06:47:17,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036834018 with entries=89, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036837359
2014-07-22 06:47:17,731 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:47:17,731 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.3m
2014-07-22 06:47:17,882 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:47:18,900 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:47:18,901 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.0m
2014-07-22 06:47:19,089 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:47:25,531 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4315, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/1f08af39a6cf4193aface27a0f4e5ef2
2014-07-22 06:47:25,558 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/1f08af39a6cf4193aface27a0f4e5ef2 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/1f08af39a6cf4193aface27a0f4e5ef2
2014-07-22 06:47:25,580 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/1f08af39a6cf4193aface27a0f4e5ef2, entries=937000, sequenceid=4315, filesize=66.7m
2014-07-22 06:47:25,581 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.3m/269847600, currentsize=14.0m/14716400 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 7850ms, sequenceid=4315, compaction requested=true
2014-07-22 06:47:25,581 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:33), split_queue=0, merge_queue=0
2014-07-22 06:47:27,097 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4317, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/40a253bc66b54b91b90eebfc9d3f7703
2014-07-22 06:47:27,129 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/40a253bc66b54b91b90eebfc9d3f7703 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/40a253bc66b54b91b90eebfc9d3f7703
2014-07-22 06:47:27,156 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/40a253bc66b54b91b90eebfc9d3f7703, entries=935830, sequenceid=4317, filesize=66.6m
2014-07-22 06:47:27,156 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269511920, currentsize=12.4m/13008720 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8255ms, sequenceid=4317, compaction requested=true
2014-07-22 06:47:27,157 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-22 06:47:50,841 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:47:50,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17231 synced till here 17229
2014-07-22 06:47:50,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036837359 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036870841
2014-07-22 06:48:01,815 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:01,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036870841 with entries=90, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036881815
2014-07-22 06:48:03,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:03,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17410 synced till here 17409
2014-07-22 06:48:03,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036881815 with entries=89, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036883496
2014-07-22 06:48:05,347 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:48:05,347 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:48:05,676 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:05,721 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:48:05,879 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17509 synced till here 17508
2014-07-22 06:48:05,896 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036883496 with entries=99, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036885677
2014-07-22 06:48:07,624 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:07,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17596 synced till here 17595
2014-07-22 06:48:07,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036885677 with entries=87, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036887624
2014-07-22 06:48:09,397 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:48:09,397 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.0m
2014-07-22 06:48:09,549 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:48:13,755 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:13,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17683 synced till here 17682
2014-07-22 06:48:13,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036887624 with entries=87, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036893756
2014-07-22 06:48:15,512 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4401, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/1181f58ea503418ba94649533f6bdefd
2014-07-22 06:48:15,529 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/1181f58ea503418ba94649533f6bdefd as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1181f58ea503418ba94649533f6bdefd
2014-07-22 06:48:15,619 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1181f58ea503418ba94649533f6bdefd, entries=939760, sequenceid=4401, filesize=66.9m
2014-07-22 06:48:15,619 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270643200, currentsize=108.8m/114122800 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10272ms, sequenceid=4401, compaction requested=true
2014-07-22 06:48:15,620 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:35), split_queue=0, merge_queue=0
2014-07-22 06:48:15,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:15,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17773 synced till here 17772
2014-07-22 06:48:15,690 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036893756 with entries=90, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036895654
2014-07-22 06:48:16,700 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.0m
2014-07-22 06:48:16,700 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:48:16,913 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:48:17,077 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:48:17,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:18,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036895654 with entries=96, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036897737
2014-07-22 06:48:19,642 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4419, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/ae48a89e28ea4c3e8af933d0454fe971
2014-07-22 06:48:19,653 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/ae48a89e28ea4c3e8af933d0454fe971 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ae48a89e28ea4c3e8af933d0454fe971
2014-07-22 06:48:19,663 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ae48a89e28ea4c3e8af933d0454fe971, entries=932250, sequenceid=4419, filesize=66.4m
2014-07-22 06:48:19,663 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.0m/268461600, currentsize=33.6m/35196160 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10266ms, sequenceid=4419, compaction requested=true
2014-07-22 06:48:19,664 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:36), split_queue=0, merge_queue=0
2014-07-22 06:48:19,664 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 303.6m
2014-07-22 06:48:19,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:19,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17960 synced till here 17958
2014-07-22 06:48:19,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036897737 with entries=91, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036899920
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036685910
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036710896
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036712665
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036714836
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036716690
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036780081
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036782000
2014-07-22 06:48:19,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036783754
2014-07-22 06:48:19,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036785803
2014-07-22 06:48:19,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036788725
2014-07-22 06:48:19,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036791542
2014-07-22 06:48:19,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036800522
2014-07-22 06:48:19,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036802925
2014-07-22 06:48:19,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036813073
2014-07-22 06:48:19,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036814935
2014-07-22 06:48:19,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036817086
2014-07-22 06:48:19,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036830472
2014-07-22 06:48:19,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036832279
2014-07-22 06:48:19,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036834018
2014-07-22 06:48:20,111 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:48:21,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:21,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18050 synced till here 18049
2014-07-22 06:48:21,816 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036899920 with entries=90, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036901770
2014-07-22 06:48:23,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:23,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036901770 with entries=95, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036903594
2014-07-22 06:48:24,178 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:48:27,563 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4482, memsize=258.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8fc8cd6f23c748f4904c3a24e5e38ff9
2014-07-22 06:48:27,574 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8fc8cd6f23c748f4904c3a24e5e38ff9 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8fc8cd6f23c748f4904c3a24e5e38ff9
2014-07-22 06:48:27,586 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8fc8cd6f23c748f4904c3a24e5e38ff9, entries=941460, sequenceid=4482, filesize=67.0m
2014-07-22 06:48:27,586 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.6m/271132240, currentsize=128.8m/135069360 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10886ms, sequenceid=4482, compaction requested=true
2014-07-22 06:48:27,586 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:37), split_queue=0, merge_queue=0
2014-07-22 06:48:27,587 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:48:27,773 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:48:31,074 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4514, memsize=305.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/fffbf0301256413493443f7a74d5273c
2014-07-22 06:48:31,098 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/fffbf0301256413493443f7a74d5273c as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fffbf0301256413493443f7a74d5273c
2014-07-22 06:48:31,111 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fffbf0301256413493443f7a74d5273c, entries=1111230, sequenceid=4514, filesize=79.1m
2014-07-22 06:48:31,112 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~305.2m/320025120, currentsize=80.9m/84794160 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 11448ms, sequenceid=4514, compaction requested=true
2014-07-22 06:48:31,112 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:38), split_queue=0, merge_queue=0
2014-07-22 06:48:35,811 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4567, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/c6b6861d84034d80994c06279c3ac829
2014-07-22 06:48:35,822 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/c6b6861d84034d80994c06279c3ac829 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6b6861d84034d80994c06279c3ac829
2014-07-22 06:48:35,834 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6b6861d84034d80994c06279c3ac829, entries=933770, sequenceid=4567, filesize=66.5m
2014-07-22 06:48:35,834 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.5m/268919120, currentsize=0.0/0 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8247ms, sequenceid=4567, compaction requested=true
2014-07-22 06:48:35,835 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-22 06:48:50,366 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:50,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036903594 with entries=87, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036930366
2014-07-22 06:48:50,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036837359
2014-07-22 06:48:50,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036870841
2014-07-22 06:48:50,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036881815
2014-07-22 06:48:50,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036883496
2014-07-22 06:48:50,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036885677
2014-07-22 06:48:52,820 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:52,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18320 synced till here 18319
2014-07-22 06:48:52,855 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036930366 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036932820
2014-07-22 06:48:55,343 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/32f6920226a1492cb10ad0c18891c6c6 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/32f6920226a1492cb10ad0c18891c6c6
2014-07-22 06:48:55,366 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:48:55,373 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c34badbb0973457db38551c5c56578a7, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c34badbb0973457db38551c5c56578a7
2014-07-22 06:48:55,379 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bae72755f5e24ff4b71effc1f3caaf80, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bae72755f5e24ff4b71effc1f3caaf80
2014-07-22 06:48:55,383 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664007390947402d8e65ecbcb0ea5b06, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/664007390947402d8e65ecbcb0ea5b06
2014-07-22 06:48:55,393 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/40876b1a92334cd1af7ecba46efa63de, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/40876b1a92334cd1af7ecba46efa63de
2014-07-22 06:48:55,423 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bd596bf42bea4c2cbd5c99f6cc603301, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bd596bf42bea4c2cbd5c99f6cc603301
2014-07-22 06:48:55,543 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2073ea8f0cfb46938ef4af8811b6b681, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2073ea8f0cfb46938ef4af8811b6b681
2014-07-22 06:48:55,618 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:48:55,748 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2717071f15434eb2a82219a79409ee84, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/2717071f15434eb2a82219a79409ee84
2014-07-22 06:48:55,967 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cf85ec511e0a4f9eae319c46f5ac3d74, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/cf85ec511e0a4f9eae319c46f5ac3d74
2014-07-22 06:48:55,967 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 8 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into 32f6920226a1492cb10ad0c18891c6c6(size=1.5g), total size for store is 1.8g. This selection was in queue for 0sec, and took 3mins, 42sec to execute.
2014-07-22 06:48:55,968 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=8, fileSize=1.5g, priority=1992, time=133694200511274; duration=3mins, 42sec
2014-07-22 06:48:55,968 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-22 06:48:55,968 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 11 store files, 0 compacting, 11 eligible, 2000 blocking
2014-07-22 06:48:55,969 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 715743558 starting at candidate #1 after considering 44 permutations with 36 in ratio
2014-07-22 06:48:55,969 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating minor compaction
2014-07-22 06:48:55,970 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:48:55,970 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=682.6m
2014-07-22 06:48:55,970 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fcc2a0292d884efcb6a7ffdd761becb6, keycount=93320, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=2975
2014-07-22 06:48:55,970 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f359601075364e12acb2a691e86db611, keycount=93920, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=3142
2014-07-22 06:48:55,970 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b5960e54d6f458bb787b7d3dd4ea50e, keycount=94820, bloomtype=ROW, size=67.6m, encoding=NONE, seqNum=3311
2014-07-22 06:48:55,970 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1014f6c94f824b938cc4dc5c0cd9633e, keycount=93346, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=3478
2014-07-22 06:48:55,970 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0c8330b0261141af8063d49197c2bcf5, keycount=94072, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=3645
2014-07-22 06:48:55,970 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/84b46c4ebe0b40fe9c014f47562f9be0, keycount=93216, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=3811
2014-07-22 06:48:55,971 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a8c756b3ff3c4e3c91e5a87499136a6d, keycount=96969, bloomtype=ROW, size=69.0m, encoding=NONE, seqNum=3983
2014-07-22 06:48:55,971 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/3c6a34fd17684f0989b9d9bff011cd0a, keycount=93875, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=4150
2014-07-22 06:48:55,971 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/40a253bc66b54b91b90eebfc9d3f7703, keycount=93583, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=4317
2014-07-22 06:48:55,971 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fffbf0301256413493443f7a74d5273c, keycount=111123, bloomtype=ROW, size=79.1m, encoding=NONE, seqNum=4514
2014-07-22 06:48:55,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18420 synced till here 18419
2014-07-22 06:48:56,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036932820 with entries=100, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036935619
2014-07-22 06:48:56,071 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:49:16,800 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:49:16,801 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.1m
2014-07-22 06:49:17,100 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:49:17,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:49:17,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18510 synced till here 18509
2014-07-22 06:49:17,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036935619 with entries=90, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036957379
2014-07-22 06:49:24,832 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4648, memsize=256.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/5207dbe4002a45e196e0e607d04980c4
2014-07-22 06:49:24,857 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/5207dbe4002a45e196e0e607d04980c4 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5207dbe4002a45e196e0e607d04980c4
2014-07-22 06:49:24,871 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5207dbe4002a45e196e0e607d04980c4, entries=932580, sequenceid=4648, filesize=66.5m
2014-07-22 06:49:24,872 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.1m/268577440, currentsize=16.9m/17708800 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8071ms, sequenceid=4648, compaction requested=true
2014-07-22 06:49:24,872 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-22 06:49:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=320222, hits=4490, hitRatio=1.40%, , cachingAccesses=4493, cachingHits=4487, cachingHitsRatio=99.86%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:49:49,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:49:49,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18597 synced till here 18596
2014-07-22 06:49:49,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036957379 with entries=87, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036989438
2014-07-22 06:49:50,313 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:49:50,313 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.4m
2014-07-22 06:49:50,461 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:49:54,163 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:49:54,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036989438 with entries=93, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036994165
2014-07-22 06:49:56,732 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:49:56,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18781 synced till here 18780
2014-07-22 06:49:57,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036994165 with entries=91, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036996732
2014-07-22 06:49:57,321 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:49:57,324 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:49:57,743 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:49:58,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:49:58,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18870 synced till here 18869
2014-07-22 06:49:58,706 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036996732 with entries=89, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036998673
2014-07-22 06:50:00,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:00,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18960 synced till here 18957
2014-07-22 06:50:00,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036998673 with entries=90, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037000617
2014-07-22 06:50:01,465 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4681, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/28c91a0738074c6f88841b394a63ece7
2014-07-22 06:50:01,478 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/28c91a0738074c6f88841b394a63ece7 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/28c91a0738074c6f88841b394a63ece7
2014-07-22 06:50:01,523 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/28c91a0738074c6f88841b394a63ece7, entries=937120, sequenceid=4681, filesize=66.8m
2014-07-22 06:50:01,523 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269885760, currentsize=146.2m/153319120 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 11210ms, sequenceid=4681, compaction requested=false
2014-07-22 06:50:03,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:03,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19049 synced till here 19048
2014-07-22 06:50:03,955 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037000617 with entries=89, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037003904
2014-07-22 06:50:07,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:07,048 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:50:07,049 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.1m
2014-07-22 06:50:07,058 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19140 synced till here 19138
2014-07-22 06:50:07,080 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037003904 with entries=91, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037007023
2014-07-22 06:50:07,357 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:50:08,033 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4736, memsize=259.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7222a51cd79445a9b517e179bafb2b75
2014-07-22 06:50:08,046 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7222a51cd79445a9b517e179bafb2b75 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7222a51cd79445a9b517e179bafb2b75
2014-07-22 06:50:08,063 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7222a51cd79445a9b517e179bafb2b75, entries=945880, sequenceid=4736, filesize=67.4m
2014-07-22 06:50:08,064 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.8m/272405360, currentsize=133.9m/140357920 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10740ms, sequenceid=4736, compaction requested=true
2014-07-22 06:50:08,064 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:40), split_queue=0, merge_queue=0
2014-07-22 06:50:14,809 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4815, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/48f8c3167dc144c5a2264b89558af6c8
2014-07-22 06:50:14,821 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/48f8c3167dc144c5a2264b89558af6c8 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/48f8c3167dc144c5a2264b89558af6c8
2014-07-22 06:50:14,835 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/48f8c3167dc144c5a2264b89558af6c8, entries=938140, sequenceid=4815, filesize=66.9m
2014-07-22 06:50:14,835 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.7m/270176560, currentsize=7.7m/8063760 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 7786ms, sequenceid=4815, compaction requested=true
2014-07-22 06:50:14,836 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-22 06:50:24,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:24,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19228 synced till here 19226
2014-07-22 06:50:24,968 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037007023 with entries=88, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037024847
2014-07-22 06:50:26,521 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:50:26,522 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.7m
2014-07-22 06:50:26,809 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:50:29,756 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:29,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037024847 with entries=89, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037029756
2014-07-22 06:50:32,514 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/9327689762b2474bb001165d79a3fd27 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/9327689762b2474bb001165d79a3fd27
2014-07-22 06:50:32,532 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:50:32,540 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fcc2a0292d884efcb6a7ffdd761becb6, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fcc2a0292d884efcb6a7ffdd761becb6
2014-07-22 06:50:32,548 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f359601075364e12acb2a691e86db611, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f359601075364e12acb2a691e86db611
2014-07-22 06:50:32,551 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b5960e54d6f458bb787b7d3dd4ea50e, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/7b5960e54d6f458bb787b7d3dd4ea50e
2014-07-22 06:50:32,640 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1014f6c94f824b938cc4dc5c0cd9633e, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1014f6c94f824b938cc4dc5c0cd9633e
2014-07-22 06:50:32,643 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0c8330b0261141af8063d49197c2bcf5, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/0c8330b0261141af8063d49197c2bcf5
2014-07-22 06:50:32,645 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/84b46c4ebe0b40fe9c014f47562f9be0, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/84b46c4ebe0b40fe9c014f47562f9be0
2014-07-22 06:50:32,647 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a8c756b3ff3c4e3c91e5a87499136a6d, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a8c756b3ff3c4e3c91e5a87499136a6d
2014-07-22 06:50:32,649 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/3c6a34fd17684f0989b9d9bff011cd0a, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/3c6a34fd17684f0989b9d9bff011cd0a
2014-07-22 06:50:32,654 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/40a253bc66b54b91b90eebfc9d3f7703, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/40a253bc66b54b91b90eebfc9d3f7703
2014-07-22 06:50:32,657 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fffbf0301256413493443f7a74d5273c, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/fffbf0301256413493443f7a74d5273c
2014-07-22 06:50:32,658 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into 9327689762b2474bb001165d79a3fd27(size=682.4m), total size for store is 1.8g. This selection was in queue for 0sec, and took 1mins, 36sec to execute.
2014-07-22 06:50:32,658 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=10, fileSize=682.6m, priority=1989, time=133916360171902; duration=1mins, 36sec
2014-07-22 06:50:32,658 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-22 06:50:32,658 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 2000 blocking
2014-07-22 06:50:32,659 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 9 files of size 635885122 starting at candidate #1 after considering 36 permutations with 28 in ratio
2014-07-22 06:50:32,659 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating minor compaction
2014-07-22 06:50:32,660 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:50:32,660 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 9 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=606.4m
2014-07-22 06:50:32,660 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3163119de88448bfb7ff8f51c32cd6ad, keycount=93886, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=3467
2014-07-22 06:50:32,660 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/e317c6f8491f4836961520a2cbf3021c, keycount=93975, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=3634
2014-07-22 06:50:32,660 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/940cccf80b434ae1acc1a4c2f2994729, keycount=94809, bloomtype=ROW, size=67.5m, encoding=NONE, seqNum=3803
2014-07-22 06:50:32,660 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/861eccb04c9c40e3be3d9aca6e5a412e, keycount=100271, bloomtype=ROW, size=71.4m, encoding=NONE, seqNum=3982
2014-07-22 06:50:32,660 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8c142c73626f487d85d3ed963aed50c5, keycount=93489, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=4148
2014-07-22 06:50:32,661 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/1f08af39a6cf4193aface27a0f4e5ef2, keycount=93700, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=4315
2014-07-22 06:50:32,661 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8fc8cd6f23c748f4904c3a24e5e38ff9, keycount=94146, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=4482
2014-07-22 06:50:32,661 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5207dbe4002a45e196e0e607d04980c4, keycount=93258, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=4648
2014-07-22 06:50:32,661 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/48f8c3167dc144c5a2264b89558af6c8, keycount=93814, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=4815
2014-07-22 06:50:32,842 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:50:34,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:34,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19413 synced till here 19409
2014-07-22 06:50:34,252 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037029756 with entries=96, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037034010
2014-07-22 06:50:35,921 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4847, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/1725e3e781d54a8ab9a2b453a49e748b
2014-07-22 06:50:35,938 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/1725e3e781d54a8ab9a2b453a49e748b as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1725e3e781d54a8ab9a2b453a49e748b
2014-07-22 06:50:35,955 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1725e3e781d54a8ab9a2b453a49e748b, entries=934710, sequenceid=4847, filesize=66.6m
2014-07-22 06:50:35,955 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.7m/269190480, currentsize=73.3m/76878800 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9434ms, sequenceid=4847, compaction requested=true
2014-07-22 06:50:35,955 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-22 06:50:54,525 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:50:54,525 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 257.5m
2014-07-22 06:50:54,822 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:50:55,464 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:55,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19509 synced till here 19508
2014-07-22 06:50:55,685 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037034010 with entries=96, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037055465
2014-07-22 06:50:57,586 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:50:57,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19599 synced till here 19597
2014-07-22 06:50:57,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037055465 with entries=90, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037057586
2014-07-22 06:51:03,461 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4904, memsize=259.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/5b519f06dc2f4497b010ba6bf21097fe
2014-07-22 06:51:03,485 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/5b519f06dc2f4497b010ba6bf21097fe as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/5b519f06dc2f4497b010ba6bf21097fe
2014-07-22 06:51:03,503 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/5b519f06dc2f4497b010ba6bf21097fe, entries=943310, sequenceid=4904, filesize=67.2m
2014-07-22 06:51:03,503 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.1m/271665280, currentsize=55.7m/58428480 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8978ms, sequenceid=4904, compaction requested=true
2014-07-22 06:51:03,503 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:42), split_queue=0, merge_queue=0
2014-07-22 06:51:35,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:51:35,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19687 synced till here 19686
2014-07-22 06:51:35,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037057586 with entries=88, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037095273
2014-07-22 06:51:39,421 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:51:39,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037095273 with entries=87, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037099422
2014-07-22 06:51:40,364 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:51:40,364 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.9m
2014-07-22 06:51:40,585 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:51:44,955 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:51:44,956 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.3m
2014-07-22 06:51:45,164 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:51:45,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19867 synced till here 19863
2014-07-22 06:51:45,346 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:51:45,452 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037099422 with entries=93, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037105164
2014-07-22 06:51:47,026 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:51:47,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:51:47,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19956 synced till here 19954
2014-07-22 06:51:47,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037105164 with entries=89, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037107495
2014-07-22 06:51:50,092 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:51:50,347 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037107495 with entries=97, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037110195
2014-07-22 06:51:51,538 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4981, memsize=256.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/6e7b86afed854c0d811b4fae50296be8
2014-07-22 06:51:51,552 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/6e7b86afed854c0d811b4fae50296be8 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/6e7b86afed854c0d811b4fae50296be8
2014-07-22 06:51:51,573 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/6e7b86afed854c0d811b4fae50296be8, entries=935390, sequenceid=4981, filesize=66.7m
2014-07-22 06:51:51,573 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.9m/269384320, currentsize=121.3m/127162640 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 11209ms, sequenceid=4981, compaction requested=false
2014-07-22 06:51:51,573 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 328.3m
2014-07-22 06:51:52,006 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:51:52,047 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:51:52,175 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:51:52,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037110195 with entries=109, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037112006
2014-07-22 06:51:55,777 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4968, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/ca1101d9dd9a4d44a844739c3c77159e
2014-07-22 06:51:55,788 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/ca1101d9dd9a4d44a844739c3c77159e as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ca1101d9dd9a4d44a844739c3c77159e
2014-07-22 06:51:55,797 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ca1101d9dd9a4d44a844739c3c77159e, entries=933130, sequenceid=4968, filesize=66.5m
2014-07-22 06:51:55,797 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268715280, currentsize=38.3m/40111600 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10841ms, sequenceid=4968, compaction requested=true
2014-07-22 06:51:55,797 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-22 06:51:55,798 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 265.4m
2014-07-22 06:51:55,947 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:51:58,878 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8dc8ccdc890e481f8774b3225f521c09 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8dc8ccdc890e481f8774b3225f521c09
2014-07-22 06:51:58,895 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:51:58,903 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3163119de88448bfb7ff8f51c32cd6ad, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3163119de88448bfb7ff8f51c32cd6ad
2014-07-22 06:51:58,906 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/e317c6f8491f4836961520a2cbf3021c, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/e317c6f8491f4836961520a2cbf3021c
2014-07-22 06:51:58,908 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/940cccf80b434ae1acc1a4c2f2994729, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/940cccf80b434ae1acc1a4c2f2994729
2014-07-22 06:51:58,910 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/861eccb04c9c40e3be3d9aca6e5a412e, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/861eccb04c9c40e3be3d9aca6e5a412e
2014-07-22 06:51:58,912 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8c142c73626f487d85d3ed963aed50c5, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8c142c73626f487d85d3ed963aed50c5
2014-07-22 06:51:58,914 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/1f08af39a6cf4193aface27a0f4e5ef2, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/1f08af39a6cf4193aface27a0f4e5ef2
2014-07-22 06:51:58,916 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8fc8cd6f23c748f4904c3a24e5e38ff9, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8fc8cd6f23c748f4904c3a24e5e38ff9
2014-07-22 06:51:58,918 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5207dbe4002a45e196e0e607d04980c4, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5207dbe4002a45e196e0e607d04980c4
2014-07-22 06:51:58,920 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/48f8c3167dc144c5a2264b89558af6c8, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/48f8c3167dc144c5a2264b89558af6c8
2014-07-22 06:51:58,920 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 9 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into 8dc8ccdc890e481f8774b3225f521c09(size=606.3m), total size for store is 1.9g. This selection was in queue for 0sec, and took 1mins, 26sec to execute.
2014-07-22 06:51:58,921 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=9, fileSize=606.4m, priority=1990, time=134013050171383; duration=1mins, 26sec
2014-07-22 06:51:58,921 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-22 06:51:58,921 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 2000 blocking
2014-07-22 06:51:58,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 7 files of size 491125108 starting at candidate #1 after considering 21 permutations with 15 in ratio
2014-07-22 06:51:58,922 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 6a9abfa0046dd16d723f3fe367c1c68f - family: Initiating minor compaction
2014-07-22 06:51:58,922 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:51:58,922 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 7 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp, totalSize=468.4m
2014-07-22 06:51:58,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/30a967f05f264fa19e88f4f3548ffb25, keycount=93812, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=3901
2014-07-22 06:51:58,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1e325298a47c4f15b3808508244ba266, keycount=93846, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=4068
2014-07-22 06:51:58,922 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/87b026b8d9d64b0fb0948e35a899e5d5, keycount=93407, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=4234
2014-07-22 06:51:58,923 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1181f58ea503418ba94649533f6bdefd, keycount=93976, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=4401
2014-07-22 06:51:58,923 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6b6861d84034d80994c06279c3ac829, keycount=93377, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=4567
2014-07-22 06:51:58,923 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7222a51cd79445a9b517e179bafb2b75, keycount=94588, bloomtype=ROW, size=67.4m, encoding=NONE, seqNum=4736
2014-07-22 06:51:58,923 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/5b519f06dc2f4497b010ba6bf21097fe, keycount=94331, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=4904
2014-07-22 06:51:59,066 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:52:00,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:00,127 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20251 synced till here 20248
2014-07-22 06:52:00,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037112006 with entries=89, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037120109
2014-07-22 06:52:00,151 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036887624
2014-07-22 06:52:00,151 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036893756
2014-07-22 06:52:00,151 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036895654
2014-07-22 06:52:00,151 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036897737
2014-07-22 06:52:00,151 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036899920
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036901770
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036903594
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036930366
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036932820
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036935619
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036957379
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036989438
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036994165
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036996732
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406036998673
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037000617
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037003904
2014-07-22 06:52:00,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037007023
2014-07-22 06:52:02,405 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:02,815 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037120109 with entries=106, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037122406
2014-07-22 06:52:04,138 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5061, memsize=329.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/62ebdd09446a455e95ce83f16f3b93c2
2014-07-22 06:52:04,156 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/62ebdd09446a455e95ce83f16f3b93c2 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/62ebdd09446a455e95ce83f16f3b93c2
2014-07-22 06:52:04,171 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/62ebdd09446a455e95ce83f16f3b93c2, entries=1200850, sequenceid=5061, filesize=85.6m
2014-07-22 06:52:04,171 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~329.8m/345832720, currentsize=116.2m/121831840 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 12598ms, sequenceid=5061, compaction requested=true
2014-07-22 06:52:04,172 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-22 06:52:04,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:04,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037122406 with entries=89, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037124928
2014-07-22 06:52:04,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037024847
2014-07-22 06:52:04,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037029756
2014-07-22 06:52:06,072 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5076, memsize=265.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/ec04f196e5c2415fad61ce1b6af46b2b
2014-07-22 06:52:06,084 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/ec04f196e5c2415fad61ce1b6af46b2b as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ec04f196e5c2415fad61ce1b6af46b2b
2014-07-22 06:52:06,093 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/ec04f196e5c2415fad61ce1b6af46b2b, entries=966180, sequenceid=5076, filesize=68.9m
2014-07-22 06:52:06,094 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.4m/278253520, currentsize=110.7m/116075760 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 10296ms, sequenceid=5076, compaction requested=false
2014-07-22 06:52:11,744 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:52:11,745 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.0m
2014-07-22 06:52:11,910 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:52:15,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:15,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037124928 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037135605
2014-07-22 06:52:15,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037034010
2014-07-22 06:52:15,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037055465
2014-07-22 06:52:15,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037057586
2014-07-22 06:52:15,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037095273
2014-07-22 06:52:17,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:17,667 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037135605 with entries=88, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037137636
2014-07-22 06:52:20,817 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5148, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/cc3a8375bc1046348d35cf5dd528eee8
2014-07-22 06:52:20,839 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/cc3a8375bc1046348d35cf5dd528eee8 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/cc3a8375bc1046348d35cf5dd528eee8
2014-07-22 06:52:20,999 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/cc3a8375bc1046348d35cf5dd528eee8, entries=932210, sequenceid=5148, filesize=66.4m
2014-07-22 06:52:20,999 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.0m/268468160, currentsize=71.3m/74776800 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9254ms, sequenceid=5148, compaction requested=true
2014-07-22 06:52:20,999 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:44), split_queue=0, merge_queue=0
2014-07-22 06:52:32,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:32,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20710 synced till here 20709
2014-07-22 06:52:32,436 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037137636 with entries=88, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037152398
2014-07-22 06:52:34,121 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:52:34,122 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 257.2m
2014-07-22 06:52:34,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:34,374 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20800 synced till here 20799
2014-07-22 06:52:34,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037152398 with entries=90, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037154274
2014-07-22 06:52:34,441 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:52:35,010 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:52:35,010 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.7m
2014-07-22 06:52:35,198 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:52:42,281 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5229, memsize=258.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b43d6948a82340a68714f55d4ef9276b
2014-07-22 06:52:42,299 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b43d6948a82340a68714f55d4ef9276b as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b43d6948a82340a68714f55d4ef9276b
2014-07-22 06:52:42,319 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b43d6948a82340a68714f55d4ef9276b, entries=942140, sequenceid=5229, filesize=67.2m
2014-07-22 06:52:42,319 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.8m/271327840, currentsize=23.4m/24533760 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8197ms, sequenceid=5229, compaction requested=true
2014-07-22 06:52:42,320 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-22 06:52:42,949 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5242, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/389226d32c7949db9dfab18762fe9b88
2014-07-22 06:52:42,979 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/389226d32c7949db9dfab18762fe9b88 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/389226d32c7949db9dfab18762fe9b88
2014-07-22 06:52:42,992 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/389226d32c7949db9dfab18762fe9b88, entries=934730, sequenceid=5242, filesize=66.6m
2014-07-22 06:52:42,993 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269195440, currentsize=4.6m/4870000 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 7982ms, sequenceid=5242, compaction requested=true
2014-07-22 06:52:42,993 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-22 06:52:44,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:52:44,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20887 synced till here 20886
2014-07-22 06:52:44,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037154274 with entries=87, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037164773
2014-07-22 06:53:02,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:02,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20975 synced till here 20973
2014-07-22 06:53:02,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037164773 with entries=88, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037182881
2014-07-22 06:53:04,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:05,051 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037182881 with entries=103, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037184708
2014-07-22 06:53:06,664 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:53:06,665 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.4m
2014-07-22 06:53:07,018 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:53:07,462 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:07,483 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21169 synced till here 21167
2014-07-22 06:53:07,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037184708 with entries=91, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037187463
2014-07-22 06:53:08,148 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/fb03e720a6154092a4a0cfb511a49cb0 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/fb03e720a6154092a4a0cfb511a49cb0
2014-07-22 06:53:08,397 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:53:08,408 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/30a967f05f264fa19e88f4f3548ffb25, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/30a967f05f264fa19e88f4f3548ffb25
2014-07-22 06:53:08,416 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1e325298a47c4f15b3808508244ba266, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1e325298a47c4f15b3808508244ba266
2014-07-22 06:53:08,422 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/87b026b8d9d64b0fb0948e35a899e5d5, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/87b026b8d9d64b0fb0948e35a899e5d5
2014-07-22 06:53:08,426 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1181f58ea503418ba94649533f6bdefd, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/1181f58ea503418ba94649533f6bdefd
2014-07-22 06:53:08,432 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6b6861d84034d80994c06279c3ac829, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c6b6861d84034d80994c06279c3ac829
2014-07-22 06:53:08,437 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7222a51cd79445a9b517e179bafb2b75, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7222a51cd79445a9b517e179bafb2b75
2014-07-22 06:53:08,449 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/5b519f06dc2f4497b010ba6bf21097fe, to hdfs://master:54310/hbase/archive/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/5b519f06dc2f4497b010ba6bf21097fe
2014-07-22 06:53:08,450 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 7 file(s) in family of usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. into fb03e720a6154092a4a0cfb511a49cb0(size=468.1m), total size for store is 2.0g. This selection was in queue for 0sec, and took 1mins, 9sec to execute.
2014-07-22 06:53:08,450 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., storeName=family, fileCount=7, fileSize=468.4m, priority=1992, time=134099312502889; duration=1mins, 9sec
2014-07-22 06:53:08,450 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-22 06:53:08,451 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 2000 blocking
2014-07-22 06:53:08,451 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 6 files of size 630413023 starting at candidate #0 after considering 10 permutations with 8 in ratio
2014-07-22 06:53:08,452 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: a1bcd7cee994fe8eb603588f61ee109e - family: Initiating major compaction
2014-07-22 06:53:08,452 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:53:08,452 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 6 file(s) in family of usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp, totalSize=601.2m
2014-07-22 06:53:08,452 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/fdf38541936c4a42937a072f45a0569d, keycount=377556, bloomtype=ROW, size=268.8m, encoding=NONE, seqNum=2222, earliestPutTs=1406035270536
2014-07-22 06:53:08,453 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/667d406c8e1e4e089001843b7c25742e, keycount=93502, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=2772, earliestPutTs=1406036140719
2014-07-22 06:53:08,453 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3d347eb654eb45a0b609aaec2070814e, keycount=93307, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=3322, earliestPutTs=1406036310511
2014-07-22 06:53:08,453 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/934cb24d58fe48e29ad7f65bd377cd20, keycount=93237, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=3871, earliestPutTs=1406036505932
2014-07-22 06:53:08,453 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ae48a89e28ea4c3e8af933d0454fe971, keycount=93225, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=4419, earliestPutTs=1406036710424
2014-07-22 06:53:08,453 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ca1101d9dd9a4d44a844739c3c77159e, keycount=93313, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=4968, earliestPutTs=1406036889839
2014-07-22 06:53:08,641 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:53:15,174 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5315, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/59bb3aa8eb1345e287b48f13c02b4cdb
2014-07-22 06:53:15,196 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/59bb3aa8eb1345e287b48f13c02b4cdb as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/59bb3aa8eb1345e287b48f13c02b4cdb
2014-07-22 06:53:15,214 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/59bb3aa8eb1345e287b48f13c02b4cdb, entries=939420, sequenceid=5315, filesize=66.9m
2014-07-22 06:53:15,215 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.0m/270544080, currentsize=34.4m/36117040 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 8550ms, sequenceid=5315, compaction requested=true
2014-07-22 06:53:15,215 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-22 06:53:28,860 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:28,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21259 synced till here 21258
2014-07-22 06:53:28,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037187463 with entries=90, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037208860
2014-07-22 06:53:31,075 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:31,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21350 synced till here 21349
2014-07-22 06:53:31,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037208860 with entries=91, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037211076
2014-07-22 06:53:47,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:48,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037211076 with entries=89, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037227905
2014-07-22 06:53:48,396 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:53:48,396 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.7m
2014-07-22 06:53:48,798 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:53:49,006 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:53:49,006 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 257.4m
2014-07-22 06:53:49,198 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:53:50,323 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:53:50,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21527 synced till here 21526
2014-07-22 06:53:50,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037227905 with entries=88, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037230323
2014-07-22 06:53:57,273 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5410, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/f5d10a93048249f993ffe84a402d83cc
2014-07-22 06:53:57,285 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/f5d10a93048249f993ffe84a402d83cc as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/f5d10a93048249f993ffe84a402d83cc
2014-07-22 06:53:57,294 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5396, memsize=258.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/e38333c3328f40039834d6569749125e
2014-07-22 06:53:57,295 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/f5d10a93048249f993ffe84a402d83cc, entries=937250, sequenceid=5410, filesize=66.8m
2014-07-22 06:53:57,296 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.4m/269921040, currentsize=38.7m/40540640 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8290ms, sequenceid=5410, compaction requested=true
2014-07-22 06:53:57,296 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-22 06:53:57,302 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/e38333c3328f40039834d6569749125e as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/e38333c3328f40039834d6569749125e
2014-07-22 06:53:57,310 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/e38333c3328f40039834d6569749125e, entries=940230, sequenceid=5396, filesize=67.0m
2014-07-22 06:53:57,311 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.2m/270778240, currentsize=57.7m/60512720 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 8915ms, sequenceid=5396, compaction requested=true
2014-07-22 06:53:57,311 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:48), split_queue=0, merge_queue=0
2014-07-22 06:54:10,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:11,173 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21630 synced till here 21629
2014-07-22 06:54:11,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037230323 with entries=103, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037250809
2014-07-22 06:54:13,974 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:14,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21720 synced till here 21717
2014-07-22 06:54:14,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037250809 with entries=90, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037253975
2014-07-22 06:54:15,795 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:54:15,796 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.5m
2014-07-22 06:54:16,076 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:16,091 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:54:16,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21811 synced till here 21808
2014-07-22 06:54:16,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037253975 with entries=91, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037256077
2014-07-22 06:54:20,468 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:20,501 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037256077 with entries=87, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037260468
2014-07-22 06:54:24,920 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5484, memsize=261.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/4f3d758804b44119903a4590fff6b776
2014-07-22 06:54:24,938 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/4f3d758804b44119903a4590fff6b776 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4f3d758804b44119903a4590fff6b776
2014-07-22 06:54:24,961 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4f3d758804b44119903a4590fff6b776, entries=950640, sequenceid=5484, filesize=67.7m
2014-07-22 06:54:24,962 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.1m/273778400, currentsize=66.5m/69728160 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9166ms, sequenceid=5484, compaction requested=true
2014-07-22 06:54:24,962 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-22 06:54:28,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:29,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21986 synced till here 21985
2014-07-22 06:54:29,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037260468 with entries=88, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037268994
2014-07-22 06:54:32,725 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/a463dbf883d04148a60e372d54c6b0d5 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/a463dbf883d04148a60e372d54c6b0d5
2014-07-22 06:54:32,741 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:54:32,750 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/fdf38541936c4a42937a072f45a0569d, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/fdf38541936c4a42937a072f45a0569d
2014-07-22 06:54:32,754 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/667d406c8e1e4e089001843b7c25742e, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/667d406c8e1e4e089001843b7c25742e
2014-07-22 06:54:32,756 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3d347eb654eb45a0b609aaec2070814e, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3d347eb654eb45a0b609aaec2070814e
2014-07-22 06:54:32,759 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/934cb24d58fe48e29ad7f65bd377cd20, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/934cb24d58fe48e29ad7f65bd377cd20
2014-07-22 06:54:32,763 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ae48a89e28ea4c3e8af933d0454fe971, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ae48a89e28ea4c3e8af933d0454fe971
2014-07-22 06:54:32,768 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ca1101d9dd9a4d44a844739c3c77159e, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/ca1101d9dd9a4d44a844739c3c77159e
2014-07-22 06:54:32,768 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 6 file(s) in family of usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. into a463dbf883d04148a60e372d54c6b0d5(size=601.1m), total size for store is 601.1m. This selection was in queue for 0sec, and took 1mins, 24sec to execute.
2014-07-22 06:54:32,768 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., storeName=family, fileCount=6, fileSize=601.2m, priority=1994, time=134168842253434; duration=1mins, 24sec
2014-07-22 06:54:32,768 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-22 06:54:32,768 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 2000 blocking
2014-07-22 06:54:32,769 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 7 files of size 2263397219 starting at candidate #0 after considering 15 permutations with 8 in ratio
2014-07-22 06:54:32,769 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 86ea69fe85336d05b86e4198e206c41d - family: Initiating major compaction
2014-07-22 06:54:32,769 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:54:32,770 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 7 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp, totalSize=2.1g
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03256958e7a426b8917f597c5cd468e, keycount=1577270, bloomtype=ROW, size=1.1g, encoding=NONE, seqNum=2809, earliestPutTs=1406035270409
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/9327689762b2474bb001165d79a3fd27, keycount=958244, bloomtype=ROW, size=682.4m, encoding=NONE, seqNum=4514, earliestPutTs=1406036332711
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/28c91a0738074c6f88841b394a63ece7, keycount=93712, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=4681, earliestPutTs=1406036899678
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1725e3e781d54a8ab9a2b453a49e748b, keycount=93471, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=4847, earliestPutTs=1406036990633
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/62ebdd09446a455e95ce83f16f3b93c2, keycount=120085, bloomtype=ROW, size=85.6m, encoding=NONE, seqNum=5061, earliestPutTs=1406037026599
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b43d6948a82340a68714f55d4ef9276b, keycount=94214, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=5229, earliestPutTs=1406037111604
2014-07-22 06:54:32,770 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/e38333c3328f40039834d6569749125e, keycount=94023, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=5396, earliestPutTs=1406037154219
2014-07-22 06:54:32,819 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:54:33,140 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 06:54:33,140 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 256.2m
2014-07-22 06:54:33,430 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:54:34,595 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:34,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22075 synced till here 22074
2014-07-22 06:54:34,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037268994 with entries=89, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037274595
2014-07-22 06:54:35,541 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:54:35,542 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.2m
2014-07-22 06:54:35,958 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:54:36,069 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=390031, hits=5244, hitRatio=1.34%, , cachingAccesses=5247, cachingHits=5241, cachingHitsRatio=99.88%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:54:36,258 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:54:36,430 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:54:36,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22164 synced till here 22163
2014-07-22 06:54:36,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037274595 with entries=89, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037276431
2014-07-22 06:54:43,671 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5517, memsize=256.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/0f08abf384e040d38c4bf4c2b1539206
2014-07-22 06:54:43,695 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/0f08abf384e040d38c4bf4c2b1539206 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/0f08abf384e040d38c4bf4c2b1539206
2014-07-22 06:54:43,717 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/0f08abf384e040d38c4bf4c2b1539206, entries=932880, sequenceid=5517, filesize=66.5m
2014-07-22 06:54:43,717 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.2m/268644320, currentsize=23.9m/25105120 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 10577ms, sequenceid=5517, compaction requested=false
2014-07-22 06:54:43,718 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 287.9m
2014-07-22 06:54:43,912 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:54:44,837 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5564, memsize=259.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/a6616031bc9f4c8fb91e8ed801ed0d82
2014-07-22 06:54:44,849 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/a6616031bc9f4c8fb91e8ed801ed0d82 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a6616031bc9f4c8fb91e8ed801ed0d82
2014-07-22 06:54:44,860 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/a6616031bc9f4c8fb91e8ed801ed0d82, entries=943810, sequenceid=5564, filesize=67.3m
2014-07-22 06:54:44,861 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.2m/271811520, currentsize=46.5m/48809040 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 9319ms, sequenceid=5564, compaction requested=false
2014-07-22 06:54:53,115 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5596, memsize=287.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/9134cea01edb4ba78e3cf09863fe909f
2014-07-22 06:54:53,131 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/9134cea01edb4ba78e3cf09863fe909f as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9134cea01edb4ba78e3cf09863fe909f
2014-07-22 06:54:53,148 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/9134cea01edb4ba78e3cf09863fe909f, entries=1048330, sequenceid=5596, filesize=74.7m
2014-07-22 06:54:53,149 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~287.9m/301909200, currentsize=0.0/0 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9431ms, sequenceid=5596, compaction requested=true
2014-07-22 06:54:53,149 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-22 06:55:05,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:06,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22270 synced till here 22268
2014-07-22 06:55:06,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037276431 with entries=106, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037305545
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037099422
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037105164
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037107495
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037110195
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037112006
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037120109
2014-07-22 06:55:06,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037122406
2014-07-22 06:55:06,139 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037124928
2014-07-22 06:55:06,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037135605
2014-07-22 06:55:06,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037137636
2014-07-22 06:55:06,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037152398
2014-07-22 06:55:06,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037154274
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037164773
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037182881
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037184708
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037187463
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037208860
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037211076
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037227905
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037230323
2014-07-22 06:55:06,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037250809
2014-07-22 06:55:08,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:09,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037305545 with entries=89, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037308985
2014-07-22 06:55:11,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:12,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22451 synced till here 22449
2014-07-22 06:55:13,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037308985 with entries=92, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037311853
2014-07-22 06:55:13,393 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:55:13,394 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 256.1m
2014-07-22 06:55:13,994 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:55:14,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:14,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22550 synced till here 22536
2014-07-22 06:55:15,010 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037311853 with entries=99, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037314639
2014-07-22 06:55:17,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:17,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037314639 with entries=91, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037317241
2014-07-22 06:55:23,482 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5654, memsize=262.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/dc36b827444b44b9abb0292f6430c650
2014-07-22 06:55:23,501 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/dc36b827444b44b9abb0292f6430c650 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/dc36b827444b44b9abb0292f6430c650
2014-07-22 06:55:23,532 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/dc36b827444b44b9abb0292f6430c650, entries=955160, sequenceid=5654, filesize=68.0m
2014-07-22 06:55:23,533 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.3m/275078720, currentsize=61.9m/64944960 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 10139ms, sequenceid=5654, compaction requested=true
2014-07-22 06:55:23,533 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:50), split_queue=0, merge_queue=0
2014-07-22 06:55:47,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:47,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22729 synced till here 22728
2014-07-22 06:55:47,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037317241 with entries=88, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037347674
2014-07-22 06:55:47,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037253975
2014-07-22 06:55:47,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037256077
2014-07-22 06:55:47,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037260468
2014-07-22 06:55:49,051 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:55:49,052 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.8m
2014-07-22 06:55:49,380 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:55:49,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:50,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037347674 with entries=88, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037349941
2014-07-22 06:55:52,823 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 06:55:52,824 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 256.5m
2014-07-22 06:55:52,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:53,148 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:55:53,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22924 synced till here 22922
2014-07-22 06:55:53,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037349941 with entries=107, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037352988
2014-07-22 06:55:55,141 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:55:55,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037352988 with entries=87, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037355142
2014-07-22 06:55:59,210 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5731, memsize=258.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b5be684738e645ea9d28318eea33ba74
2014-07-22 06:55:59,236 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b5be684738e645ea9d28318eea33ba74 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b5be684738e645ea9d28318eea33ba74
2014-07-22 06:55:59,255 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b5be684738e645ea9d28318eea33ba74, entries=940700, sequenceid=5731, filesize=67.0m
2014-07-22 06:55:59,256 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.4m/270913360, currentsize=110.7m/116032000 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 10204ms, sequenceid=5731, compaction requested=false
2014-07-22 06:56:01,783 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5762, memsize=256.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/8a4f7e0461c74c288f6f858e6cde2481
2014-07-22 06:56:01,797 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/8a4f7e0461c74c288f6f858e6cde2481 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/8a4f7e0461c74c288f6f858e6cde2481
2014-07-22 06:56:01,823 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/8a4f7e0461c74c288f6f858e6cde2481, entries=933880, sequenceid=5762, filesize=66.6m
2014-07-22 06:56:01,824 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268949360, currentsize=64.8m/67946080 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 9000ms, sequenceid=5762, compaction requested=true
2014-07-22 06:56:01,825 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:51), split_queue=0, merge_queue=0
2014-07-22 06:56:16,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:56:16,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23107 synced till here 23105
2014-07-22 06:56:17,014 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037355142 with entries=96, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037376785
2014-07-22 06:56:17,464 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:56:17,464 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.0m
2014-07-22 06:56:17,706 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:56:18,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:56:18,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23198 synced till here 23196
2014-07-22 06:56:18,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037376785 with entries=91, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037378704
2014-07-22 06:56:21,163 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:56:21,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23287 synced till here 23286
2014-07-22 06:56:21,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037378704 with entries=89, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037381164
2014-07-22 06:56:26,757 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5820, memsize=257.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/75b27075301d4e8d86896582790e2d14
2014-07-22 06:56:26,773 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/75b27075301d4e8d86896582790e2d14 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/75b27075301d4e8d86896582790e2d14
2014-07-22 06:56:26,811 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/75b27075301d4e8d86896582790e2d14, entries=935830, sequenceid=5820, filesize=66.7m
2014-07-22 06:56:26,811 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.0m/269511280, currentsize=57.0m/59792960 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 9347ms, sequenceid=5820, compaction requested=true
2014-07-22 06:56:26,812 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:52), split_queue=0, merge_queue=0
2014-07-22 06:56:45,312 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:56:45,335 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037381164 with entries=86, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037405312
2014-07-22 06:56:47,173 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 06:56:47,174 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 256.3m
2014-07-22 06:56:47,350 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:56:54,346 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5897, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/f1dcd366da2f49f5a8bdff97de4fcb60
2014-07-22 06:56:54,359 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/f1dcd366da2f49f5a8bdff97de4fcb60 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f1dcd366da2f49f5a8bdff97de4fcb60
2014-07-22 06:56:54,369 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f1dcd366da2f49f5a8bdff97de4fcb60, entries=933360, sequenceid=5897, filesize=66.5m
2014-07-22 06:56:54,370 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268800880, currentsize=1.5m/1555040 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 7196ms, sequenceid=5897, compaction requested=true
2014-07-22 06:56:54,370 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-22 06:58:15,095 INFO  [regionserver60020-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1406034877632 znode expired, triggering replicatorRemoved event
2014-07-22 06:58:15,463 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:15,465 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:15,517 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037316033
2014-07-22 06:58:15,620 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037316033, length=73996265
2014-07-22 06:58:15,620 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:15,644 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037316033
2014-07-22 06:58:15,645 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037316033 after 1ms
2014-07-22 06:58:15,702 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:15,703 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:15,704 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:15,844 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015443.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:15,882 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015440.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:15,917 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015467.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:15,933 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015435.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:15,978 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015434.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:16,289 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037319960
2014-07-22 06:58:16,312 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037319960, length=89701287
2014-07-22 06:58:16,312 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:16,326 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037319960
2014-07-22 06:58:16,333 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037319960 after 6ms
2014-07-22 06:58:16,341 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:16,341 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:16,348 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:16,349 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015443.temp
2014-07-22 06:58:16,351 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015467.temp
2014-07-22 06:58:16,351 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015443.temp
2014-07-22 06:58:16,351 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015440.temp
2014-07-22 06:58:16,351 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015467.temp
2014-07-22 06:58:16,351 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015435.temp
2014-07-22 06:58:16,352 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015434.temp
2014-07-22 06:58:16,352 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015440.temp
2014-07-22 06:58:16,352 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:16,352 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:16,352 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:16,356 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015467.temp (wrote 25 edits in 207ms)
2014-07-22 06:58:16,357 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015440.temp (wrote 13 edits in 135ms)
2014-07-22 06:58:16,358 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015443.temp (wrote 24 edits in 207ms)
2014-07-22 06:58:16,361 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015467.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015491
2014-07-22 06:58:16,361 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015435.temp
2014-07-22 06:58:16,361 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015440.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015452
2014-07-22 06:58:16,361 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015434.temp
2014-07-22 06:58:16,364 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015443.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015467
2014-07-22 06:58:16,366 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015435.temp (wrote 11 edits in 124ms)
2014-07-22 06:58:16,367 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015434.temp (wrote 9 edits in 75ms)
2014-07-22 06:58:16,369 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015435.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015445
2014-07-22 06:58:16,372 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015434.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015442
2014-07-22 06:58:16,372 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 82 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037316033 is corrupted = false progress failed = false
2014-07-22 06:58:16,380 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037316033 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:16,380 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037316033 in 808ms
2014-07-22 06:58:16,393 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015492.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:16,394 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015453.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:16,451 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015443.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:16,460 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015468.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:16,576 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015446.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:16,981 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:16,981 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:16,987 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:16,987 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015468.temp
2014-07-22 06:58:16,987 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015492.temp
2014-07-22 06:58:16,988 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015468.temp
2014-07-22 06:58:16,988 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015453.temp
2014-07-22 06:58:16,988 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015492.temp
2014-07-22 06:58:16,988 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015446.temp
2014-07-22 06:58:16,988 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015453.temp
2014-07-22 06:58:16,988 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015443.temp
2014-07-22 06:58:16,998 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015492.temp (wrote 23 edits in 172ms)
2014-07-22 06:58:17,000 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015453.temp (wrote 23 edits in 182ms)
2014-07-22 06:58:17,002 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015468.temp (wrote 17 edits in 120ms)
2014-07-22 06:58:17,008 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015492.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015514
2014-07-22 06:58:17,008 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015446.temp
2014-07-22 06:58:17,016 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015453.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015475
2014-07-22 06:58:17,016 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015443.temp
2014-07-22 06:58:17,017 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015468.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015484
2014-07-22 06:58:17,019 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015446.temp (wrote 18 edits in 143ms)
2014-07-22 06:58:17,021 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015443.temp (wrote 19 edits in 189ms)
2014-07-22 06:58:17,030 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015446.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015464
2014-07-22 06:58:17,070 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015443.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015461
2014-07-22 06:58:17,071 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 100 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037319960 is corrupted = false progress failed = false
2014-07-22 06:58:17,078 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037319960 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:17,079 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037319960 in 788ms
2014-07-22 06:58:17,257 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037381520
2014-07-22 06:58:17,283 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037381520, length=78423790
2014-07-22 06:58:17,283 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:17,289 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037381520
2014-07-22 06:58:17,291 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037381520 after 2ms
2014-07-22 06:58:17,305 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:17,305 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:17,305 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:17,334 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015960.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:17,338 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015987.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:17,352 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015951.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:17,368 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015949.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:17,370 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015958.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:18,006 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037326352
2014-07-22 06:58:18,025 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037326352, length=88333489
2014-07-22 06:58:18,025 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:18,029 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037326352
2014-07-22 06:58:18,030 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037326352 after 1ms
2014-07-22 06:58:18,052 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:18,052 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:18,052 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:18,095 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015517.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:18,102 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015525.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:18,116 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015507.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:18,164 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015559.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:18,255 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015505.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:18,620 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:18,731 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Moving sceplus-vm48.almaden.ibm.com,60020,1406034877632's hlogs to my queue
2014-07-22 06:58:18,890 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:18,890 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:18,897 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:18,897 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015525.temp
2014-07-22 06:58:18,898 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015559.temp
2014-07-22 06:58:18,898 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015525.temp
2014-07-22 06:58:18,898 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015517.temp
2014-07-22 06:58:18,898 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015559.temp
2014-07-22 06:58:18,898 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015505.temp
2014-07-22 06:58:18,898 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015517.temp
2014-07-22 06:58:18,898 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015507.temp
2014-07-22 06:58:18,902 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015525.temp (wrote 22 edits in 272ms)
2014-07-22 06:58:18,908 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015525.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015546
2014-07-22 06:58:18,908 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015505.temp
2014-07-22 06:58:18,924 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015517.temp (wrote 21 edits in 234ms)
2014-07-22 06:58:18,928 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015505.temp (wrote 16 edits in 128ms)
2014-07-22 06:58:18,930 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015559.temp (wrote 16 edits in 174ms)
2014-07-22 06:58:18,937 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015517.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015537
2014-07-22 06:58:18,937 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015507.temp
2014-07-22 06:58:18,937 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015505.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015520
2014-07-22 06:58:18,940 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015559.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015574
2014-07-22 06:58:18,978 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015507.temp (wrote 23 edits in 221ms)
2014-07-22 06:58:18,984 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015507.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015529
2014-07-22 06:58:18,984 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 98 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037326352 is corrupted = false progress failed = false
2014-07-22 06:58:19,138 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037326352 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:19,138 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037326352 in 1132ms
2014-07-22 06:58:19,156 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:19,169 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037377643
2014-07-22 06:58:19,189 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037377643, length=72875696
2014-07-22 06:58:19,189 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:19,193 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037377643
2014-07-22 06:58:19,195 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037377643 after 2ms
2014-07-22 06:58:19,231 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:19,231 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:19,232 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:19,304 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015906.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:19,315 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015912.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:19,385 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015939.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:19,432 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:19,432 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:19,438 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:19,439 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015960.temp
2014-07-22 06:58:19,439 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015987.temp
2014-07-22 06:58:19,439 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015960.temp
2014-07-22 06:58:19,439 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015958.temp
2014-07-22 06:58:19,439 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015951.temp
2014-07-22 06:58:19,439 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015987.temp
2014-07-22 06:58:19,439 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015949.temp
2014-07-22 06:58:19,439 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015958.temp
2014-07-22 06:58:19,445 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015960.temp (wrote 19 edits in 178ms)
2014-07-22 06:58:19,446 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015958.temp (wrote 17 edits in 206ms)
2014-07-22 06:58:19,447 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015987.temp (wrote 20 edits in 176ms)
2014-07-22 06:58:19,449 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015960.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015978
2014-07-22 06:58:19,450 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015951.temp
2014-07-22 06:58:19,450 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015958.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015974
2014-07-22 06:58:19,451 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015949.temp
2014-07-22 06:58:19,453 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015987.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016006
2014-07-22 06:58:19,457 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015951.temp (wrote 16 edits in 142ms)
2014-07-22 06:58:19,459 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015949.temp (wrote 15 edits in 160ms)
2014-07-22 06:58:19,464 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015951.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015966
2014-07-22 06:58:19,465 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015949.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015963
2014-07-22 06:58:19,466 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 87 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037381520 is corrupted = false progress failed = false
2014-07-22 06:58:19,472 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037381520 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:19,472 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037381520 in 2215ms
2014-07-22 06:58:19,482 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:19,521 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015911.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:19,524 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015903.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:19,914 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037364069
2014-07-22 06:58:19,939 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037364069, length=97657548
2014-07-22 06:58:19,940 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:19,944 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037364069
2014-07-22 06:58:19,945 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037364069 after 1ms
2014-07-22 06:58:19,979 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:19,979 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:19,980 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:20,012 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015858.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:20,016 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015826.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:20,047 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015803.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:20,048 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015802.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:20,095 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015820.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:20,597 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:20,597 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:20,602 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:20,602 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015826.temp
2014-07-22 06:58:20,602 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015858.temp
2014-07-22 06:58:20,602 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015826.temp
2014-07-22 06:58:20,602 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015820.temp
2014-07-22 06:58:20,602 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015858.temp
2014-07-22 06:58:20,603 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015802.temp
2014-07-22 06:58:20,603 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015803.temp
2014-07-22 06:58:20,603 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015820.temp
2014-07-22 06:58:20,635 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015858.temp (wrote 26 edits in 187ms)
2014-07-22 06:58:20,747 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015820.temp (wrote 16 edits in 160ms)
2014-07-22 06:58:20,860 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:20,865 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:20,874 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015858.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015883
2014-07-22 06:58:20,874 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015802.temp
2014-07-22 06:58:20,878 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015826.temp (wrote 26 edits in 252ms)
2014-07-22 06:58:20,913 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015820.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015835
2014-07-22 06:58:20,914 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015803.temp
2014-07-22 06:58:21,073 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015826.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015851
2014-07-22 06:58:21,114 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015802.temp (wrote 20 edits in 209ms)
2014-07-22 06:58:21,116 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015803.temp (wrote 21 edits in 230ms)
2014-07-22 06:58:21,275 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015802.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015821
2014-07-22 06:58:21,415 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:21,415 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:21,423 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:21,423 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015912.temp
2014-07-22 06:58:21,423 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015939.temp
2014-07-22 06:58:21,423 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015912.temp
2014-07-22 06:58:21,423 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015911.temp
2014-07-22 06:58:21,423 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015939.temp
2014-07-22 06:58:21,424 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015906.temp
2014-07-22 06:58:21,424 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015903.temp
2014-07-22 06:58:21,424 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015911.temp
2014-07-22 06:58:21,438 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015803.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015824
2014-07-22 06:58:21,438 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 109 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037364069 is corrupted = false progress failed = false
2014-07-22 06:58:21,465 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037364069 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:21,465 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037364069 in 1550ms
2014-07-22 06:58:21,562 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015939.temp (wrote 15 edits in 103ms)
2014-07-22 06:58:21,565 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015911.temp (wrote 16 edits in 181ms)
2014-07-22 06:58:21,565 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015912.temp (wrote 17 edits in 131ms)
2014-07-22 06:58:21,663 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015911.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015926
2014-07-22 06:58:21,663 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015906.temp
2014-07-22 06:58:21,667 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015939.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015953
2014-07-22 06:58:21,667 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015903.temp
2014-07-22 06:58:21,678 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015912.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015928
2014-07-22 06:58:21,679 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:21,708 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037378531
2014-07-22 06:58:21,715 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015903.temp (wrote 17 edits in 204ms)
2014-07-22 06:58:21,715 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015906.temp (wrote 16 edits in 136ms)
2014-07-22 06:58:21,735 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037378531, length=67331252
2014-07-22 06:58:21,735 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:21,737 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015903.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015919
2014-07-22 06:58:21,746 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037378531
2014-07-22 06:58:21,750 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015906.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015921
2014-07-22 06:58:21,751 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 81 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037377643 is corrupted = false progress failed = false
2014-07-22 06:58:21,761 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037377643 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:21,761 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037377643 in 2591ms
2014-07-22 06:58:21,775 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:21,790 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037378531 after 44ms
2014-07-22 06:58:21,817 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:21,817 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:21,818 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:21,848 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015922.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:21,858 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015927.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:21,868 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015929.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:21,889 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015954.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:21,932 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015920.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:22,272 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:22,272 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:22,278 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:22,278 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015929.temp
2014-07-22 06:58:22,278 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015954.temp
2014-07-22 06:58:22,279 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015929.temp
2014-07-22 06:58:22,279 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015927.temp
2014-07-22 06:58:22,279 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015954.temp
2014-07-22 06:58:22,279 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015922.temp
2014-07-22 06:58:22,279 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015927.temp
2014-07-22 06:58:22,279 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015920.temp
2014-07-22 06:58:22,285 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015929.temp (wrote 16 edits in 146ms)
2014-07-22 06:58:22,293 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015954.temp (wrote 16 edits in 151ms)
2014-07-22 06:58:22,295 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015927.temp (wrote 15 edits in 116ms)
2014-07-22 06:58:22,300 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015929.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015944
2014-07-22 06:58:22,300 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015922.temp
2014-07-22 06:58:22,301 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015954.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015969
2014-07-22 06:58:22,301 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015920.temp
2014-07-22 06:58:22,303 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015927.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015941
2014-07-22 06:58:22,305 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015922.temp (wrote 14 edits in 113ms)
2014-07-22 06:58:22,310 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015920.temp (wrote 14 edits in 138ms)
2014-07-22 06:58:22,325 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015922.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015935
2014-07-22 06:58:22,366 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015920.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015933
2014-07-22 06:58:22,366 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 75 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037378531 is corrupted = false progress failed = false
2014-07-22 06:58:22,453 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037408679
2014-07-22 06:58:22,454 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037378531 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:22,454 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037378531 in 746ms
2014-07-22 06:58:22,470 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037408679, length=0
2014-07-22 06:58:22,470 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:22,473 WARN  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: File hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037408679 might be still open, length is 0
2014-07-22 06:58:22,473 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037408679
2014-07-22 06:58:22,518 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037408679 after 45ms
2014-07-22 06:58:23,436 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037396272
2014-07-22 06:58:23,460 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037396272, length=84436623
2014-07-22 06:58:23,460 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:23,463 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037396272
2014-07-22 06:58:23,464 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037396272 after 1ms
2014-07-22 06:58:23,486 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:23,487 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:23,488 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:23,530 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016066.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:23,560 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016083.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:23,561 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016110.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:23,597 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016076.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:23,598 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016064.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:24,325 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:24,325 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:24,330 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:24,331 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016083.temp
2014-07-22 06:58:24,331 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016110.temp
2014-07-22 06:58:24,331 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016083.temp
2014-07-22 06:58:24,331 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016076.temp
2014-07-22 06:58:24,331 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016110.temp
2014-07-22 06:58:24,331 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016064.temp
2014-07-22 06:58:24,331 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016066.temp
2014-07-22 06:58:24,331 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016076.temp
2014-07-22 06:58:24,340 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016110.temp (wrote 19 edits in 166ms)
2014-07-22 06:58:24,341 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016076.temp (wrote 22 edits in 157ms)
2014-07-22 06:58:24,344 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016083.temp (wrote 23 edits in 211ms)
2014-07-22 06:58:24,348 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016110.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016128
2014-07-22 06:58:24,348 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016064.temp
2014-07-22 06:58:24,349 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016076.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016097
2014-07-22 06:58:24,350 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016066.temp
2014-07-22 06:58:24,351 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016083.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016105
2014-07-22 06:58:24,353 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016064.temp (wrote 16 edits in 168ms)
2014-07-22 06:58:24,360 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016066.temp (wrote 14 edits in 155ms)
2014-07-22 06:58:24,365 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016064.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016079
2014-07-22 06:58:24,404 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016066.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016079
2014-07-22 06:58:24,404 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 94 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037396272 is corrupted = false progress failed = false
2014-07-22 06:58:24,414 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037396272 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:24,414 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037396272 in 973ms
2014-07-22 06:58:24,441 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037402815
2014-07-22 06:58:24,460 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037402815, length=69889719
2014-07-22 06:58:24,460 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:24,463 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037402815
2014-07-22 06:58:24,464 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037402815 after 1ms
2014-07-22 06:58:24,478 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:24,478 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:24,479 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:24,510 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016099.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:24,681 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016119.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:24,830 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016150.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:25,420 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:25,423 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:25,524 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016116.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:25,910 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016103.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:26,519 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037408679 after 4046ms
2014-07-22 06:58:26,539 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:26,539 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:26,542 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:26,559 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016165.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:26,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016180.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:26,578 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:26,584 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:26,590 ERROR [RS_LOG_REPLAY_OPS-slave1:60020-1] codec.BaseDecoder: Partial cell read caused by EOF: java.io.IOException: Premature EOF from inputStream
2014-07-22 06:58:26,592 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:26,593 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:26,605 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:26,615 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:26,615 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016180.temp
2014-07-22 06:58:26,615 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205.temp
2014-07-22 06:58:26,616 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016180.temp
2014-07-22 06:58:26,616 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175.temp
2014-07-22 06:58:26,616 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205.temp
2014-07-22 06:58:26,616 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168.temp
2014-07-22 06:58:26,616 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016165.temp
2014-07-22 06:58:26,616 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175.temp
2014-07-22 06:58:26,629 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175.temp (wrote 1 edits in 19ms)
2014-07-22 06:58:26,631 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016180.temp (wrote 2 edits in 45ms)
2014-07-22 06:58:26,631 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205.temp (wrote 1 edits in 25ms)
2014-07-22 06:58:26,634 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175
2014-07-22 06:58:26,634 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168.temp
2014-07-22 06:58:26,638 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016180.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016181
2014-07-22 06:58:26,638 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016165.temp
2014-07-22 06:58:26,639 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205
2014-07-22 06:58:26,641 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168.temp (wrote 1 edits in 17ms)
2014-07-22 06:58:26,642 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016165.temp (wrote 2 edits in 34ms)
2014-07-22 06:58:26,645 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168
2014-07-22 06:58:26,690 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016165.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016166
2014-07-22 06:58:26,690 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 7 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037408679 is corrupted = false progress failed = false
2014-07-22 06:58:26,696 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037408679 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:26,696 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037408679 in 4243ms
2014-07-22 06:58:26,714 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:26,720 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037385006
2014-07-22 06:58:26,742 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037385006, length=130523102
2014-07-22 06:58:26,742 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:26,745 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:26,745 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:26,746 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037385006
2014-07-22 06:58:26,748 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037385006 after 2ms
2014-07-22 06:58:26,751 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:26,751 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016119.temp
2014-07-22 06:58:26,752 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016150.temp
2014-07-22 06:58:26,752 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016119.temp
2014-07-22 06:58:26,752 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016116.temp
2014-07-22 06:58:26,752 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016150.temp
2014-07-22 06:58:26,752 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016103.temp
2014-07-22 06:58:26,752 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016099.temp
2014-07-22 06:58:26,752 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016116.temp
2014-07-22 06:58:26,756 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016119.temp (wrote 13 edits in 91ms)
2014-07-22 06:58:26,757 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016150.temp (wrote 6 edits in 47ms)
2014-07-22 06:58:26,758 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016116.temp (wrote 14 edits in 131ms)
2014-07-22 06:58:26,758 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:26,758 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:26,759 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:26,761 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016119.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016131
2014-07-22 06:58:26,761 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016103.temp
2014-07-22 06:58:26,761 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016150.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016155
2014-07-22 06:58:26,761 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016099.temp
2014-07-22 06:58:26,765 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016116.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016129
2014-07-22 06:58:26,765 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016103.temp (wrote 21 edits in 189ms)
2014-07-22 06:58:26,766 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016099.temp (wrote 24 edits in 166ms)
2014-07-22 06:58:26,768 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016103.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016123
2014-07-22 06:58:26,769 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016099.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016122
2014-07-22 06:58:26,769 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 78 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037402815 is corrupted = false progress failed = false
2014-07-22 06:58:26,774 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037402815 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:26,774 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037402815 in 2332ms
2014-07-22 06:58:26,788 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:26,793 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016026.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:26,794 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015997.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:26,813 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015981.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:26,814 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015993.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:26,880 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015980.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:27,342 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037359757
2014-07-22 06:58:27,360 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037359757, length=75594473
2014-07-22 06:58:27,360 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:27,364 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037359757
2014-07-22 06:58:27,365 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037359757 after 1ms
2014-07-22 06:58:27,379 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:27,380 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:27,380 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:27,424 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015771.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:27,489 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015815.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:27,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015787.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:27,679 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015772.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:27,785 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015784.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:28,090 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:28,093 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:29,404 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:29,404 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:29,410 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:29,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015787.temp
2014-07-22 06:58:29,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015815.temp
2014-07-22 06:58:29,410 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015787.temp
2014-07-22 06:58:29,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015784.temp
2014-07-22 06:58:29,411 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015771.temp
2014-07-22 06:58:29,411 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015772.temp
2014-07-22 06:58:29,411 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015784.temp
2014-07-22 06:58:29,411 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015815.temp
2014-07-22 06:58:29,421 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015787.temp (wrote 19 edits in 121ms)
2014-07-22 06:58:29,424 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015815.temp (wrote 19 edits in 119ms)
2014-07-22 06:58:29,424 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015784.temp (wrote 17 edits in 105ms)
2014-07-22 06:58:29,428 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015815.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015833
2014-07-22 06:58:29,428 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015771.temp
2014-07-22 06:58:29,428 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015787.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015805
2014-07-22 06:58:29,428 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015772.temp
2014-07-22 06:58:29,431 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015784.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015800
2014-07-22 06:58:29,433 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015772.temp (wrote 12 edits in 86ms)
2014-07-22 06:58:29,434 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015771.temp (wrote 17 edits in 107ms)
2014-07-22 06:58:29,439 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015772.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015783
2014-07-22 06:58:29,478 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015771.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015787
2014-07-22 06:58:29,478 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 84 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037359757 is corrupted = false progress failed = false
2014-07-22 06:58:29,486 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037359757 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:29,486 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037359757 in 2144ms
2014-07-22 06:58:29,497 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:29,523 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037349163
2014-07-22 06:58:29,542 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037349163, length=66372173
2014-07-22 06:58:29,542 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:29,545 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037349163
2014-07-22 06:58:29,548 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037349163 after 3ms
2014-07-22 06:58:29,563 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:29,563 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:29,564 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:29,594 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015675.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:29,618 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015707.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:29,625 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015677.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:29,675 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015684.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:29,851 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015683.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:30,136 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:30,316 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:30,316 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:30,326 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:30,326 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015684.temp
2014-07-22 06:58:30,327 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015707.temp
2014-07-22 06:58:30,327 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015684.temp
2014-07-22 06:58:30,327 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015683.temp
2014-07-22 06:58:30,327 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015707.temp
2014-07-22 06:58:30,327 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015677.temp
2014-07-22 06:58:30,327 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015675.temp
2014-07-22 06:58:30,327 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015683.temp
2014-07-22 06:58:30,331 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015684.temp (wrote 14 edits in 123ms)
2014-07-22 06:58:30,333 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015683.temp (wrote 14 edits in 281ms)
2014-07-22 06:58:30,334 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015707.temp (wrote 16 edits in 140ms)
2014-07-22 06:58:30,338 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015683.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015697
2014-07-22 06:58:30,338 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015677.temp
2014-07-22 06:58:30,339 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015684.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015697
2014-07-22 06:58:30,339 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015675.temp
2014-07-22 06:58:30,342 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015707.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015722
2014-07-22 06:58:30,342 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015677.temp (wrote 16 edits in 140ms)
2014-07-22 06:58:30,343 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015675.temp (wrote 14 edits in 115ms)
2014-07-22 06:58:30,346 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015677.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015692
2014-07-22 06:58:30,390 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015675.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015688
2014-07-22 06:58:30,390 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 74 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037349163 is corrupted = false progress failed = false
2014-07-22 06:58:30,395 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037349163 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:30,395 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037349163 in 871ms
2014-07-22 06:58:30,406 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:30,422 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037330967
2014-07-22 06:58:30,446 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037330967, length=76296272
2014-07-22 06:58:30,446 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:30,449 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037330967
2014-07-22 06:58:30,450 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037330967 after 1ms
2014-07-22 06:58:30,465 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:30,465 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:30,466 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:30,491 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015595.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:30,523 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015558.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:30,536 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015546.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:30,603 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015547.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:30,611 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015566.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:31,220 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:31,220 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:31,227 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:31,227 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015997.temp
2014-07-22 06:58:31,227 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016026.temp
2014-07-22 06:58:31,227 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015997.temp
2014-07-22 06:58:31,227 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015993.temp
2014-07-22 06:58:31,227 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016026.temp
2014-07-22 06:58:31,227 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015980.temp
2014-07-22 06:58:31,228 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015981.temp
2014-07-22 06:58:31,228 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015993.temp
2014-07-22 06:58:31,233 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015993.temp (wrote 27 edits in 224ms)
2014-07-22 06:58:31,234 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015997.temp (wrote 31 edits in 244ms)
2014-07-22 06:58:31,235 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016026.temp (wrote 33 edits in 221ms)
2014-07-22 06:58:31,237 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015993.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016019
2014-07-22 06:58:31,238 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015980.temp
2014-07-22 06:58:31,239 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015997.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016027
2014-07-22 06:58:31,239 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015981.temp
2014-07-22 06:58:31,241 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016026.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016058
2014-07-22 06:58:31,243 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015980.temp (wrote 29 edits in 215ms)
2014-07-22 06:58:31,244 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015981.temp (wrote 25 edits in 214ms)
2014-07-22 06:58:31,248 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015980.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016008
2014-07-22 06:58:31,286 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015981.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016005
2014-07-22 06:58:31,286 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 145 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037385006 is corrupted = false progress failed = false
2014-07-22 06:58:31,292 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037385006 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:31,292 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037385006 in 4571ms
2014-07-22 06:58:31,302 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:31,320 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:31,320 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:31,325 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:31,325 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015566.temp
2014-07-22 06:58:31,325 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015595.temp
2014-07-22 06:58:31,326 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015566.temp
2014-07-22 06:58:31,326 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015558.temp
2014-07-22 06:58:31,326 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015595.temp
2014-07-22 06:58:31,326 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015547.temp
2014-07-22 06:58:31,326 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015546.temp
2014-07-22 06:58:31,326 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015558.temp
2014-07-22 06:58:31,330 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015558.temp (wrote 18 edits in 118ms)
2014-07-22 06:58:31,333 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015566.temp (wrote 21 edits in 140ms)
2014-07-22 06:58:31,334 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015595.temp (wrote 17 edits in 126ms)
2014-07-22 06:58:31,341 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015558.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015575
2014-07-22 06:58:31,342 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015547.temp
2014-07-22 06:58:31,342 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015595.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015611
2014-07-22 06:58:31,342 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015546.temp
2014-07-22 06:58:31,344 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015566.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015586
2014-07-22 06:58:31,348 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015547.temp (wrote 14 edits in 101ms)
2014-07-22 06:58:31,349 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015546.temp (wrote 15 edits in 96ms)
2014-07-22 06:58:31,357 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015547.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015560
2014-07-22 06:58:31,399 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015546.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015560
2014-07-22 06:58:31,399 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 85 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037330967 is corrupted = false progress failed = false
2014-07-22 06:58:31,405 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037361943
2014-07-22 06:58:31,405 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037330967 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:31,405 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037330967 in 982ms
2014-07-22 06:58:31,426 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037361943, length=85800961
2014-07-22 06:58:31,426 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:31,429 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037361943
2014-07-22 06:58:31,437 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037361943 after 8ms
2014-07-22 06:58:31,457 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:31,457 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:31,458 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:31,512 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015834.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:31,577 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015784.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:31,709 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015806.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:31,726 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015801.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:31,874 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015788.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:32,358 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037405860
2014-07-22 06:58:32,377 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037405860, length=67617372
2014-07-22 06:58:32,377 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:32,390 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037405860
2014-07-22 06:58:32,393 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037405860 after 3ms
2014-07-22 06:58:32,426 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:32,426 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:32,427 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:32,537 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016171.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:32,678 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016145.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:32,678 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016147.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:32,840 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016137.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:32,842 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016141.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:33,063 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:33,063 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:33,074 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:33,074 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:33,085 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:33,085 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015806.temp
2014-07-22 06:58:33,086 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015834.temp
2014-07-22 06:58:33,086 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015806.temp
2014-07-22 06:58:33,086 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015801.temp
2014-07-22 06:58:33,086 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015834.temp
2014-07-22 06:58:33,086 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015788.temp
2014-07-22 06:58:33,086 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015784.temp
2014-07-22 06:58:33,086 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015801.temp
2014-07-22 06:58:33,091 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015806.temp (wrote 20 edits in 226ms)
2014-07-22 06:58:33,093 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015834.temp (wrote 24 edits in 280ms)
2014-07-22 06:58:33,093 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:33,093 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016147.temp
2014-07-22 06:58:33,094 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016171.temp
2014-07-22 06:58:33,094 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016147.temp
2014-07-22 06:58:33,094 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016145.temp
2014-07-22 06:58:33,094 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016171.temp
2014-07-22 06:58:33,094 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016141.temp
2014-07-22 06:58:33,094 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016137.temp
2014-07-22 06:58:33,094 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016145.temp
2014-07-22 06:58:33,095 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015801.temp (wrote 19 edits in 163ms)
2014-07-22 06:58:33,097 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015806.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015825
2014-07-22 06:58:33,097 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015788.temp
2014-07-22 06:58:33,097 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015834.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015857
2014-07-22 06:58:33,097 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015784.temp
2014-07-22 06:58:33,098 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016147.temp (wrote 17 edits in 451ms)
2014-07-22 06:58:33,100 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016171.temp (wrote 17 edits in 394ms)
2014-07-22 06:58:33,101 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015801.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015819
2014-07-22 06:58:33,102 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016145.temp (wrote 15 edits in 418ms)
2014-07-22 06:58:33,102 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015788.temp (wrote 14 edits in 90ms)
2014-07-22 06:58:33,103 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015784.temp (wrote 19 edits in 303ms)
2014-07-22 06:58:33,106 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016147.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016163
2014-07-22 06:58:33,106 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016141.temp
2014-07-22 06:58:33,108 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016145.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016159
2014-07-22 06:58:33,108 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016137.temp
2014-07-22 06:58:33,109 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015788.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015801
2014-07-22 06:58:33,110 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015784.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015802
2014-07-22 06:58:33,110 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 96 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037361943 is corrupted = false progress failed = false
2014-07-22 06:58:33,110 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016141.temp (wrote 12 edits in 280ms)
2014-07-22 06:58:33,111 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016137.temp (wrote 14 edits in 375ms)
2014-07-22 06:58:33,114 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037361943 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:33,114 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037361943 in 1709ms
2014-07-22 06:58:33,121 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016141.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016152
2014-07-22 06:58:33,162 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016137.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016150
2014-07-22 06:58:33,162 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016171.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016187
2014-07-22 06:58:33,162 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 75 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037405860 is corrupted = false progress failed = false
2014-07-22 06:58:33,169 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037405860 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:33,169 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037405860 in 810ms
2014-07-22 06:58:33,305 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037354249
2014-07-22 06:58:33,323 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037354249, length=69630570
2014-07-22 06:58:33,323 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:33,329 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037354249
2014-07-22 06:58:33,330 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037354249 after 1ms
2014-07-22 06:58:33,349 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:33,349 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:33,350 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:33,365 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015726.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:33,374 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015758.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:33,391 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015725.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:33,397 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015734.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:33,493 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015735.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:34,113 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:34,113 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:34,118 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:34,118 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015735.temp
2014-07-22 06:58:34,119 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015758.temp
2014-07-22 06:58:34,119 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015735.temp
2014-07-22 06:58:34,119 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015734.temp
2014-07-22 06:58:34,119 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015758.temp
2014-07-22 06:58:34,119 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015726.temp
2014-07-22 06:58:34,119 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015725.temp
2014-07-22 06:58:34,119 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015734.temp
2014-07-22 06:58:34,124 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015758.temp (wrote 17 edits in 113ms)
2014-07-22 06:58:34,128 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015735.temp (wrote 15 edits in 141ms)
2014-07-22 06:58:34,129 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015734.temp (wrote 15 edits in 115ms)
2014-07-22 06:58:34,140 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015758.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015774
2014-07-22 06:58:34,140 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015726.temp
2014-07-22 06:58:34,140 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015735.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015749
2014-07-22 06:58:34,140 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015725.temp
2014-07-22 06:58:34,143 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015734.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015748
2014-07-22 06:58:34,143 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015725.temp (wrote 16 edits in 127ms)
2014-07-22 06:58:34,148 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015726.temp (wrote 14 edits in 120ms)
2014-07-22 06:58:34,152 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015725.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015740
2014-07-22 06:58:34,162 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037333081
2014-07-22 06:58:34,164 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015726.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015739
2014-07-22 06:58:34,164 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 77 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037354249 is corrupted = false progress failed = false
2014-07-22 06:58:34,169 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037354249 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:34,169 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037354249 in 864ms
2014-07-22 06:58:34,219 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037333081, length=79228099
2014-07-22 06:58:34,219 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:34,227 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037333081
2014-07-22 06:58:34,227 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037333081 after 0ms
2014-07-22 06:58:34,257 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:34,257 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:34,258 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:34,276 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015561.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:34,295 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015561.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:34,298 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015587.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:34,305 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015576.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:34,402 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015612.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:34,766 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:34,766 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:34,774 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:34,775 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015587.temp
2014-07-22 06:58:34,775 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015612.temp
2014-07-22 06:58:34,775 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015587.temp
2014-07-22 06:58:34,775 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015576.temp
2014-07-22 06:58:34,775 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015612.temp
2014-07-22 06:58:34,775 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015561.temp
2014-07-22 06:58:34,775 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015561.temp
2014-07-22 06:58:34,776 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015576.temp
2014-07-22 06:58:34,781 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015612.temp (wrote 13 edits in 95ms)
2014-07-22 06:58:34,784 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015587.temp (wrote 12 edits in 108ms)
2014-07-22 06:58:34,784 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015576.temp (wrote 17 edits in 135ms)
2014-07-22 06:58:34,791 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015612.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015624
2014-07-22 06:58:34,792 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015561.temp
2014-07-22 06:58:34,792 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015587.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015598
2014-07-22 06:58:34,792 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015561.temp
2014-07-22 06:58:34,796 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015576.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015592
2014-07-22 06:58:34,805 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015561.temp (wrote 23 edits in 175ms)
2014-07-22 06:58:34,813 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015561.temp (wrote 23 edits in 188ms)
2014-07-22 06:58:34,821 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015561.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015583
2014-07-22 06:58:34,860 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015561.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015583
2014-07-22 06:58:34,861 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 88 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037333081 is corrupted = false progress failed = false
2014-07-22 06:58:35,043 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037333081 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:35,043 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037333081 in 881ms
2014-07-22 06:58:35,079 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037352538
2014-07-22 06:58:35,100 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037352538, length=91630745
2014-07-22 06:58:35,100 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:35,103 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037352538
2014-07-22 06:58:35,104 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037352538 after 1ms
2014-07-22 06:58:35,122 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:35,122 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:35,123 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:35,148 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015714.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:35,150 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015707.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:35,163 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015738.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:35,181 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015713.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:35,227 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015704.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:35,927 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:35,927 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:35,932 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:35,932 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015714.temp
2014-07-22 06:58:35,933 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015738.temp
2014-07-22 06:58:35,933 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015713.temp
2014-07-22 06:58:35,933 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015707.temp
2014-07-22 06:58:35,933 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015704.temp
2014-07-22 06:58:35,933 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015714.temp
2014-07-22 06:58:35,934 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015713.temp
2014-07-22 06:58:35,934 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015738.temp
2014-07-22 06:58:36,003 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037374051
2014-07-22 06:58:36,003 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015714.temp (wrote 21 edits in 138ms)
2014-07-22 06:58:36,022 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037374051, length=75985672
2014-07-22 06:58:36,022 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:36,042 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037374051
2014-07-22 06:58:36,050 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037374051 after 8ms
2014-07-22 06:58:36,065 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015738.temp (wrote 20 edits in 177ms)
2014-07-22 06:58:36,066 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015713.temp (wrote 21 edits in 146ms)
2014-07-22 06:58:36,065 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015714.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015734
2014-07-22 06:58:36,066 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015707.temp
2014-07-22 06:58:36,070 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015707.temp (wrote 19 edits in 141ms)
2014-07-22 06:58:36,071 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015738.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015757
2014-07-22 06:58:36,072 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015704.temp
2014-07-22 06:58:36,072 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015713.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015733
2014-07-22 06:58:36,074 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:36,074 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:36,074 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:36,078 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015704.temp (wrote 21 edits in 171ms)
2014-07-22 06:58:36,082 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015707.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015725
2014-07-22 06:58:36,110 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015704.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015724
2014-07-22 06:58:36,110 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 102 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037352538 is corrupted = false progress failed = false
2014-07-22 06:58:36,115 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037352538 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:36,115 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037352538 in 1036ms
2014-07-22 06:58:36,158 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015884.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:36,168 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015868.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:36,205 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015912.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:36,214 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015879.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:36,262 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015868.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:37,147 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037393561
2014-07-22 06:58:37,169 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037393561, length=78109480
2014-07-22 06:58:37,169 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:37,402 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037393561
2014-07-22 06:58:37,403 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037393561 after 1ms
2014-07-22 06:58:37,415 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:37,415 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:37,416 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:37,479 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016059.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:37,548 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016042.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:37,571 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016043.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:37,624 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016096.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:37,706 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:37,709 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:37,740 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016072.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:38,185 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:38,186 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:38,195 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:38,196 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015884.temp
2014-07-22 06:58:38,196 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015912.temp
2014-07-22 06:58:38,196 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015884.temp
2014-07-22 06:58:38,196 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015879.temp
2014-07-22 06:58:38,196 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015912.temp
2014-07-22 06:58:38,196 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015868.temp
2014-07-22 06:58:38,196 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015868.temp
2014-07-22 06:58:38,196 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015879.temp
2014-07-22 06:58:38,260 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015884.temp (wrote 16 edits in 164ms)
2014-07-22 06:58:38,313 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015879.temp (wrote 19 edits in 220ms)
2014-07-22 06:58:38,314 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015912.temp (wrote 13 edits in 153ms)
2014-07-22 06:58:38,330 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:38,330 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:38,443 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:38,443 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016072.temp
2014-07-22 06:58:38,443 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016096.temp
2014-07-22 06:58:38,444 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016072.temp
2014-07-22 06:58:38,444 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016059.temp
2014-07-22 06:58:38,444 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016096.temp
2014-07-22 06:58:38,444 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016043.temp
2014-07-22 06:58:38,444 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016042.temp
2014-07-22 06:58:38,444 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016059.temp
2014-07-22 06:58:38,545 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015884.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015899
2014-07-22 06:58:38,545 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015868.temp
2014-07-22 06:58:38,655 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016096.temp (wrote 14 edits in 172ms)
2014-07-22 06:58:38,655 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015879.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015897
2014-07-22 06:58:38,655 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016072.temp (wrote 11 edits in 159ms)
2014-07-22 06:58:38,655 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015912.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015924
2014-07-22 06:58:38,656 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015868.temp
2014-07-22 06:58:38,655 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016059.temp (wrote 17 edits in 202ms)
2014-07-22 06:58:38,706 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015868.temp (wrote 18 edits in 160ms)
2014-07-22 06:58:38,865 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016059.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016075
2014-07-22 06:58:38,865 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016043.temp
2014-07-22 06:58:38,903 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015868.temp (wrote 19 edits in 252ms)
2014-07-22 06:58:38,903 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016072.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016082
2014-07-22 06:58:38,903 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016096.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016109
2014-07-22 06:58:38,903 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016042.temp
2014-07-22 06:58:38,903 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015868.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015885
2014-07-22 06:58:38,993 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016043.temp (wrote 21 edits in 508ms)
2014-07-22 06:58:38,994 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015868.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015886
2014-07-22 06:58:38,994 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016042.temp (wrote 24 edits in 284ms)
2014-07-22 06:58:38,995 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 85 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037374051 is corrupted = false progress failed = false
2014-07-22 06:58:38,999 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016042.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016065
2014-07-22 06:58:38,999 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037374051 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:38,999 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037374051 in 2995ms
2014-07-22 06:58:39,017 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:39,026 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037387995
2014-07-22 06:58:39,028 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016043.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016063
2014-07-22 06:58:39,028 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 87 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037393561 is corrupted = false progress failed = false
2014-07-22 06:58:39,031 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037393561 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:39,031 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037393561 in 1883ms
2014-07-22 06:58:39,049 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:39,088 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037387995, length=92285624
2014-07-22 06:58:39,088 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:39,099 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037387995
2014-07-22 06:58:39,103 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037387995 after 4ms
2014-07-22 06:58:39,125 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:39,125 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:39,126 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:39,192 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016029.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:39,262 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016059.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:39,269 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016006.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:39,274 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016020.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:39,336 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016009.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:39,732 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:39,732 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:39,746 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037334925
2014-07-22 06:58:39,778 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:39,778 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016029.temp
2014-07-22 06:58:39,779 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016059.temp
2014-07-22 06:58:39,779 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016029.temp
2014-07-22 06:58:39,779 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016020.temp
2014-07-22 06:58:39,779 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016059.temp
2014-07-22 06:58:39,779 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016009.temp
2014-07-22 06:58:39,779 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016006.temp
2014-07-22 06:58:39,779 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016020.temp
2014-07-22 06:58:39,785 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037334925, length=78879689
2014-07-22 06:58:39,785 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:39,791 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037334925
2014-07-22 06:58:39,791 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016059.temp (wrote 20 edits in 181ms)
2014-07-22 06:58:39,793 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037334925 after 2ms
2014-07-22 06:58:39,810 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:39,810 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:39,811 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:39,819 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016059.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016078
2014-07-22 06:58:39,819 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016009.temp
2014-07-22 06:58:39,823 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016009.temp (wrote 18 edits in 124ms)
2014-07-22 06:58:39,830 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016009.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016026
2014-07-22 06:58:39,830 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016006.temp
2014-07-22 06:58:39,832 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015584.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:39,833 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016006.temp (wrote 23 edits in 188ms)
2014-07-22 06:58:39,834 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015599.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:39,838 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016006.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016028
2014-07-22 06:58:39,855 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015625.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:39,889 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015593.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:39,932 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015584.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:40,187 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016020.temp (wrote 23 edits in 193ms)
2014-07-22 06:58:40,190 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016029.temp (wrote 19 edits in 148ms)
2014-07-22 06:58:40,194 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016020.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016042
2014-07-22 06:58:40,195 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016029.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016047
2014-07-22 06:58:40,195 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 103 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037387995 is corrupted = false progress failed = false
2014-07-22 06:58:40,199 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037387995 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:40,199 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037387995 in 1172ms
2014-07-22 06:58:40,539 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:40,539 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:40,545 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:40,545 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015599.temp
2014-07-22 06:58:40,545 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015625.temp
2014-07-22 06:58:40,545 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015599.temp
2014-07-22 06:58:40,545 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015593.temp
2014-07-22 06:58:40,546 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015625.temp
2014-07-22 06:58:40,546 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015584.temp
2014-07-22 06:58:40,546 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015584.temp
2014-07-22 06:58:40,546 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015593.temp
2014-07-22 06:58:40,550 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015599.temp (wrote 18 edits in 146ms)
2014-07-22 06:58:40,551 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015593.temp (wrote 18 edits in 140ms)
2014-07-22 06:58:40,553 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015625.temp (wrote 16 edits in 126ms)
2014-07-22 06:58:40,556 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015599.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015616
2014-07-22 06:58:40,556 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015584.temp
2014-07-22 06:58:40,557 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015593.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015610
2014-07-22 06:58:40,557 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015584.temp
2014-07-22 06:58:40,560 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015625.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015640
2014-07-22 06:58:40,563 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015584.temp (wrote 17 edits in 134ms)
2014-07-22 06:58:40,564 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015584.temp (wrote 19 edits in 194ms)
2014-07-22 06:58:40,568 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015584.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015600
2014-07-22 06:58:40,607 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015584.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015602
2014-07-22 06:58:40,607 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 88 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037334925 is corrupted = false progress failed = false
2014-07-22 06:58:40,618 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037334925 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:40,618 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037334925 in 871ms
2014-07-22 06:58:40,625 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037343730
2014-07-22 06:58:40,642 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037343730, length=80355547
2014-07-22 06:58:40,642 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:40,645 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037343730
2014-07-22 06:58:40,646 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037343730 after 1ms
2014-07-22 06:58:40,664 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:40,665 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:40,666 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:40,703 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015660.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:40,736 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015617.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:40,746 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015626.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:40,800 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015631.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:40,867 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015619.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:41,180 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:41,180 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:41,186 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:41,186 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015631.temp
2014-07-22 06:58:41,186 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015660.temp
2014-07-22 06:58:41,186 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015631.temp
2014-07-22 06:58:41,186 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015626.temp
2014-07-22 06:58:41,187 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015660.temp
2014-07-22 06:58:41,187 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015619.temp
2014-07-22 06:58:41,187 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015617.temp
2014-07-22 06:58:41,187 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015626.temp
2014-07-22 06:58:41,191 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015660.temp (wrote 32 edits in 226ms)
2014-07-22 06:58:41,194 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015626.temp (wrote 10 edits in 77ms)
2014-07-22 06:58:41,196 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015631.temp (wrote 31 edits in 218ms)
2014-07-22 06:58:41,216 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015660.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015691
2014-07-22 06:58:41,216 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015619.temp
2014-07-22 06:58:41,233 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015626.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015635
2014-07-22 06:58:41,234 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015617.temp
2014-07-22 06:58:41,234 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015631.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015661
2014-07-22 06:58:41,236 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015619.temp (wrote 8 edits in 81ms)
2014-07-22 06:58:41,237 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015617.temp (wrote 9 edits in 65ms)
2014-07-22 06:58:41,248 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015619.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015626
2014-07-22 06:58:41,286 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015617.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015625
2014-07-22 06:58:41,286 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 90 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037343730 is corrupted = false progress failed = false
2014-07-22 06:58:41,291 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037343730 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:41,291 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037343730 in 666ms
2014-07-22 06:58:41,516 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037371067
2014-07-22 06:58:41,550 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037371067, length=81199136
2014-07-22 06:58:41,550 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:41,558 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037371067
2014-07-22 06:58:41,558 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037371067 after 0ms
2014-07-22 06:58:41,586 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:41,586 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:41,587 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:41,616 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015898.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:41,654 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015870.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:41,661 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015839.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:41,752 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015866.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:41,759 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015846.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:42,328 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:42,328 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:42,333 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:42,334 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015870.temp
2014-07-22 06:58:42,334 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015898.temp
2014-07-22 06:58:42,334 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015870.temp
2014-07-22 06:58:42,334 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015866.temp
2014-07-22 06:58:42,349 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015898.temp
2014-07-22 06:58:42,349 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015839.temp
2014-07-22 06:58:42,349 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015846.temp
2014-07-22 06:58:42,349 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015866.temp
2014-07-22 06:58:42,356 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015870.temp (wrote 14 edits in 110ms)
2014-07-22 06:58:42,358 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015898.temp (wrote 14 edits in 94ms)
2014-07-22 06:58:42,360 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015866.temp (wrote 13 edits in 116ms)
2014-07-22 06:58:42,370 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015870.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015883
2014-07-22 06:58:42,370 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015839.temp
2014-07-22 06:58:42,371 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015898.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015911
2014-07-22 06:58:42,371 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015846.temp
2014-07-22 06:58:42,373 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015866.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015878
2014-07-22 06:58:42,376 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015839.temp (wrote 28 edits in 169ms)
2014-07-22 06:58:42,377 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015846.temp (wrote 22 edits in 175ms)
2014-07-22 06:58:42,384 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015839.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015867
2014-07-22 06:58:42,421 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015846.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015867
2014-07-22 06:58:42,422 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 91 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037371067 is corrupted = false progress failed = false
2014-07-22 06:58:42,429 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037371067 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:42,429 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037371067 in 912ms
2014-07-22 06:58:42,505 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037356147
2014-07-22 06:58:42,521 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037356147, length=72472376
2014-07-22 06:58:42,521 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:42,528 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037356147
2014-07-22 06:58:42,530 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037356147 after 2ms
2014-07-22 06:58:42,562 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:42,562 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:42,563 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:42,586 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015775.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:42,590 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015740.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:42,610 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015749.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:42,616 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015750.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:42,707 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015741.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:43,404 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:43,404 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:43,409 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:43,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015750.temp
2014-07-22 06:58:43,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015775.temp
2014-07-22 06:58:43,410 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015750.temp
2014-07-22 06:58:43,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015749.temp
2014-07-22 06:58:43,410 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015775.temp
2014-07-22 06:58:43,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015740.temp
2014-07-22 06:58:43,410 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015741.temp
2014-07-22 06:58:43,410 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015749.temp
2014-07-22 06:58:43,416 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015775.temp (wrote 19 edits in 156ms)
2014-07-22 06:58:43,420 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015749.temp (wrote 17 edits in 107ms)
2014-07-22 06:58:43,420 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015750.temp (wrote 17 edits in 100ms)
2014-07-22 06:58:43,427 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015775.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015793
2014-07-22 06:58:43,428 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015740.temp
2014-07-22 06:58:43,429 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015749.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015765
2014-07-22 06:58:43,429 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015741.temp
2014-07-22 06:58:43,430 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015750.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015766
2014-07-22 06:58:43,433 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015740.temp (wrote 15 edits in 107ms)
2014-07-22 06:58:43,436 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015741.temp (wrote 13 edits in 141ms)
2014-07-22 06:58:43,443 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015740.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015754
2014-07-22 06:58:43,468 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037345249
2014-07-22 06:58:43,469 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015741.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015753
2014-07-22 06:58:43,470 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 81 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037356147 is corrupted = false progress failed = false
2014-07-22 06:58:43,477 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037356147 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:43,477 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037356147 in 972ms
2014-07-22 06:58:43,524 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037345249, length=98365976
2014-07-22 06:58:43,524 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:43,528 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037345249
2014-07-22 06:58:43,529 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037345249 after 1ms
2014-07-22 06:58:43,548 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:43,549 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:43,549 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:43,580 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015636.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:43,708 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015662.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:43,862 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015626.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:43,868 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015627.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:44,381 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037324232
2014-07-22 06:58:44,398 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037324232, length=98825307
2014-07-22 06:58:44,398 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:44,424 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037324232
2014-07-22 06:58:44,425 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037324232 after 1ms
2014-07-22 06:58:44,438 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:44,438 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:44,449 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:44,467 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:44,467 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:44,613 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015692.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:44,645 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:44,645 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015662.temp
2014-07-22 06:58:44,646 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015692.temp
2014-07-22 06:58:44,646 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015662.temp
2014-07-22 06:58:44,646 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015636.temp
2014-07-22 06:58:44,646 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015692.temp
2014-07-22 06:58:44,646 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015627.temp
2014-07-22 06:58:44,646 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015626.temp
2014-07-22 06:58:44,646 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015636.temp
2014-07-22 06:58:44,711 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015479.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:44,714 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015479.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:44,714 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015537.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:44,884 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015662.temp (wrote 7 edits in 57ms)
2014-07-22 06:58:44,885 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015692.temp (wrote 2 edits in 217ms)
2014-07-22 06:58:44,885 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015636.temp (wrote 32 edits in 231ms)
2014-07-22 06:58:45,218 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:45,220 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:45,343 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015499.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:45,345 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015509.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:45,399 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015692.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015693
2014-07-22 06:58:45,400 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015636.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015667
2014-07-22 06:58:45,400 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015662.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015668
2014-07-22 06:58:45,400 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015626.temp
2014-07-22 06:58:45,400 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015627.temp
2014-07-22 06:58:45,428 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015627.temp (wrote 34 edits in 228ms)
2014-07-22 06:58:45,431 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015626.temp (wrote 35 edits in 235ms)
2014-07-22 06:58:45,436 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015627.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015660
2014-07-22 06:58:45,438 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015626.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015660
2014-07-22 06:58:45,438 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 110 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037345249 is corrupted = false progress failed = false
2014-07-22 06:58:45,445 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037345249 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:45,445 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037345249 in 1976ms
2014-07-22 06:58:45,458 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:45,469 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037347043
2014-07-22 06:58:45,489 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037347043, length=65576124
2014-07-22 06:58:45,489 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:45,494 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037347043
2014-07-22 06:58:45,496 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037347043 after 1ms
2014-07-22 06:58:45,508 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:45,508 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:45,508 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:45,562 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015694.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:45,567 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015661.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:45,595 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015669.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:45,636 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:45,636 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:45,654 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015668.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:45,670 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:45,671 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015509.temp
2014-07-22 06:58:45,671 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015537.temp
2014-07-22 06:58:45,671 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015509.temp
2014-07-22 06:58:45,671 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015499.temp
2014-07-22 06:58:45,671 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015537.temp
2014-07-22 06:58:45,671 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015479.temp
2014-07-22 06:58:45,672 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015479.temp
2014-07-22 06:58:45,672 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015499.temp
2014-07-22 06:58:45,679 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015509.temp (wrote 16 edits in 755ms)
2014-07-22 06:58:45,681 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015499.temp (wrote 18 edits in 642ms)
2014-07-22 06:58:45,688 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015537.temp (wrote 22 edits in 566ms)
2014-07-22 06:58:45,691 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015499.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015516
2014-07-22 06:58:45,691 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015479.temp
2014-07-22 06:58:45,692 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015509.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015524
2014-07-22 06:58:45,692 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015479.temp
2014-07-22 06:58:45,695 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015537.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015558
2014-07-22 06:58:45,695 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015661.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:45,698 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015479.temp (wrote 26 edits in 557ms)
2014-07-22 06:58:45,699 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015479.temp (wrote 28 edits in 567ms)
2014-07-22 06:58:45,705 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015479.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015504
2014-07-22 06:58:45,748 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015479.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015506
2014-07-22 06:58:45,748 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 110 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037324232 is corrupted = false progress failed = false
2014-07-22 06:58:45,903 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037324232 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:45,903 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037324232 in 1521ms
2014-07-22 06:58:45,951 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:46,195 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:46,195 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:46,202 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:46,202 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015669.temp
2014-07-22 06:58:46,202 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015694.temp
2014-07-22 06:58:46,203 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015669.temp
2014-07-22 06:58:46,203 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015668.temp
2014-07-22 06:58:46,203 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015694.temp
2014-07-22 06:58:46,203 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015661.temp
2014-07-22 06:58:46,203 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015661.temp
2014-07-22 06:58:46,203 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015668.temp
2014-07-22 06:58:46,207 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015669.temp (wrote 15 edits in 137ms)
2014-07-22 06:58:46,208 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015668.temp (wrote 15 edits in 120ms)
2014-07-22 06:58:46,209 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015694.temp (wrote 13 edits in 126ms)
2014-07-22 06:58:46,217 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015669.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015683
2014-07-22 06:58:46,218 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015661.temp
2014-07-22 06:58:46,218 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015668.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015682
2014-07-22 06:58:46,218 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015661.temp
2014-07-22 06:58:46,221 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015694.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015706
2014-07-22 06:58:46,222 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015661.temp (wrote 16 edits in 162ms)
2014-07-22 06:58:46,222 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015661.temp (wrote 14 edits in 110ms)
2014-07-22 06:58:46,230 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015661.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015676
2014-07-22 06:58:46,269 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037336794
2014-07-22 06:58:46,270 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015661.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015674
2014-07-22 06:58:46,270 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 73 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037347043 is corrupted = false progress failed = false
2014-07-22 06:58:46,277 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037347043 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:46,277 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037347043 in 807ms
2014-07-22 06:58:46,285 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037336794, length=69878627
2014-07-22 06:58:46,285 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:46,289 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037336794
2014-07-22 06:58:46,290 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037336794 after 1ms
2014-07-22 06:58:46,310 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:46,310 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:46,311 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:46,345 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015603.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:46,350 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015641.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:46,356 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015611.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:46,363 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015617.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:46,389 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015601.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:47,121 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:47,121 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:47,126 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:47,127 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015617.temp
2014-07-22 06:58:47,127 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015641.temp
2014-07-22 06:58:47,127 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015617.temp
2014-07-22 06:58:47,127 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015611.temp
2014-07-22 06:58:47,127 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015641.temp
2014-07-22 06:58:47,127 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015603.temp
2014-07-22 06:58:47,128 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015601.temp
2014-07-22 06:58:47,128 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015611.temp
2014-07-22 06:58:47,139 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015617.temp (wrote 14 edits in 95ms)
2014-07-22 06:58:47,141 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015611.temp (wrote 15 edits in 129ms)
2014-07-22 06:58:47,142 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015641.temp (wrote 18 edits in 141ms)
2014-07-22 06:58:47,153 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015617.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015630
2014-07-22 06:58:47,154 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015603.temp
2014-07-22 06:58:47,154 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015611.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015625
2014-07-22 06:58:47,154 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015601.temp
2014-07-22 06:58:47,156 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015641.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015659
2014-07-22 06:58:47,157 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015603.temp (wrote 16 edits in 119ms)
2014-07-22 06:58:47,160 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015601.temp (wrote 16 edits in 101ms)
2014-07-22 06:58:47,166 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015603.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015618
2014-07-22 06:58:47,194 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037407225
2014-07-22 06:58:47,197 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015601.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015616
2014-07-22 06:58:47,198 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 79 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037336794 is corrupted = false progress failed = false
2014-07-22 06:58:47,205 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037336794 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:47,205 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037336794 in 936ms
2014-07-22 06:58:47,254 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037407225, length=69157200
2014-07-22 06:58:47,254 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:47,257 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037407225
2014-07-22 06:58:47,260 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037407225 after 3ms
2014-07-22 06:58:47,273 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:47,274 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:47,274 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:47,296 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016160.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:47,304 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016164.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:47,314 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016188.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:47,324 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016153.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:47,393 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016151.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:47,712 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:47,712 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:47,720 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:47,720 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016164.temp
2014-07-22 06:58:47,720 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016188.temp
2014-07-22 06:58:47,720 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016164.temp
2014-07-22 06:58:47,720 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016160.temp
2014-07-22 06:58:47,720 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016188.temp
2014-07-22 06:58:47,721 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016153.temp
2014-07-22 06:58:47,721 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016160.temp
2014-07-22 06:58:47,721 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016151.temp
2014-07-22 06:58:47,725 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016160.temp (wrote 15 edits in 127ms)
2014-07-22 06:58:47,728 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016188.temp (wrote 17 edits in 121ms)
2014-07-22 06:58:47,729 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016164.temp (wrote 16 edits in 124ms)
2014-07-22 06:58:47,740 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016160.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016174
2014-07-22 06:58:47,740 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016153.temp
2014-07-22 06:58:47,740 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016188.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016204
2014-07-22 06:58:47,740 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016151.temp
2014-07-22 06:58:47,743 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016164.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016179
2014-07-22 06:58:47,745 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016153.temp (wrote 15 edits in 137ms)
2014-07-22 06:58:47,747 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016151.temp (wrote 14 edits in 111ms)
2014-07-22 06:58:47,753 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016153.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016167
2014-07-22 06:58:47,796 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016151.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016164
2014-07-22 06:58:47,797 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 77 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037407225 is corrupted = false progress failed = false
2014-07-22 06:58:47,805 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037407225 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:47,805 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037407225 in 611ms
2014-07-22 06:58:48,021 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037322081
2014-07-22 06:58:48,037 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037322081, length=89995097
2014-07-22 06:58:48,037 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:48,045 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037322081
2014-07-22 06:58:48,046 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037322081 after 1ms
2014-07-22 06:58:48,080 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:48,080 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:48,080 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:48,104 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015465.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:48,112 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015515.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:48,154 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015462.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:48,161 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015476.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:48,236 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015485.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:49,059 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037391633
2014-07-22 06:58:49,077 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037391633, length=77613911
2014-07-22 06:58:49,077 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:49,081 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037391633
2014-07-22 06:58:49,083 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037391633 after 2ms
2014-07-22 06:58:49,093 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:49,093 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:49,094 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:49,114 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016043.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:49,138 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016079.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:49,156 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016029.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:49,161 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016027.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:49,246 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016048.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:49,590 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:49,591 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:49,601 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:49,601 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015485.temp
2014-07-22 06:58:49,601 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015515.temp
2014-07-22 06:58:49,601 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015485.temp
2014-07-22 06:58:49,601 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015476.temp
2014-07-22 06:58:49,602 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015515.temp
2014-07-22 06:58:49,602 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015465.temp
2014-07-22 06:58:49,602 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015462.temp
2014-07-22 06:58:49,602 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015476.temp
2014-07-22 06:58:49,605 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:49,608 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:49,645 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015515.temp (wrote 22 edits in 220ms)
2014-07-22 06:58:49,647 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015485.temp (wrote 24 edits in 232ms)
2014-07-22 06:58:49,649 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015476.temp (wrote 23 edits in 172ms)
2014-07-22 06:58:49,651 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015515.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015536
2014-07-22 06:58:49,651 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015465.temp
2014-07-22 06:58:49,652 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015485.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015508
2014-07-22 06:58:49,652 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015462.temp
2014-07-22 06:58:49,656 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015465.temp (wrote 14 edits in 138ms)
2014-07-22 06:58:49,656 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015476.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015498
2014-07-22 06:58:49,657 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015462.temp (wrote 17 edits in 177ms)
2014-07-22 06:58:49,659 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015465.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015478
2014-07-22 06:58:49,699 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015462.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015478
2014-07-22 06:58:49,699 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 100 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037322081 is corrupted = false progress failed = false
2014-07-22 06:58:49,703 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037322081 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:49,703 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037322081 in 1682ms
2014-07-22 06:58:49,718 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:49,725 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037328978
2014-07-22 06:58:49,749 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037328978, length=90739096
2014-07-22 06:58:49,749 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:49,753 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037328978
2014-07-22 06:58:49,755 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037328978 after 1ms
2014-07-22 06:58:49,768 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:49,768 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:49,768 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:49,795 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015538.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:49,804 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015521.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:49,846 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015547.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:49,862 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015530.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:49,980 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015575.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:49,997 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:49,997 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:50,013 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:50,013 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016048.temp
2014-07-22 06:58:50,013 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016079.temp
2014-07-22 06:58:50,014 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016048.temp
2014-07-22 06:58:50,014 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016043.temp
2014-07-22 06:58:50,014 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016079.temp
2014-07-22 06:58:50,014 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016027.temp
2014-07-22 06:58:50,014 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016029.temp
2014-07-22 06:58:50,014 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016043.temp
2014-07-22 06:58:50,048 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016079.temp (wrote 17 edits in 186ms)
2014-07-22 06:58:50,057 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016048.temp (wrote 24 edits in 240ms)
2014-07-22 06:58:50,205 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016043.temp (wrote 16 edits in 182ms)
2014-07-22 06:58:50,210 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016048.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016071
2014-07-22 06:58:50,210 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016079.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016095
2014-07-22 06:58:50,210 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016027.temp
2014-07-22 06:58:50,210 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016029.temp
2014-07-22 06:58:50,213 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016043.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016058
2014-07-22 06:58:50,254 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016027.temp (wrote 16 edits in 142ms)
2014-07-22 06:58:50,271 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016027.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016042
2014-07-22 06:58:50,296 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 2 tasks in progress and can't take more.
2014-07-22 06:58:50,505 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:50,505 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:50,510 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:50,510 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015547.temp
2014-07-22 06:58:50,510 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015575.temp
2014-07-22 06:58:50,510 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015547.temp
2014-07-22 06:58:50,511 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015538.temp
2014-07-22 06:58:50,511 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015575.temp
2014-07-22 06:58:50,511 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015521.temp
2014-07-22 06:58:50,511 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015530.temp
2014-07-22 06:58:50,511 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015538.temp
2014-07-22 06:58:50,518 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015547.temp (wrote 19 edits in 133ms)
2014-07-22 06:58:50,525 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015547.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015565
2014-07-22 06:58:50,526 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015521.temp
2014-07-22 06:58:50,538 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015575.temp (wrote 20 edits in 144ms)
2014-07-22 06:58:50,543 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015521.temp (wrote 26 edits in 210ms)
2014-07-22 06:58:50,543 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015538.temp (wrote 20 edits in 152ms)
2014-07-22 06:58:50,550 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015575.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015594
2014-07-22 06:58:50,550 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015530.temp
2014-07-22 06:58:50,551 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015521.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015546
2014-07-22 06:58:50,553 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015538.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015557
2014-07-22 06:58:50,590 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015530.temp (wrote 16 edits in 110ms)
2014-07-22 06:58:50,600 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015530.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015545
2014-07-22 06:58:50,601 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 101 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037328978 is corrupted = false progress failed = false
2014-07-22 06:58:50,609 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037328978 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:50,609 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037328978 in 884ms
2014-07-22 06:58:50,617 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016029.temp (wrote 13 edits in 141ms)
2014-07-22 06:58:50,619 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:50,621 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016029.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016041
2014-07-22 06:58:50,621 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 86 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037391633 is corrupted = false progress failed = false
2014-07-22 06:58:50,625 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037391633 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:50,625 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037391633 in 1565ms
2014-07-22 06:58:50,625 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037383210
2014-07-22 06:58:50,636 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:50,641 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037383210, length=76205532
2014-07-22 06:58:50,641 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:50,646 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037383210
2014-07-22 06:58:50,647 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037383210 after 1ms
2014-07-22 06:58:50,666 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:50,666 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:50,666 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:50,703 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016007.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:50,711 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015979.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:50,762 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015975.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:50,768 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015964.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:50,826 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015967.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:51,710 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037398409
2014-07-22 06:58:51,730 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037398409, length=83935214
2014-07-22 06:58:51,730 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:51,744 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037398409
2014-07-22 06:58:51,745 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037398409 after 1ms
2014-07-22 06:58:51,765 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:51,765 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:51,765 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:51,870 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:51,870 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:51,871 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016098.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:51,877 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:51,878 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015979.temp
2014-07-22 06:58:51,878 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016007.temp
2014-07-22 06:58:51,878 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015979.temp
2014-07-22 06:58:51,878 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015975.temp
2014-07-22 06:58:51,878 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016007.temp
2014-07-22 06:58:51,878 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015967.temp
2014-07-22 06:58:51,878 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015964.temp
2014-07-22 06:58:51,879 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015975.temp
2014-07-22 06:58:51,882 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016007.temp (wrote 19 edits in 159ms)
2014-07-22 06:58:51,883 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015979.temp (wrote 18 edits in 140ms)
2014-07-22 06:58:51,884 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015975.temp (wrote 18 edits in 121ms)
2014-07-22 06:58:51,888 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016007.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016025
2014-07-22 06:58:51,888 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015967.temp
2014-07-22 06:58:51,889 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015979.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015996
2014-07-22 06:58:51,889 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015964.temp
2014-07-22 06:58:51,891 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015975.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015992
2014-07-22 06:58:51,892 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015967.temp (wrote 13 edits in 105ms)
2014-07-22 06:58:51,893 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015964.temp (wrote 17 edits in 128ms)
2014-07-22 06:58:51,900 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015967.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015979
2014-07-22 06:58:51,902 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015964.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015980
2014-07-22 06:58:51,902 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 85 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037383210 is corrupted = false progress failed = false
2014-07-22 06:58:51,906 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037383210 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:51,906 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037383210 in 1281ms
2014-07-22 06:58:51,948 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016129.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:51,982 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016080.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:52,072 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016106.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:52,147 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016080.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:52,507 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037380068
2014-07-22 06:58:52,523 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037380068, length=69681729
2014-07-22 06:58:52,523 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:52,553 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037380068
2014-07-22 06:58:52,554 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037380068 after 1ms
2014-07-22 06:58:52,574 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:52,574 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:52,574 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:52,611 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:52,611 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:52,611 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015936.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:52,617 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:52,617 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016106.temp
2014-07-22 06:58:52,618 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016129.temp
2014-07-22 06:58:52,618 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016106.temp
2014-07-22 06:58:52,618 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016098.temp
2014-07-22 06:58:52,618 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016129.temp
2014-07-22 06:58:52,618 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016080.temp
2014-07-22 06:58:52,618 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016080.temp
2014-07-22 06:58:52,618 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016098.temp
2014-07-22 06:58:52,622 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016106.temp (wrote 13 edits in 113ms)
2014-07-22 06:58:52,623 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016129.temp (wrote 20 edits in 175ms)
2014-07-22 06:58:52,624 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016098.temp (wrote 18 edits in 154ms)
2014-07-22 06:58:52,624 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015942.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:52,627 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016106.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016118
2014-07-22 06:58:52,627 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016080.temp
2014-07-22 06:58:52,628 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016129.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016149
2014-07-22 06:58:52,628 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016080.temp
2014-07-22 06:58:52,630 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016098.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016115
2014-07-22 06:58:52,631 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016080.temp (wrote 23 edits in 170ms)
2014-07-22 06:58:52,632 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016080.temp (wrote 19 edits in 149ms)
2014-07-22 06:58:52,633 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015945.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:52,635 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016080.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016102
2014-07-22 06:58:52,665 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016080.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016098
2014-07-22 06:58:52,666 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 93 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037398409 is corrupted = false progress failed = false
2014-07-22 06:58:52,668 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015970.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:52,671 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037398409 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:52,671 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037398409 in 961ms
2014-07-22 06:58:52,715 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015934.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:53,431 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:53,432 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:53,436 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:53,437 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015945.temp
2014-07-22 06:58:53,437 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015970.temp
2014-07-22 06:58:53,437 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015945.temp
2014-07-22 06:58:53,437 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015942.temp
2014-07-22 06:58:53,437 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015970.temp
2014-07-22 06:58:53,437 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015936.temp
2014-07-22 06:58:53,437 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015934.temp
2014-07-22 06:58:53,438 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015942.temp
2014-07-22 06:58:53,441 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015945.temp (wrote 15 edits in 99ms)
2014-07-22 06:58:53,443 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015970.temp (wrote 17 edits in 161ms)
2014-07-22 06:58:53,445 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015942.temp (wrote 16 edits in 154ms)
2014-07-22 06:58:53,453 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015945.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015959
2014-07-22 06:58:53,454 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015936.temp
2014-07-22 06:58:53,454 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015970.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015986
2014-07-22 06:58:53,454 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015934.temp
2014-07-22 06:58:53,457 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015942.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015957
2014-07-22 06:58:53,457 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015936.temp (wrote 15 edits in 131ms)
2014-07-22 06:58:53,459 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015934.temp (wrote 15 edits in 164ms)
2014-07-22 06:58:53,466 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015936.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015950
2014-07-22 06:58:53,494 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037375980
2014-07-22 06:58:53,495 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015934.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015948
2014-07-22 06:58:53,495 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 78 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037380068 is corrupted = false progress failed = false
2014-07-22 06:58:53,505 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037380068 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:53,505 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037380068 in 998ms
2014-07-22 06:58:53,548 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037375980, length=67131782
2014-07-22 06:58:53,548 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:53,557 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037375980
2014-07-22 06:58:53,563 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037375980 after 6ms
2014-07-22 06:58:53,590 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:53,590 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:53,592 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:53,614 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015925.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:53,624 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015886.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:53,703 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015898.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:53,791 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015887.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:53,846 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015900.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:54,447 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037357633
2014-07-22 06:58:54,476 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037357633, length=82986914
2014-07-22 06:58:54,476 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:54,622 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037357633
2014-07-22 06:58:54,624 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037357633 after 2ms
2014-07-22 06:58:54,653 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:54,654 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:54,654 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:54,735 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015754.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:54,801 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015755.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:54,866 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015766.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:54,904 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015794.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:54,980 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:54,980 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:54,985 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:54,986 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015900.temp
2014-07-22 06:58:54,986 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015925.temp
2014-07-22 06:58:54,986 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015898.temp
2014-07-22 06:58:54,986 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015900.temp
2014-07-22 06:58:54,986 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015925.temp
2014-07-22 06:58:54,986 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015886.temp
2014-07-22 06:58:54,986 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015898.temp
2014-07-22 06:58:54,986 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015887.temp
2014-07-22 06:58:54,991 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015900.temp (wrote 12 edits in 182ms)
2014-07-22 06:58:55,000 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015898.temp (wrote 13 edits in 85ms)
2014-07-22 06:58:55,004 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015925.temp (wrote 14 edits in 129ms)
2014-07-22 06:58:55,007 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015900.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015911
2014-07-22 06:58:55,007 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015886.temp
2014-07-22 06:58:55,013 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015898.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015910
2014-07-22 06:58:55,013 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015925.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015938
2014-07-22 06:58:55,013 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015887.temp
2014-07-22 06:58:55,016 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015886.temp (wrote 20 edits in 169ms)
2014-07-22 06:58:55,021 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015887.temp (wrote 16 edits in 162ms)
2014-07-22 06:58:55,025 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015886.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015905
2014-07-22 06:58:55,036 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015767.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:55,077 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015887.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015902
2014-07-22 06:58:55,078 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 75 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037375980 is corrupted = false progress failed = false
2014-07-22 06:58:55,255 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037375980 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:55,256 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037375980 in 1762ms
2014-07-22 06:58:55,582 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037350702
2014-07-22 06:58:55,598 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037350702, length=67239652
2014-07-22 06:58:55,598 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:55,603 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037350702
2014-07-22 06:58:55,604 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037350702 after 1ms
2014-07-22 06:58:55,614 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:55,614 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:55,614 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:55,629 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015698.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:55,692 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015689.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:55,736 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015723.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:55,738 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015698.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:55,781 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015693.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:56,242 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:56,242 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:56,247 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:56,247 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015767.temp
2014-07-22 06:58:56,248 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015794.temp
2014-07-22 06:58:56,248 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015767.temp
2014-07-22 06:58:56,248 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015766.temp
2014-07-22 06:58:56,248 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015794.temp
2014-07-22 06:58:56,248 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015755.temp
2014-07-22 06:58:56,248 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015754.temp
2014-07-22 06:58:56,248 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015766.temp
2014-07-22 06:58:56,253 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015767.temp (wrote 20 edits in 201ms)
2014-07-22 06:58:56,254 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015794.temp (wrote 21 edits in 164ms)
2014-07-22 06:58:56,255 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015766.temp (wrote 18 edits in 152ms)
2014-07-22 06:58:56,257 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015767.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015786
2014-07-22 06:58:56,257 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015755.temp
2014-07-22 06:58:56,258 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015794.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015814
2014-07-22 06:58:56,258 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015754.temp
2014-07-22 06:58:56,260 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015766.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015783
2014-07-22 06:58:56,261 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015755.temp (wrote 16 edits in 149ms)
2014-07-22 06:58:56,262 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015754.temp (wrote 18 edits in 179ms)
2014-07-22 06:58:56,266 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015755.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015770
2014-07-22 06:58:56,310 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015754.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015771
2014-07-22 06:58:56,310 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 93 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037357633 is corrupted = false progress failed = false
2014-07-22 06:58:56,321 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037357633 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:56,321 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037357633 in 1873ms
2014-07-22 06:58:56,366 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037404629
2014-07-22 06:58:56,398 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037404629, length=68222031
2014-07-22 06:58:56,398 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:56,403 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037404629
2014-07-22 06:58:56,404 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037404629 after 1ms
2014-07-22 06:58:56,415 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:56,415 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:56,420 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:56,420 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015698.temp
2014-07-22 06:58:56,420 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015723.temp
2014-07-22 06:58:56,420 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015698.temp
2014-07-22 06:58:56,420 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015698.temp
2014-07-22 06:58:56,420 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015723.temp
2014-07-22 06:58:56,421 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015693.temp
2014-07-22 06:58:56,421 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015689.temp
2014-07-22 06:58:56,421 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015698.temp
2014-07-22 06:58:56,423 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0,5,main]: starting
2014-07-22 06:58:56,424 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1,5,main]: starting
2014-07-22 06:58:56,424 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2,5,main]: starting
2014-07-22 06:58:56,425 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015698.temp (wrote 16 edits in 123ms)
2014-07-22 06:58:56,427 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015698.temp (wrote 15 edits in 220ms)
2014-07-22 06:58:56,427 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015723.temp (wrote 15 edits in 179ms)
2014-07-22 06:58:56,432 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015698.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015713
2014-07-22 06:58:56,432 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015693.temp
2014-07-22 06:58:56,433 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015723.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015737
2014-07-22 06:58:56,433 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015689.temp
2014-07-22 06:58:56,434 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015698.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015712
2014-07-22 06:58:56,436 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015693.temp (wrote 14 edits in 217ms)
2014-07-22 06:58:56,437 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015689.temp (wrote 15 edits in 145ms)
2014-07-22 06:58:56,443 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015693.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015706
2014-07-22 06:58:56,444 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015689.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015703
2014-07-22 06:58:56,444 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 75 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037350702 is corrupted = false progress failed = false
2014-07-22 06:58:56,448 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037350702 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:56,448 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037350702 in 866ms
2014-07-22 06:58:56,449 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016124.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:56,454 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016156.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:56,487 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016132.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:56,522 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016130.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:56,572 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016123.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:56,903 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:56,903 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:56,908 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:56,908 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016132.temp
2014-07-22 06:58:56,908 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016156.temp
2014-07-22 06:58:56,908 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016132.temp
2014-07-22 06:58:56,909 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016130.temp
2014-07-22 06:58:56,909 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016156.temp
2014-07-22 06:58:56,909 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016124.temp
2014-07-22 06:58:56,909 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016123.temp
2014-07-22 06:58:56,909 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016130.temp
2014-07-22 06:58:56,913 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016156.temp (wrote 15 edits in 115ms)
2014-07-22 06:58:56,916 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016132.temp (wrote 15 edits in 139ms)
2014-07-22 06:58:56,919 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016130.temp (wrote 15 edits in 159ms)
2014-07-22 06:58:56,936 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016156.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016170
2014-07-22 06:58:56,936 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016124.temp
2014-07-22 06:58:56,937 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016132.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016146
2014-07-22 06:58:56,937 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016123.temp
2014-07-22 06:58:56,939 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016130.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016144
2014-07-22 06:58:56,940 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016124.temp (wrote 17 edits in 128ms)
2014-07-22 06:58:56,941 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016123.temp (wrote 14 edits in 159ms)
2014-07-22 06:58:56,949 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016124.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016140
2014-07-22 06:58:56,990 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016123.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016136
2014-07-22 06:58:56,990 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] wal.HLogSplitter: Processed 76 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037404629 is corrupted = false progress failed = false
2014-07-22 06:58:56,999 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037404629 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:56,999 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-1] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037404629 in 632ms
2014-07-22 06:58:57,305 INFO  [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: worker slave1,60020,1406034875944 acquired task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037367380
2014-07-22 06:58:57,367 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037367380, length=89600637
2014-07-22 06:58:57,368 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2014-07-22 06:58:57,374 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037367380
2014-07-22 06:58:57,375 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=0 on file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037367380 after 1ms
2014-07-22 06:58:57,420 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0,5,main]: starting
2014-07-22 06:58:57,421 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1,5,main]: starting
2014-07-22 06:58:57,421 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2,5,main]: starting
2014-07-22 06:58:57,496 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015852.temp region=5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:57,524 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-0] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015884.temp region=708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:57,532 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015825.temp region=d29123f6203691d46817543c7ec8a423
2014-07-22 06:58:57,576 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-1] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015836.temp region=9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:57,665 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0-Writer-2] wal.HLogSplitter: Creating writer path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015822.temp region=9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:58:57,955 DEBUG [SplitLogWorker-slave1,60020,1406034875944] regionserver.SplitLogWorker: Current region server slave1,60020,1406034875944 has 1 tasks in progress and can't take more.
2014-07-22 06:58:58,375 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2014-07-22 06:58:58,375 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2014-07-22 06:58:58,385 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Split writers finished
2014-07-22 06:58:58,386 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015852.temp
2014-07-22 06:58:58,386 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015884.temp
2014-07-22 06:58:58,386 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015852.temp
2014-07-22 06:58:58,386 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015836.temp
2014-07-22 06:58:58,386 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015884.temp
2014-07-22 06:58:58,386 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015822.temp
2014-07-22 06:58:58,387 DEBUG [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Submitting close of hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015825.temp
2014-07-22 06:58:58,387 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015836.temp
2014-07-22 06:58:58,515 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015884.temp (wrote 14 edits in 104ms)
2014-07-22 06:58:58,569 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015852.temp (wrote 18 edits in 149ms)
2014-07-22 06:58:58,570 INFO  [split-log-closeStream-3] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015836.temp (wrote 30 edits in 240ms)
2014-07-22 06:58:58,570 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015884.temp to hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015897
2014-07-22 06:58:58,570 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015822.temp
2014-07-22 06:58:58,625 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015852.temp to hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015869
2014-07-22 06:58:58,625 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Closing hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015825.temp
2014-07-22 06:58:58,631 INFO  [split-log-closeStream-2] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015822.temp (wrote 17 edits in 118ms)
2014-07-22 06:58:58,631 DEBUG [split-log-closeStream-3] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015836.temp to hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015865
2014-07-22 06:58:58,632 INFO  [split-log-closeStream-1] wal.HLogSplitter: Closed wap hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015825.temp (wrote 21 edits in 159ms)
2014-07-22 06:58:58,634 DEBUG [split-log-closeStream-2] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015822.temp to hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015838
2014-07-22 06:58:58,677 DEBUG [split-log-closeStream-1] wal.HLogSplitter: Rename hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015825.temp to hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015845
2014-07-22 06:58:58,678 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] wal.HLogSplitter: Processed 100 edits across 5 regions; log file=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1406034877632-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632.1406037367380 is corrupted = false progress failed = false
2014-07-22 06:58:58,684 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037367380 to final state DONE slave1,60020,1406034875944
2014-07-22 06:58:58,684 INFO  [RS_LOG_REPLAY_OPS-slave1:60020-0] handler.HLogSplitterHandler: worker slave1,60020,1406034875944 done with task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1406034877632-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1406034877632.1406037367380 in 1378ms
2014-07-22 06:58:58,695 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2014-07-22 06:58:58,730 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 06:58:58,732 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 06:58:58,732 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 06:58:58,733 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5688494b49c628b8cf95eecd57a989f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:58:58,733 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 708b12ffe5692a8a792bd1bf752b8516 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:58:58,733 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 06:58:58,734 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Open usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 06:58:58,737 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9adf623b44aef5d1cfacd411890c83ff from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:58:58,738 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5688494b49c628b8cf95eecd57a989f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:58:58,739 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 5688494b49c628b8cf95eecd57a989f3, NAME => 'usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-22 06:58:58,739 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 708b12ffe5692a8a792bd1bf752b8516 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:58:58,739 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 708b12ffe5692a8a792bd1bf752b8516, NAME => 'usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-22 06:58:58,739 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:58,739 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 06:58:58,740 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:58,740 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 06:58:58,742 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9adf623b44aef5d1cfacd411890c83ff from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:58:58,743 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 9adf623b44aef5d1cfacd411890c83ff, NAME => 'usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-22 06:58:58,743 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:58,743 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 06:58:58,746 INFO  [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:58:58,747 INFO  [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:58:58,751 INFO  [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:58:58,775 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/077e5755c8f94dc9b4a12c45631ae2c2, isReference=false, isBulkLoadResult=false, seqid=14851, majorCompaction=false
2014-07-22 06:58:58,789 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/231b035db5ea4bf4a4f4e382b73f31b7, isReference=false, isBulkLoadResult=false, seqid=13672, majorCompaction=false
2014-07-22 06:58:58,791 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/37a961270d5540268cdc5d1aa166d580, isReference=false, isBulkLoadResult=false, seqid=3132, majorCompaction=false
2014-07-22 06:58:58,801 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/41cb33e841214b7789a2a0931b0e16d1, isReference=false, isBulkLoadResult=false, seqid=15143, majorCompaction=false
2014-07-22 06:58:58,807 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/14ec1a107ee644e0a7c5f2ebd0bf5540, isReference=false, isBulkLoadResult=false, seqid=5356, majorCompaction=false
2014-07-22 06:58:58,822 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5720111f9f124599aced3b249c50e4f4, isReference=false, isBulkLoadResult=false, seqid=12145, majorCompaction=false
2014-07-22 06:58:58,833 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1674367faab441ff881703230003f336, isReference=false, isBulkLoadResult=false, seqid=3953, majorCompaction=true
2014-07-22 06:58:58,847 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/25ef051314c74699bf182002b5ec1eef, isReference=false, isBulkLoadResult=false, seqid=14110, majorCompaction=false
2014-07-22 06:58:58,852 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/172e1b190f024e6087c312bf88d20461, isReference=false, isBulkLoadResult=false, seqid=12984, majorCompaction=false
2014-07-22 06:58:58,852 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5a7fb74819fd43e798938d6fe0b5c50b, isReference=false, isBulkLoadResult=false, seqid=11624, majorCompaction=false
2014-07-22 06:58:58,888 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3ded22a8b3574acf85003be3b5e3c767, isReference=false, isBulkLoadResult=false, seqid=13199, majorCompaction=false
2014-07-22 06:58:58,890 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/6eda1fd9a3e64cef9b9d7cdbb709460d, isReference=false, isBulkLoadResult=false, seqid=4082, majorCompaction=false
2014-07-22 06:58:58,896 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1ccf96deb35543c89ec1126161482090, isReference=false, isBulkLoadResult=false, seqid=13340, majorCompaction=false
2014-07-22 06:58:58,904 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/40534aa6c5c2431693d77ef4a70d12c9, isReference=false, isBulkLoadResult=false, seqid=6724, majorCompaction=false
2014-07-22 06:58:58,918 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2cbf12193f5c4838b70abc15e3898b93, isReference=false, isBulkLoadResult=false, seqid=13715, majorCompaction=false
2014-07-22 06:58:58,939 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/509f3aeb795e4bada18f2caa332b71ba, isReference=false, isBulkLoadResult=false, seqid=6123, majorCompaction=false
2014-07-22 06:58:58,939 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/71c68ca4b86a474ca15c84cb4e30731b, isReference=false, isBulkLoadResult=false, seqid=14685, majorCompaction=false
2014-07-22 06:58:58,954 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2dfe2a2d51d94ff5add86d31be6189c2, isReference=false, isBulkLoadResult=false, seqid=14266, majorCompaction=false
2014-07-22 06:58:58,963 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7af41fb7b9e049b5aa5ce5890b0a6c03, isReference=false, isBulkLoadResult=false, seqid=9646, majorCompaction=false
2014-07-22 06:58:58,964 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/6531e105c3fd446ba258c9b5748a91f7, isReference=false, isBulkLoadResult=false, seqid=4955, majorCompaction=true
2014-07-22 06:58:58,975 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/4ff364350dc34cd09e8cb170f59e379e, isReference=false, isBulkLoadResult=false, seqid=6549, majorCompaction=false
2014-07-22 06:58:58,978 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7d4ad5e320d045649eb3e38cc10cac9d, isReference=false, isBulkLoadResult=false, seqid=15653, majorCompaction=false
2014-07-22 06:58:59,011 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/8013058ed5104eab85c448f9f0e857c9, isReference=false, isBulkLoadResult=false, seqid=11781, majorCompaction=false
2014-07-22 06:58:59,013 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/58f3076a07844aae9fab0bd3d449c4dc, isReference=false, isBulkLoadResult=false, seqid=11382, majorCompaction=false
2014-07-22 06:58:59,019 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/81b965e4e38b4bb99c795276e0f94ba5, isReference=false, isBulkLoadResult=false, seqid=8884, majorCompaction=false
2014-07-22 06:58:59,138 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/ae065a93e8ba45e3888ddb144a69e17f, isReference=false, isBulkLoadResult=false, seqid=11186, majorCompaction=false
2014-07-22 06:58:59,139 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/7c55cb42f9cc4317b4bef7df2dc2cc29, isReference=false, isBulkLoadResult=false, seqid=4781, majorCompaction=false
2014-07-22 06:58:59,139 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8722071116fa409b84d55b65195034dc, isReference=false, isBulkLoadResult=false, seqid=13175, majorCompaction=false
2014-07-22 06:58:59,173 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/8ced515f00114c6490b8aed259b63a16, isReference=false, isBulkLoadResult=false, seqid=4470, majorCompaction=false
2014-07-22 06:58:59,174 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b9b84c76d58e4d9eb1cd5bd7b2c036cd, isReference=false, isBulkLoadResult=false, seqid=14887, majorCompaction=false
2014-07-22 06:58:59,175 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/88dc6e86718e4aa9a43f131553c1c59b, isReference=false, isBulkLoadResult=false, seqid=10857, majorCompaction=false
2014-07-22 06:58:59,195 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/bde5b1544dda49e185381cacb6c21b22, isReference=false, isBulkLoadResult=false, seqid=12733, majorCompaction=false
2014-07-22 06:58:59,201 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9b3b101aa4b24ded8c1ecff649f33dc4, isReference=false, isBulkLoadResult=false, seqid=5961, majorCompaction=false
2014-07-22 06:58:59,206 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/94c98d1a7d424f5bb78abac24a40d27a, isReference=false, isBulkLoadResult=false, seqid=2756, majorCompaction=false
2014-07-22 06:58:59,258 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9fe5afb63e0f43b5869664493d458e0e, isReference=false, isBulkLoadResult=false, seqid=15448, majorCompaction=false
2014-07-22 06:58:59,260 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cd7b03321d144b37829902818676e6e3, isReference=false, isBulkLoadResult=false, seqid=15273, majorCompaction=false
2014-07-22 06:58:59,268 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/adbd1296130544acab67c568c7388ce1, isReference=false, isBulkLoadResult=false, seqid=8493, majorCompaction=false
2014-07-22 06:58:59,291 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bb2900d3d3aa42659202e06ffe35d9a4, isReference=false, isBulkLoadResult=false, seqid=10089, majorCompaction=false
2014-07-22 06:58:59,292 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e4ba8a8e417c4397afa7cb4137ffcc62, isReference=false, isBulkLoadResult=false, seqid=15688, majorCompaction=false
2014-07-22 06:58:59,303 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/abe9d048a30848b6be5cdf916ee7221d, isReference=false, isBulkLoadResult=false, seqid=11956, majorCompaction=false
2014-07-22 06:58:59,319 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e4df85ebb7e741268b88e178aee38e48, isReference=false, isBulkLoadResult=false, seqid=12204, majorCompaction=false
2014-07-22 06:58:59,327 DEBUG [StoreOpener-5688494b49c628b8cf95eecd57a989f3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/c4ff002cc9844009938b34c5adf78617, isReference=false, isBulkLoadResult=false, seqid=12553, majorCompaction=false
2014-07-22 06:58:59,338 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bf96ae81429e4c0c85aae1fe7b099744, isReference=false, isBulkLoadResult=false, seqid=9266, majorCompaction=false
2014-07-22 06:58:59,375 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/c65c9f29319b4fb78f5846b9c73221d4, isReference=false, isBulkLoadResult=false, seqid=10440, majorCompaction=false
2014-07-22 06:58:59,380 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 42 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:58:59,380 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f8cd59fb153e4713ad2c54c1f8db2616, isReference=false, isBulkLoadResult=false, seqid=14511, majorCompaction=false
2014-07-22 06:58:59,381 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015467
2014-07-22 06:58:59,418 DEBUG [StoreOpener-9adf623b44aef5d1cfacd411890c83ff-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/fbecc0275d1c498aa8212161e3a10db9, isReference=false, isBulkLoadResult=false, seqid=5555, majorCompaction=false
2014-07-22 06:58:59,420 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d336419c0ebb4e8aafb27f5dce8463c0, isReference=false, isBulkLoadResult=false, seqid=12636, majorCompaction=false
2014-07-22 06:58:59,501 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d91463129cec4d3491cd1632f385e1b2, isReference=false, isBulkLoadResult=false, seqid=13619, majorCompaction=false
2014-07-22 06:58:59,510 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 42 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:59,512 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15452 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015452
2014-07-22 06:58:59,515 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15475 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015475
2014-07-22 06:58:59,517 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15498 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015498
2014-07-22 06:58:59,519 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15516 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015516
2014-07-22 06:58:59,524 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15537 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015537
2014-07-22 06:58:59,529 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15557 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015557
2014-07-22 06:58:59,532 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/dbe8b4f5a1294eafa0efbdc6bd686509, isReference=false, isBulkLoadResult=false, seqid=14118, majorCompaction=false
2014-07-22 06:58:59,532 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15575 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015575
2014-07-22 06:58:59,534 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15592 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015592
2014-07-22 06:58:59,536 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15610 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015610
2014-07-22 06:58:59,538 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15625 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015625
2014-07-22 06:58:59,539 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15635 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015635
2014-07-22 06:58:59,541 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15667 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015667
2014-07-22 06:58:59,543 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15682 and minimum sequenceid for the region is 15688, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015682
2014-07-22 06:58:59,544 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015697
2014-07-22 06:58:59,553 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/df19b37c54844c5e8b85f5d90ec2dd01, isReference=false, isBulkLoadResult=false, seqid=11121, majorCompaction=false
2014-07-22 06:58:59,597 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/eebb5235ed9947c1b1705f707fd646bc, isReference=false, isBulkLoadResult=false, seqid=2327, majorCompaction=true
2014-07-22 06:58:59,626 DEBUG [StoreOpener-708b12ffe5692a8a792bd1bf752b8516-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/fe3d257ef26645c78e6a867f3b83922b, isReference=false, isBulkLoadResult=false, seqid=3538, majorCompaction=false
2014-07-22 06:58:59,673 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 42 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:59,674 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15491 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015491
2014-07-22 06:58:59,676 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15514 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015514
2014-07-22 06:58:59,678 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15536 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015536
2014-07-22 06:58:59,679 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15558 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015558
2014-07-22 06:58:59,682 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15574 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015574
2014-07-22 06:58:59,685 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15594 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015594
2014-07-22 06:58:59,686 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15611 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015611
2014-07-22 06:58:59,689 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15624 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015624
2014-07-22 06:58:59,693 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15640 and minimum sequenceid for the region is 15653, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015640
2014-07-22 06:58:59,694 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015659
2014-07-22 06:58:59,879 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:58:59,882 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 51310, skipped 27490, firstSequenceidInLog=15683, maxSequenceidInLog=15697, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015697
2014-07-22 06:58:59,885 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015712
2014-07-22 06:58:59,919 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:58:59,921 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 28200, skipped 67050, firstSequenceidInLog=15641, maxSequenceidInLog=15659, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015659
2014-07-22 06:58:59,924 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015691
2014-07-22 06:59:00,114 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:00,117 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 107180, skipped 28630, firstSequenceidInLog=15443, maxSequenceidInLog=15467, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015467
2014-07-22 06:59:00,119 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015484
2014-07-22 06:59:00,381 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:00,383 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 85450, skipped 0, firstSequenceidInLog=15698, maxSequenceidInLog=15712, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015712
2014-07-22 06:59:00,385 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015733
2014-07-22 06:59:00,826 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:00,829 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 95890, skipped 0, firstSequenceidInLog=15468, maxSequenceidInLog=15484, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015484
2014-07-22 06:59:00,831 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015508
2014-07-22 06:59:01,110 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:01,112 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 179360, skipped 0, firstSequenceidInLog=15660, maxSequenceidInLog=15691, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015691
2014-07-22 06:59:01,115 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015693
2014-07-22 06:59:01,227 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:01,229 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 119410, skipped 0, firstSequenceidInLog=15713, maxSequenceidInLog=15733, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015733
2014-07-22 06:59:01,234 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015748
2014-07-22 06:59:01,253 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:01,256 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 11080, skipped 0, firstSequenceidInLog=15692, maxSequenceidInLog=15693, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015693
2014-07-22 06:59:01,261 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015706
2014-07-22 06:59:01,805 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:01,807 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 83300, skipped 0, firstSequenceidInLog=15734, maxSequenceidInLog=15748, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015748
2014-07-22 06:59:01,809 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015765
2014-07-22 06:59:01,834 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:01,836 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 72620, skipped 0, firstSequenceidInLog=15694, maxSequenceidInLog=15706, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015706
2014-07-22 06:59:01,837 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015722
2014-07-22 06:59:02,040 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:02,043 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 136330, skipped 0, firstSequenceidInLog=15485, maxSequenceidInLog=15508, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015508
2014-07-22 06:59:02,045 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015524
2014-07-22 06:59:02,507 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:02,509 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 90310, skipped 0, firstSequenceidInLog=15707, maxSequenceidInLog=15722, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015722
2014-07-22 06:59:02,512 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015737
2014-07-22 06:59:02,530 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:02,531 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 96490, skipped 0, firstSequenceidInLog=15749, maxSequenceidInLog=15765, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015765
2014-07-22 06:59:02,533 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015783
2014-07-22 06:59:02,902 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:02,904 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 90490, skipped 0, firstSequenceidInLog=15509, maxSequenceidInLog=15524, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015524
2014-07-22 06:59:02,906 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015546
2014-07-22 06:59:03,103 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:03,105 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 84660, skipped 0, firstSequenceidInLog=15723, maxSequenceidInLog=15737, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015737
2014-07-22 06:59:03,107 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015757
2014-07-22 06:59:03,326 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:03,329 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 101890, skipped 0, firstSequenceidInLog=15766, maxSequenceidInLog=15783, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015783
2014-07-22 06:59:03,331 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015800
2014-07-22 06:59:03,996 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:03,998 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 113810, skipped 0, firstSequenceidInLog=15738, maxSequenceidInLog=15757, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015757
2014-07-22 06:59:04,000 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015774
2014-07-22 06:59:04,207 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:04,209 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 97040, skipped 0, firstSequenceidInLog=15784, maxSequenceidInLog=15800, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015800
2014-07-22 06:59:04,212 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015819
2014-07-22 06:59:04,212 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:04,214 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 125720, skipped 0, firstSequenceidInLog=15525, maxSequenceidInLog=15546, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015546
2014-07-22 06:59:04,215 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015565
2014-07-22 06:59:04,838 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:04,840 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 98100, skipped 0, firstSequenceidInLog=15758, maxSequenceidInLog=15774, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015774
2014-07-22 06:59:04,858 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015793
2014-07-22 06:59:05,180 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:05,183 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 105290, skipped 0, firstSequenceidInLog=15801, maxSequenceidInLog=15819, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015819
2014-07-22 06:59:05,185 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015835
2014-07-22 06:59:05,425 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:05,427 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 107530, skipped 0, firstSequenceidInLog=15547, maxSequenceidInLog=15565, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015565
2014-07-22 06:59:05,429 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015586
2014-07-22 06:59:05,748 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:05,750 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 107020, skipped 0, firstSequenceidInLog=15775, maxSequenceidInLog=15793, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015793
2014-07-22 06:59:05,753 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015814
2014-07-22 06:59:06,187 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:06,190 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 92040, skipped 0, firstSequenceidInLog=15820, maxSequenceidInLog=15835, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015835
2014-07-22 06:59:06,199 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015865
2014-07-22 06:59:06,865 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:06,868 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 118320, skipped 0, firstSequenceidInLog=15566, maxSequenceidInLog=15586, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015586
2014-07-22 06:59:06,870 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015598
2014-07-22 06:59:06,881 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:06,883 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 117790, skipped 0, firstSequenceidInLog=15794, maxSequenceidInLog=15814, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015814
2014-07-22 06:59:06,884 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015833
2014-07-22 06:59:07,271 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 257.5m; wal is null, using passed sequenceid=15820
2014-07-22 06:59:07,465 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 256.1m; wal is null, using passed sequenceid=15853
2014-07-22 06:59:07,499 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:07,627 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:07,757 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:07,759 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 69380, skipped 0, firstSequenceidInLog=15587, maxSequenceidInLog=15598, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015598
2014-07-22 06:59:07,761 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015616
2014-07-22 06:59:08,799 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 257.1m; wal is null, using passed sequenceid=15613
2014-07-22 06:59:09,025 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:09,028 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-22 06:59:09,028 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-22 06:59:11,108 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15613, memsize=45.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/3822aef797904b07810b83fa4e5ac184
2014-07-22 06:59:11,119 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/3822aef797904b07810b83fa4e5ac184 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/3822aef797904b07810b83fa4e5ac184
2014-07-22 06:59:11,134 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/3822aef797904b07810b83fa4e5ac184, entries=164190, sequenceid=15613, filesize=11.7m
2014-07-22 06:59:11,135 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~257.1m/269591680, currentsize=0.0/0 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 2336ms, sequenceid=15613, compaction requested=true; wal=null
2014-07-22 06:59:11,203 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:11,205 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101400, skipped 0, firstSequenceidInLog=15599, maxSequenceidInLog=15616, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015616
2014-07-22 06:59:11,208 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015630
2014-07-22 06:59:11,593 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:11,596 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 79240, skipped 0, firstSequenceidInLog=15617, maxSequenceidInLog=15630, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015630
2014-07-22 06:59:11,598 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015661
2014-07-22 06:59:12,719 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:12,721 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 173470, skipped 0, firstSequenceidInLog=15631, maxSequenceidInLog=15661, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015661
2014-07-22 06:59:12,724 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015668
2014-07-22 06:59:12,869 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15853, memsize=152.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/a86bfe980bc64065847f825de646ab56
2014-07-22 06:59:12,879 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/a86bfe980bc64065847f825de646ab56 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/a86bfe980bc64065847f825de646ab56
2014-07-22 06:59:12,892 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/a86bfe980bc64065847f825de646ab56, entries=553490, sequenceid=15853, filesize=39.5m
2014-07-22 06:59:12,892 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~256.1m/268548560, currentsize=0.0/0 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 5427ms, sequenceid=15853, compaction requested=true; wal=null
2014-07-22 06:59:13,054 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:13,057 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 40560, skipped 0, firstSequenceidInLog=15662, maxSequenceidInLog=15668, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015668
2014-07-22 06:59:13,058 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015683
2014-07-22 06:59:13,241 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:13,243 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 169180, skipped 0, firstSequenceidInLog=15836, maxSequenceidInLog=15865, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015865
2014-07-22 06:59:13,245 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015878
2014-07-22 06:59:13,734 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15820, memsize=181.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/550de4ff4a484b639a03cb3d572890e0
2014-07-22 06:59:13,746 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/550de4ff4a484b639a03cb3d572890e0 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/550de4ff4a484b639a03cb3d572890e0
2014-07-22 06:59:13,753 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/550de4ff4a484b639a03cb3d572890e0, entries=661800, sequenceid=15820, filesize=47.2m
2014-07-22 06:59:13,754 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~257.5m/269963840, currentsize=0.0/0 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 6483ms, sequenceid=15820, compaction requested=true; wal=null
2014-07-22 06:59:13,827 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:13,830 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 72370, skipped 0, firstSequenceidInLog=15866, maxSequenceidInLog=15878, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015878
2014-07-22 06:59:13,832 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015897
2014-07-22 06:59:14,306 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:14,308 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 83920, skipped 0, firstSequenceidInLog=15669, maxSequenceidInLog=15683, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015683
2014-07-22 06:59:14,311 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015697
2014-07-22 06:59:14,467 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:14,469 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 106920, skipped 0, firstSequenceidInLog=15815, maxSequenceidInLog=15833, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015833
2014-07-22 06:59:14,472 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015857
2014-07-22 06:59:15,176 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:15,178 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 78260, skipped 0, firstSequenceidInLog=15684, maxSequenceidInLog=15697, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015697
2014-07-22 06:59:15,180 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015713
2014-07-22 06:59:15,227 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:15,228 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 108230, skipped 0, firstSequenceidInLog=15879, maxSequenceidInLog=15897, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015897
2014-07-22 06:59:15,230 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015910
2014-07-22 06:59:15,578 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:15,580 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 135830, skipped 0, firstSequenceidInLog=15834, maxSequenceidInLog=15857, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015857
2014-07-22 06:59:15,582 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015883
2014-07-22 06:59:16,348 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:16,351 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 72760, skipped 0, firstSequenceidInLog=15898, maxSequenceidInLog=15910, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015910
2014-07-22 06:59:16,353 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015926
2014-07-22 06:59:16,486 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:16,491 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 89410, skipped 0, firstSequenceidInLog=15698, maxSequenceidInLog=15713, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015713
2014-07-22 06:59:16,494 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015734
2014-07-22 06:59:17,354 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:17,356 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 90170, skipped 0, firstSequenceidInLog=15911, maxSequenceidInLog=15926, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015926
2014-07-22 06:59:17,358 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015941
2014-07-22 06:59:17,514 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:17,517 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 146100, skipped 0, firstSequenceidInLog=15858, maxSequenceidInLog=15883, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015883
2014-07-22 06:59:17,519 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015897
2014-07-22 06:59:17,693 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:17,696 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 117880, skipped 0, firstSequenceidInLog=15714, maxSequenceidInLog=15734, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015734
2014-07-22 06:59:17,698 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015749
2014-07-22 06:59:18,294 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:18,296 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 84080, skipped 0, firstSequenceidInLog=15927, maxSequenceidInLog=15941, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015941
2014-07-22 06:59:18,298 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015957
2014-07-22 06:59:18,819 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:18,821 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 78990, skipped 0, firstSequenceidInLog=15884, maxSequenceidInLog=15897, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015897
2014-07-22 06:59:18,825 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015911
2014-07-22 06:59:19,142 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:19,145 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 85920, skipped 0, firstSequenceidInLog=15735, maxSequenceidInLog=15749, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015749
2014-07-22 06:59:19,147 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015766
2014-07-22 06:59:19,460 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:19,462 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 94360, skipped 0, firstSequenceidInLog=15942, maxSequenceidInLog=15957, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015957
2014-07-22 06:59:19,464 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015974
2014-07-22 06:59:19,770 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:19,772 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 79530, skipped 0, firstSequenceidInLog=15898, maxSequenceidInLog=15911, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015911
2014-07-22 06:59:19,774 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015924
2014-07-22 06:59:20,084 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:20,087 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 94410, skipped 0, firstSequenceidInLog=15750, maxSequenceidInLog=15766, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015766
2014-07-22 06:59:20,089 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015786
2014-07-22 06:59:20,322 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:20,324 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 95500, skipped 0, firstSequenceidInLog=15958, maxSequenceidInLog=15974, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015974
2014-07-22 06:59:20,326 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015992
2014-07-22 06:59:20,611 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:20,614 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 72400, skipped 0, firstSequenceidInLog=15912, maxSequenceidInLog=15924, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015924
2014-07-22 06:59:20,616 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015938
2014-07-22 06:59:20,905 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 256.1m; wal is null, using passed sequenceid=15779
2014-07-22 06:59:21,073 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:21,245 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:21,247 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 102970, skipped 0, firstSequenceidInLog=15975, maxSequenceidInLog=15992, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015992
2014-07-22 06:59:21,250 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016019
2014-07-22 06:59:21,476 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:21,478 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 79090, skipped 0, firstSequenceidInLog=15925, maxSequenceidInLog=15938, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015938
2014-07-22 06:59:21,480 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015953
2014-07-22 06:59:22,268 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:22,270 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 83840, skipped 0, firstSequenceidInLog=15939, maxSequenceidInLog=15953, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015953
2014-07-22 06:59:22,272 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015969
2014-07-22 06:59:22,648 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 256.1m; wal is null, using passed sequenceid=16017
2014-07-22 06:59:22,843 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:23,158 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:23,160 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 90860, skipped 0, firstSequenceidInLog=15954, maxSequenceidInLog=15969, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015969
2014-07-22 06:59:23,163 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015986
2014-07-22 06:59:24,113 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 256.6m; wal is null, using passed sequenceid=15986
2014-07-22 06:59:24,274 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:26,840 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15779, memsize=168.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/252894c5615148b08bbda7e8aa013252
2014-07-22 06:59:26,849 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/252894c5615148b08bbda7e8aa013252 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/252894c5615148b08bbda7e8aa013252
2014-07-22 06:59:26,859 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/252894c5615148b08bbda7e8aa013252, entries=612130, sequenceid=15779, filesize=43.6m
2014-07-22 06:59:26,860 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~256.1m/268501600, currentsize=0.0/0 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 5955ms, sequenceid=15779, compaction requested=true; wal=null
2014-07-22 06:59:27,026 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:27,029 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 112420, skipped 0, firstSequenceidInLog=15767, maxSequenceidInLog=15786, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015786
2014-07-22 06:59:27,031 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015805
2014-07-22 06:59:27,623 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:27,625 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 106830, skipped 0, firstSequenceidInLog=15787, maxSequenceidInLog=15805, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015805
2014-07-22 06:59:27,627 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015825
2014-07-22 06:59:27,914 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16017, memsize=131.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/00e2ebcc50414b47b91e734d9d17e9a3
2014-07-22 06:59:27,932 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/00e2ebcc50414b47b91e734d9d17e9a3 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/00e2ebcc50414b47b91e734d9d17e9a3
2014-07-22 06:59:27,948 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/00e2ebcc50414b47b91e734d9d17e9a3, entries=477420, sequenceid=16017, filesize=34.0m
2014-07-22 06:59:27,949 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~256.1m/268558400, currentsize=0.0/0 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 5301ms, sequenceid=16017, compaction requested=true; wal=null
2014-07-22 06:59:27,990 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:27,993 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 154380, skipped 0, firstSequenceidInLog=15993, maxSequenceidInLog=16019, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016019
2014-07-22 06:59:27,995 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016042
2014-07-22 06:59:28,098 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15986, memsize=100.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/75ac1cfd34004c899b4a4275fcfc7f60
2014-07-22 06:59:28,108 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/75ac1cfd34004c899b4a4275fcfc7f60 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/75ac1cfd34004c899b4a4275fcfc7f60
2014-07-22 06:59:28,122 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/75ac1cfd34004c899b4a4275fcfc7f60, entries=366090, sequenceid=15986, filesize=26.1m
2014-07-22 06:59:28,123 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~256.6m/269105040, currentsize=0.0/0 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 4009ms, sequenceid=15986, compaction requested=true; wal=null
2014-07-22 06:59:28,123 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:28,125 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 95310, skipped 0, firstSequenceidInLog=15970, maxSequenceidInLog=15986, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015986
2014-07-22 06:59:28,126 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016006
2014-07-22 06:59:28,522 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:28,525 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 114230, skipped 0, firstSequenceidInLog=15806, maxSequenceidInLog=15825, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015825
2014-07-22 06:59:28,527 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015851
2014-07-22 06:59:28,811 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:28,813 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 113600, skipped 0, firstSequenceidInLog=15987, maxSequenceidInLog=16006, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016006
2014-07-22 06:59:28,814 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:28,815 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016025
2014-07-22 06:59:28,815 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 130890, skipped 0, firstSequenceidInLog=16020, maxSequenceidInLog=16042, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016042
2014-07-22 06:59:28,817 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016058
2014-07-22 06:59:29,633 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:29,635 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 93070, skipped 0, firstSequenceidInLog=16043, maxSequenceidInLog=16058, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016058
2014-07-22 06:59:29,637 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016075
2014-07-22 06:59:29,680 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:29,682 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 107420, skipped 0, firstSequenceidInLog=16007, maxSequenceidInLog=16025, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016025
2014-07-22 06:59:29,684 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016058
2014-07-22 06:59:29,961 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:29,964 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 146240, skipped 0, firstSequenceidInLog=15826, maxSequenceidInLog=15851, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015851
2014-07-22 06:59:29,966 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015869
2014-07-22 06:59:30,499 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:30,502 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 95400, skipped 0, firstSequenceidInLog=16059, maxSequenceidInLog=16075, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016075
2014-07-22 06:59:30,504 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016097
2014-07-22 06:59:31,122 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:31,125 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 101570, skipped 0, firstSequenceidInLog=15852, maxSequenceidInLog=15869, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015869
2014-07-22 06:59:31,127 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015883
2014-07-22 06:59:31,525 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:31,528 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 186580, skipped 0, firstSequenceidInLog=16026, maxSequenceidInLog=16058, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016058
2014-07-22 06:59:31,530 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016078
2014-07-22 06:59:31,833 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:31,836 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 124730, skipped 0, firstSequenceidInLog=16076, maxSequenceidInLog=16097, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016097
2014-07-22 06:59:31,837 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016115
2014-07-22 06:59:32,145 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:32,147 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 78490, skipped 0, firstSequenceidInLog=15870, maxSequenceidInLog=15883, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015883
2014-07-22 06:59:32,150 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015899
2014-07-22 06:59:32,827 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:32,830 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 112580, skipped 0, firstSequenceidInLog=16059, maxSequenceidInLog=16078, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016078
2014-07-22 06:59:32,832 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016095
2014-07-22 06:59:33,008 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:33,010 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 102450, skipped 0, firstSequenceidInLog=16098, maxSequenceidInLog=16115, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016115
2014-07-22 06:59:33,012 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016129
2014-07-22 06:59:33,323 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:33,325 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 90300, skipped 0, firstSequenceidInLog=15884, maxSequenceidInLog=15899, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015899
2014-07-22 06:59:33,327 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015911
2014-07-22 06:59:33,907 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:33,910 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 97160, skipped 0, firstSequenceidInLog=16079, maxSequenceidInLog=16095, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016095
2014-07-22 06:59:33,912 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016109
2014-07-22 06:59:33,948 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:33,951 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 80800, skipped 0, firstSequenceidInLog=16116, maxSequenceidInLog=16129, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016129
2014-07-22 06:59:33,954 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016144
2014-07-22 06:59:34,240 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:34,243 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 67600, skipped 0, firstSequenceidInLog=15900, maxSequenceidInLog=15911, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015911
2014-07-22 06:59:34,245 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015928
2014-07-22 06:59:34,711 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:34,713 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 84660, skipped 0, firstSequenceidInLog=16130, maxSequenceidInLog=16144, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016144
2014-07-22 06:59:34,716 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016159
2014-07-22 06:59:34,947 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:34,950 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 80000, skipped 0, firstSequenceidInLog=16096, maxSequenceidInLog=16109, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016109
2014-07-22 06:59:34,952 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016128
2014-07-22 06:59:35,402 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:35,405 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 97000, skipped 0, firstSequenceidInLog=15912, maxSequenceidInLog=15928, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015928
2014-07-22 06:59:35,407 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015944
2014-07-22 06:59:35,709 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:35,711 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 83340, skipped 0, firstSequenceidInLog=16145, maxSequenceidInLog=16159, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016159
2014-07-22 06:59:35,713 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016174
2014-07-22 06:59:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=461206, hits=5706, hitRatio=1.23%, , cachingAccesses=5709, cachingHits=5703, cachingHitsRatio=99.89%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-22 06:59:36,356 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:36,359 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 88840, skipped 0, firstSequenceidInLog=15929, maxSequenceidInLog=15944, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015944
2014-07-22 06:59:36,361 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015959
2014-07-22 06:59:36,375 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:36,377 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 106760, skipped 0, firstSequenceidInLog=16110, maxSequenceidInLog=16128, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016128
2014-07-22 06:59:36,378 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016149
2014-07-22 06:59:36,417 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 257.0m; wal is null, using passed sequenceid=15945
2014-07-22 06:59:36,626 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:36,683 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:36,685 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 84850, skipped 0, firstSequenceidInLog=16160, maxSequenceidInLog=16174, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016174
2014-07-22 06:59:36,688 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175
2014-07-22 06:59:36,785 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:36,787 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 5990, skipped 0, firstSequenceidInLog=16175, maxSequenceidInLog=16175, path=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175
2014-07-22 06:59:36,787 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 246.5m; wal is null, using passed sequenceid=16175
2014-07-22 06:59:36,944 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:37,692 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/6073b4ccfb4c4ba2a801279c20ad55cf as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6073b4ccfb4c4ba2a801279c20ad55cf
2014-07-22 06:59:37,710 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 06:59:37,717 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03256958e7a426b8917f597c5cd468e, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/f03256958e7a426b8917f597c5cd468e
2014-07-22 06:59:37,719 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/9327689762b2474bb001165d79a3fd27, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/9327689762b2474bb001165d79a3fd27
2014-07-22 06:59:37,721 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/28c91a0738074c6f88841b394a63ece7, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/28c91a0738074c6f88841b394a63ece7
2014-07-22 06:59:37,723 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1725e3e781d54a8ab9a2b453a49e748b, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/1725e3e781d54a8ab9a2b453a49e748b
2014-07-22 06:59:37,725 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/62ebdd09446a455e95ce83f16f3b93c2, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/62ebdd09446a455e95ce83f16f3b93c2
2014-07-22 06:59:37,727 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b43d6948a82340a68714f55d4ef9276b, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b43d6948a82340a68714f55d4ef9276b
2014-07-22 06:59:37,729 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/e38333c3328f40039834d6569749125e, to hdfs://master:54310/hbase/archive/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/e38333c3328f40039834d6569749125e
2014-07-22 06:59:37,729 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed major compaction of 7 file(s) in family of usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. into 6073b4ccfb4c4ba2a801279c20ad55cf(size=2.1g), total size for store is 2.3g. This selection was in queue for 0sec, and took 5mins, 4sec to execute.
2014-07-22 06:59:37,729 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., storeName=family, fileCount=7, fileSize=2.1g, priority=1993, time=134253159626839; duration=5mins, 4sec
2014-07-22 06:59:37,729 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-22 06:59:37,729 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 2000 blocking
2014-07-22 06:59:37,730 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 6 files of size 422011543 starting at candidate #2 after considering 21 permutations with 10 in ratio
2014-07-22 06:59:37,730 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 753f5973e99ebd3e7e2bc45781eaf616 - family: Initiating minor compaction
2014-07-22 06:59:37,730 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 06:59:37,730 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 6 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp, totalSize=402.5m
2014-07-22 06:59:37,731 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/6e7b86afed854c0d811b4fae50296be8, keycount=93539, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=4981
2014-07-22 06:59:37,731 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/cc3a8375bc1046348d35cf5dd528eee8, keycount=93221, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=5148
2014-07-22 06:59:37,731 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/59bb3aa8eb1345e287b48f13c02b4cdb, keycount=93942, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=5315
2014-07-22 06:59:37,731 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4f3d758804b44119903a4590fff6b776, keycount=95064, bloomtype=ROW, size=67.7m, encoding=NONE, seqNum=5484
2014-07-22 06:59:37,731 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/dc36b827444b44b9abb0292f6430c650, keycount=95516, bloomtype=ROW, size=68.0m, encoding=NONE, seqNum=5654
2014-07-22 06:59:37,731 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/75b27075301d4e8d86896582790e2d14, keycount=93583, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=5820
2014-07-22 06:59:37,869 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:37,873 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 113450, skipped 0, firstSequenceidInLog=16129, maxSequenceidInLog=16149, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016149
2014-07-22 06:59:37,876 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016155
2014-07-22 06:59:37,877 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:38,073 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 256.6m; wal is null, using passed sequenceid=16152
2014-07-22 06:59:38,272 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:39,491 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15945, memsize=72.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/d60504373db54f91b4042bd422989b4d
2014-07-22 06:59:39,501 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/d60504373db54f91b4042bd422989b4d as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d60504373db54f91b4042bd422989b4d
2014-07-22 06:59:39,510 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d60504373db54f91b4042bd422989b4d, entries=264880, sequenceid=15945, filesize=18.9m
2014-07-22 06:59:39,510 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~257.0m/269533040, currentsize=0.0/0 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 3093ms, sequenceid=15945, compaction requested=true; wal=null
2014-07-22 06:59:39,873 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:39,876 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 84010, skipped 0, firstSequenceidInLog=15945, maxSequenceidInLog=15959, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015959
2014-07-22 06:59:39,878 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015978
2014-07-22 06:59:40,252 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16175, memsize=90.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/3f72caef6c0e4a2daadc0cd2fa6d4da6
2014-07-22 06:59:40,261 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/3f72caef6c0e4a2daadc0cd2fa6d4da6 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3f72caef6c0e4a2daadc0cd2fa6d4da6
2014-07-22 06:59:40,270 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3f72caef6c0e4a2daadc0cd2fa6d4da6, entries=328220, sequenceid=16175, filesize=23.4m
2014-07-22 06:59:40,271 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~246.5m/258442480, currentsize=0.0/0 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 3484ms, sequenceid=16175, compaction requested=true; wal=null
2014-07-22 06:59:40,272 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015452
2014-07-22 06:59:40,273 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015475
2014-07-22 06:59:40,274 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015498
2014-07-22 06:59:40,276 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015516
2014-07-22 06:59:40,277 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015537
2014-07-22 06:59:40,278 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015557
2014-07-22 06:59:40,279 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015575
2014-07-22 06:59:40,281 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015592
2014-07-22 06:59:40,282 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015610
2014-07-22 06:59:40,283 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015625
2014-07-22 06:59:40,284 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015635
2014-07-22 06:59:40,285 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015667
2014-07-22 06:59:40,286 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015682
2014-07-22 06:59:40,288 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015697
2014-07-22 06:59:40,289 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015712
2014-07-22 06:59:40,290 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015733
2014-07-22 06:59:40,291 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015748
2014-07-22 06:59:40,293 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015765
2014-07-22 06:59:40,294 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015783
2014-07-22 06:59:40,295 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015800
2014-07-22 06:59:40,296 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015819
2014-07-22 06:59:40,324 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015835
2014-07-22 06:59:40,327 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015865
2014-07-22 06:59:40,328 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015878
2014-07-22 06:59:40,329 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015897
2014-07-22 06:59:40,330 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16152, memsize=46.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/e49771c6e18546449481ea73899f299e
2014-07-22 06:59:40,331 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015910
2014-07-22 06:59:40,332 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015926
2014-07-22 06:59:40,334 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015941
2014-07-22 06:59:40,335 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015957
2014-07-22 06:59:40,336 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015974
2014-07-22 06:59:40,338 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000015992
2014-07-22 06:59:40,339 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016019
2014-07-22 06:59:40,340 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016042
2014-07-22 06:59:40,341 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016058
2014-07-22 06:59:40,342 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016075
2014-07-22 06:59:40,343 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/e49771c6e18546449481ea73899f299e as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/e49771c6e18546449481ea73899f299e
2014-07-22 06:59:40,344 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016097
2014-07-22 06:59:40,346 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016115
2014-07-22 06:59:40,347 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016129
2014-07-22 06:59:40,348 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016144
2014-07-22 06:59:40,350 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016159
2014-07-22 06:59:40,351 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016174
2014-07-22 06:59:40,352 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/recovered.edits/0000000000000016175
2014-07-22 06:59:40,353 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/e49771c6e18546449481ea73899f299e, entries=169240, sequenceid=16152, filesize=12.1m
2014-07-22 06:59:40,354 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~256.6m/269013440, currentsize=0.0/0 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 2281ms, sequenceid=16152, compaction requested=true; wal=null
2014-07-22 06:59:40,354 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 9adf623b44aef5d1cfacd411890c83ff; next sequenceid=16176
2014-07-22 06:59:40,354 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9adf623b44aef5d1cfacd411890c83ff
2014-07-22 06:59:40,357 INFO  [PostOpenDeployTasks:9adf623b44aef5d1cfacd411890c83ff] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 06:59:40,357 DEBUG [PostOpenDeployTasks:9adf623b44aef5d1cfacd411890c83ff] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-22 06:59:40,386 INFO  [PostOpenDeployTasks:9adf623b44aef5d1cfacd411890c83ff] catalog.MetaEditor: Updated row usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. with server=slave1,60020,1406034875944
2014-07-22 06:59:40,386 INFO  [PostOpenDeployTasks:9adf623b44aef5d1cfacd411890c83ff] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 06:59:40,387 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9adf623b44aef5d1cfacd411890c83ff from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:59:40,394 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9adf623b44aef5d1cfacd411890c83ff from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:59:40,394 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 9adf623b44aef5d1cfacd411890c83ff to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:59:40,394 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. on slave1,60020,1406034875944
2014-07-22 06:59:40,395 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d29123f6203691d46817543c7ec8a423 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:59:40,401 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d29123f6203691d46817543c7ec8a423 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:59:40,401 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => d29123f6203691d46817543c7ec8a423, NAME => 'usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-22 06:59:40,403 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:40,403 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 06:59:40,410 INFO  [StoreOpener-d29123f6203691d46817543c7ec8a423-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:59:40,426 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/00f6d33998674401839b3ae62fa5521c, isReference=false, isBulkLoadResult=false, seqid=8625, majorCompaction=false
2014-07-22 06:59:40,429 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:40,431 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 33490, skipped 0, firstSequenceidInLog=16150, maxSequenceidInLog=16155, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016155
2014-07-22 06:59:40,432 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016170
2014-07-22 06:59:40,486 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/02ce2fb6f04e44c2a342336cd7a12783, isReference=false, isBulkLoadResult=false, seqid=7710, majorCompaction=false
2014-07-22 06:59:40,498 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/0e4e860d90f7442bb6005f077eb06531, isReference=false, isBulkLoadResult=false, seqid=15812, majorCompaction=false
2014-07-22 06:59:40,524 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/42733b4b4ba640719db9c2e4de8ab79c, isReference=false, isBulkLoadResult=false, seqid=6797, majorCompaction=false
2014-07-22 06:59:40,539 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/42ab5240f0084e7db74ce55fe06584d3, isReference=false, isBulkLoadResult=false, seqid=9098, majorCompaction=false
2014-07-22 06:59:40,552 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:40,601 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 108810, skipped 0, firstSequenceidInLog=15960, maxSequenceidInLog=15978, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015978
2014-07-22 06:59:40,606 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015996
2014-07-22 06:59:40,607 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/47b1f47e0c524d88bde7cb8d9bb76ee1, isReference=false, isBulkLoadResult=false, seqid=13322, majorCompaction=false
2014-07-22 06:59:40,624 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/4f8d04600c5d4ac392d0888c939fea01, isReference=false, isBulkLoadResult=false, seqid=11384, majorCompaction=false
2014-07-22 06:59:40,648 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/555dc8f41485430193da712c2a680b9c, isReference=false, isBulkLoadResult=false, seqid=12359, majorCompaction=false
2014-07-22 06:59:40,700 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/56ebd5ce142f4191b60194ef3c8fe744, isReference=false, isBulkLoadResult=false, seqid=10167, majorCompaction=false
2014-07-22 06:59:40,715 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/5a9a8906c7a34a01ae2e02d0e0199167, isReference=false, isBulkLoadResult=false, seqid=10645, majorCompaction=false
2014-07-22 06:59:40,734 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6835e0e2aa5a45c5a16b34802c5bdf1a, isReference=false, isBulkLoadResult=false, seqid=15221, majorCompaction=false
2014-07-22 06:59:40,757 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6c69f1e18641455ca4f78f0c8fea49fe, isReference=false, isBulkLoadResult=false, seqid=11024, majorCompaction=false
2014-07-22 06:59:40,780 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/7cf6a4fb3fa04958b9bcad55afa9cbbb, isReference=false, isBulkLoadResult=false, seqid=2090, majorCompaction=false
2014-07-22 06:59:40,800 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/88b0ce85efd946f3a61f5f5e9e8bf5b4, isReference=false, isBulkLoadResult=false, seqid=1509, majorCompaction=true
2014-07-22 06:59:40,821 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/8c042cefef50456196f097646bea6225, isReference=false, isBulkLoadResult=false, seqid=9587, majorCompaction=false
2014-07-22 06:59:40,847 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/95c1c4f39c2642e5a08b8b73448092ae, isReference=false, isBulkLoadResult=false, seqid=8043, majorCompaction=false
2014-07-22 06:59:40,907 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:40,910 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 85130, skipped 0, firstSequenceidInLog=16156, maxSequenceidInLog=16170, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016170
2014-07-22 06:59:40,912 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016187
2014-07-22 06:59:40,922 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/a073abf02f1c4446a5571b5d1a043db4, isReference=false, isBulkLoadResult=false, seqid=12755, majorCompaction=false
2014-07-22 06:59:40,940 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/bf88db1035cb4cb88525ce6b8dbb83c5, isReference=false, isBulkLoadResult=false, seqid=13823, majorCompaction=false
2014-07-22 06:59:40,975 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/c41798491fc74568830862894e016796, isReference=false, isBulkLoadResult=false, seqid=11837, majorCompaction=false
2014-07-22 06:59:40,998 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/dfdb09bb61264e83ba9dce2c449104ff, isReference=false, isBulkLoadResult=false, seqid=14699, majorCompaction=false
2014-07-22 06:59:41,022 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e9f603087f304328b1e0804c7ac3b860, isReference=false, isBulkLoadResult=false, seqid=14273, majorCompaction=false
2014-07-22 06:59:41,040 DEBUG [StoreOpener-d29123f6203691d46817543c7ec8a423-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/ff5fd872e6aa421590cb32c9adb34250, isReference=false, isBulkLoadResult=false, seqid=7234, majorCompaction=false
2014-07-22 06:59:41,075 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 42 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:41,077 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15442 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015442
2014-07-22 06:59:41,078 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15461 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015461
2014-07-22 06:59:41,079 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15478 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015478
2014-07-22 06:59:41,080 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15506 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015506
2014-07-22 06:59:41,082 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15529 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015529
2014-07-22 06:59:41,084 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15545 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015545
2014-07-22 06:59:41,085 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15560 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015560
2014-07-22 06:59:41,086 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15583 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015583
2014-07-22 06:59:41,087 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15600 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015600
2014-07-22 06:59:41,088 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15616 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015616
2014-07-22 06:59:41,090 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15625 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015625
2014-07-22 06:59:41,091 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15660 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015660
2014-07-22 06:59:41,092 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15674 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015674
2014-07-22 06:59:41,094 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15688 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015688
2014-07-22 06:59:41,095 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15703 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015703
2014-07-22 06:59:41,096 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15724 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015724
2014-07-22 06:59:41,098 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15740 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015740
2014-07-22 06:59:41,099 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15753 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015753
2014-07-22 06:59:41,100 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15771 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015771
2014-07-22 06:59:41,101 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15783 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015783
2014-07-22 06:59:41,103 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Maximum sequenceid for this log is 15802 and minimum sequenceid for the region is 15812, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015802
2014-07-22 06:59:41,104 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015824
2014-07-22 06:59:41,436 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 06:59:41,474 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037405312 with entries=88, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037581436
2014-07-22 06:59:41,572 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:41,574 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 100380, skipped 0, firstSequenceidInLog=15979, maxSequenceidInLog=15996, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015996
2014-07-22 06:59:41,576 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016027
2014-07-22 06:59:41,707 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:41,710 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 66640, skipped 50480, firstSequenceidInLog=15803, maxSequenceidInLog=15824, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015824
2014-07-22 06:59:41,712 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015845
2014-07-22 06:59:41,724 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:41,726 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 96410, skipped 0, firstSequenceidInLog=16171, maxSequenceidInLog=16187, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016187
2014-07-22 06:59:41,727 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016204
2014-07-22 06:59:42,525 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:42,528 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 96480, skipped 0, firstSequenceidInLog=16188, maxSequenceidInLog=16204, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016204
2014-07-22 06:59:42,533 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205
2014-07-22 06:59:42,564 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:42,566 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 118630, skipped 0, firstSequenceidInLog=15825, maxSequenceidInLog=15845, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015845
2014-07-22 06:59:42,570 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015867
2014-07-22 06:59:42,608 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:42,609 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 6000, skipped 0, firstSequenceidInLog=16205, maxSequenceidInLog=16205, path=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205
2014-07-22 06:59:42,610 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 82.7m; wal is null, using passed sequenceid=16205
2014-07-22 06:59:42,634 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:43,318 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:43,321 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 173840, skipped 0, firstSequenceidInLog=15997, maxSequenceidInLog=16027, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016027
2014-07-22 06:59:43,323 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016047
2014-07-22 06:59:43,557 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:43,559 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 123650, skipped 0, firstSequenceidInLog=15846, maxSequenceidInLog=15867, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015867
2014-07-22 06:59:43,561 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015886
2014-07-22 06:59:44,550 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:44,554 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 105560, skipped 0, firstSequenceidInLog=16029, maxSequenceidInLog=16047, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016047
2014-07-22 06:59:44,557 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016071
2014-07-22 06:59:44,568 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:44,570 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 105610, skipped 0, firstSequenceidInLog=15868, maxSequenceidInLog=15886, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015886
2014-07-22 06:59:44,573 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015902
2014-07-22 06:59:45,110 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16205, memsize=82.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/8690042935ad4e1bb8bba5840f5aef52
2014-07-22 06:59:45,123 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/8690042935ad4e1bb8bba5840f5aef52 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8690042935ad4e1bb8bba5840f5aef52
2014-07-22 06:59:45,132 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8690042935ad4e1bb8bba5840f5aef52, entries=300960, sequenceid=16205, filesize=21.4m
2014-07-22 06:59:45,132 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~82.7m/86674320, currentsize=0.0/0 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 2522ms, sequenceid=16205, compaction requested=true; wal=null
2014-07-22 06:59:45,133 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015491
2014-07-22 06:59:45,134 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015514
2014-07-22 06:59:45,136 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015536
2014-07-22 06:59:45,137 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015558
2014-07-22 06:59:45,138 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015574
2014-07-22 06:59:45,139 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015594
2014-07-22 06:59:45,140 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015611
2014-07-22 06:59:45,141 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015624
2014-07-22 06:59:45,143 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015640
2014-07-22 06:59:45,144 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015659
2014-07-22 06:59:45,145 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015691
2014-07-22 06:59:45,146 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015693
2014-07-22 06:59:45,147 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015706
2014-07-22 06:59:45,149 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015722
2014-07-22 06:59:45,150 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015737
2014-07-22 06:59:45,151 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015757
2014-07-22 06:59:45,152 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015774
2014-07-22 06:59:45,153 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015793
2014-07-22 06:59:45,155 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015814
2014-07-22 06:59:45,156 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015833
2014-07-22 06:59:45,157 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015857
2014-07-22 06:59:45,158 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015883
2014-07-22 06:59:45,159 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015897
2014-07-22 06:59:45,160 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015911
2014-07-22 06:59:45,161 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015924
2014-07-22 06:59:45,162 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015938
2014-07-22 06:59:45,163 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015953
2014-07-22 06:59:45,164 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015969
2014-07-22 06:59:45,165 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000015986
2014-07-22 06:59:45,166 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016006
2014-07-22 06:59:45,167 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016025
2014-07-22 06:59:45,168 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016058
2014-07-22 06:59:45,169 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016078
2014-07-22 06:59:45,170 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016095
2014-07-22 06:59:45,171 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016109
2014-07-22 06:59:45,172 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016128
2014-07-22 06:59:45,173 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016149
2014-07-22 06:59:45,174 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016155
2014-07-22 06:59:45,175 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016170
2014-07-22 06:59:45,177 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016187
2014-07-22 06:59:45,178 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016204
2014-07-22 06:59:45,179 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/recovered.edits/0000000000000016205
2014-07-22 06:59:45,181 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 708b12ffe5692a8a792bd1bf752b8516; next sequenceid=16206
2014-07-22 06:59:45,181 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 708b12ffe5692a8a792bd1bf752b8516
2014-07-22 06:59:45,183 INFO  [PostOpenDeployTasks:708b12ffe5692a8a792bd1bf752b8516] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 06:59:45,184 DEBUG [PostOpenDeployTasks:708b12ffe5692a8a792bd1bf752b8516] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:54), split_queue=0, merge_queue=0
2014-07-22 06:59:45,194 INFO  [PostOpenDeployTasks:708b12ffe5692a8a792bd1bf752b8516] catalog.MetaEditor: Updated row usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. with server=slave1,60020,1406034875944
2014-07-22 06:59:45,194 INFO  [PostOpenDeployTasks:708b12ffe5692a8a792bd1bf752b8516] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 06:59:45,195 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 708b12ffe5692a8a792bd1bf752b8516 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:59:45,200 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 708b12ffe5692a8a792bd1bf752b8516 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:59:45,200 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 708b12ffe5692a8a792bd1bf752b8516 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:59:45,200 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. on slave1,60020,1406034875944
2014-07-22 06:59:45,201 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9fefab8f11c8e58bf455cb6ad77b765c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:59:45,205 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9fefab8f11c8e58bf455cb6ad77b765c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-22 06:59:45,205 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 9fefab8f11c8e58bf455cb6ad77b765c, NAME => 'usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-22 06:59:45,206 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:45,206 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 06:59:45,221 INFO  [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-22 06:59:45,257 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/03858644134e4df7b435aaba4bd9d0fe, isReference=false, isBulkLoadResult=false, seqid=10382, majorCompaction=false
2014-07-22 06:59:45,275 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/1ab8253e1fd947daa42b003703f25997, isReference=false, isBulkLoadResult=false, seqid=11606, majorCompaction=false
2014-07-22 06:59:45,314 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3bae8a7b79d84068bed5795b80db58cb, isReference=false, isBulkLoadResult=false, seqid=9791, majorCompaction=false
2014-07-22 06:59:45,334 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/4882bf7a2c3b40a2948cf0d2ea032397, isReference=false, isBulkLoadResult=false, seqid=8195, majorCompaction=false
2014-07-22 06:59:45,396 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/48a8cc01aba64e69bea1afdaf999eea0, isReference=false, isBulkLoadResult=false, seqid=15862, majorCompaction=false
2014-07-22 06:59:45,417 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/55edf31d3eb24d4ba44cabb518e520a3, isReference=false, isBulkLoadResult=false, seqid=15030, majorCompaction=false
2014-07-22 06:59:45,486 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/69604728e239407a8668dd5af18d1d34, isReference=false, isBulkLoadResult=false, seqid=11191, majorCompaction=false
2014-07-22 06:59:45,503 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/71a95375fa85497fba3f5f3d7db11df3, isReference=false, isBulkLoadResult=false, seqid=9207, majorCompaction=false
2014-07-22 06:59:45,512 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:45,515 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 91240, skipped 0, firstSequenceidInLog=15887, maxSequenceidInLog=15902, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015902
2014-07-22 06:59:45,518 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015919
2014-07-22 06:59:45,545 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/84a511896e07469499a2e047e5db4513, isReference=false, isBulkLoadResult=false, seqid=12449, majorCompaction=false
2014-07-22 06:59:45,560 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/9168c866a8d7465196569fab1efb4dc5, isReference=false, isBulkLoadResult=false, seqid=3332, majorCompaction=false
2014-07-22 06:59:45,583 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/997339b8061b4b2aa1c9656bd23b0914, isReference=false, isBulkLoadResult=false, seqid=15463, majorCompaction=false
2014-07-22 06:59:45,598 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/9c2b1f3f11f4480c95da891b12f67058, isReference=false, isBulkLoadResult=false, seqid=2890, majorCompaction=true
2014-07-22 06:59:45,637 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/9e4bacb917c848a7b0df3a6ca9f909a8, isReference=false, isBulkLoadResult=false, seqid=14433, majorCompaction=false
2014-07-22 06:59:45,661 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/a93d44377bc14801bf4ca2bad5572628, isReference=false, isBulkLoadResult=false, seqid=3858, majorCompaction=false
2014-07-22 06:59:45,690 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/aa47e61d44994378a37717573f7370c7, isReference=false, isBulkLoadResult=false, seqid=10986, majorCompaction=false
2014-07-22 06:59:45,730 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ca5b51fc35de4255bfea293f17644204, isReference=false, isBulkLoadResult=false, seqid=13510, majorCompaction=false
2014-07-22 06:59:45,777 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/d292b381c1f14bf186b0460426280367, isReference=false, isBulkLoadResult=false, seqid=8695, majorCompaction=false
2014-07-22 06:59:45,802 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/e861d459c9f44bd682a2ac6ad2f793ae, isReference=false, isBulkLoadResult=false, seqid=12934, majorCompaction=false
2014-07-22 06:59:45,815 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ed707520a6a6462486d4786f96381b76, isReference=false, isBulkLoadResult=false, seqid=13854, majorCompaction=false
2014-07-22 06:59:45,840 DEBUG [StoreOpener-9fefab8f11c8e58bf455cb6ad77b765c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/fd2ce35f53a746e6a016678942461d35, isReference=false, isBulkLoadResult=false, seqid=11997, majorCompaction=false
2014-07-22 06:59:45,971 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 42 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:45,974 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15445 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015445
2014-07-22 06:59:45,976 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15464 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015464
2014-07-22 06:59:45,978 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15478 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015478
2014-07-22 06:59:45,981 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15504 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015504
2014-07-22 06:59:45,982 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15520 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015520
2014-07-22 06:59:45,984 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15546 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015546
2014-07-22 06:59:45,986 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15560 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015560
2014-07-22 06:59:45,988 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15583 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015583
2014-07-22 06:59:46,079 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15602 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015602
2014-07-22 06:59:46,081 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15618 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015618
2014-07-22 06:59:46,082 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15626 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015626
2014-07-22 06:59:46,083 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15660 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015660
2014-07-22 06:59:46,087 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15676 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015676
2014-07-22 06:59:46,088 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15692 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015692
2014-07-22 06:59:46,095 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15706 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015706
2014-07-22 06:59:46,097 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15725 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015725
2014-07-22 06:59:46,099 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15739 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015739
2014-07-22 06:59:46,101 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15754 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015754
2014-07-22 06:59:46,103 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15770 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015770
2014-07-22 06:59:46,105 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15787 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015787
2014-07-22 06:59:46,113 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15801 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015801
2014-07-22 06:59:46,115 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15821 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015821
2014-07-22 06:59:46,117 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Maximum sequenceid for this log is 15838 and minimum sequenceid for the region is 15862, skipped the whole file, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015838
2014-07-22 06:59:46,119 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015867
2014-07-22 06:59:46,552 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:46,603 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 136430, skipped 0, firstSequenceidInLog=16048, maxSequenceidInLog=16071, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016071
2014-07-22 06:59:46,608 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016082
2014-07-22 06:59:46,655 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:46,659 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 28020, skipped 128950, firstSequenceidInLog=15839, maxSequenceidInLog=15867, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015867
2014-07-22 06:59:46,662 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015885
2014-07-22 06:59:46,996 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:47,002 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 98020, skipped 0, firstSequenceidInLog=15903, maxSequenceidInLog=15919, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015919
2014-07-22 06:59:47,005 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015933
2014-07-22 06:59:47,484 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:47,487 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 101660, skipped 0, firstSequenceidInLog=15868, maxSequenceidInLog=15885, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015885
2014-07-22 06:59:47,491 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015905
2014-07-22 06:59:47,694 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:47,699 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 61810, skipped 0, firstSequenceidInLog=16072, maxSequenceidInLog=16082, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016082
2014-07-22 06:59:47,702 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016105
2014-07-22 06:59:47,865 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:47,868 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 79610, skipped 0, firstSequenceidInLog=15920, maxSequenceidInLog=15933, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015933
2014-07-22 06:59:47,873 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015948
2014-07-22 06:59:48,538 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:48,541 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 111790, skipped 0, firstSequenceidInLog=15886, maxSequenceidInLog=15905, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015905
2014-07-22 06:59:48,544 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015921
2014-07-22 06:59:48,796 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:48,799 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 81530, skipped 0, firstSequenceidInLog=15934, maxSequenceidInLog=15948, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015948
2014-07-22 06:59:48,802 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015963
2014-07-22 06:59:49,425 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:49,429 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 89600, skipped 0, firstSequenceidInLog=15906, maxSequenceidInLog=15921, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015921
2014-07-22 06:59:49,433 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015935
2014-07-22 06:59:49,693 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:49,697 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 84110, skipped 0, firstSequenceidInLog=15949, maxSequenceidInLog=15963, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015963
2014-07-22 06:59:49,702 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015980
2014-07-22 06:59:49,785 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:49,789 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 129600, skipped 0, firstSequenceidInLog=16083, maxSequenceidInLog=16105, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016105
2014-07-22 06:59:49,794 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016118
2014-07-22 06:59:50,044 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:50,056 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 80350, skipped 0, firstSequenceidInLog=15922, maxSequenceidInLog=15935, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015935
2014-07-22 06:59:50,060 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015950
2014-07-22 06:59:50,364 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 256.7m; wal is null, using passed sequenceid=16112
2014-07-22 06:59:50,465 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 256.5m; wal is null, using passed sequenceid=15978
2014-07-22 06:59:50,607 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:50,667 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:50,718 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:50,721 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 83320, skipped 0, firstSequenceidInLog=15936, maxSequenceidInLog=15950, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015950
2014-07-22 06:59:50,723 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015966
2014-07-22 06:59:51,391 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:51,395 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 91520, skipped 0, firstSequenceidInLog=15951, maxSequenceidInLog=15966, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015966
2014-07-22 06:59:51,398 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015979
2014-07-22 06:59:51,950 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:51,953 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 73410, skipped 0, firstSequenceidInLog=15967, maxSequenceidInLog=15979, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015979
2014-07-22 06:59:51,956 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016008
2014-07-22 06:59:52,968 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16112, memsize=63.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/352c16c0101e4bfca0cac63529ca766e
2014-07-22 06:59:52,983 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/352c16c0101e4bfca0cac63529ca766e as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/352c16c0101e4bfca0cac63529ca766e
2014-07-22 06:59:52,998 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/352c16c0101e4bfca0cac63529ca766e, entries=229510, sequenceid=16112, filesize=16.4m
2014-07-22 06:59:52,998 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~256.7m/269125840, currentsize=0.0/0 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 2635ms, sequenceid=16112, compaction requested=true; wal=null
2014-07-22 06:59:53,159 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:53,163 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 74190, skipped 0, firstSequenceidInLog=16106, maxSequenceidInLog=16118, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016118
2014-07-22 06:59:53,165 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016131
2014-07-22 06:59:53,459 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:53,464 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 164710, skipped 0, firstSequenceidInLog=15980, maxSequenceidInLog=16008, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016008
2014-07-22 06:59:53,467 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016026
2014-07-22 06:59:53,557 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:53,560 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 71330, skipped 0, firstSequenceidInLog=16119, maxSequenceidInLog=16131, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016131
2014-07-22 06:59:53,564 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016146
2014-07-22 06:59:54,067 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:54,069 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 85080, skipped 0, firstSequenceidInLog=16132, maxSequenceidInLog=16146, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016146
2014-07-22 06:59:54,075 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016163
2014-07-22 06:59:54,539 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:54,542 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 101580, skipped 0, firstSequenceidInLog=16009, maxSequenceidInLog=16026, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016026
2014-07-22 06:59:54,585 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016042
2014-07-22 06:59:54,718 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 257.6m; wal is null, using passed sequenceid=16028
2014-07-22 06:59:54,743 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:54,745 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 97490, skipped 0, firstSequenceidInLog=16147, maxSequenceidInLog=16163, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016163
2014-07-22 06:59:54,750 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016179
2014-07-22 06:59:54,904 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:55,120 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15978, memsize=125.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/175293c9ff234c52b3b3efa92f05a3e8
2014-07-22 06:59:55,133 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/175293c9ff234c52b3b3efa92f05a3e8 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/175293c9ff234c52b3b3efa92f05a3e8
2014-07-22 06:59:55,142 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/175293c9ff234c52b3b3efa92f05a3e8, entries=457300, sequenceid=15978, filesize=32.6m
2014-07-22 06:59:55,142 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~256.5m/268941200, currentsize=0.0/0 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 4677ms, sequenceid=15978, compaction requested=true; wal=null
2014-07-22 06:59:55,177 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:55,180 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 95410, skipped 0, firstSequenceidInLog=15964, maxSequenceidInLog=15980, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015980
2014-07-22 06:59:55,184 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016005
2014-07-22 06:59:55,507 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:55,510 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 90490, skipped 0, firstSequenceidInLog=16164, maxSequenceidInLog=16179, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016179
2014-07-22 06:59:55,513 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016181
2014-07-22 06:59:55,604 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:55,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Applied 11320, skipped 0, firstSequenceidInLog=16180, maxSequenceidInLog=16181, path=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016181
2014-07-22 06:59:55,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 107.2m; wal is null, using passed sequenceid=16181
2014-07-22 06:59:55,642 DEBUG [RS_OPEN_REGION-slave1:60020-1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 06:59:56,000 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:56,003 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 141910, skipped 0, firstSequenceidInLog=15981, maxSequenceidInLog=16005, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016005
2014-07-22 06:59:56,007 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016028
2014-07-22 06:59:56,953 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:56,958 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 130180, skipped 0, firstSequenceidInLog=16006, maxSequenceidInLog=16028, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016028
2014-07-22 06:59:56,960 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016041
2014-07-22 06:59:57,536 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:57,542 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 72720, skipped 0, firstSequenceidInLog=16029, maxSequenceidInLog=16041, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016041
2014-07-22 06:59:57,547 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016065
2014-07-22 06:59:58,426 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16181, memsize=88.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/1541ef227b7243e2a4844f3f6bef50a3
2014-07-22 06:59:58,443 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/1541ef227b7243e2a4844f3f6bef50a3 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1541ef227b7243e2a4844f3f6bef50a3
2014-07-22 06:59:58,456 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1541ef227b7243e2a4844f3f6bef50a3, entries=322210, sequenceid=16181, filesize=22.9m
2014-07-22 06:59:58,457 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Finished memstore flush of ~107.2m/112412720, currentsize=0.0/0 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 2848ms, sequenceid=16181, compaction requested=true; wal=null
2014-07-22 06:59:58,459 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015467
2014-07-22 06:59:58,461 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015484
2014-07-22 06:59:58,462 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015508
2014-07-22 06:59:58,465 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015524
2014-07-22 06:59:58,467 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015546
2014-07-22 06:59:58,469 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015565
2014-07-22 06:59:58,470 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015586
2014-07-22 06:59:58,472 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015598
2014-07-22 06:59:58,474 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015616
2014-07-22 06:59:58,478 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015630
2014-07-22 06:59:58,479 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015661
2014-07-22 06:59:58,481 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015668
2014-07-22 06:59:58,483 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015683
2014-07-22 06:59:58,484 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015697
2014-07-22 06:59:58,488 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015713
2014-07-22 06:59:58,489 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015734
2014-07-22 06:59:58,491 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015749
2014-07-22 06:59:58,493 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015766
2014-07-22 06:59:58,497 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015786
2014-07-22 06:59:58,498 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015805
2014-07-22 06:59:58,500 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015825
2014-07-22 06:59:58,501 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015851
2014-07-22 06:59:58,504 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015869
2014-07-22 06:59:58,505 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015883
2014-07-22 06:59:58,507 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015899
2014-07-22 06:59:58,508 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015911
2014-07-22 06:59:58,510 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015928
2014-07-22 06:59:58,512 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015944
2014-07-22 06:59:58,514 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015959
2014-07-22 06:59:58,515 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015978
2014-07-22 06:59:58,517 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000015996
2014-07-22 06:59:58,520 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016027
2014-07-22 06:59:58,521 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016047
2014-07-22 06:59:58,523 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016071
2014-07-22 06:59:58,524 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016082
2014-07-22 06:59:58,525 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016105
2014-07-22 06:59:58,527 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016118
2014-07-22 06:59:58,528 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016131
2014-07-22 06:59:58,529 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016146
2014-07-22 06:59:58,531 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016163
2014-07-22 06:59:58,533 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016179
2014-07-22 06:59:58,535 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/recovered.edits/0000000000000016181
2014-07-22 06:59:58,537 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 5688494b49c628b8cf95eecd57a989f3; next sequenceid=16182
2014-07-22 06:59:58,537 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5688494b49c628b8cf95eecd57a989f3
2014-07-22 06:59:58,541 INFO  [PostOpenDeployTasks:5688494b49c628b8cf95eecd57a989f3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 06:59:58,542 DEBUG [PostOpenDeployTasks:5688494b49c628b8cf95eecd57a989f3] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:55), split_queue=0, merge_queue=0
2014-07-22 06:59:58,551 INFO  [PostOpenDeployTasks:5688494b49c628b8cf95eecd57a989f3] catalog.MetaEditor: Updated row usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. with server=slave1,60020,1406034875944
2014-07-22 06:59:58,551 INFO  [PostOpenDeployTasks:5688494b49c628b8cf95eecd57a989f3] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 06:59:58,552 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5688494b49c628b8cf95eecd57a989f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:59:58,561 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5688494b49c628b8cf95eecd57a989f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 06:59:58,561 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 5688494b49c628b8cf95eecd57a989f3 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 06:59:58,561 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. on slave1,60020,1406034875944
2014-07-22 06:59:58,774 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:58,777 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 135640, skipped 0, firstSequenceidInLog=16042, maxSequenceidInLog=16065, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016065
2014-07-22 06:59:58,780 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016079
2014-07-22 06:59:59,521 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16028, memsize=130.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/3452674414ae4558a562768ac1138b75
2014-07-22 06:59:59,544 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/3452674414ae4558a562768ac1138b75 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3452674414ae4558a562768ac1138b75
2014-07-22 06:59:59,572 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3452674414ae4558a562768ac1138b75, entries=473940, sequenceid=16028, filesize=33.8m
2014-07-22 06:59:59,573 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~257.6m/270125040, currentsize=0.0/0 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 4854ms, sequenceid=16028, compaction requested=true; wal=null
2014-07-22 06:59:59,846 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 06:59:59,855 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 79880, skipped 0, firstSequenceidInLog=16066, maxSequenceidInLog=16079, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016079
2014-07-22 06:59:59,862 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016098
2014-07-22 06:59:59,949 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 06:59:59,955 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 89070, skipped 0, firstSequenceidInLog=16027, maxSequenceidInLog=16042, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016042
2014-07-22 06:59:59,957 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016063
2014-07-22 07:00:00,728 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:00,731 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 118710, skipped 0, firstSequenceidInLog=16043, maxSequenceidInLog=16063, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016063
2014-07-22 07:00:00,737 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016079
2014-07-22 07:00:01,336 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:01,342 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 107560, skipped 0, firstSequenceidInLog=16080, maxSequenceidInLog=16098, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016098
2014-07-22 07:00:01,344 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016122
2014-07-22 07:00:01,465 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:01,467 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 90420, skipped 0, firstSequenceidInLog=16064, maxSequenceidInLog=16079, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016079
2014-07-22 07:00:01,471 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016102
2014-07-22 07:00:02,683 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:02,687 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 130580, skipped 0, firstSequenceidInLog=16080, maxSequenceidInLog=16102, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016102
2014-07-22 07:00:02,691 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016123
2014-07-22 07:00:02,933 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:02,936 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 134970, skipped 0, firstSequenceidInLog=16099, maxSequenceidInLog=16122, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016122
2014-07-22 07:00:02,938 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016136
2014-07-22 07:00:03,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:03,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23540 synced till here 23538
2014-07-22 07:00:03,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037581436 with entries=79, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037603700
2014-07-22 07:00:03,992 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:03,995 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 78660, skipped 0, firstSequenceidInLog=16123, maxSequenceidInLog=16136, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016136
2014-07-22 07:00:03,997 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016150
2014-07-22 07:00:04,826 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:04,830 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 119250, skipped 0, firstSequenceidInLog=16103, maxSequenceidInLog=16123, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016123
2014-07-22 07:00:04,836 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016140
2014-07-22 07:00:05,399 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 257.7m; wal is null, using passed sequenceid=16144
2014-07-22 07:00:05,760 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:00:05,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:05,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037603700 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037605901
2014-07-22 07:00:06,933 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:07,011 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 95810, skipped 0, firstSequenceidInLog=16124, maxSequenceidInLog=16140, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016140
2014-07-22 07:00:07,015 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016152
2014-07-22 07:00:07,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:07,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037605901 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037607884
2014-07-22 07:00:08,199 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:08,203 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 68060, skipped 0, firstSequenceidInLog=16141, maxSequenceidInLog=16152, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016152
2014-07-22 07:00:08,205 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016167
2014-07-22 07:00:08,418 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:00:08,418 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 257.4m
2014-07-22 07:00:08,716 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:00:09,298 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:09,302 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 85310, skipped 0, firstSequenceidInLog=16153, maxSequenceidInLog=16167, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016167
2014-07-22 07:00:09,304 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168
2014-07-22 07:00:09,455 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:09,460 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Applied 5670, skipped 0, firstSequenceidInLog=16168, maxSequenceidInLog=16168, path=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168
2014-07-22 07:00:09,460 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 217.2m; wal is null, using passed sequenceid=16168
2014-07-22 07:00:09,610 DEBUG [RS_OPEN_REGION-slave1:60020-0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:00:10,257 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16144, memsize=74.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/2e78da83772141b68d35840856d610ff
2014-07-22 07:00:10,268 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/2e78da83772141b68d35840856d610ff as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/2e78da83772141b68d35840856d610ff
2014-07-22 07:00:10,289 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/2e78da83772141b68d35840856d610ff, entries=270220, sequenceid=16144, filesize=19.2m
2014-07-22 07:00:10,289 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~257.7m/270202480, currentsize=0.0/0 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 4890ms, sequenceid=16144, compaction requested=true; wal=null
2014-07-22 07:00:10,411 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:10,414 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 80240, skipped 0, firstSequenceidInLog=16137, maxSequenceidInLog=16150, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016150
2014-07-22 07:00:10,416 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016164
2014-07-22 07:00:10,834 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:10,837 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 78090, skipped 0, firstSequenceidInLog=16151, maxSequenceidInLog=16164, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016164
2014-07-22 07:00:10,839 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Replaying edits from hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016166
2014-07-22 07:00:10,910 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:10,913 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Applied 11750, skipped 0, firstSequenceidInLog=16165, maxSequenceidInLog=16166, path=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016166
2014-07-22 07:00:10,913 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 34.0m; wal is null, using passed sequenceid=16166
2014-07-22 07:00:10,932 DEBUG [RS_OPEN_REGION-slave1:60020-2] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:00:11,843 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16166, memsize=34.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/529275e7378f4d429d5be2615aafc9e4
2014-07-22 07:00:11,852 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/529275e7378f4d429d5be2615aafc9e4 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/529275e7378f4d429d5be2615aafc9e4
2014-07-22 07:00:11,859 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/529275e7378f4d429d5be2615aafc9e4, entries=123960, sequenceid=16166, filesize=8.8m
2014-07-22 07:00:11,860 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Finished memstore flush of ~34.0m/35699280, currentsize=0.0/0 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 947ms, sequenceid=16166, compaction requested=true; wal=null
2014-07-22 07:00:11,861 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015442
2014-07-22 07:00:11,863 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015461
2014-07-22 07:00:11,864 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015478
2014-07-22 07:00:11,865 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015506
2014-07-22 07:00:11,866 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015529
2014-07-22 07:00:11,867 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015545
2014-07-22 07:00:11,878 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015560
2014-07-22 07:00:11,879 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015583
2014-07-22 07:00:11,881 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015600
2014-07-22 07:00:11,891 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015616
2014-07-22 07:00:11,892 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015625
2014-07-22 07:00:11,893 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015660
2014-07-22 07:00:11,895 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015674
2014-07-22 07:00:11,896 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015688
2014-07-22 07:00:11,897 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015703
2014-07-22 07:00:11,898 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015724
2014-07-22 07:00:11,900 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015740
2014-07-22 07:00:11,901 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015753
2014-07-22 07:00:11,902 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015771
2014-07-22 07:00:11,903 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015783
2014-07-22 07:00:11,904 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015802
2014-07-22 07:00:11,905 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015824
2014-07-22 07:00:11,906 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015845
2014-07-22 07:00:11,907 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015867
2014-07-22 07:00:11,908 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015886
2014-07-22 07:00:11,909 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015902
2014-07-22 07:00:11,910 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015919
2014-07-22 07:00:11,912 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015933
2014-07-22 07:00:11,913 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015948
2014-07-22 07:00:11,914 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015963
2014-07-22 07:00:11,915 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000015980
2014-07-22 07:00:11,916 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016005
2014-07-22 07:00:11,917 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016028
2014-07-22 07:00:11,918 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016041
2014-07-22 07:00:11,920 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016065
2014-07-22 07:00:11,921 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016079
2014-07-22 07:00:11,922 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016098
2014-07-22 07:00:11,930 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016122
2014-07-22 07:00:11,931 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016136
2014-07-22 07:00:11,933 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016150
2014-07-22 07:00:11,935 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016164
2014-07-22 07:00:11,936 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/recovered.edits/0000000000000016166
2014-07-22 07:00:11,941 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined d29123f6203691d46817543c7ec8a423; next sequenceid=16167
2014-07-22 07:00:11,941 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d29123f6203691d46817543c7ec8a423
2014-07-22 07:00:11,943 INFO  [PostOpenDeployTasks:d29123f6203691d46817543c7ec8a423] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:00:11,944 DEBUG [PostOpenDeployTasks:d29123f6203691d46817543c7ec8a423] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:56), split_queue=0, merge_queue=0
2014-07-22 07:00:11,952 INFO  [PostOpenDeployTasks:d29123f6203691d46817543c7ec8a423] catalog.MetaEditor: Updated row usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. with server=slave1,60020,1406034875944
2014-07-22 07:00:11,952 INFO  [PostOpenDeployTasks:d29123f6203691d46817543c7ec8a423] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:00:11,953 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d29123f6203691d46817543c7ec8a423 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 07:00:11,962 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d29123f6203691d46817543c7ec8a423 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 07:00:11,962 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned d29123f6203691d46817543c7ec8a423 to OPENED in zk on slave1,60020,1406034875944
2014-07-22 07:00:11,962 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. on slave1,60020,1406034875944
2014-07-22 07:00:12,715 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16168, memsize=90.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/65163f646a254f85b30a41099c174d35
2014-07-22 07:00:12,920 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/65163f646a254f85b30a41099c174d35 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/65163f646a254f85b30a41099c174d35
2014-07-22 07:00:12,934 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/65163f646a254f85b30a41099c174d35, entries=328870, sequenceid=16168, filesize=23.4m
2014-07-22 07:00:12,935 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Finished memstore flush of ~217.2m/227767280, currentsize=0.0/0 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 3475ms, sequenceid=16168, compaction requested=true; wal=null
2014-07-22 07:00:12,936 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015445
2014-07-22 07:00:12,937 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015464
2014-07-22 07:00:12,939 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015478
2014-07-22 07:00:12,940 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015504
2014-07-22 07:00:12,941 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015520
2014-07-22 07:00:12,942 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015546
2014-07-22 07:00:12,944 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015560
2014-07-22 07:00:12,945 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015583
2014-07-22 07:00:12,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015602
2014-07-22 07:00:12,947 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015618
2014-07-22 07:00:12,948 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015626
2014-07-22 07:00:12,949 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015660
2014-07-22 07:00:12,951 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015676
2014-07-22 07:00:12,952 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015692
2014-07-22 07:00:12,953 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015706
2014-07-22 07:00:12,954 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015725
2014-07-22 07:00:12,955 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015739
2014-07-22 07:00:12,956 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015754
2014-07-22 07:00:12,957 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015770
2014-07-22 07:00:12,958 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015787
2014-07-22 07:00:12,959 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015801
2014-07-22 07:00:12,960 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015821
2014-07-22 07:00:12,962 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015838
2014-07-22 07:00:12,963 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015867
2014-07-22 07:00:12,965 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015885
2014-07-22 07:00:12,966 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015905
2014-07-22 07:00:12,967 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015921
2014-07-22 07:00:12,968 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015935
2014-07-22 07:00:12,969 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015950
2014-07-22 07:00:12,971 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015966
2014-07-22 07:00:12,972 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000015979
2014-07-22 07:00:12,973 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016008
2014-07-22 07:00:12,974 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016026
2014-07-22 07:00:12,975 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016042
2014-07-22 07:00:12,976 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016063
2014-07-22 07:00:12,977 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016079
2014-07-22 07:00:12,979 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016102
2014-07-22 07:00:12,980 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016123
2014-07-22 07:00:12,981 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016140
2014-07-22 07:00:12,982 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016152
2014-07-22 07:00:12,983 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016167
2014-07-22 07:00:13,000 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Deleted recovered.edits file=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/recovered.edits/0000000000000016168
2014-07-22 07:00:13,002 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 9fefab8f11c8e58bf455cb6ad77b765c; next sequenceid=16169
2014-07-22 07:00:13,002 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fefab8f11c8e58bf455cb6ad77b765c
2014-07-22 07:00:13,005 INFO  [PostOpenDeployTasks:9fefab8f11c8e58bf455cb6ad77b765c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:00:13,005 DEBUG [PostOpenDeployTasks:9fefab8f11c8e58bf455cb6ad77b765c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-22 07:00:13,013 INFO  [PostOpenDeployTasks:9fefab8f11c8e58bf455cb6ad77b765c] catalog.MetaEditor: Updated row usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. with server=slave1,60020,1406034875944
2014-07-22 07:00:13,013 INFO  [PostOpenDeployTasks:9fefab8f11c8e58bf455cb6ad77b765c] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:00:13,014 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9fefab8f11c8e58bf455cb6ad77b765c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 07:00:13,019 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x475e35978f0000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9fefab8f11c8e58bf455cb6ad77b765c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-22 07:00:13,019 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 9fefab8f11c8e58bf455cb6ad77b765c to OPENED in zk on slave1,60020,1406034875944
2014-07-22 07:00:13,019 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. on slave1,60020,1406034875944
2014-07-22 07:00:13,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:13,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037607884 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037613403
2014-07-22 07:00:17,085 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5929, memsize=257.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/c538702c6afe40eaaa5071f9b77a9cea
2014-07-22 07:00:17,096 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/c538702c6afe40eaaa5071f9b77a9cea as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c538702c6afe40eaaa5071f9b77a9cea
2014-07-22 07:00:17,106 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/c538702c6afe40eaaa5071f9b77a9cea, entries=937240, sequenceid=5929, filesize=66.8m
2014-07-22 07:00:17,107 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.4m/269918240, currentsize=7.8m/8135760 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 8689ms, sequenceid=5929, compaction requested=true
2014-07-22 07:00:17,107 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-22 07:00:24,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:24,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23851 synced till here 23850
2014-07-22 07:00:24,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037613403 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037624143
2014-07-22 07:00:25,771 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23931 synced till here 23927
2014-07-22 07:00:25,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037624143 with entries=80, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037625772
2014-07-22 07:00:27,327 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:27,437 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24016 synced till here 24010
2014-07-22 07:00:27,635 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037625772 with entries=85, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037627328
2014-07-22 07:00:29,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:29,168 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037627328 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037629147
2014-07-22 07:00:31,185 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:31,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24179 synced till here 24173
2014-07-22 07:00:31,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037629147 with entries=84, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037631185
2014-07-22 07:00:33,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:33,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24273 synced till here 24262
2014-07-22 07:00:33,452 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037631185 with entries=94, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037633142
2014-07-22 07:00:34,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:34,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24361 synced till here 24352
2014-07-22 07:00:35,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037633142 with entries=88, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037634781
2014-07-22 07:00:35,538 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:00:35,538 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 257.7m
2014-07-22 07:00:36,125 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:00:36,903 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:36,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24451 synced till here 24441
2014-07-22 07:00:37,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037634781 with entries=90, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037636904
2014-07-22 07:00:38,479 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:38,558 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24536 synced till here 24527
2014-07-22 07:00:38,729 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037636904 with entries=85, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037638479
2014-07-22 07:00:40,332 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:40,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24624 synced till here 24617
2014-07-22 07:00:40,501 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037638479 with entries=88, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037640332
2014-07-22 07:00:42,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:42,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24710 synced till here 24699
2014-07-22 07:00:42,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037640332 with entries=86, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037642295
2014-07-22 07:00:43,723 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:00:43,724 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 256.0m
2014-07-22 07:00:44,389 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:00:44,588 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:44,595 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:00:44,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24803 synced till here 24794
2014-07-22 07:00:44,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037642295 with entries=93, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037644588
2014-07-22 07:00:45,258 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:00:45,776 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:00:46,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:47,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24894 synced till here 24883
2014-07-22 07:00:47,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037644588 with entries=91, filesize=73.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037646880
2014-07-22 07:00:47,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:00:47,600 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:00:49,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:49,955 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24989 synced till here 24978
2014-07-22 07:00:50,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037646880 with entries=95, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037649797
2014-07-22 07:00:50,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:00:55,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:55,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25076 synced till here 25068
2014-07-22 07:00:55,725 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037649797 with entries=87, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037655322
2014-07-22 07:00:55,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:00:55,993 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:00:58,610 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:00:58,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25171 synced till here 25155
2014-07-22 07:00:58,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037655322 with entries=95, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037658611
2014-07-22 07:00:58,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:01,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:01:01,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25269 synced till here 25253
2014-07-22 07:01:11,058 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9083ms
GC pool 'ParNew' had collection(s): count=1 time=100ms
2014-07-22 07:01:11,096 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:01:11,601 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037658611 with entries=98, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037661233
2014-07-22 07:01:11,602 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:12,690 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14624,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037656951,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:12,690 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14094,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037657483,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:12,690 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14969,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037656606,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:12,690 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14188,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037657764,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:13,293 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037658205,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:13,294 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14658,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037658612,"queuetimems":10,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:14,087 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f0d8c4517af44f8ca9f60e963a481f60 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f0d8c4517af44f8ca9f60e963a481f60
2014-07-22 07:01:14,257 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:01:14,268 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15421,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037658816,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:14,392 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/6e7b86afed854c0d811b4fae50296be8, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/6e7b86afed854c0d811b4fae50296be8
2014-07-22 07:01:14,406 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/cc3a8375bc1046348d35cf5dd528eee8, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/cc3a8375bc1046348d35cf5dd528eee8
2014-07-22 07:01:14,408 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/59bb3aa8eb1345e287b48f13c02b4cdb, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/59bb3aa8eb1345e287b48f13c02b4cdb
2014-07-22 07:01:14,411 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4f3d758804b44119903a4590fff6b776, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/4f3d758804b44119903a4590fff6b776
2014-07-22 07:01:14,416 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/dc36b827444b44b9abb0292f6430c650, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/dc36b827444b44b9abb0292f6430c650
2014-07-22 07:01:14,418 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/75b27075301d4e8d86896582790e2d14, to hdfs://master:54310/hbase/archive/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/75b27075301d4e8d86896582790e2d14
2014-07-22 07:01:14,418 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 6 file(s) in family of usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. into f0d8c4517af44f8ca9f60e963a481f60(size=402.3m), total size for store is 2.3g. This selection was in queue for 0sec, and took 1mins, 36sec to execute.
2014-07-22 07:01:14,419 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., storeName=family, fileCount=6, fileSize=402.5m, priority=1992, time=134558120804238; duration=1mins, 36sec
2014-07-22 07:01:14,419 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-22 07:01:14,419 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 2000 blocking
2014-07-22 07:01:14,444 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 619661611 starting at candidate #16 after considering 164 permutations with 135 in ratio
2014-07-22 07:01:14,445 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 708b12ffe5692a8a792bd1bf752b8516 - family: Initiating minor compaction
2014-07-22 07:01:14,445 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:01:14,445 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp, totalSize=591.0m
2014-07-22 07:01:14,445 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8722071116fa409b84d55b65195034dc, keycount=153054, bloomtype=ROW, size=109.1m, encoding=NONE, seqNum=13175
2014-07-22 07:01:14,445 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d91463129cec4d3491cd1632f385e1b2, keycount=53206, bloomtype=ROW, size=37.9m, encoding=NONE, seqNum=13619
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/dbe8b4f5a1294eafa0efbdc6bd686509, keycount=156723, bloomtype=ROW, size=111.7m, encoding=NONE, seqNum=14118
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/71c68ca4b86a474ca15c84cb4e30731b, keycount=114995, bloomtype=ROW, size=81.9m, encoding=NONE, seqNum=14685
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/41cb33e841214b7789a2a0931b0e16d1, keycount=103718, bloomtype=ROW, size=73.9m, encoding=NONE, seqNum=15143
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7d4ad5e320d045649eb3e38cc10cac9d, keycount=97921, bloomtype=ROW, size=69.7m, encoding=NONE, seqNum=15653
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/550de4ff4a484b639a03cb3d572890e0, keycount=66180, bloomtype=ROW, size=47.2m, encoding=NONE, seqNum=15820
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/75ac1cfd34004c899b4a4275fcfc7f60, keycount=36609, bloomtype=ROW, size=26.1m, encoding=NONE, seqNum=15986
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/e49771c6e18546449481ea73899f299e, keycount=16924, bloomtype=ROW, size=12.1m, encoding=NONE, seqNum=16152
2014-07-22 07:01:14,446 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8690042935ad4e1bb8bba5840f5aef52, keycount=30096, bloomtype=ROW, size=21.4m, encoding=NONE, seqNum=16205
2014-07-22 07:01:14,694 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037659164,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:14,750 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5989, memsize=260.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/9e5197a109284984b7859b69750278c5
2014-07-22 07:01:15,119 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/9e5197a109284984b7859b69750278c5 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9e5197a109284984b7859b69750278c5
2014-07-22 07:01:15,121 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:01:15,170 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9e5197a109284984b7859b69750278c5, entries=949200, sequenceid=5989, filesize=67.7m
2014-07-22 07:01:15,184 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.7m/273360800, currentsize=155.2m/162700560 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 39646ms, sequenceid=5989, compaction requested=true
2014-07-22 07:01:15,184 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-22 07:01:15,184 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 347.2m
2014-07-22 07:01:17,087 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1033ms
GC pool 'ParNew' had collection(s): count=1 time=1370ms
2014-07-22 07:01:17,262 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17842,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037659319,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:19,082 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19540,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037659472,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:19,215 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:01:20,036 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:01:20,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25357 synced till here 25348
2014-07-22 07:01:21,121 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037659741,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:21,203 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21139,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037659982,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:21,263 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037661233 with entries=88, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037679216
2014-07-22 07:01:21,263 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:23,235 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22642,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037660565,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:23,797 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23269,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037660292,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:23,897 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23760,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037660132,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:26,298 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1629ms
GC pool 'ParNew' had collection(s): count=1 time=1943ms
2014-07-22 07:01:27,167 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:01:27,218 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26125,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037661043,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:28,035 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037661209,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:28,120 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27227,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037660892,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:28,121 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037660729,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:28,121 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26630,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037661489,"queuetimems":6,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:28,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:01:28,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25441 synced till here 25436
2014-07-22 07:01:29,100 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037679216 with entries=84, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037688594
2014-07-22 07:01:29,101 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:30,043 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15551,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037674487,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:31,794 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14674,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037677093,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:31,795 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16193,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037675574,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,177 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13984,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037678189,"queuetimems":50,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,190 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17043,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037675115,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,416 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12378,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037679905,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,465 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15243,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037677220,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,465 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12284,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037680179,"queuetimems":10,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,466 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037679028,"queuetimems":15,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,526 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13894,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037678630,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,546 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11037,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037681507,"queuetimems":3,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:32,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:01:33,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25525 synced till here 25522
2014-07-22 07:01:33,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037688594 with entries=84, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037692921
2014-07-22 07:01:33,291 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:35,119 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10901,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037684204,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:01:38,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:01:38,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25606 synced till here 25605
2014-07-22 07:01:39,083 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037692921 with entries=81, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037698483
2014-07-22 07:01:39,091 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:45,098 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:01:45,288 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16373, memsize=257.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/4899efe7e3f64f4a81bc2527c65a313b
2014-07-22 07:01:45,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25696 synced till here 25684
2014-07-22 07:01:45,338 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/4899efe7e3f64f4a81bc2527c65a313b as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/4899efe7e3f64f4a81bc2527c65a313b
2014-07-22 07:01:45,358 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/4899efe7e3f64f4a81bc2527c65a313b, entries=937910, sequenceid=16373, filesize=66.8m
2014-07-22 07:01:45,359 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.6m/270110320, currentsize=161.6m/169454160 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 61635ms, sequenceid=16373, compaction requested=true
2014-07-22 07:01:45,359 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-22 07:01:45,369 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 404.0m
2014-07-22 07:01:45,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037698483 with entries=90, filesize=73.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037705099
2014-07-22 07:01:45,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:01:47,708 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:02:25,576 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 44208ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-22 07:02:25,576 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 35593ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=35919ms
2014-07-22 07:02:25,576 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 44208ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-22 07:02:25,576 WARN  [regionserver60020] util.Sleeper: We slept 36022ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-22 07:02:25,580 WARN  [ResponseProcessor for block blk_7621706887234115673_259337] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_7621706887234115673_259337java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.59:47896 remote=/9.1.143.59:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-22 07:02:25,580 WARN  [DataStreamer for file /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034912792.meta block blk_7621706887234115673_259337] hdfs.DFSClient: Error Recovery for blk_7621706887234115673_259337 bad datanode[0] 9.1.143.59:50010
2014-07-22 07:02:25,581 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 65698ms for sessionid 0x1475e3590bf0004, closing socket connection and attempting reconnect
2014-07-22 07:02:25,583 WARN  [DataStreamer for file /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034912792.meta block blk_7621706887234115673_259337] hdfs.DFSClient: Error Recovery for block blk_7621706887234115673_259337 in pipeline 9.1.143.59:50010, 9.1.143.58:50010: bad datanode 9.1.143.59:50010
2014-07-22 07:02:25,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:25,640 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45409,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037700230,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:25,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25786 synced till here 25777
2014-07-22 07:02:25,793 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037705099 with entries=90, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037745638
2014-07-22 07:02:25,794 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:26,055 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-22 07:02:26,056 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-22 07:02:26,069 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x1475e3590bf0004, negotiated timeout = 90000
2014-07-22 07:02:26,306 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45328,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037700978,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:26,867 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037701388,"queuetimems":4,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:26,867 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":46277,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037700589,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:26,869 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44547,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037702321,"queuetimems":3,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:27,035 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037701903,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:27,073 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42529,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037704544,"queuetimems":4,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,279 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037704174,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,289 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037703698,"queuetimems":12,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,291 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":45896,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037702394,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,291 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44168,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037704122,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,397 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037706107,"queuetimems":8,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,514 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":44034,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037704479,"queuetimems":8,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,514 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42775,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037705739,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,514 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037706769,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:28,642 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:28,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25871 synced till here 25870
2014-07-22 07:02:28,844 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41705,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037707138,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:30,226 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1146ms
GC pool 'ParNew' had collection(s): count=1 time=1353ms
2014-07-22 07:02:30,241 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037745638 with entries=85, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037748643
2014-07-22 07:02:30,241 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:30,499 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:02:30,502 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41811,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037708691,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:30,550 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41741,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037708808,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:30,550 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037708298,"queuetimems":5,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:30,550 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":41044,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037709506,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:02:31,149 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:32,537 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1309ms
GC pool 'ParNew' had collection(s): count=1 time=1357ms
2014-07-22 07:02:32,552 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25958 synced till here 25952
2014-07-22 07:02:32,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037748643 with entries=87, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037751149
2014-07-22 07:02:32,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:34,323 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:34,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26044 synced till here 26037
2014-07-22 07:02:34,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037751149 with entries=86, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037754324
2014-07-22 07:02:34,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:35,543 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1005ms
GC pool 'ParNew' had collection(s): count=1 time=1080ms
2014-07-22 07:02:38,186 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1141ms
GC pool 'ParNew' had collection(s): count=1 time=1488ms
2014-07-22 07:02:38,190 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:38,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26137 synced till here 26127
2014-07-22 07:02:38,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037754324 with entries=93, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037758190
2014-07-22 07:02:38,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:42,050 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:42,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26231 synced till here 26219
2014-07-22 07:02:42,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037758190 with entries=94, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037762051
2014-07-22 07:02:42,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:42,430 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16406, memsize=347.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/747a94e63aa742398f307a2262b602e6
2014-07-22 07:02:42,441 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/747a94e63aa742398f307a2262b602e6 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/747a94e63aa742398f307a2262b602e6
2014-07-22 07:02:42,462 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/747a94e63aa742398f307a2262b602e6, entries=1264020, sequenceid=16406, filesize=90.0m
2014-07-22 07:02:42,462 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~347.2m/364029440, currentsize=161.4m/169250480 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 87278ms, sequenceid=16406, compaction requested=true
2014-07-22 07:02:42,463 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-22 07:02:42,463 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 499.0m
2014-07-22 07:02:42,570 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:02:45,030 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1438ms
GC pool 'ParNew' had collection(s): count=1 time=1564ms
2014-07-22 07:02:45,148 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:02:45,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:45,272 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26321 synced till here 26312
2014-07-22 07:02:45,365 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037762051 with entries=90, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037765254
2014-07-22 07:02:45,366 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:47,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:47,429 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26404 synced till here 26403
2014-07-22 07:02:47,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037765254 with entries=83, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037767398
2014-07-22 07:02:47,452 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:48,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:48,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26488 synced till here 26482
2014-07-22 07:02:48,579 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037767398 with entries=84, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037768442
2014-07-22 07:02:48,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:49,885 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1032ms
GC pool 'ParNew' had collection(s): count=1 time=1248ms
2014-07-22 07:02:51,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:51,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26576 synced till here 26575
2014-07-22 07:02:51,495 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037768442 with entries=88, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037771356
2014-07-22 07:02:51,496 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:53,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:53,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26660 synced till here 26654
2014-07-22 07:02:54,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037771356 with entries=84, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037773813
2014-07-22 07:02:54,031 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:02:55,571 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1178ms
GC pool 'ParNew' had collection(s): count=1 time=1293ms
2014-07-22 07:02:56,184 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,312 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,320 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,358 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,359 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,362 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,368 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,407 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,407 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,409 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,447 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,543 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,667 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,822 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,909 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:56,986 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:02:57,078 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16439, memsize=407.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/b3e2fc90205e4862b25f891e5d1e4cb2
2014-07-22 07:02:57,094 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/b3e2fc90205e4862b25f891e5d1e4cb2 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b3e2fc90205e4862b25f891e5d1e4cb2
2014-07-22 07:02:57,105 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b3e2fc90205e4862b25f891e5d1e4cb2, entries=1482760, sequenceid=16439, filesize=105.7m
2014-07-22 07:02:57,105 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~407.2m/427023680, currentsize=175.2m/183675520 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 71736ms, sequenceid=16439, compaction requested=true
2014-07-22 07:02:57,106 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-22 07:02:57,106 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 120ms
2014-07-22 07:02:57,106 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,106 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 326.1m
2014-07-22 07:02:57,106 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 197ms
2014-07-22 07:02:57,106 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,107 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 285ms
2014-07-22 07:02:57,107 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,107 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 440ms
2014-07-22 07:02:57,107 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,109 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 566ms
2014-07-22 07:02:57,109 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,110 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 662ms
2014-07-22 07:02:57,110 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,110 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 701ms
2014-07-22 07:02:57,110 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,125 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 718ms
2014-07-22 07:02:57,125 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,125 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 718ms
2014-07-22 07:02:57,126 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,126 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 758ms
2014-07-22 07:02:57,126 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,129 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 767ms
2014-07-22 07:02:57,129 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,129 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 771ms
2014-07-22 07:02:57,129 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,129 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 771ms
2014-07-22 07:02:57,129 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,130 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 810ms
2014-07-22 07:02:57,130 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,130 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 818ms
2014-07-22 07:02:57,130 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:57,137 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 956ms
2014-07-22 07:02:57,137 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:02:58,882 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1310ms
GC pool 'ParNew' had collection(s): count=1 time=1501ms
2014-07-22 07:02:58,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:02:58,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26745 synced till here 26737
2014-07-22 07:02:58,991 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:02:59,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037773813 with entries=85, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037778920
2014-07-22 07:02:59,506 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:03:01,143 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:01,161 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26839 synced till here 26828
2014-07-22 07:03:01,260 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037778920 with entries=94, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037781143
2014-07-22 07:03:02,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:02,342 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26928 synced till here 26921
2014-07-22 07:03:02,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037781143 with entries=89, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037782323
2014-07-22 07:03:04,080 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,103 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,122 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,153 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,155 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,155 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,159 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,199 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,199 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,200 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,229 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,294 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,362 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,444 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,513 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,579 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:04,654 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:05,912 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:05,940 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:06,006 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:09,081 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,103 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,122 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,153 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,156 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,156 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,159 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,199 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,200 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,200 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,229 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,295 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,363 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,444 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,513 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:09,579 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:09,654 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:10,912 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:10,941 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:11,006 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:12,523 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6216, memsize=326.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/3297e78663784aa08a6250411672e4fb
2014-07-22 07:03:12,545 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/3297e78663784aa08a6250411672e4fb as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3297e78663784aa08a6250411672e4fb
2014-07-22 07:03:12,561 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/3297e78663784aa08a6250411672e4fb, entries=1187550, sequenceid=6216, filesize=84.6m
2014-07-22 07:03:12,562 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~326.1m/341981600, currentsize=14.7m/15426800 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 15456ms, sequenceid=6216, compaction requested=true
2014-07-22 07:03:12,562 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:62), split_queue=0, merge_queue=0
2014-07-22 07:03:12,563 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6557ms
2014-07-22 07:03:12,563 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,563 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6623ms
2014-07-22 07:03:12,563 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 623.6m
2014-07-22 07:03:12,563 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,563 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6651ms
2014-07-22 07:03:12,563 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,565 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7911ms
2014-07-22 07:03:12,565 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,577 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7998ms
2014-07-22 07:03:12,577 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,577 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8065ms
2014-07-22 07:03:12,578 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,578 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8134ms
2014-07-22 07:03:12,578 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,582 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8220ms
2014-07-22 07:03:12,582 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,583 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8289ms
2014-07-22 07:03:12,583 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,585 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8356ms
2014-07-22 07:03:12,585 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,585 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8386ms
2014-07-22 07:03:12,585 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,587 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8388ms
2014-07-22 07:03:12,587 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,588 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8388ms
2014-07-22 07:03:12,588 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,588 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8429ms
2014-07-22 07:03:12,588 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,590 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8434ms
2014-07-22 07:03:12,590 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,590 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8435ms
2014-07-22 07:03:12,590 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,591 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8437ms
2014-07-22 07:03:12,591 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,591 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8469ms
2014-07-22 07:03:12,592 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,597 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8494ms
2014-07-22 07:03:12,597 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,598 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8518ms
2014-07-22 07:03:12,598 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:12,634 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10578,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037782045,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:12,767 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10315,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037782451,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:12,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:13,007 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27022 synced till here 27016
2014-07-22 07:03:13,050 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037782323 with entries=94, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037792950
2014-07-22 07:03:13,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037268994
2014-07-22 07:03:13,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037274595
2014-07-22 07:03:13,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037276431
2014-07-22 07:03:13,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037305545
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037308985
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037311853
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037314639
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037317241
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037347674
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037349941
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037352988
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037355142
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037376785
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037378704
2014-07-22 07:03:13,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037381164
2014-07-22 07:03:13,079 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10803,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037782275,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:13,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 86ea69fe85336d05b86e4198e206c41d
2014-07-22 07:03:13,265 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:03:13,576 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16492, memsize=503.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/02834524d89c43c680eb4b67e66db764
2014-07-22 07:03:13,603 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/02834524d89c43c680eb4b67e66db764 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/02834524d89c43c680eb4b67e66db764
2014-07-22 07:03:13,615 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/02834524d89c43c680eb4b67e66db764, entries=1834100, sequenceid=16492, filesize=130.7m
2014-07-22 07:03:13,615 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~503.7m/528206240, currentsize=131.8m/138244160 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 31152ms, sequenceid=16492, compaction requested=true
2014-07-22 07:03:13,615 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:63), split_queue=0, merge_queue=0
2014-07-22 07:03:13,616 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 598.1m
2014-07-22 07:03:14,727 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10869,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037783857,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:14,786 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10719,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784067,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:14,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:14,860 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27109 synced till here 27101
2014-07-22 07:03:14,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037792950 with entries=87, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037794830
2014-07-22 07:03:15,105 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:03:15,377 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:03:15,402 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11041,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784360,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:15,414 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10903,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784510,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:15,415 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10973,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784442,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:15,417 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784292,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:15,419 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784652,"queuetimems":3,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:15,420 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11263,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784157,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:16,818 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1168ms
GC pool 'ParNew' had collection(s): count=1 time=1191ms
2014-07-22 07:03:16,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:16,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27198 synced till here 27190
2014-07-22 07:03:16,954 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12727,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784227,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:16,954 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037785908,"queuetimems":1173,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:16,976 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037794830 with entries=89, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037796884
2014-07-22 07:03:17,023 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12445,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037784577,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:17,024 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11019,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037786004,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:17,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:17,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27285 synced till here 27283
2014-07-22 07:03:18,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037796884 with entries=87, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037797868
2014-07-22 07:03:21,039 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1241ms
GC pool 'ParNew' had collection(s): count=1 time=1365ms
2014-07-22 07:03:21,048 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:21,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27370 synced till here 27362
2014-07-22 07:03:21,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037797868 with entries=85, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037801049
2014-07-22 07:03:23,691 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1150ms
GC pool 'ParNew' had collection(s): count=1 time=1310ms
2014-07-22 07:03:23,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:23,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27462 synced till here 27448
2014-07-22 07:03:23,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037801049 with entries=92, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037803787
2014-07-22 07:03:25,744 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:25,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27553 synced till here 27542
2014-07-22 07:03:25,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037803787 with entries=91, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037805744
2014-07-22 07:03:26,085 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,086 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,105 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,122 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,122 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,123 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,123 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,123 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,124 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,125 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,143 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,154 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,191 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,192 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,207 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,295 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,428 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,519 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,609 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:26,718 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:31,085 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,086 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,106 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,122 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,123 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,123 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,124 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,124 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,125 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,125 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,144 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,157 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-22 07:03:31,192 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,192 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,214 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5007ms
2014-07-22 07:03:31,295 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,428 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,519 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:03:31,610 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:31,718 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:03:36,086 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:03:36,086 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:03:36,108 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-22 07:03:36,130 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10007ms
2014-07-22 07:03:36,130 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-22 07:03:36,131 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-22 07:03:36,131 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10009ms
2014-07-22 07:03:36,131 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-22 07:03:36,131 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10009ms
2014-07-22 07:03:36,132 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10007ms
2014-07-22 07:03:36,145 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:03:36,157 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-22 07:03:36,192 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:03:36,193 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:03:36,225 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10018ms
2014-07-22 07:03:36,295 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:03:36,446 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10018ms
2014-07-22 07:03:36,674 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10065ms
2014-07-22 07:03:36,674 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10155ms
2014-07-22 07:03:36,718 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:03:41,087 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:03:41,087 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:03:41,109 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-22 07:03:41,130 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15007ms
2014-07-22 07:03:41,131 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15006ms
2014-07-22 07:03:41,131 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15008ms
2014-07-22 07:03:41,131 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15009ms
2014-07-22 07:03:41,132 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15008ms
2014-07-22 07:03:41,132 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15010ms
2014-07-22 07:03:41,132 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15008ms
2014-07-22 07:03:41,145 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:03:41,158 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-22 07:03:41,193 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:03:41,193 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:03:41,229 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15018ms
2014-07-22 07:03:41,296 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:03:41,446 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15018ms
2014-07-22 07:03:41,674 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15065ms
2014-07-22 07:03:41,675 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15156ms
2014-07-22 07:03:41,719 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:03:42,021 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6285, memsize=599.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/30e8a4b86ffa406db04d26cfb9ac453a
2014-07-22 07:03:42,032 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/30e8a4b86ffa406db04d26cfb9ac453a as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/30e8a4b86ffa406db04d26cfb9ac453a
2014-07-22 07:03:42,042 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/30e8a4b86ffa406db04d26cfb9ac453a, entries=2183250, sequenceid=6285, filesize=155.6m
2014-07-22 07:03:42,042 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~599.6m/628757360, currentsize=90.0m/94406720 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 28426ms, sequenceid=6285, compaction requested=true
2014-07-22 07:03:42,043 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:64), split_queue=0, merge_queue=0
2014-07-22 07:03:42,043 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15326ms
2014-07-22 07:03:42,043 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,043 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15524ms
2014-07-22 07:03:42,043 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 656.1m
2014-07-22 07:03:42,043 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,043 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15434ms
2014-07-22 07:03:42,043 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,057 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15629ms
2014-07-22 07:03:42,057 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,057 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15762ms
2014-07-22 07:03:42,057 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,057 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15850ms
2014-07-22 07:03:42,057 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,057 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15866ms
2014-07-22 07:03:42,057 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,061 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15870ms
2014-07-22 07:03:42,061 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,061 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15907ms
2014-07-22 07:03:42,061 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,062 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15919ms
2014-07-22 07:03:42,062 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,073 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15949ms
2014-07-22 07:03:42,073 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,073 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15951ms
2014-07-22 07:03:42,073 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,074 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15951ms
2014-07-22 07:03:42,074 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,074 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15952ms
2014-07-22 07:03:42,074 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,074 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15951ms
2014-07-22 07:03:42,074 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,074 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15949ms
2014-07-22 07:03:42,074 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,087 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15964ms
2014-07-22 07:03:42,087 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,096 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15991ms
2014-07-22 07:03:42,096 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,096 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16011ms
2014-07-22 07:03:42,096 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,096 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16011ms
2014-07-22 07:03:42,097 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:03:42,314 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20286,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037802027,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:42,426 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18651,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037803775,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:42,426 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037801948,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:42,456 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16571, memsize=623.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/33b94033dfb44310b62795bf50b9b3e9
2014-07-22 07:03:42,505 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/33b94033dfb44310b62795bf50b9b3e9 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/33b94033dfb44310b62795bf50b9b3e9
2014-07-22 07:03:42,528 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037802134,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:42,528 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037803698,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:42,529 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/33b94033dfb44310b62795bf50b9b3e9, entries=2270410, sequenceid=16571, filesize=161.8m
2014-07-22 07:03:42,529 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~623.6m/653858400, currentsize=102.3m/107217200 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 29966ms, sequenceid=16571, compaction requested=true
2014-07-22 07:03:42,530 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:65), split_queue=0, merge_queue=0
2014-07-22 07:03:42,530 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 552.9m
2014-07-22 07:03:43,043 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:03:43,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:43,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27651 synced till here 27637
2014-07-22 07:03:43,212 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037804045,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:43,212 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18978,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037804233,"queuetimems":14,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:43,225 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037803979,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:43,226 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037804141,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:43,286 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:03:43,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037805744 with entries=98, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037823077
2014-07-22 07:03:43,343 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037405312
2014-07-22 07:03:43,343 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037581436
2014-07-22 07:03:43,343 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037603700
2014-07-22 07:03:43,343 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037605901
2014-07-22 07:03:43,546 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18865,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037804680,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,696 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18955,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037805740,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,894 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18970,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037805924,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,894 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037804787,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,894 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19199,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037805695,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,967 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18360,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037806606,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,967 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037806715,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,967 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18452,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037806514,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,967 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18762,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037806204,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:44,974 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18681,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037806292,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:44,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27740 synced till here 27733
2014-07-22 07:03:45,007 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18584,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037806422,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:03:45,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037823077 with entries=89, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037824970
2014-07-22 07:03:45,125 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:03:46,426 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:46,449 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27824 synced till here 27820
2014-07-22 07:03:46,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037824970 with entries=84, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037826426
2014-07-22 07:03:48,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:48,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27906 synced till here 27901
2014-07-22 07:03:48,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037826426 with entries=82, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037828018
2014-07-22 07:03:49,323 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:49,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27987 synced till here 27986
2014-07-22 07:03:49,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037828018 with entries=81, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037829324
2014-07-22 07:03:50,857 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:50,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28069 synced till here 28065
2014-07-22 07:03:50,930 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037829324 with entries=82, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037830858
2014-07-22 07:03:52,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:52,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28151 synced till here 28144
2014-07-22 07:03:52,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037830858 with entries=82, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037832325
2014-07-22 07:03:53,743 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:53,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28236 synced till here 28232
2014-07-22 07:03:53,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037832325 with entries=85, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037833743
2014-07-22 07:03:55,308 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:55,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28319 synced till here 28316
2014-07-22 07:03:55,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037833743 with entries=83, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037835308
2014-07-22 07:03:56,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:03:57,002 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28403 synced till here 28398
2014-07-22 07:03:57,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037835308 with entries=84, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037836969
2014-07-22 07:03:57,201 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,201 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,202 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,205 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,220 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,225 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,233 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,235 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,254 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,296 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,303 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,372 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,453 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:57,532 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:58,439 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:58,471 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:58,537 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:58,612 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:58,720 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:03:58,811 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:02,201 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,201 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,202 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,206 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,221 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,226 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,234 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:02,235 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,254 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,304 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5007ms
2014-07-22 07:04:02,304 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:02,373 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:02,454 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:02,532 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-22 07:04:03,440 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:03,471 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:03,538 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:03,613 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:03,720 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:03,811 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:07,202 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,202 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,202 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:04:07,206 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,221 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,226 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,234 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,235 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:04:07,254 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:04:07,304 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-22 07:04:07,304 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,373 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,454 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:07,533 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-22 07:04:08,440 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:08,455 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6347, memsize=552.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/feaeb6cca5584c959510edd7732afbb3
2014-07-22 07:04:08,466 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/feaeb6cca5584c959510edd7732afbb3 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/feaeb6cca5584c959510edd7732afbb3
2014-07-22 07:04:08,472 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:04:08,475 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/feaeb6cca5584c959510edd7732afbb3, entries=2013110, sequenceid=6347, filesize=143.5m
2014-07-22 07:04:08,476 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~552.9m/579760160, currentsize=141.4m/148254000 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 25945ms, sequenceid=6347, compaction requested=true
2014-07-22 07:04:08,476 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:66), split_queue=0, merge_queue=0
2014-07-22 07:04:08,476 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-22 07:04:08,476 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,476 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10037ms
2014-07-22 07:04:08,477 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,477 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10949ms
2014-07-22 07:04:08,477 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,477 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 623.2m
2014-07-22 07:04:08,477 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11024ms
2014-07-22 07:04:08,477 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,479 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11107ms
2014-07-22 07:04:08,479 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,484 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11181ms
2014-07-22 07:04:08,484 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,484 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11188ms
2014-07-22 07:04:08,484 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,485 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11231ms
2014-07-22 07:04:08,485 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,493 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11258ms
2014-07-22 07:04:08,493 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,496 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11263ms
2014-07-22 07:04:08,496 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,496 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11271ms
2014-07-22 07:04:08,496 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,505 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11285ms
2014-07-22 07:04:08,505 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,505 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11300ms
2014-07-22 07:04:08,506 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,506 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11304ms
2014-07-22 07:04:08,506 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,521 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11320ms
2014-07-22 07:04:08,521 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,522 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11321ms
2014-07-22 07:04:08,522 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,522 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9711ms
2014-07-22 07:04:08,522 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,522 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9802ms
2014-07-22 07:04:08,522 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,523 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9911ms
2014-07-22 07:04:08,523 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,534 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9996ms
2014-07-22 07:04:08,534 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:08,986 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13197,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037835788,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:09,095 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12529,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836566,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:09,095 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12560,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836535,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:09,482 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12846,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836635,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:09,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:09,674 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12887,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836786,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:09,675 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12955,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836720,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:09,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28495 synced till here 28485
2014-07-22 07:04:09,784 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:04:09,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037836969 with entries=92, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037849673
2014-07-22 07:04:09,986 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13133,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836853,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:10,078 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13066,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037837011,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:10,113 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:04:10,285 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13363,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037836922,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:11,333 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:11,334 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:04:11,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28578 synced till here 28568
2014-07-22 07:04:11,467 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14015,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037837451,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:11,784 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037849673 with entries=83, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037851334
2014-07-22 07:04:11,855 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14485,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037837370,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:11,855 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14623,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037837232,"queuetimems":4,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:11,855 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037838436,"queuetimems":842,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:11,855 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14329,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037837526,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:11,857 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037838469,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:12,159 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14857,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037837301,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:12,160 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13550,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037838610,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:12,161 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13445,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037838715,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:12,165 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037838536,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:12,165 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13357,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037838808,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:12,790 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:12,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28666 synced till here 28663
2014-07-22 07:04:13,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037851334 with entries=88, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037852790
2014-07-22 07:04:14,055 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:14,942 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6352, memsize=656.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/b3ef870d27c24c5dbc156a0cf3162575
2014-07-22 07:04:14,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28752 synced till here 28745
2014-07-22 07:04:14,998 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/b3ef870d27c24c5dbc156a0cf3162575 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b3ef870d27c24c5dbc156a0cf3162575
2014-07-22 07:04:15,017 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/b3ef870d27c24c5dbc156a0cf3162575, entries=2388710, sequenceid=6352, filesize=170.2m
2014-07-22 07:04:15,017 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~656.1m/687927840, currentsize=198.5m/208102880 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 32974ms, sequenceid=6352, compaction requested=true
2014-07-22 07:04:15,018 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-22 07:04:15,018 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 588.8m
2014-07-22 07:04:15,024 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037852790 with entries=86, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037854055
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037607884
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037613403
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037624143
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037625772
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037627328
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037629147
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037631185
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037633142
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037634781
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037636904
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037638479
2014-07-22 07:04:15,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037640332
2014-07-22 07:04:16,024 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:04:16,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:17,694 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28841 synced till here 28829
2014-07-22 07:04:17,924 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037854055 with entries=89, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037856484
2014-07-22 07:04:19,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:20,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28992 synced till here 28983
2014-07-22 07:04:21,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037856484 with entries=151, filesize=118.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037859789
2014-07-22 07:04:22,308 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1028ms
GC pool 'ParNew' had collection(s): count=1 time=1046ms
2014-07-22 07:04:22,911 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:04:23,068 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:23,093 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29081 synced till here 29071
2014-07-22 07:04:23,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037859789 with entries=89, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037863068
2014-07-22 07:04:24,176 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:04:24,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:24,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29170 synced till here 29160
2014-07-22 07:04:24,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037863068 with entries=89, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037864607
2014-07-22 07:04:26,208 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:26,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29252 synced till here 29249
2014-07-22 07:04:26,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037864607 with entries=82, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037866209
2014-07-22 07:04:26,374 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,396 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,421 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,430 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,624 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,788 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,876 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:26,968 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:27,076 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:27,168 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:27,244 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:27,332 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:27,404 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:27,483 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:28,425 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:28,469 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:28,531 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:28,596 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:28,661 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:28,737 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:31,375 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:31,397 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:31,426 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-22 07:04:31,430 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:31,625 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:31,788 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:31,876 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:31,971 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-22 07:04:32,077 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:32,169 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:32,244 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:32,332 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:32,404 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:32,483 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:33,359 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/41d9c1d8f8064567bbd0c65d167f7ade as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/41d9c1d8f8064567bbd0c65d167f7ade
2014-07-22 07:04:33,370 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:04:33,380 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8722071116fa409b84d55b65195034dc, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8722071116fa409b84d55b65195034dc
2014-07-22 07:04:33,382 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d91463129cec4d3491cd1632f385e1b2, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d91463129cec4d3491cd1632f385e1b2
2014-07-22 07:04:33,385 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/dbe8b4f5a1294eafa0efbdc6bd686509, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/dbe8b4f5a1294eafa0efbdc6bd686509
2014-07-22 07:04:33,387 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/71c68ca4b86a474ca15c84cb4e30731b, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/71c68ca4b86a474ca15c84cb4e30731b
2014-07-22 07:04:33,389 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/41cb33e841214b7789a2a0931b0e16d1, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/41cb33e841214b7789a2a0931b0e16d1
2014-07-22 07:04:33,392 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7d4ad5e320d045649eb3e38cc10cac9d, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7d4ad5e320d045649eb3e38cc10cac9d
2014-07-22 07:04:33,395 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/550de4ff4a484b639a03cb3d572890e0, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/550de4ff4a484b639a03cb3d572890e0
2014-07-22 07:04:33,397 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/75ac1cfd34004c899b4a4275fcfc7f60, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/75ac1cfd34004c899b4a4275fcfc7f60
2014-07-22 07:04:33,399 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/e49771c6e18546449481ea73899f299e, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/e49771c6e18546449481ea73899f299e
2014-07-22 07:04:33,402 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8690042935ad4e1bb8bba5840f5aef52, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/8690042935ad4e1bb8bba5840f5aef52
2014-07-22 07:04:33,402 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. into 41d9c1d8f8064567bbd0c65d167f7ade(size=514.1m), total size for store is 2.5g. This selection was in queue for 0sec, and took 3mins, 18sec to execute.
2014-07-22 07:04:33,402 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., storeName=family, fileCount=10, fileSize=591.0m, priority=1974, time=134654835149117; duration=3mins, 18sec
2014-07-22 07:04:33,402 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-22 07:04:33,403 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 26 store files, 0 compacting, 26 eligible, 2000 blocking
2014-07-22 07:04:33,407 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 645090911 starting at candidate #15 after considering 164 permutations with 148 in ratio
2014-07-22 07:04:33,407 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: d29123f6203691d46817543c7ec8a423 - family: Initiating minor compaction
2014-07-22 07:04:33,408 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:04:33,408 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp, totalSize=615.2m
2014-07-22 07:04:33,408 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/a073abf02f1c4446a5571b5d1a043db4, keycount=89880, bloomtype=ROW, size=64.1m, encoding=NONE, seqNum=12755
2014-07-22 07:04:33,408 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/47b1f47e0c524d88bde7cb8d9bb76ee1, keycount=130618, bloomtype=ROW, size=93.1m, encoding=NONE, seqNum=13322
2014-07-22 07:04:33,408 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/bf88db1035cb4cb88525ce6b8dbb83c5, keycount=113137, bloomtype=ROW, size=80.6m, encoding=NONE, seqNum=13823
2014-07-22 07:04:33,408 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e9f603087f304328b1e0804c7ac3b860, keycount=98513, bloomtype=ROW, size=70.2m, encoding=NONE, seqNum=14273
2014-07-22 07:04:33,408 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/dfdb09bb61264e83ba9dce2c449104ff, keycount=80670, bloomtype=ROW, size=57.5m, encoding=NONE, seqNum=14699
2014-07-22 07:04:33,409 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6835e0e2aa5a45c5a16b34802c5bdf1a, keycount=131722, bloomtype=ROW, size=93.8m, encoding=NONE, seqNum=15221
2014-07-22 07:04:33,409 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/0e4e860d90f7442bb6005f077eb06531, keycount=133879, bloomtype=ROW, size=95.4m, encoding=NONE, seqNum=15812
2014-07-22 07:04:33,409 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/175293c9ff234c52b3b3efa92f05a3e8, keycount=45730, bloomtype=ROW, size=32.6m, encoding=NONE, seqNum=15978
2014-07-22 07:04:33,409 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/2e78da83772141b68d35840856d610ff, keycount=27022, bloomtype=ROW, size=19.2m, encoding=NONE, seqNum=16144
2014-07-22 07:04:33,409 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/529275e7378f4d429d5be2615aafc9e4, keycount=12396, bloomtype=ROW, size=8.8m, encoding=NONE, seqNum=16166
2014-07-22 07:04:33,425 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:33,469 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:33,531 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:33,542 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:04:33,596 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:33,662 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:33,738 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:36,035 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.79 MB, free=3.95 GB, max=3.96 GB, blocks=8, accesses=510239, hits=20627, hitRatio=4.04%, , cachingAccesses=20640, cachingHits=20619, cachingHitsRatio=99.89%, evictions=0, evicted=13, evictedPerRun=Infinity
2014-07-22 07:04:36,375 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:36,397 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:36,427 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10006ms
2014-07-22 07:04:36,431 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:36,626 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:36,792 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-22 07:04:36,877 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:36,971 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-22 07:04:37,077 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:37,169 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:37,245 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:04:37,333 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:04:37,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:37,484 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:38,426 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:38,470 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:04:38,532 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:38,597 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:38,662 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:38,738 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:04:38,912 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16775, memsize=623.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/2a0aba9dbfac4c0db25c0545a014af90
2014-07-22 07:04:38,926 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/2a0aba9dbfac4c0db25c0545a014af90 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/2a0aba9dbfac4c0db25c0545a014af90
2014-07-22 07:04:38,935 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/2a0aba9dbfac4c0db25c0545a014af90, entries=2269180, sequenceid=16775, filesize=161.7m
2014-07-22 07:04:38,936 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~623.2m/653506320, currentsize=141.4m/148238960 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 30458ms, sequenceid=16775, compaction requested=true
2014-07-22 07:04:38,936 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-22 07:04:38,936 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10199ms
2014-07-22 07:04:38,936 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,936 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10275ms
2014-07-22 07:04:38,936 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,936 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 615.5m
2014-07-22 07:04:38,936 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10340ms
2014-07-22 07:04:38,937 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,937 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10406ms
2014-07-22 07:04:38,937 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,937 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10469ms
2014-07-22 07:04:38,937 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,938 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10514ms
2014-07-22 07:04:38,938 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,945 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11462ms
2014-07-22 07:04:38,946 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,947 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11542ms
2014-07-22 07:04:38,947 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,953 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11621ms
2014-07-22 07:04:38,953 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,954 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11711ms
2014-07-22 07:04:38,954 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,954 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11786ms
2014-07-22 07:04:38,954 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,954 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11878ms
2014-07-22 07:04:38,954 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,954 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11986ms
2014-07-22 07:04:38,955 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,955 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12079ms
2014-07-22 07:04:38,955 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,955 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12167ms
2014-07-22 07:04:38,955 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,956 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12332ms
2014-07-22 07:04:38,956 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,957 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12526ms
2014-07-22 07:04:38,957 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,958 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12537ms
2014-07-22 07:04:38,959 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,959 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12563ms
2014-07-22 07:04:38,959 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:38,961 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12587ms
2014-07-22 07:04:38,961 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:04:39,003 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14197,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037864806,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:39,194 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14309,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037864885,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:39,530 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13753,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037865776,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:39,778 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13896,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037865881,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:39,781 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:04:39,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:39,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29341 synced till here 29330
2014-07-22 07:04:40,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037866209 with entries=89, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037879902
2014-07-22 07:04:40,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037642295
2014-07-22 07:04:40,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037644588
2014-07-22 07:04:40,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037646880
2014-07-22 07:04:40,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037649797
2014-07-22 07:04:40,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037655322
2014-07-22 07:04:40,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037658611
2014-07-22 07:04:41,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:41,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29427 synced till here 29414
2014-07-22 07:04:41,256 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12597,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037868658,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,276 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12681,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037868594,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037879902 with entries=86, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037881165
2014-07-22 07:04:41,310 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037868529,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,326 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037868735,"queuetimems":7,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,327 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037866784,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,327 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13926,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037867400,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,327 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14705,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037866621,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,431 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14265,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037867165,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,440 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14199,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037867241,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,440 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14570,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037866869,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,440 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037867329,"queuetimems":8,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,441 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14368,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037867072,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,440 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13960,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037867480,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,440 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12974,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037868466,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,442 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13018,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037868423,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:41,443 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037866964,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:04:42,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:42,718 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29514 synced till here 29513
2014-07-22 07:04:42,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037881165 with entries=87, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037882697
2014-07-22 07:04:42,841 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16787, memsize=590.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/d4180b9282524ca6a06e645761b5d7fa
2014-07-22 07:04:42,854 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/d4180b9282524ca6a06e645761b5d7fa as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d4180b9282524ca6a06e645761b5d7fa
2014-07-22 07:04:42,863 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d4180b9282524ca6a06e645761b5d7fa, entries=2149660, sequenceid=16787, filesize=153.2m
2014-07-22 07:04:42,863 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~590.4m/619083680, currentsize=130.3m/136669360 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 27845ms, sequenceid=16787, compaction requested=true
2014-07-22 07:04:42,864 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:68), split_queue=0, merge_queue=0
2014-07-22 07:04:42,864 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 562.5m
2014-07-22 07:04:43,273 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:04:44,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:44,123 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29597 synced till here 29590
2014-07-22 07:04:44,216 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037882697 with entries=83, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037884099
2014-07-22 07:04:44,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037661233
2014-07-22 07:04:44,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037679216
2014-07-22 07:04:44,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037688594
2014-07-22 07:04:44,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037692921
2014-07-22 07:04:44,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037698483
2014-07-22 07:04:45,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:45,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29681 synced till here 29676
2014-07-22 07:04:45,994 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037884099 with entries=84, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037885125
2014-07-22 07:04:46,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:47,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29787 synced till here 29785
2014-07-22 07:04:47,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037885125 with entries=106, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037886630
2014-07-22 07:04:50,641 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1181ms
GC pool 'ParNew' had collection(s): count=1 time=1334ms
2014-07-22 07:04:51,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:51,024 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:04:51,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29875 synced till here 29863
2014-07-22 07:04:51,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037886630 with entries=88, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037891018
2014-07-22 07:04:52,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:52,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29965 synced till here 29952
2014-07-22 07:04:52,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037891018 with entries=90, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037892694
2014-07-22 07:04:53,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:04:53,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30049 synced till here 30045
2014-07-22 07:04:54,387 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037892694 with entries=84, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037893590
2014-07-22 07:04:54,979 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:54,982 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:54,989 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:54,994 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,004 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,009 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,014 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,047 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,112 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,176 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,242 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,307 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,373 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,438 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:55,503 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:56,612 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:56,661 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:56,726 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:56,791 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:56,854 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:04:59,980 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:59,982 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:04:59,989 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:04:59,995 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:00,004 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:00,009 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,014 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,047 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,113 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,177 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:00,242 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,307 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,373 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:00,439 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:00,503 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:01,613 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:01,661 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:01,726 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:01,792 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:01,854 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:04,981 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:04,982 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:04,989 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:04,995 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:05,004 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:05,009 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:05,014 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:05,047 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:05,113 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:05,177 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:05,242 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:05,307 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:05,374 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:05,439 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:05,504 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:06,613 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:06,661 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:06,726 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:06,792 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:06,854 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:07,998 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16836, memsize=615.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/7c466ff054094ccda1a375e41aeafb68
2014-07-22 07:05:08,011 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/7c466ff054094ccda1a375e41aeafb68 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/7c466ff054094ccda1a375e41aeafb68
2014-07-22 07:05:08,021 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/7c466ff054094ccda1a375e41aeafb68, entries=2241210, sequenceid=16836, filesize=159.6m
2014-07-22 07:05:08,022 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~615.5m/645448800, currentsize=147.4m/154556880 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 29085ms, sequenceid=16836, compaction requested=true
2014-07-22 07:05:08,022 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:69), split_queue=0, merge_queue=0
2014-07-22 07:05:08,022 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11168ms
2014-07-22 07:05:08,022 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,022 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11231ms
2014-07-22 07:05:08,022 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,022 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 538.2m
2014-07-22 07:05:08,022 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11296ms
2014-07-22 07:05:08,022 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,025 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11364ms
2014-07-22 07:05:08,025 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,026 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11414ms
2014-07-22 07:05:08,026 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,026 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12523ms
2014-07-22 07:05:08,026 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,026 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12588ms
2014-07-22 07:05:08,026 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,029 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12656ms
2014-07-22 07:05:08,029 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,030 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12723ms
2014-07-22 07:05:08,030 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,033 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12791ms
2014-07-22 07:05:08,033 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,033 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12857ms
2014-07-22 07:05:08,034 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,037 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12925ms
2014-07-22 07:05:08,037 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,041 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12994ms
2014-07-22 07:05:08,042 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,048 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13034ms
2014-07-22 07:05:08,048 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,048 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13039ms
2014-07-22 07:05:08,048 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,049 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13046ms
2014-07-22 07:05:08,049 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,053 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13059ms
2014-07-22 07:05:08,053 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,057 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13068ms
2014-07-22 07:05:08,057 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,060 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13079ms
2014-07-22 07:05:08,060 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,061 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13082ms
2014-07-22 07:05:08,061 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:08,093 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13737,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894355,"queuetimems":739,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:08,350 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:08,352 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13965,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894386,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:08,352 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894498,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:08,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30140 synced till here 30129
2014-07-22 07:05:08,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037893590 with entries=91, filesize=71.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037908351
2014-07-22 07:05:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037705099
2014-07-22 07:05:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037745638
2014-07-22 07:05:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037748643
2014-07-22 07:05:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037751149
2014-07-22 07:05:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037754324
2014-07-22 07:05:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037758190
2014-07-22 07:05:08,613 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14035,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894578,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:08,649 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:05:08,759 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14092,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894666,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:08,779 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16855, memsize=562.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/e86d99fe78f54d12ba61ff8a93110943
2014-07-22 07:05:08,781 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894749,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:08,810 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/e86d99fe78f54d12ba61ff8a93110943 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e86d99fe78f54d12ba61ff8a93110943
2014-07-22 07:05:08,819 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e86d99fe78f54d12ba61ff8a93110943, entries=2048240, sequenceid=16855, filesize=145.9m
2014-07-22 07:05:08,820 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~562.5m/589876080, currentsize=104.4m/109428080 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 25956ms, sequenceid=16855, compaction requested=true
2014-07-22 07:05:08,820 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:70), split_queue=0, merge_queue=0
2014-07-22 07:05:08,820 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 534.2m
2014-07-22 07:05:08,933 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:05:09,179 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:09,204 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30227 synced till here 30217
2014-07-22 07:05:09,885 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:05:09,915 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037908351 with entries=87, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037909180
2014-07-22 07:05:09,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037762051
2014-07-22 07:05:09,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037765254
2014-07-22 07:05:09,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037767398
2014-07-22 07:05:09,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037768442
2014-07-22 07:05:09,916 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037771356
2014-07-22 07:05:09,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:10,136 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037896852,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,222 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037896610,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,223 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13435,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037896788,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,280 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13556,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037896723,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,418 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14981,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895436,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,418 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15243,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895174,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,418 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895500,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,418 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15114,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895304,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,450 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895045,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,450 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037894979,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,451 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895371,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,452 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037896659,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,457 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15216,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895240,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,465 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15354,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037895110,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:10,492 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:10,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30315 synced till here 30312
2014-07-22 07:05:10,544 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037909180 with entries=88, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037910492
2014-07-22 07:05:10,544 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:11,826 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:11,850 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30397 synced till here 30392
2014-07-22 07:05:11,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037910492 with entries=82, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037911826
2014-07-22 07:05:11,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:13,304 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:13,356 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30484 synced till here 30478
2014-07-22 07:05:13,407 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037911826 with entries=87, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037913304
2014-07-22 07:05:13,407 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:14,766 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:14,782 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30564 synced till here 30562
2014-07-22 07:05:14,803 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037913304 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037914767
2014-07-22 07:05:14,804 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:16,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:16,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30646 synced till here 30642
2014-07-22 07:05:16,210 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037914767 with entries=82, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037916149
2014-07-22 07:05:16,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:17,625 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:17,645 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30729 synced till here 30726
2014-07-22 07:05:17,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037916149 with entries=83, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037917625
2014-07-22 07:05:17,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:18,083 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:05:19,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:19,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30814 synced till here 30810
2014-07-22 07:05:19,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037917625 with entries=85, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037919221
2014-07-22 07:05:19,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:20,507 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:20,529 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30895 synced till here 30893
2014-07-22 07:05:20,564 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037919221 with entries=81, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037920508
2014-07-22 07:05:20,565 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:20,926 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,927 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,934 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,948 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,948 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,971 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,975 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,981 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:20,982 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,046 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,126 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,203 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,285 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,362 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,446 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,528 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,603 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:21,689 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:22,943 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:23,009 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:25,927 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:25,927 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:25,934 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:25,948 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:25,949 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:25,971 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:25,975 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:25,981 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:25,982 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:26,047 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:26,127 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:26,204 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:26,286 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:26,363 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:26,446 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:26,529 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:26,604 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:26,689 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:27,944 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:28,009 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:30,927 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:30,928 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:30,935 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:30,948 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:30,949 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:30,971 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:30,975 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:30,981 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:30,982 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:31,047 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,127 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,204 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,286 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,363 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,446 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,529 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,604 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:31,689 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:31,778 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16919, memsize=538.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/f9fbd64ab1e04563a60c6225715a5752
2014-07-22 07:05:31,789 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/f9fbd64ab1e04563a60c6225715a5752 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/f9fbd64ab1e04563a60c6225715a5752
2014-07-22 07:05:31,799 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/f9fbd64ab1e04563a60c6225715a5752, entries=1959430, sequenceid=16919, filesize=139.6m
2014-07-22 07:05:31,799 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~538.2m/564300480, currentsize=143.3m/150266400 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 23777ms, sequenceid=16919, compaction requested=true
2014-07-22 07:05:31,800 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-22 07:05:31,800 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10111ms
2014-07-22 07:05:31,800 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,800 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 575.8m
2014-07-22 07:05:31,800 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10197ms
2014-07-22 07:05:31,800 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,800 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10272ms
2014-07-22 07:05:31,800 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,801 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10356ms
2014-07-22 07:05:31,801 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,805 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10443ms
2014-07-22 07:05:31,805 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,806 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10521ms
2014-07-22 07:05:31,806 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,811 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10608ms
2014-07-22 07:05:31,811 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,811 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10685ms
2014-07-22 07:05:31,811 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,811 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10765ms
2014-07-22 07:05:31,811 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,823 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10840ms
2014-07-22 07:05:31,823 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,823 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10843ms
2014-07-22 07:05:31,823 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,832 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10857ms
2014-07-22 07:05:31,832 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,837 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10866ms
2014-07-22 07:05:31,837 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,841 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10893ms
2014-07-22 07:05:31,841 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,841 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10893ms
2014-07-22 07:05:31,842 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,842 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10908ms
2014-07-22 07:05:31,842 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,853 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10926ms
2014-07-22 07:05:31,853 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,861 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10935ms
2014-07-22 07:05:31,861 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,862 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8852ms
2014-07-22 07:05:31,862 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,864 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8921ms
2014-07-22 07:05:31,864 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:31,903 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12172,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037919730,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:32,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:32,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30985 synced till here 30972
2014-07-22 07:05:32,350 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11878,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920470,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:32,354 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:05:32,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037920508 with entries=90, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037932274
2014-07-22 07:05:32,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:33,066 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6630, memsize=534.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/db1ff4ce5718477cb930246a3c3233b4
2014-07-22 07:05:33,076 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12545,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920531,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,076 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920601,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,083 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/db1ff4ce5718477cb930246a3c3233b4 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/db1ff4ce5718477cb930246a3c3233b4
2014-07-22 07:05:33,098 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/db1ff4ce5718477cb930246a3c3233b4, entries=1945070, sequenceid=6630, filesize=138.5m
2014-07-22 07:05:33,098 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~534.2m/560165840, currentsize=141.8m/148670480 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 24278ms, sequenceid=6630, compaction requested=true
2014-07-22 07:05:33,098 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:72), split_queue=0, merge_queue=0
2014-07-22 07:05:33,099 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 579.5m
2014-07-22 07:05:33,128 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920678,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,186 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:05:33,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:33,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31074 synced till here 31063
2014-07-22 07:05:33,570 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12741,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920828,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,577 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037932274 with entries=89, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037933489
2014-07-22 07:05:33,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:33,691 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12933,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920758,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,694 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12008,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921685,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,698 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12799,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920898,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,699 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12256,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921442,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,714 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:05:33,727 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921600,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,727 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12526,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921200,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,727 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12206,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921520,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,731 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10723,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037923007,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,732 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12372,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921359,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,732 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12453,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921278,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,733 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037922941,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,814 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12694,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921120,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,816 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12771,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037921044,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:33,816 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037920979,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:34,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:34,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31160 synced till here 31158
2014-07-22 07:05:34,864 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037933489 with entries=86, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037934836
2014-07-22 07:05:34,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:36,177 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:36,194 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31244 synced till here 31241
2014-07-22 07:05:36,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037934836 with entries=84, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037936178
2014-07-22 07:05:36,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:37,512 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:37,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31325 synced till here 31322
2014-07-22 07:05:37,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037936178 with entries=81, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037937513
2014-07-22 07:05:37,593 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:38,989 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:39,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31406 synced till here 31401
2014-07-22 07:05:39,050 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037937513 with entries=81, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037938989
2014-07-22 07:05:39,051 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:40,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:40,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31488 synced till here 31485
2014-07-22 07:05:40,362 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037938989 with entries=82, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037940311
2014-07-22 07:05:40,362 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:41,090 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:41,104 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31570 synced till here 31567
2014-07-22 07:05:41,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037940311 with entries=82, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037941091
2014-07-22 07:05:41,121 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:41,921 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:05:42,220 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:05:42,286 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:05:42,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:42,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31659 synced till here 31655
2014-07-22 07:05:43,113 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037941091 with entries=89, filesize=71.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037942326
2014-07-22 07:05:43,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:43,329 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,330 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,331 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,350 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,352 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,362 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,378 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,378 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,379 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,384 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,393 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,440 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,505 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,568 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,632 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,694 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,758 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,821 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,884 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:43,950 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:05:48,329 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,331 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:48,331 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:48,350 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,352 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,362 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,378 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,379 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:48,379 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,384 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,394 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:48,441 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:48,506 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,569 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,632 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,694 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,758 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:05:48,822 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,884 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:48,951 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:05:53,330 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,331 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,332 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:05:53,351 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,352 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:53,363 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:53,378 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:53,379 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,379 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:53,385 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,395 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,441 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,506 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,569 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,645 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10013ms
2014-07-22 07:05:53,695 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,759 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,822 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:53,884 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:05:53,951 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:05:55,349 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6724, memsize=575.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/89266a26381049b29d7ca8d794d8ed3b
2014-07-22 07:05:55,361 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/89266a26381049b29d7ca8d794d8ed3b as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/89266a26381049b29d7ca8d794d8ed3b
2014-07-22 07:05:55,370 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/89266a26381049b29d7ca8d794d8ed3b, entries=2096450, sequenceid=6724, filesize=149.3m
2014-07-22 07:05:55,370 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~575.8m/603760320, currentsize=129.3m/135595760 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 23570ms, sequenceid=6724, compaction requested=true
2014-07-22 07:05:55,371 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:73), split_queue=0, merge_queue=0
2014-07-22 07:05:55,371 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11421ms
2014-07-22 07:05:55,371 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,371 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11487ms
2014-07-22 07:05:55,371 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 565.8m
2014-07-22 07:05:55,371 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,371 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11550ms
2014-07-22 07:05:55,371 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,373 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11616ms
2014-07-22 07:05:55,373 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,374 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11679ms
2014-07-22 07:05:55,374 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,380 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11748ms
2014-07-22 07:05:55,380 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,380 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11812ms
2014-07-22 07:05:55,380 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,380 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11875ms
2014-07-22 07:05:55,380 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,385 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11945ms
2014-07-22 07:05:55,385 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,385 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11992ms
2014-07-22 07:05:55,386 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,386 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12002ms
2014-07-22 07:05:55,386 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,389 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12010ms
2014-07-22 07:05:55,389 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,401 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12023ms
2014-07-22 07:05:55,401 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,402 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12024ms
2014-07-22 07:05:55,402 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,403 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12041ms
2014-07-22 07:05:55,403 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,403 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12051ms
2014-07-22 07:05:55,403 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,404 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12054ms
2014-07-22 07:05:55,404 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,404 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12074ms
2014-07-22 07:05:55,404 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,405 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12075ms
2014-07-22 07:05:55,405 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,405 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12076ms
2014-07-22 07:05:55,405 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:05:55,490 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037941959,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:55,525 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037942029,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:55,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:55,907 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:05:55,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31746 synced till here 31736
2014-07-22 07:05:55,976 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037942166,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:55,976 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13882,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037942094,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:55,985 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037942326 with entries=87, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037955873
2014-07-22 07:05:55,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:56,391 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14159,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037942230,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:56,443 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037942293,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:56,612 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13484,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943128,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:56,751 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13584,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943166,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:56,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:56,934 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13622,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943311,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:56,934 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943240,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:56,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31835 synced till here 31824
2014-07-22 07:05:57,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037955873 with entries=89, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037956932
2014-07-22 07:05:57,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:57,178 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13740,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943438,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,944 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943948,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,944 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943503,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,946 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14063,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943882,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,946 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14571,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943374,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,944 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14125,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943819,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,944 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14189,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943755,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,996 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943692,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,996 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14365,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943630,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:57,997 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037943566,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:05:58,137 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6726, memsize=587.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/c9aeb886e8594ab9b115b8134132c474
2014-07-22 07:05:58,152 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/c9aeb886e8594ab9b115b8134132c474 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/c9aeb886e8594ab9b115b8134132c474
2014-07-22 07:05:58,170 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/c9aeb886e8594ab9b115b8134132c474, entries=2137740, sequenceid=6726, filesize=152.3m
2014-07-22 07:05:58,170 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~587.1m/615654080, currentsize=153.8m/161298400 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 25071ms, sequenceid=6726, compaction requested=true
2014-07-22 07:05:58,170 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-22 07:05:58,171 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 537.3m
2014-07-22 07:05:58,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:58,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037956932 with entries=86, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037958449
2014-07-22 07:05:58,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:05:58,603 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:05:59,803 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:05:59,828 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32003 synced till here 32000
2014-07-22 07:05:59,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037958449 with entries=82, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037959803
2014-07-22 07:05:59,862 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:06:01,330 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:01,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32090 synced till here 32084
2014-07-22 07:06:01,453 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037959803 with entries=87, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037961330
2014-07-22 07:06:01,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:06:03,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:03,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32177 synced till here 32169
2014-07-22 07:06:03,168 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037961330 with entries=87, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037963079
2014-07-22 07:06:03,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:06:04,785 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:04,803 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32263 synced till here 32256
2014-07-22 07:06:04,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037963079 with entries=86, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037964786
2014-07-22 07:06:04,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:06:06,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:06,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32347 synced till here 32341
2014-07-22 07:06:06,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037964786 with entries=84, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037966389
2014-07-22 07:06:06,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:06:07,793 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:06:07,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:07,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32435 synced till here 32430
2014-07-22 07:06:07,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037966389 with entries=88, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037967887
2014-07-22 07:06:07,968 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:06:08,509 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:06:08,593 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,601 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,601 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,602 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,607 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,622 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,622 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,639 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,640 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,649 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:08,732 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:09,714 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:09,744 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:09,808 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:09,872 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:09,935 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:09,999 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:10,064 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:10,128 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:10,191 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:13,594 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,601 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,602 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,602 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,607 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:13,622 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:13,623 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,639 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:13,640 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,650 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:13,732 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:14,714 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:14,744 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:14,808 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:14,872 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:14,935 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:15,000 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:15,064 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:15,128 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:15,191 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:18,594 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,601 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,602 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,602 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,607 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:06:18,623 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,623 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,640 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,640 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,650 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:18,732 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:19,715 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:19,744 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:06:19,809 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:06:19,872 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:06:19,936 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:20,000 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:20,064 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:06:20,129 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:20,192 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:06:20,538 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17141, memsize=565.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/a5e4e5a554a64f4ebff77c5b868485b4
2014-07-22 07:06:20,550 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/a5e4e5a554a64f4ebff77c5b868485b4 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/a5e4e5a554a64f4ebff77c5b868485b4
2014-07-22 07:06:20,903 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/a5e4e5a554a64f4ebff77c5b868485b4, entries=2059990, sequenceid=17141, filesize=146.7m
2014-07-22 07:06:20,904 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~565.8m/593260880, currentsize=138.1m/144784560 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 25533ms, sequenceid=17141, compaction requested=true
2014-07-22 07:06:20,904 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-22 07:06:20,904 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10713ms
2014-07-22 07:06:20,904 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,905 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 300.5m
2014-07-22 07:06:20,905 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10777ms
2014-07-22 07:06:20,905 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,905 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10841ms
2014-07-22 07:06:20,905 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,913 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10914ms
2014-07-22 07:06:20,913 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,913 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10978ms
2014-07-22 07:06:20,914 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,914 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11042ms
2014-07-22 07:06:20,914 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,917 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11109ms
2014-07-22 07:06:20,917 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,918 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11174ms
2014-07-22 07:06:20,918 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,918 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11204ms
2014-07-22 07:06:20,918 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,918 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12187ms
2014-07-22 07:06:20,919 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,919 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12270ms
2014-07-22 07:06:20,919 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,923 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12284ms
2014-07-22 07:06:20,923 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,924 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12285ms
2014-07-22 07:06:20,924 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,924 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12302ms
2014-07-22 07:06:20,924 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,925 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12303ms
2014-07-22 07:06:20,925 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,933 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12326ms
2014-07-22 07:06:20,933 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,933 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12332ms
2014-07-22 07:06:20,934 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,941 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12340ms
2014-07-22 07:06:20,941 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,941 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12341ms
2014-07-22 07:06:20,941 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,941 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12348ms
2014-07-22 07:06:20,941 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:20,961 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037967747,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:20,963 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13244,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037967718,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:21,105 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:21,216 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13372,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037967843,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:21,245 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:06:21,511 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968031,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:21,547 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037967938,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:21,547 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968229,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:21,555 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17136, memsize=540.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/0f5e25130e96459c8dd8fb73be017802
2014-07-22 07:06:21,650 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/0f5e25130e96459c8dd8fb73be017802 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/0f5e25130e96459c8dd8fb73be017802
2014-07-22 07:06:21,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037967887 with entries=120, filesize=94.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037981105
2014-07-22 07:06:22,247 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13927,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968319,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:22,326 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/0f5e25130e96459c8dd8fb73be017802, entries=1967380, sequenceid=17136, filesize=140.1m
2014-07-22 07:06:22,332 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~540.3m/566590720, currentsize=130.4m/136771760 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 24160ms, sequenceid=17136, compaction requested=true
2014-07-22 07:06:22,332 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-22 07:06:22,332 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 565.3m
2014-07-22 07:06:23,203 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14784,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968419,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,246 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14739,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968507,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,246 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13056,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037970189,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:23,341 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32639 synced till here 32631
2014-07-22 07:06:23,373 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13502,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037969870,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037981105 with entries=84, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037983312
2014-07-22 07:06:23,587 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13653,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037969933,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,629 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:06:23,757 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14014,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037969742,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,757 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13950,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037969806,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,760 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15162,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968598,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,760 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037970126,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,761 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037970062,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,789 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037969712,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,790 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037968723,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:23,798 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037969997,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:24,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:24,547 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037983312 with entries=86, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037984518
2014-07-22 07:06:25,838 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:25,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32807 synced till here 32803
2014-07-22 07:06:25,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037984518 with entries=82, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037985838
2014-07-22 07:06:26,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:26,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32888 synced till here 32885
2014-07-22 07:06:26,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037985838 with entries=81, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037986591
2014-07-22 07:06:28,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:28,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037986591 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037988071
2014-07-22 07:06:29,347 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:29,363 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33049 synced till here 33045
2014-07-22 07:06:29,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037988071 with entries=82, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037989348
2014-07-22 07:06:29,441 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/400bce124d724115b69f6e384d6cdac2 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/400bce124d724115b69f6e384d6cdac2
2014-07-22 07:06:29,485 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:06:29,495 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/a073abf02f1c4446a5571b5d1a043db4, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/a073abf02f1c4446a5571b5d1a043db4
2014-07-22 07:06:29,498 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/47b1f47e0c524d88bde7cb8d9bb76ee1, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/47b1f47e0c524d88bde7cb8d9bb76ee1
2014-07-22 07:06:29,501 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/bf88db1035cb4cb88525ce6b8dbb83c5, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/bf88db1035cb4cb88525ce6b8dbb83c5
2014-07-22 07:06:29,508 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e9f603087f304328b1e0804c7ac3b860, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e9f603087f304328b1e0804c7ac3b860
2014-07-22 07:06:29,518 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/dfdb09bb61264e83ba9dce2c449104ff, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/dfdb09bb61264e83ba9dce2c449104ff
2014-07-22 07:06:29,522 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6835e0e2aa5a45c5a16b34802c5bdf1a, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6835e0e2aa5a45c5a16b34802c5bdf1a
2014-07-22 07:06:29,533 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/0e4e860d90f7442bb6005f077eb06531, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/0e4e860d90f7442bb6005f077eb06531
2014-07-22 07:06:29,541 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/175293c9ff234c52b3b3efa92f05a3e8, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/175293c9ff234c52b3b3efa92f05a3e8
2014-07-22 07:06:29,544 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/2e78da83772141b68d35840856d610ff, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/2e78da83772141b68d35840856d610ff
2014-07-22 07:06:29,552 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/529275e7378f4d429d5be2615aafc9e4, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/529275e7378f4d429d5be2615aafc9e4
2014-07-22 07:06:29,552 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. into 400bce124d724115b69f6e384d6cdac2(size=541.8m), total size for store is 2.7g. This selection was in queue for 0sec, and took 1mins, 56sec to execute.
2014-07-22 07:06:29,552 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., storeName=family, fileCount=10, fileSize=615.2m, priority=1974, time=134853798030629; duration=1mins, 56sec
2014-07-22 07:06:29,552 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-22 07:06:29,553 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 2000 blocking
2014-07-22 07:06:29,557 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 754382899 starting at candidate #12 after considering 148 permutations with 131 in ratio
2014-07-22 07:06:29,557 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 9fefab8f11c8e58bf455cb6ad77b765c - family: Initiating minor compaction
2014-07-22 07:06:29,557 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:06:29,558 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp, totalSize=719.4m
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/84a511896e07469499a2e047e5db4513, keycount=133621, bloomtype=ROW, size=95.1m, encoding=NONE, seqNum=12449
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/e861d459c9f44bd682a2ac6ad2f793ae, keycount=160479, bloomtype=ROW, size=114.3m, encoding=NONE, seqNum=12934
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ca5b51fc35de4255bfea293f17644204, keycount=84892, bloomtype=ROW, size=60.5m, encoding=NONE, seqNum=13510
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ed707520a6a6462486d4786f96381b76, keycount=124830, bloomtype=ROW, size=88.9m, encoding=NONE, seqNum=13854
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/9e4bacb917c848a7b0df3a6ca9f909a8, keycount=124584, bloomtype=ROW, size=88.7m, encoding=NONE, seqNum=14433
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/55edf31d3eb24d4ba44cabb518e520a3, keycount=118858, bloomtype=ROW, size=84.7m, encoding=NONE, seqNum=15030
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/997339b8061b4b2aa1c9656bd23b0914, keycount=106093, bloomtype=ROW, size=75.5m, encoding=NONE, seqNum=15463
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/48a8cc01aba64e69bea1afdaf999eea0, keycount=76517, bloomtype=ROW, size=54.5m, encoding=NONE, seqNum=15862
2014-07-22 07:06:29,558 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3452674414ae4558a562768ac1138b75, keycount=47394, bloomtype=ROW, size=33.8m, encoding=NONE, seqNum=16028
2014-07-22 07:06:29,559 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/65163f646a254f85b30a41099c174d35, keycount=32887, bloomtype=ROW, size=23.4m, encoding=NONE, seqNum=16168
2014-07-22 07:06:30,340 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:06:30,610 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:30,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33131 synced till here 33127
2014-07-22 07:06:30,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037989348 with entries=82, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037990610
2014-07-22 07:06:31,976 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:06:32,201 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:32,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33215 synced till here 33213
2014-07-22 07:06:32,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037990610 with entries=84, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037992201
2014-07-22 07:06:33,820 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,820 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,828 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,832 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,833 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,841 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,852 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,855 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,865 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,873 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,873 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,885 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:33,938 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,003 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,068 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,133 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,199 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,265 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,330 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:34,394 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:36,416 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6859, memsize=300.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/19bf2e759d50460abc19ae2b3d255592
2014-07-22 07:06:36,429 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/19bf2e759d50460abc19ae2b3d255592 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/19bf2e759d50460abc19ae2b3d255592
2014-07-22 07:06:36,445 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/19bf2e759d50460abc19ae2b3d255592, entries=1094270, sequenceid=6859, filesize=77.9m
2014-07-22 07:06:36,445 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~300.5m/315120320, currentsize=39.7m/41592560 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 15541ms, sequenceid=6859, compaction requested=true
2014-07-22 07:06:36,445 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-22 07:06:36,445 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2051ms
2014-07-22 07:06:36,446 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,446 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 648.1m
2014-07-22 07:06:36,446 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2116ms
2014-07-22 07:06:36,446 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,447 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2181ms
2014-07-22 07:06:36,447 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,447 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2248ms
2014-07-22 07:06:36,447 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,448 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2315ms
2014-07-22 07:06:36,448 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,448 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2380ms
2014-07-22 07:06:36,449 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,449 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2446ms
2014-07-22 07:06:36,449 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,461 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2523ms
2014-07-22 07:06:36,461 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,461 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2577ms
2014-07-22 07:06:36,462 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,462 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2589ms
2014-07-22 07:06:36,462 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,462 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2589ms
2014-07-22 07:06:36,462 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,463 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2598ms
2014-07-22 07:06:36,463 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,463 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2608ms
2014-07-22 07:06:36,463 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,465 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2611ms
2014-07-22 07:06:36,466 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,466 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2626ms
2014-07-22 07:06:36,466 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,466 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2633ms
2014-07-22 07:06:36,466 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,466 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2635ms
2014-07-22 07:06:36,466 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,468 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2639ms
2014-07-22 07:06:36,468 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,469 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2649ms
2014-07-22 07:06:36,470 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,481 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2661ms
2014-07-22 07:06:36,481 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:36,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:37,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33306 synced till here 33295
2014-07-22 07:06:37,454 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037992201 with entries=91, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037996721
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037773813
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037778920
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037781143
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037782323
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037792950
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037794830
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037796884
2014-07-22 07:06:37,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037797868
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037801049
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037803787
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037805744
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037823077
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037824970
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037826426
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037828018
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037829324
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037830858
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037832325
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037833743
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037835308
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037836969
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037849673
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037851334
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037852790
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037854055
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037856484
2014-07-22 07:06:37,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037859789
2014-07-22 07:06:37,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037863068
2014-07-22 07:06:37,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037864607
2014-07-22 07:06:37,661 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:06:37,671 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:06:38,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:38,262 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33392 synced till here 33383
2014-07-22 07:06:38,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037996721 with entries=86, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037998185
2014-07-22 07:06:39,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:39,602 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33478 synced till here 33475
2014-07-22 07:06:39,608 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,609 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,627 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,628 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,630 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037998185 with entries=86, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037999587
2014-07-22 07:06:39,647 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,664 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,664 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,675 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,676 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,692 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,756 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,821 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,885 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:39,951 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:40,906 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:40,936 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:41,000 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:41,084 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:41,175 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:41,248 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:44,609 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:44,610 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:44,627 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,628 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,648 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:44,665 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,665 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:44,676 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:44,676 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,693 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:44,757 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,821 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,885 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:44,951 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:45,907 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:45,937 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:46,000 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:06:46,085 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:06:46,260 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5013ms
2014-07-22 07:06:46,260 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5085ms
2014-07-22 07:06:49,048 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17213, memsize=583.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/f332663ce38a4cffb2dc1836de3108e0
2014-07-22 07:06:49,059 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/f332663ce38a4cffb2dc1836de3108e0 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f332663ce38a4cffb2dc1836de3108e0
2014-07-22 07:06:49,068 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f332663ce38a4cffb2dc1836de3108e0, entries=2126010, sequenceid=17213, filesize=151.4m
2014-07-22 07:06:49,069 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~583.9m/612274560, currentsize=144.3m/151299520 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 26737ms, sequenceid=17213, compaction requested=true
2014-07-22 07:06:49,069 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:77), split_queue=0, merge_queue=0
2014-07-22 07:06:49,069 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7894ms
2014-07-22 07:06:49,069 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,070 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 580.0m
2014-07-22 07:06:49,070 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7823ms
2014-07-22 07:06:49,070 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,070 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7986ms
2014-07-22 07:06:49,070 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,070 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8070ms
2014-07-22 07:06:49,070 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,071 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8134ms
2014-07-22 07:06:49,071 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,077 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8171ms
2014-07-22 07:06:49,077 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,085 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9134ms
2014-07-22 07:06:49,085 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,085 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9200ms
2014-07-22 07:06:49,086 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,086 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9265ms
2014-07-22 07:06:49,086 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,088 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9332ms
2014-07-22 07:06:49,088 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,088 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9396ms
2014-07-22 07:06:49,088 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,089 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9413ms
2014-07-22 07:06:49,089 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,089 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9414ms
2014-07-22 07:06:49,089 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,090 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9426ms
2014-07-22 07:06:49,090 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,101 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9437ms
2014-07-22 07:06:49,101 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,102 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9454ms
2014-07-22 07:06:49,102 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,102 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9474ms
2014-07-22 07:06:49,102 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,102 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9475ms
2014-07-22 07:06:49,102 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,102 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9494ms
2014-07-22 07:06:49,103 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,109 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9501ms
2014-07-22 07:06:49,109 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:06:49,281 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10280,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999000,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:49,572 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999068,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:49,572 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999140,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:49,572 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999208,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:49,591 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:06:50,069 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10781,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999287,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:50,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:50,339 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10991,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999347,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:50,446 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999483,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:50,744 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11189,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999555,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:50,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33628 synced till here 33621
2014-07-22 07:06:51,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037999587 with entries=150, filesize=121.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038010151
2014-07-22 07:06:51,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037866209
2014-07-22 07:06:51,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037879902
2014-07-22 07:06:51,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037881165
2014-07-22 07:06:51,878 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10944,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038000934,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,110 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999883,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,110 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12160,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999949,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,111 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12292,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999818,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,110 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999690,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,111 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12485,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999625,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,110 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12355,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406037999754,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,110 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11206,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038000903,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:06:52,303 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:53,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33743 synced till here 33740
2014-07-22 07:06:53,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038010151 with entries=115, filesize=88.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038012304
2014-07-22 07:06:53,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:06:53,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33827 synced till here 33821
2014-07-22 07:06:53,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038012304 with entries=84, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038013875
2014-07-22 07:06:55,069 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,070 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,099 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,100 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,100 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,101 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,119 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,119 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,120 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,134 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,134 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,134 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,266 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,329 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,393 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,457 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,521 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,584 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,649 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:06:55,712 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:00,070 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:00,071 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-22 07:07:00,099 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,100 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,101 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:00,102 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,119 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,119 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,120 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,134 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,135 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:00,135 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:00,266 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,330 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,393 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,457 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,521 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,584 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,649 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:00,712 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:01,567 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17274, memsize=648.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/25d271e15438486a8655abdc165c3e38
2014-07-22 07:07:01,578 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/25d271e15438486a8655abdc165c3e38 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/25d271e15438486a8655abdc165c3e38
2014-07-22 07:07:01,588 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/25d271e15438486a8655abdc165c3e38, entries=2359650, sequenceid=17274, filesize=168.1m
2014-07-22 07:07:01,589 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~648.1m/679560000, currentsize=105.1m/110171600 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 25142ms, sequenceid=17274, compaction requested=true
2014-07-22 07:07:01,589 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:78), split_queue=0, merge_queue=0
2014-07-22 07:07:01,589 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5878ms
2014-07-22 07:07:01,589 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,590 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5941ms
2014-07-22 07:07:01,590 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,590 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6006ms
2014-07-22 07:07:01,590 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 645.1m
2014-07-22 07:07:01,590 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,596 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6075ms
2014-07-22 07:07:01,596 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,596 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6139ms
2014-07-22 07:07:01,596 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,596 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6203ms
2014-07-22 07:07:01,596 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,596 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6267ms
2014-07-22 07:07:01,597 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,597 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6331ms
2014-07-22 07:07:01,597 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,597 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6463ms
2014-07-22 07:07:01,597 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,597 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6463ms
2014-07-22 07:07:01,598 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,598 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6464ms
2014-07-22 07:07:01,598 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,605 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6485ms
2014-07-22 07:07:01,605 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,606 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6487ms
2014-07-22 07:07:01,606 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,606 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6487ms
2014-07-22 07:07:01,606 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,606 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6505ms
2014-07-22 07:07:01,606 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,626 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6526ms
2014-07-22 07:07:01,626 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,627 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6527ms
2014-07-22 07:07:01,627 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,629 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6530ms
2014-07-22 07:07:01,629 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,629 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6560ms
2014-07-22 07:07:01,630 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,633 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6564ms
2014-07-22 07:07:01,633 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:01,766 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:01,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33917 synced till here 33903
2014-07-22 07:07:02,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038013875 with entries=90, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038021767
2014-07-22 07:07:02,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037882697
2014-07-22 07:07:02,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037884099
2014-07-22 07:07:02,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037885125
2014-07-22 07:07:02,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037886630
2014-07-22 07:07:02,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037891018
2014-07-22 07:07:02,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037892694
2014-07-22 07:07:02,417 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:07:02,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:02,803 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34008 synced till here 33998
2014-07-22 07:07:03,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038021767 with entries=91, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038022781
2014-07-22 07:07:04,299 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:04,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34096 synced till here 34090
2014-07-22 07:07:04,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038022781 with entries=88, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038024300
2014-07-22 07:07:05,210 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:07:05,634 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:05,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34181 synced till here 34176
2014-07-22 07:07:05,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038024300 with entries=85, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038025635
2014-07-22 07:07:07,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:07,045 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34261 synced till here 34257
2014-07-22 07:07:07,083 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038025635 with entries=80, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038027023
2014-07-22 07:07:08,678 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,679 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,711 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:08,725 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,725 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,726 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,731 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34344 synced till here 34337
2014-07-22 07:07:08,744 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,744 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,751 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,797 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,798 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,798 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,800 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038027023 with entries=83, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038028712
2014-07-22 07:07:08,822 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,907 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:08,987 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:09,068 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:09,146 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:09,235 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:09,328 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:13,678 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:13,680 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:13,725 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,725 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,726 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,731 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,744 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,745 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:13,751 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,797 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,798 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,799 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:13,800 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,822 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,907 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:13,987 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:14,069 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:14,146 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:14,236 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:14,263 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17293, memsize=580.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/8cb8d6dc812e4fb48598120fcaa6c3d0
2014-07-22 07:07:14,275 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/8cb8d6dc812e4fb48598120fcaa6c3d0 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/8cb8d6dc812e4fb48598120fcaa6c3d0
2014-07-22 07:07:14,284 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/8cb8d6dc812e4fb48598120fcaa6c3d0, entries=2111770, sequenceid=17293, filesize=150.4m
2014-07-22 07:07:14,285 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~580.0m/608172400, currentsize=147.8m/154957600 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 25215ms, sequenceid=17293, compaction requested=true
2014-07-22 07:07:14,285 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:79), split_queue=0, merge_queue=0
2014-07-22 07:07:14,285 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5050ms
2014-07-22 07:07:14,285 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,285 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5139ms
2014-07-22 07:07:14,285 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 590.6m
2014-07-22 07:07:14,285 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,286 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5218ms
2014-07-22 07:07:14,286 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,286 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5299ms
2014-07-22 07:07:14,286 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,287 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5380ms
2014-07-22 07:07:14,287 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,293 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5470ms
2014-07-22 07:07:14,293 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,293 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5493ms
2014-07-22 07:07:14,293 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,293 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5495ms
2014-07-22 07:07:14,293 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,293 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5495ms
2014-07-22 07:07:14,293 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,293 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5496ms
2014-07-22 07:07:14,293 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,293 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5542ms
2014-07-22 07:07:14,294 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,294 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5550ms
2014-07-22 07:07:14,294 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,294 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5550ms
2014-07-22 07:07:14,294 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,294 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5563ms
2014-07-22 07:07:14,294 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,297 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5571ms
2014-07-22 07:07:14,297 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,297 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5572ms
2014-07-22 07:07:14,297 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,298 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5573ms
2014-07-22 07:07:14,298 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,309 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5630ms
2014-07-22 07:07:14,309 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,309 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5632ms
2014-07-22 07:07:14,309 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,310 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4983ms
2014-07-22 07:07:14,310 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:14,794 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:07:15,380 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:15,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34431 synced till here 34422
2014-07-22 07:07:15,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038028712 with entries=87, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038035381
2014-07-22 07:07:15,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037893590
2014-07-22 07:07:16,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:16,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34519 synced till here 34514
2014-07-22 07:07:16,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038035381 with entries=88, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038036866
2014-07-22 07:07:18,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:19,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34677 synced till here 34669
2014-07-22 07:07:20,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038036866 with entries=158, filesize=126.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038038445
2014-07-22 07:07:20,830 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,834 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,836 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,836 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,848 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,852 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,852 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,874 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,905 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,907 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,908 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,912 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,931 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,935 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,936 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,936 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:20,987 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:21,078 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:21,158 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:22,136 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:25,831 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,834 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,836 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,837 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,849 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,852 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,852 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,874 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,906 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,908 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,908 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,913 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,932 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:25,935 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,936 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,936 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:25,988 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:26,078 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:26,158 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:27,137 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:29,537 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7046, memsize=645.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b4f8ef18a5ee45ee9b3be756f2740474
2014-07-22 07:07:29,549 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b4f8ef18a5ee45ee9b3be756f2740474 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b4f8ef18a5ee45ee9b3be756f2740474
2014-07-22 07:07:29,559 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b4f8ef18a5ee45ee9b3be756f2740474, entries=2348840, sequenceid=7046, filesize=167.3m
2014-07-22 07:07:29,559 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~645.1m/676444720, currentsize=144.4m/151462800 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 27969ms, sequenceid=7046, compaction requested=true
2014-07-22 07:07:29,559 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:80), split_queue=0, merge_queue=0
2014-07-22 07:07:29,560 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7424ms
2014-07-22 07:07:29,560 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,560 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 643.6m
2014-07-22 07:07:29,560 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8402ms
2014-07-22 07:07:29,560 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,560 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8482ms
2014-07-22 07:07:29,560 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,561 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8574ms
2014-07-22 07:07:29,561 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,565 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8629ms
2014-07-22 07:07:29,565 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,566 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8629ms
2014-07-22 07:07:29,566 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,566 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8631ms
2014-07-22 07:07:29,566 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,567 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8636ms
2014-07-22 07:07:29,567 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,567 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8655ms
2014-07-22 07:07:29,567 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,577 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8670ms
2014-07-22 07:07:29,577 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,578 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8670ms
2014-07-22 07:07:29,578 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,581 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8676ms
2014-07-22 07:07:29,581 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,582 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8708ms
2014-07-22 07:07:29,582 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,586 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8733ms
2014-07-22 07:07:29,586 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,589 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8737ms
2014-07-22 07:07:29,589 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,590 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8741ms
2014-07-22 07:07:29,590 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,590 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8754ms
2014-07-22 07:07:29,590 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,590 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8755ms
2014-07-22 07:07:29,590 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,591 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8756ms
2014-07-22 07:07:29,591 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,592 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8761ms
2014-07-22 07:07:29,592 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:29,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:29,644 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10975,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038038668,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:29,712 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34770 synced till here 34757
2014-07-22 07:07:29,804 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038038445 with entries=93, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038049631
2014-07-22 07:07:29,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037908351
2014-07-22 07:07:29,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037909180
2014-07-22 07:07:29,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037910492
2014-07-22 07:07:29,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037911826
2014-07-22 07:07:29,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037913304
2014-07-22 07:07:29,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037914767
2014-07-22 07:07:29,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037916149
2014-07-22 07:07:29,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037917625
2014-07-22 07:07:29,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037919221
2014-07-22 07:07:29,998 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:07:29,999 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038038757,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:30,138 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11302,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038038835,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:30,138 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11134,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038039003,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:30,138 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11233,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038038904,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:30,228 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:07:30,244 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11173,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038039071,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:30,246 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10019,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040226,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:30,974 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10950,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040023,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,030 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:31,032 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10890,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040141,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34863 synced till here 34852
2014-07-22 07:07:31,097 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040074,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,097 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11941,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038039155,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,097 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10786,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040310,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038049631 with entries=93, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038051031
2014-07-22 07:07:31,127 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10500,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040626,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,193 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10687,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040505,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,309 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10526,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040783,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,346 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10191,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038041154,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,372 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040984,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,372 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038041072,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:31,393 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10522,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038040870,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:32,448 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:32,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34949 synced till here 34944
2014-07-22 07:07:32,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038051031 with entries=86, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038052449
2014-07-22 07:07:32,557 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:07:33,086 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:33,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35031 synced till here 35030
2014-07-22 07:07:33,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038052449 with entries=82, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038053087
2014-07-22 07:07:34,620 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:34,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35111 synced till here 35110
2014-07-22 07:07:34,661 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038053087 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038054620
2014-07-22 07:07:35,966 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:35,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35192 synced till here 35188
2014-07-22 07:07:35,990 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:35,990 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,010 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,013 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038054620 with entries=81, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038055966
2014-07-22 07:07:36,027 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,056 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,057 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,057 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,057 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,079 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,081 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,081 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,092 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,155 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:36,217 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:37,159 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:37,190 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:37,254 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:37,339 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:37,439 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:37,512 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:40,198 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7105, memsize=590.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/bea5dc9c0ca542248addb773a66e9bc2
2014-07-22 07:07:40,208 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/bea5dc9c0ca542248addb773a66e9bc2 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bea5dc9c0ca542248addb773a66e9bc2
2014-07-22 07:07:40,216 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/bea5dc9c0ca542248addb773a66e9bc2, entries=2150320, sequenceid=7105, filesize=153.1m
2014-07-22 07:07:40,216 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~590.6m/619274880, currentsize=145.2m/152235600 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 25931ms, sequenceid=7105, compaction requested=true
2014-07-22 07:07:40,217 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:81), split_queue=0, merge_queue=0
2014-07-22 07:07:40,217 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2705ms
2014-07-22 07:07:40,217 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,217 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2778ms
2014-07-22 07:07:40,217 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 605.4m
2014-07-22 07:07:40,217 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,217 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2878ms
2014-07-22 07:07:40,217 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,217 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2963ms
2014-07-22 07:07:40,217 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,218 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3028ms
2014-07-22 07:07:40,218 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,218 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3059ms
2014-07-22 07:07:40,218 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,219 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4002ms
2014-07-22 07:07:40,219 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,219 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4065ms
2014-07-22 07:07:40,219 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,220 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4128ms
2014-07-22 07:07:40,220 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,220 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4139ms
2014-07-22 07:07:40,220 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,221 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4139ms
2014-07-22 07:07:40,221 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,221 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4142ms
2014-07-22 07:07:40,221 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,221 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4164ms
2014-07-22 07:07:40,222 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,228 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4171ms
2014-07-22 07:07:40,229 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,229 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4172ms
2014-07-22 07:07:40,229 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,229 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4173ms
2014-07-22 07:07:40,229 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,229 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4202ms
2014-07-22 07:07:40,229 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,235 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4225ms
2014-07-22 07:07:40,235 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,235 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4245ms
2014-07-22 07:07:40,235 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:40,235 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4245ms
2014-07-22 07:07:40,235 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:41,353 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:07:41,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:41,529 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35284 synced till here 35273
2014-07-22 07:07:41,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038055966 with entries=92, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038061484
2014-07-22 07:07:41,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037920508
2014-07-22 07:07:42,944 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:42,945 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:07:42,971 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35375 synced till here 35365
2014-07-22 07:07:43,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038061484 with entries=91, filesize=71.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038062945
2014-07-22 07:07:44,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:44,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35460 synced till here 35455
2014-07-22 07:07:44,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038062945 with entries=85, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038064470
2014-07-22 07:07:46,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:46,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35543 synced till here 35539
2014-07-22 07:07:46,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038064470 with entries=83, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038066117
2014-07-22 07:07:46,707 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,717 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,728 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,751 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,751 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,787 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,789 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,789 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,789 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,802 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,804 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,869 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:46,933 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:47,837 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:47,866 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:47,930 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:48,009 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:48,093 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:48,169 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:48,252 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:07:51,707 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,718 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:51,728 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,751 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,751 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,787 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,789 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:51,789 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,789 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:51,803 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:51,804 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:51,870 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:51,933 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:52,842 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-22 07:07:52,867 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:07:52,930 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:53,109 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5016ms
2014-07-22 07:07:53,110 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5101ms
2014-07-22 07:07:53,170 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:53,252 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:07:56,707 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:07:56,718 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:56,729 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:56,751 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:07:56,752 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:56,788 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:07:56,789 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:56,789 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:07:56,789 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:07:56,803 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:56,804 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:56,870 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:07:56,934 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:07:57,031 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7141, memsize=643.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/682a544618aa466d8db01bd92f1e719d
2014-07-22 07:07:57,042 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/682a544618aa466d8db01bd92f1e719d as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/682a544618aa466d8db01bd92f1e719d
2014-07-22 07:07:57,050 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/682a544618aa466d8db01bd92f1e719d, entries=2343300, sequenceid=7141, filesize=166.9m
2014-07-22 07:07:57,051 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~643.6m/674851120, currentsize=150.7m/157987200 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 27491ms, sequenceid=7141, compaction requested=true
2014-07-22 07:07:57,051 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:82), split_queue=0, merge_queue=0
2014-07-22 07:07:57,051 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10118ms
2014-07-22 07:07:57,051 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,051 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10183ms
2014-07-22 07:07:57,051 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 643.0m
2014-07-22 07:07:57,051 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,052 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10249ms
2014-07-22 07:07:57,052 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,057 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10255ms
2014-07-22 07:07:57,057 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,057 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10268ms
2014-07-22 07:07:57,057 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,057 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10268ms
2014-07-22 07:07:57,057 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,065 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10277ms
2014-07-22 07:07:57,066 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,066 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10279ms
2014-07-22 07:07:57,066 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,066 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10315ms
2014-07-22 07:07:57,066 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,066 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10315ms
2014-07-22 07:07:57,066 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,079 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10351ms
2014-07-22 07:07:57,079 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,079 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10362ms
2014-07-22 07:07:57,079 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,079 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10372ms
2014-07-22 07:07:57,079 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,080 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8827ms
2014-07-22 07:07:57,080 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,080 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8911ms
2014-07-22 07:07:57,080 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,089 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9080ms
2014-07-22 07:07:57,089 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,090 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8997ms
2014-07-22 07:07:57,090 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,097 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9167ms
2014-07-22 07:07:57,097 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,098 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9231ms
2014-07-22 07:07:57,098 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,105 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9268ms
2014-07-22 07:07:57,105 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:07:57,151 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11948,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038065202,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:57,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:57,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35632 synced till here 35620
2014-07-22 07:07:57,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038066117 with entries=89, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038077176
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037932274
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037933489
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037934836
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037936178
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037937513
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037938989
2014-07-22 07:07:57,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037940311
2014-07-22 07:07:57,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037941091
2014-07-22 07:07:57,420 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038065282,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:57,766 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066136,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:57,766 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066067,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:57,872 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11665,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066207,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:57,874 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11579,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066294,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:57,940 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:07:58,182 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11812,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066369,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:58,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:58,227 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35717 synced till here 35708
2014-07-22 07:07:58,285 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11845,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066439,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:58,286 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066505,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:58,296 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038077176 with entries=85, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038078203
2014-07-22 07:07:58,495 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066576,"queuetimems":3,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,226 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12573,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066652,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,328 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11162,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038068166,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,328 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12462,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066866,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,328 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12397,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038066931,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,430 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11595,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038067835,"queuetimems":839,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,430 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038068247,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,501 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11574,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038067927,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,501 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038067864,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,503 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11497,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038068005,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,503 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11413,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038068088,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:07:59,547 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:07:59,568 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35802 synced till here 35797
2014-07-22 07:07:59,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038078203 with entries=85, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038079547
2014-07-22 07:07:59,999 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:08:00,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:01,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35887 synced till here 35883
2014-07-22 07:08:01,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038079547 with entries=85, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038080984
2014-07-22 07:08:02,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:02,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35970 synced till here 35966
2014-07-22 07:08:02,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038080984 with entries=83, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038082242
2014-07-22 07:08:03,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:03,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038082242 with entries=80, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038083672
2014-07-22 07:08:03,741 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:03,751 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:03,799 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:03,799 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:03,816 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:03,880 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:03,943 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,007 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,071 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,135 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,201 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,267 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,332 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,397 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,462 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,528 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,592 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,657 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,721 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:04,785 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:05,456 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17532, memsize=605.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/ce0360d8f563457dbf0a2f3b4e8aa95c
2014-07-22 07:08:05,475 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/ce0360d8f563457dbf0a2f3b4e8aa95c as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/ce0360d8f563457dbf0a2f3b4e8aa95c
2014-07-22 07:08:05,487 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/ce0360d8f563457dbf0a2f3b4e8aa95c, entries=2204170, sequenceid=17532, filesize=157.0m
2014-07-22 07:08:05,487 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~605.4m/634783920, currentsize=143.1m/150081680 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 25270ms, sequenceid=17532, compaction requested=true
2014-07-22 07:08:05,488 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:83), split_queue=0, merge_queue=0
2014-07-22 07:08:05,488 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 703ms
2014-07-22 07:08:05,488 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,488 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 767ms
2014-07-22 07:08:05,488 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 586.1m
2014-07-22 07:08:05,488 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,488 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 831ms
2014-07-22 07:08:05,488 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,489 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 897ms
2014-07-22 07:08:05,489 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,493 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 965ms
2014-07-22 07:08:05,493 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,493 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1031ms
2014-07-22 07:08:05,493 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,494 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1097ms
2014-07-22 07:08:05,494 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,494 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1162ms
2014-07-22 07:08:05,494 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,494 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1227ms
2014-07-22 07:08:05,494 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,494 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1293ms
2014-07-22 07:08:05,494 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,494 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1359ms
2014-07-22 07:08:05,494 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,494 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1423ms
2014-07-22 07:08:05,495 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,497 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1490ms
2014-07-22 07:08:05,497 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,497 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1554ms
2014-07-22 07:08:05,497 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,516 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1636ms
2014-07-22 07:08:05,516 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,516 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1700ms
2014-07-22 07:08:05,517 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,517 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1718ms
2014-07-22 07:08:05,517 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,517 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1718ms
2014-07-22 07:08:05,517 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,517 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1766ms
2014-07-22 07:08:05,517 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:05,519 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1778ms
2014-07-22 07:08:05,520 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:06,953 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:08:07,227 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:07,264 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36135 synced till here 36127
2014-07-22 07:08:07,319 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038083672 with entries=85, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038087228
2014-07-22 07:08:07,319 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037942326
2014-07-22 07:08:07,319 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037955873
2014-07-22 07:08:08,476 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:08:08,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:08,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36224 synced till here 36211
2014-07-22 07:08:08,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038087228 with entries=89, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038088594
2014-07-22 07:08:09,954 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:09,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36311 synced till here 36310
2014-07-22 07:08:10,005 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038088594 with entries=87, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038089954
2014-07-22 07:08:11,399 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36391 synced till here 36389
2014-07-22 07:08:11,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038089954 with entries=80, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038091399
2014-07-22 07:08:13,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:13,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36473 synced till here 36469
2014-07-22 07:08:13,256 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038091399 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038093181
2014-07-22 07:08:13,289 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,290 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,291 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,291 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,306 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,307 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,311 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,317 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,317 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,326 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,374 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,439 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,501 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,565 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,630 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,694 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,759 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,823 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,887 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:13,950 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:18,290 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:18,291 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:18,291 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,291 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,306 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,308 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:18,312 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,320 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-22 07:08:18,321 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-22 07:08:18,326 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,374 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,439 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,502 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:18,565 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,630 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,694 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,759 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,823 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,887 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:18,951 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:23,290 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,291 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,292 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:08:23,292 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,307 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,308 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,312 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,321 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-22 07:08:23,321 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-22 07:08:23,326 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:08:23,375 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,440 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:08:23,502 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,566 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,631 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,695 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:23,759 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:08:23,824 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:08:23,887 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:08:23,951 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:24,006 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17551, memsize=643.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/1d479adeba0d43a8bfc900901b392552
2014-07-22 07:08:24,018 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/1d479adeba0d43a8bfc900901b392552 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1d479adeba0d43a8bfc900901b392552
2014-07-22 07:08:24,027 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1d479adeba0d43a8bfc900901b392552, entries=2341040, sequenceid=17551, filesize=166.7m
2014-07-22 07:08:24,027 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~643.0m/674202320, currentsize=147.9m/155118560 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 26976ms, sequenceid=17551, compaction requested=true
2014-07-22 07:08:24,027 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:84), split_queue=0, merge_queue=0
2014-07-22 07:08:24,028 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10078ms
2014-07-22 07:08:24,028 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,028 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10141ms
2014-07-22 07:08:24,028 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 551.0m
2014-07-22 07:08:24,028 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,033 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10210ms
2014-07-22 07:08:24,033 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,033 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10274ms
2014-07-22 07:08:24,033 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,041 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10347ms
2014-07-22 07:08:24,041 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,041 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10411ms
2014-07-22 07:08:24,041 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,052 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10487ms
2014-07-22 07:08:24,053 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,053 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10552ms
2014-07-22 07:08:24,053 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,055 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10616ms
2014-07-22 07:08:24,055 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,057 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10683ms
2014-07-22 07:08:24,057 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,057 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10731ms
2014-07-22 07:08:24,057 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,058 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10740ms
2014-07-22 07:08:24,058 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,058 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10741ms
2014-07-22 07:08:24,058 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,058 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10747ms
2014-07-22 07:08:24,058 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,061 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10754ms
2014-07-22 07:08:24,062 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,073 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10767ms
2014-07-22 07:08:24,073 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,073 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10782ms
2014-07-22 07:08:24,073 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,074 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10783ms
2014-07-22 07:08:24,074 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,074 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10784ms
2014-07-22 07:08:24,074 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,085 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10796ms
2014-07-22 07:08:24,085 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:24,171 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038091720,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:24,171 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038091860,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:24,492 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12494,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038091998,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:24,620 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:08:24,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:24,848 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12736,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038092111,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:24,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36559 synced till here 36550
2014-07-22 07:08:24,906 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12618,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038092286,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:24,906 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12694,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038092210,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:24,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038093181 with entries=86, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038104847
2014-07-22 07:08:24,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037956932
2014-07-22 07:08:24,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037958449
2014-07-22 07:08:24,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037959803
2014-07-22 07:08:24,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037961330
2014-07-22 07:08:24,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037963079
2014-07-22 07:08:24,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037964786
2014-07-22 07:08:24,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037966389
2014-07-22 07:08:24,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:25,730 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093139,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,089 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:26,094 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093240,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,094 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093948,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,095 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12208,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093885,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,096 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12596,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093499,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,096 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12920,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093176,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36642 synced till here 36637
2014-07-22 07:08:26,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038104847 with entries=83, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038106089
2014-07-22 07:08:26,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:26,163 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12534,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093628,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,250 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12941,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093308,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,262 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12825,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093436,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,263 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12441,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093821,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,262 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093563,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,283 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093692,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,285 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093372,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:26,288 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038093757,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:27,125 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:08:27,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:27,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36733 synced till here 36727
2014-07-22 07:08:27,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038106089 with entries=91, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038107382
2014-07-22 07:08:27,469 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:28,783 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:28,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36813 synced till here 36811
2014-07-22 07:08:28,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038107382 with entries=80, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038108783
2014-07-22 07:08:28,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:30,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:30,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038108783 with entries=79, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038110243
2014-07-22 07:08:30,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:30,536 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,537 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,554 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,559 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,583 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,589 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,602 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,604 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,604 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:30,623 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17591, memsize=586.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/cf0071d088214503b220bf5b063313d3
2014-07-22 07:08:30,634 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/cf0071d088214503b220bf5b063313d3 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cf0071d088214503b220bf5b063313d3
2014-07-22 07:08:30,642 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cf0071d088214503b220bf5b063313d3, entries=2133930, sequenceid=17591, filesize=151.9m
2014-07-22 07:08:30,642 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~586.1m/614553360, currentsize=151.0m/158381760 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 25154ms, sequenceid=17591, compaction requested=true
2014-07-22 07:08:30,643 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-22 07:08:30,643 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 39ms
2014-07-22 07:08:30,643 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,643 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 40ms
2014-07-22 07:08:30,643 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 599.3m
2014-07-22 07:08:30,643 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,643 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 41ms
2014-07-22 07:08:30,643 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,643 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 54ms
2014-07-22 07:08:30,643 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,644 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 61ms
2014-07-22 07:08:30,644 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,644 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 85ms
2014-07-22 07:08:30,644 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,644 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 90ms
2014-07-22 07:08:30,644 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,644 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 107ms
2014-07-22 07:08:30,644 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:30,644 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 108ms
2014-07-22 07:08:30,644 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:31,685 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:31,710 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36976 synced till here 36972
2014-07-22 07:08:31,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038110243 with entries=84, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038111686
2014-07-22 07:08:31,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:31,837 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:08:33,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:33,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37062 synced till here 37055
2014-07-22 07:08:33,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038111686 with entries=86, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038113132
2014-07-22 07:08:33,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:33,471 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:08:34,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:34,711 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37147 synced till here 37139
2014-07-22 07:08:34,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038113132 with entries=85, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038114691
2014-07-22 07:08:34,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:35,354 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:35,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37231 synced till here 37228
2014-07-22 07:08:36,054 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038114691 with entries=84, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038115354
2014-07-22 07:08:36,054 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:36,660 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:36,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37314 synced till here 37308
2014-07-22 07:08:36,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038115354 with entries=83, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038116661
2014-07-22 07:08:36,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:37,441 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,442 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,442 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,459 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,463 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,474 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,480 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,488 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,496 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,560 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,624 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,688 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,751 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,818 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,883 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:37,947 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:38,011 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:38,075 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:38,139 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:38,214 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:42,300 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/511d919d2bf44020ad3b5fa27ef5f2e8 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/511d919d2bf44020ad3b5fa27ef5f2e8
2014-07-22 07:08:42,313 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:08:42,326 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/84a511896e07469499a2e047e5db4513, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/84a511896e07469499a2e047e5db4513
2014-07-22 07:08:42,328 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/e861d459c9f44bd682a2ac6ad2f793ae, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/e861d459c9f44bd682a2ac6ad2f793ae
2014-07-22 07:08:42,330 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ca5b51fc35de4255bfea293f17644204, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ca5b51fc35de4255bfea293f17644204
2014-07-22 07:08:42,332 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ed707520a6a6462486d4786f96381b76, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ed707520a6a6462486d4786f96381b76
2014-07-22 07:08:42,334 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/9e4bacb917c848a7b0df3a6ca9f909a8, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/9e4bacb917c848a7b0df3a6ca9f909a8
2014-07-22 07:08:42,335 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/55edf31d3eb24d4ba44cabb518e520a3, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/55edf31d3eb24d4ba44cabb518e520a3
2014-07-22 07:08:42,337 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/997339b8061b4b2aa1c9656bd23b0914, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/997339b8061b4b2aa1c9656bd23b0914
2014-07-22 07:08:42,339 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/48a8cc01aba64e69bea1afdaf999eea0, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/48a8cc01aba64e69bea1afdaf999eea0
2014-07-22 07:08:42,341 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3452674414ae4558a562768ac1138b75, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3452674414ae4558a562768ac1138b75
2014-07-22 07:08:42,343 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/65163f646a254f85b30a41099c174d35, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/65163f646a254f85b30a41099c174d35
2014-07-22 07:08:42,343 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. into 511d919d2bf44020ad3b5fa27ef5f2e8(size=623.7m), total size for store is 2.8g. This selection was in queue for 0sec, and took 2mins, 12sec to execute.
2014-07-22 07:08:42,344 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., storeName=family, fileCount=10, fileSize=719.4m, priority=1976, time=134969947722688; duration=2mins, 12sec
2014-07-22 07:08:42,344 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-22 07:08:42,344 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 24 store files, 0 compacting, 24 eligible, 2000 blocking
2014-07-22 07:08:42,348 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 525609350 starting at candidate #10 after considering 148 permutations with 117 in ratio
2014-07-22 07:08:42,348 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 5688494b49c628b8cf95eecd57a989f3 - family: Initiating minor compaction
2014-07-22 07:08:42,348 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:08:42,349 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp, totalSize=501.3m
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1ccf96deb35543c89ec1126161482090, keycount=72295, bloomtype=ROW, size=51.5m, encoding=NONE, seqNum=13340
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2cbf12193f5c4838b70abc15e3898b93, keycount=71337, bloomtype=ROW, size=50.9m, encoding=NONE, seqNum=13715
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2dfe2a2d51d94ff5add86d31be6189c2, keycount=142186, bloomtype=ROW, size=101.3m, encoding=NONE, seqNum=14266
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/077e5755c8f94dc9b4a12c45631ae2c2, keycount=108525, bloomtype=ROW, size=77.3m, encoding=NONE, seqNum=14851
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9fe5afb63e0f43b5869664493d458e0e, keycount=149863, bloomtype=ROW, size=106.7m, encoding=NONE, seqNum=15448
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/3822aef797904b07810b83fa4e5ac184, keycount=16419, bloomtype=ROW, size=11.7m, encoding=NONE, seqNum=15613
2014-07-22 07:08:42,349 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/252894c5615148b08bbda7e8aa013252, keycount=61213, bloomtype=ROW, size=43.6m, encoding=NONE, seqNum=15779
2014-07-22 07:08:42,350 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d60504373db54f91b4042bd422989b4d, keycount=26488, bloomtype=ROW, size=18.9m, encoding=NONE, seqNum=15945
2014-07-22 07:08:42,350 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/352c16c0101e4bfca0cac63529ca766e, keycount=22951, bloomtype=ROW, size=16.4m, encoding=NONE, seqNum=16112
2014-07-22 07:08:42,350 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1541ef227b7243e2a4844f3f6bef50a3, keycount=32221, bloomtype=ROW, size=22.9m, encoding=NONE, seqNum=16181
2014-07-22 07:08:42,442 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:42,442 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:42,443 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,461 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-22 07:08:42,463 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,474 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:42,480 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:42,489 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,497 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,507 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:08:42,560 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,624 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,689 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,752 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,819 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:42,884 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:42,952 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-22 07:08:43,012 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:08:43,075 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:43,139 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:43,215 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:08:47,634 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10010ms
2014-07-22 07:08:47,635 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10192ms
2014-07-22 07:08:47,636 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10176ms
2014-07-22 07:08:47,636 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10173ms
2014-07-22 07:08:47,637 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10164ms
2014-07-22 07:08:47,637 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10158ms
2014-07-22 07:08:47,637 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10141ms
2014-07-22 07:08:47,638 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10149ms
2014-07-22 07:08:47,639 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10078ms
2014-07-22 07:08:47,639 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10198ms
2014-07-22 07:08:47,639 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10198ms
2014-07-22 07:08:47,689 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:47,752 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:47,819 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:47,884 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:47,952 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-22 07:08:48,013 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:08:48,076 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:48,118 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17630, memsize=551.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/3fe3470d043947e7aa463f7635332e12
2014-07-22 07:08:48,131 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/3fe3470d043947e7aa463f7635332e12 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/3fe3470d043947e7aa463f7635332e12
2014-07-22 07:08:48,139 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/3fe3470d043947e7aa463f7635332e12, entries=2006040, sequenceid=17630, filesize=142.9m
2014-07-22 07:08:48,139 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~551.0m/577723120, currentsize=148.6m/155771920 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 24111ms, sequenceid=17630, compaction requested=true
2014-07-22 07:08:48,140 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-22 07:08:48,140 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:08:48,140 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,140 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10065ms
2014-07-22 07:08:48,140 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,140 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10129ms
2014-07-22 07:08:48,140 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 595.9m
2014-07-22 07:08:48,140 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,140 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10193ms
2014-07-22 07:08:48,140 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,141 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10258ms
2014-07-22 07:08:48,141 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,143 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10325ms
2014-07-22 07:08:48,143 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,143 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10392ms
2014-07-22 07:08:48,143 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,144 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10456ms
2014-07-22 07:08:48,144 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,144 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10703ms
2014-07-22 07:08:48,144 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,144 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10703ms
2014-07-22 07:08:48,144 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,144 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10584ms
2014-07-22 07:08:48,144 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,157 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10669ms
2014-07-22 07:08:48,157 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,157 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10661ms
2014-07-22 07:08:48,158 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,165 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10686ms
2014-07-22 07:08:48,165 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,165 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10692ms
2014-07-22 07:08:48,165 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,166 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10703ms
2014-07-22 07:08:48,166 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,177 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10718ms
2014-07-22 07:08:48,177 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,177 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10735ms
2014-07-22 07:08:48,177 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,177 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10553ms
2014-07-22 07:08:48,178 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,178 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9964ms
2014-07-22 07:08:48,178 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:48,200 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11914,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038116285,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:48,406 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12054,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038116352,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:48,489 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12069,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038116419,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:48,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:48,803 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:08:48,807 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37403 synced till here 37393
2014-07-22 07:08:48,890 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038116661 with entries=89, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038128781
2014-07-22 07:08:48,891 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:49,155 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12541,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038116613,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:49,155 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038116687,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:49,669 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038116756,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:50,023 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117395,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,023 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117430,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,049 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:08:50,050 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11914,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038118136,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,061 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117945,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,061 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11988,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038118073,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,061 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117494,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,158 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12341,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117816,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,159 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12537,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117622,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,190 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117686,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,191 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12632,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117558,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,191 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12181,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038118009,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,191 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11979,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038118212,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,196 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12315,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117881,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,216 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038117749,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:08:50,270 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:08:51,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37580 synced till here 37579
2014-07-22 07:08:52,034 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038128781 with entries=177, filesize=137.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038130022
2014-07-22 07:08:52,034 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:53,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:53,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37664 synced till here 37657
2014-07-22 07:08:53,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038130022 with entries=84, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038133458
2014-07-22 07:08:53,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:54,744 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,744 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,758 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,767 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,769 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,773 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,780 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,789 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,820 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,820 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,821 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,837 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,902 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:54,977 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:55,041 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:55,106 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:55,170 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:55,235 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:55,300 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:55,367 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:08:56,274 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17680, memsize=599.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/6363a1b47d2f42b2b4e64450938b7f77
2014-07-22 07:08:56,297 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/6363a1b47d2f42b2b4e64450938b7f77 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/6363a1b47d2f42b2b4e64450938b7f77
2014-07-22 07:08:56,315 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/6363a1b47d2f42b2b4e64450938b7f77, entries=2181920, sequenceid=17680, filesize=155.4m
2014-07-22 07:08:56,315 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~599.3m/628374960, currentsize=132.5m/138974400 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 25672ms, sequenceid=17680, compaction requested=true
2014-07-22 07:08:56,316 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:86), split_queue=0, merge_queue=0
2014-07-22 07:08:56,316 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 949ms
2014-07-22 07:08:56,316 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,316 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1016ms
2014-07-22 07:08:56,317 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 579.5m
2014-07-22 07:08:56,317 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,317 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1082ms
2014-07-22 07:08:56,318 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,318 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1148ms
2014-07-22 07:08:56,318 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,318 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1212ms
2014-07-22 07:08:56,318 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,322 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1281ms
2014-07-22 07:08:56,322 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,322 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1345ms
2014-07-22 07:08:56,322 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,323 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1421ms
2014-07-22 07:08:56,323 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,325 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1488ms
2014-07-22 07:08:56,325 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,327 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1507ms
2014-07-22 07:08:56,327 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,327 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1507ms
2014-07-22 07:08:56,327 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,327 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1507ms
2014-07-22 07:08:56,328 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,328 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1539ms
2014-07-22 07:08:56,328 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,329 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1548ms
2014-07-22 07:08:56,329 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,329 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1556ms
2014-07-22 07:08:56,329 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,337 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1568ms
2014-07-22 07:08:56,337 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,345 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1578ms
2014-07-22 07:08:56,345 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,345 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1587ms
2014-07-22 07:08:56,345 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,346 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1602ms
2014-07-22 07:08:56,346 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,346 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1602ms
2014-07-22 07:08:56,346 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:08:56,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:56,589 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37757 synced till here 37751
2014-07-22 07:08:57,645 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038133458 with entries=93, filesize=73.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038136541
2014-07-22 07:08:57,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:57,791 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:08:58,401 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:58,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37842 synced till here 37833
2014-07-22 07:08:58,542 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038136541 with entries=85, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038138401
2014-07-22 07:08:58,542 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:08:59,857 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:08:59,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37932 synced till here 37924
2014-07-22 07:08:59,923 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038138401 with entries=90, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038139857
2014-07-22 07:08:59,923 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:00,150 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:09:01,471 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:01,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38014 synced till here 38013
2014-07-22 07:09:01,533 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038139857 with entries=82, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038141472
2014-07-22 07:09:01,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:02,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:03,006 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38100 synced till here 38094
2014-07-22 07:09:03,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038141472 with entries=86, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038142980
2014-07-22 07:09:03,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:03,400 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,404 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,408 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,430 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,430 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,442 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,443 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,455 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,458 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,476 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:03,488 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,491 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,519 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,585 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,649 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,718 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,784 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,853 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,920 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:04,985 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:08,400 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:08,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:08,408 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:08,431 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:08,431 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:08,443 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:08,443 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:08,455 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:08,459 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:08,476 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:08,488 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:09,492 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:09,519 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:09,585 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:09,650 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:09,719 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:09,784 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:09,853 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:09,920 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:09,985 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:13,401 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,408 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:09:13,431 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,443 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,444 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10013ms
2014-07-22 07:09:13,444 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:09:13,456 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,459 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,477 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,489 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:13,907 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7431, memsize=595.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/c4852aeac27c4e4bb8c72fa9e52f4519
2014-07-22 07:09:13,919 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/c4852aeac27c4e4bb8c72fa9e52f4519 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/c4852aeac27c4e4bb8c72fa9e52f4519
2014-07-22 07:09:13,926 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/c4852aeac27c4e4bb8c72fa9e52f4519, entries=2169520, sequenceid=7431, filesize=154.5m
2014-07-22 07:09:13,927 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~595.9m/624803680, currentsize=135.3m/141905600 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 25787ms, sequenceid=7431, compaction requested=true
2014-07-22 07:09:13,927 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-22 07:09:13,927 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10439ms
2014-07-22 07:09:13,927 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,927 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10451ms
2014-07-22 07:09:13,927 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 588.5m
2014-07-22 07:09:13,927 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,929 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10471ms
2014-07-22 07:09:13,929 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,929 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10474ms
2014-07-22 07:09:13,929 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,929 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10487ms
2014-07-22 07:09:13,929 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,929 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10499ms
2014-07-22 07:09:13,929 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,942 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10500ms
2014-07-22 07:09:13,942 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,942 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10512ms
2014-07-22 07:09:13,942 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,946 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10538ms
2014-07-22 07:09:13,946 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,946 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10542ms
2014-07-22 07:09:13,946 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,950 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10550ms
2014-07-22 07:09:13,950 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,951 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8966ms
2014-07-22 07:09:13,951 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,957 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9037ms
2014-07-22 07:09:13,957 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,958 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9105ms
2014-07-22 07:09:13,959 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,960 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9176ms
2014-07-22 07:09:13,960 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,960 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9242ms
2014-07-22 07:09:13,960 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,969 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9320ms
2014-07-22 07:09:13,969 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,970 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9385ms
2014-07-22 07:09:13,970 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,971 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9452ms
2014-07-22 07:09:13,971 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,971 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9480ms
2014-07-22 07:09:13,971 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:13,983 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11298,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038142683,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:14,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38182 synced till here 38174
2014-07-22 07:09:14,614 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11730,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038142883,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,633 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11884,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038142749,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,635 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11819,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038142815,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,636 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11684,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038142951,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038142980 with entries=82, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038154565
2014-07-22 07:09:14,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:14,882 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11866,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143015,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,884 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:09:14,968 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11797,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143170,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:14,968 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143081,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:15,387 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143291,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:15,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:15,515 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38271 synced till here 38260
2014-07-22 07:09:16,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038154565 with entries=89, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038155496
2014-07-22 07:09:16,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:16,410 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12928,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143481,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,470 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143390,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,471 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11487,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144983,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,471 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11755,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144716,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,473 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11889,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144583,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,638 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144517,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,638 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11786,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144851,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,657 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144782,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,657 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12010,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144647,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,657 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11740,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038144917,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,697 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13139,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038143558,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:09:16,889 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:16,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38356 synced till here 38354
2014-07-22 07:09:16,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038155496 with entries=85, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038156889
2014-07-22 07:09:16,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:18,106 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:09:18,164 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:18,187 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38436 synced till here 38435
2014-07-22 07:09:18,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038156889 with entries=80, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038158165
2014-07-22 07:09:18,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:19,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:21,041 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,042 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,043 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,046 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,057 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,087 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,087 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,089 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,089 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,089 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,089 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,124 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,136 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,138 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,138 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,138 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,139 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,139 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,198 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,266 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:21,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038158165 with entries=125, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038159930
2014-07-22 07:09:21,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:09:22,225 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7479, memsize=579.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/a1be4c4c0f0a4ed4853cfa9cb9a639f4
2014-07-22 07:09:22,245 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/a1be4c4c0f0a4ed4853cfa9cb9a639f4 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/a1be4c4c0f0a4ed4853cfa9cb9a639f4
2014-07-22 07:09:22,259 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/a1be4c4c0f0a4ed4853cfa9cb9a639f4, entries=2109940, sequenceid=7479, filesize=150.2m
2014-07-22 07:09:22,259 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~579.5m/607647120, currentsize=148.1m/155330240 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 25943ms, sequenceid=7479, compaction requested=true
2014-07-22 07:09:22,259 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:88), split_queue=0, merge_queue=0
2014-07-22 07:09:22,259 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 993ms
2014-07-22 07:09:22,260 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,260 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 312.8m
2014-07-22 07:09:22,260 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1062ms
2014-07-22 07:09:22,260 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,260 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1122ms
2014-07-22 07:09:22,260 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,260 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1122ms
2014-07-22 07:09:22,260 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,260 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1122ms
2014-07-22 07:09:22,260 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,263 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1125ms
2014-07-22 07:09:22,263 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,263 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1125ms
2014-07-22 07:09:22,263 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,263 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1127ms
2014-07-22 07:09:22,263 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,263 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1139ms
2014-07-22 07:09:22,264 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,265 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1176ms
2014-07-22 07:09:22,265 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,270 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1181ms
2014-07-22 07:09:22,270 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,270 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1181ms
2014-07-22 07:09:22,270 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,270 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1181ms
2014-07-22 07:09:22,270 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,270 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1183ms
2014-07-22 07:09:22,270 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,270 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1184ms
2014-07-22 07:09:22,278 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,278 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1221ms
2014-07-22 07:09:22,278 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,278 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1232ms
2014-07-22 07:09:22,278 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,285 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1242ms
2014-07-22 07:09:22,285 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,285 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1243ms
2014-07-22 07:09:22,285 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,286 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1245ms
2014-07-22 07:09:22,286 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:22,631 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:09:23,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:23,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38656 synced till here 38649
2014-07-22 07:09:23,722 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038159930 with entries=95, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038163650
2014-07-22 07:09:25,072 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:25,114 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38744 synced till here 38734
2014-07-22 07:09:25,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038163650 with entries=88, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038165073
2014-07-22 07:09:26,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:26,626 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:09:26,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38828 synced till here 38826
2014-07-22 07:09:26,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038165073 with entries=84, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038166606
2014-07-22 07:09:28,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:28,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38910 synced till here 38907
2014-07-22 07:09:28,587 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038166606 with entries=82, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038168514
2014-07-22 07:09:28,992 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,007 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,009 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,016 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,030 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,030 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,033 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,040 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,058 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,060 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,060 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,129 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,196 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,266 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,332 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,399 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:29,468 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:30,489 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:30,518 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:30,583 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:33,992 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,008 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:34,009 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,016 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,030 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,031 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,033 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,040 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,059 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:34,060 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,060 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,130 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:34,197 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,267 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,332 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:34,399 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:34,468 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:35,489 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:35,519 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:35,583 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:35,764 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7529, memsize=312.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/136169bfe7584369995b27eb008fc307
2014-07-22 07:09:35,776 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/136169bfe7584369995b27eb008fc307 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/136169bfe7584369995b27eb008fc307
2014-07-22 07:09:35,785 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/136169bfe7584369995b27eb008fc307, entries=1139040, sequenceid=7529, filesize=81.1m
2014-07-22 07:09:35,786 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~312.8m/328014560, currentsize=23.1m/24181440 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 13526ms, sequenceid=7529, compaction requested=true
2014-07-22 07:09:35,786 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:89), split_queue=0, merge_queue=0
2014-07-22 07:09:35,786 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5204ms
2014-07-22 07:09:35,786 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,786 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5268ms
2014-07-22 07:09:35,786 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 649.4m
2014-07-22 07:09:35,786 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,788 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5300ms
2014-07-22 07:09:35,788 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,790 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6322ms
2014-07-22 07:09:35,790 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,793 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6395ms
2014-07-22 07:09:35,793 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,793 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6461ms
2014-07-22 07:09:35,793 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,793 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6527ms
2014-07-22 07:09:35,794 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,794 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6598ms
2014-07-22 07:09:35,794 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,794 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6665ms
2014-07-22 07:09:35,794 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,798 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6738ms
2014-07-22 07:09:35,798 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,798 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6738ms
2014-07-22 07:09:35,798 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,806 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6748ms
2014-07-22 07:09:35,806 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,807 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6767ms
2014-07-22 07:09:35,807 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,807 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6774ms
2014-07-22 07:09:35,807 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,809 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6779ms
2014-07-22 07:09:35,809 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,813 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6783ms
2014-07-22 07:09:35,813 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,814 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6798ms
2014-07-22 07:09:35,814 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,814 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6805ms
2014-07-22 07:09:35,814 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,815 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6808ms
2014-07-22 07:09:35,815 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:35,815 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6823ms
2014-07-22 07:09:35,815 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.54 MB, free=3.95 GB, max=3.96 GB, blocks=6, accesses=600422, hits=56900, hitRatio=9.47%, , cachingAccesses=56922, cachingHits=56881, cachingHitsRatio=99.92%, evictions=0, evicted=35, evictedPerRun=Infinity
2014-07-22 07:09:36,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:36,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38996 synced till here 38985
2014-07-22 07:09:36,335 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038168514 with entries=86, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038176213
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037967887
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037981105
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037983312
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037984518
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037985838
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037986591
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037988071
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037989348
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037990610
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037992201
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037996721
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037998185
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406037999587
2014-07-22 07:09:36,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038010151
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038012304
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038013875
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038021767
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038022781
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038024300
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038025635
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038027023
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038028712
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038035381
2014-07-22 07:09:36,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038036866
2014-07-22 07:09:36,594 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:09:37,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:37,807 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39086 synced till here 39075
2014-07-22 07:09:37,895 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038176213 with entries=90, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038177782
2014-07-22 07:09:38,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:38,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39175 synced till here 39166
2014-07-22 07:09:38,587 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:38,592 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:38,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038177782 with entries=89, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038178509
2014-07-22 07:09:38,609 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,372 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,383 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,384 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,395 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,396 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,396 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,402 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,466 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,533 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,599 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,664 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,729 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,794 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,859 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,929 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:39,989 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:40,075 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:40,805 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7521, memsize=588.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3f590abb89604d5ebe621551db9a2629
2014-07-22 07:09:40,825 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/3f590abb89604d5ebe621551db9a2629 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3f590abb89604d5ebe621551db9a2629
2014-07-22 07:09:40,838 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/3f590abb89604d5ebe621551db9a2629, entries=2142670, sequenceid=7521, filesize=152.5m
2014-07-22 07:09:40,838 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~588.5m/617071680, currentsize=179.1m/187833600 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 26911ms, sequenceid=7521, compaction requested=true
2014-07-22 07:09:40,839 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:90), split_queue=0, merge_queue=0
2014-07-22 07:09:40,839 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 764ms
2014-07-22 07:09:40,839 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,839 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 615.3m
2014-07-22 07:09:40,839 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 850ms
2014-07-22 07:09:40,839 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,840 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 910ms
2014-07-22 07:09:40,840 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,841 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 982ms
2014-07-22 07:09:40,841 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,842 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1047ms
2014-07-22 07:09:40,842 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,846 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1116ms
2014-07-22 07:09:40,846 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,846 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1182ms
2014-07-22 07:09:40,846 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,846 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1247ms
2014-07-22 07:09:40,846 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,847 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1314ms
2014-07-22 07:09:40,847 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,848 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1382ms
2014-07-22 07:09:40,848 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,853 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1450ms
2014-07-22 07:09:40,853 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,853 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1457ms
2014-07-22 07:09:40,854 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,854 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1459ms
2014-07-22 07:09:40,854 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,854 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1459ms
2014-07-22 07:09:40,854 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,854 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1470ms
2014-07-22 07:09:40,854 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,855 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1471ms
2014-07-22 07:09:40,855 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,855 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1483ms
2014-07-22 07:09:40,855 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,856 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2247ms
2014-07-22 07:09:40,856 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,856 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2264ms
2014-07-22 07:09:40,856 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:40,856 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2269ms
2014-07-22 07:09:40,856 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:09:41,416 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:09:41,429 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:09:42,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:42,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39268 synced till here 39258
2014-07-22 07:09:42,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038178509 with entries=93, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038182570
2014-07-22 07:09:42,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038038445
2014-07-22 07:09:42,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038049631
2014-07-22 07:09:42,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038051031
2014-07-22 07:09:42,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038052449
2014-07-22 07:09:42,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038053087
2014-07-22 07:09:42,668 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038054620
2014-07-22 07:09:43,951 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:44,326 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39391 synced till here 39386
2014-07-22 07:09:44,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038182570 with entries=123, filesize=95.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038183952
2014-07-22 07:09:45,592 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:45,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39474 synced till here 39470
2014-07-22 07:09:45,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038183952 with entries=83, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038185593
2014-07-22 07:09:46,926 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:09:46,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39556 synced till here 39551
2014-07-22 07:09:46,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038185593 with entries=82, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038186927
2014-07-22 07:09:47,279 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,280 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,294 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,310 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,338 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,341 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,341 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,350 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,351 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,361 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,440 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,523 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,605 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,676 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,756 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,828 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:47,895 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:48,760 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:48,818 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:48,879 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:09:52,279 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,280 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,294 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,311 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,338 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,341 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,341 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,351 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:52,351 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:52,362 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:52,441 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:52,523 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,605 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,677 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,757 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:52,829 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:52,896 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:53,760 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:09:53,818 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:53,879 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:09:57,280 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,281 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,295 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:09:57,311 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,339 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:09:57,342 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,342 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,351 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,352 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:09:57,362 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,441 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,524 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:09:57,606 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,677 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,758 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:09:57,829 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:57,896 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:58,761 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:09:58,819 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:09:58,880 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:01,735 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17951, memsize=649.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/a113218491ea42e2920d50d52aaa75c2
2014-07-22 07:10:01,744 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/a113218491ea42e2920d50d52aaa75c2 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/a113218491ea42e2920d50d52aaa75c2
2014-07-22 07:10:01,761 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/a113218491ea42e2920d50d52aaa75c2, entries=2364620, sequenceid=17951, filesize=168.4m
2014-07-22 07:10:01,761 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~649.4m/680991840, currentsize=107.7m/112930240 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 25975ms, sequenceid=17951, compaction requested=true
2014-07-22 07:10:01,761 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:91), split_queue=0, merge_queue=0
2014-07-22 07:10:01,761 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12882ms
2014-07-22 07:10:01,762 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,762 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12944ms
2014-07-22 07:10:01,762 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 612.3m
2014-07-22 07:10:01,762 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,765 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13006ms
2014-07-22 07:10:01,765 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,766 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13871ms
2014-07-22 07:10:01,767 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,767 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13939ms
2014-07-22 07:10:01,767 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,769 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14011ms
2014-07-22 07:10:01,769 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,774 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14098ms
2014-07-22 07:10:01,774 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,776 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14171ms
2014-07-22 07:10:01,776 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,782 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14259ms
2014-07-22 07:10:01,782 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,782 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14342ms
2014-07-22 07:10:01,782 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,782 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14421ms
2014-07-22 07:10:01,783 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,783 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14433ms
2014-07-22 07:10:01,783 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,783 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14433ms
2014-07-22 07:10:01,783 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,790 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14448ms
2014-07-22 07:10:01,790 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,790 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14449ms
2014-07-22 07:10:01,791 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,791 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14453ms
2014-07-22 07:10:01,791 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,793 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14483ms
2014-07-22 07:10:01,793 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,793 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14499ms
2014-07-22 07:10:01,793 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,801 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14521ms
2014-07-22 07:10:01,801 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,802 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14523ms
2014-07-22 07:10:01,802 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:01,838 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15843,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038185995,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:02,116 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038186728,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:02,116 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038186068,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:02,247 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:02,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39640 synced till here 39634
2014-07-22 07:10:02,315 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15515,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038186800,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:02,326 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038186927 with entries=84, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038202247
2014-07-22 07:10:02,326 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038055966
2014-07-22 07:10:02,326 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038061484
2014-07-22 07:10:02,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038062945
2014-07-22 07:10:02,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038064470
2014-07-22 07:10:02,406 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:02,514 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:10:02,515 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15636,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038186878,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,354 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16379,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038186974,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,402 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187150,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:03,652 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16586,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187066,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,687 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39726 synced till here 39714
2014-07-22 07:10:03,743 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16490,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187252,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038202247 with entries=86, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038203651
2014-07-22 07:10:03,890 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15012,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038188877,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,950 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15192,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038188757,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,950 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15133,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038188816,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,987 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187600,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,988 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16162,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187825,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,988 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187892,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:03,989 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16237,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187751,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:04,052 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16533,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187518,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:04,074 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16635,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187438,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:04,076 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16725,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187351,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:04,077 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038187672,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:04,867 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17948, memsize=615.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/b22b47f14e2d434e9ed6acf9dd1f752a
2014-07-22 07:10:04,878 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/b22b47f14e2d434e9ed6acf9dd1f752a as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/b22b47f14e2d434e9ed6acf9dd1f752a
2014-07-22 07:10:04,889 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/b22b47f14e2d434e9ed6acf9dd1f752a, entries=2240290, sequenceid=17948, filesize=159.5m
2014-07-22 07:10:04,889 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~615.3m/645185760, currentsize=105.7m/110787040 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 24050ms, sequenceid=17948, compaction requested=true
2014-07-22 07:10:04,890 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-22 07:10:04,890 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 571.4m
2014-07-22 07:10:04,976 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:05,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39813 synced till here 39809
2014-07-22 07:10:05,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038203651 with entries=87, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038204977
2014-07-22 07:10:05,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038066117
2014-07-22 07:10:05,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038077176
2014-07-22 07:10:05,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038078203
2014-07-22 07:10:05,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038079547
2014-07-22 07:10:05,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038080984
2014-07-22 07:10:05,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038082242
2014-07-22 07:10:05,421 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:06,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:06,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39897 synced till here 39895
2014-07-22 07:10:06,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038204977 with entries=84, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038206359
2014-07-22 07:10:07,846 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:07,877 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39979 synced till here 39975
2014-07-22 07:10:07,936 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038206359 with entries=82, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038207846
2014-07-22 07:10:09,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:09,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40063 synced till here 40055
2014-07-22 07:10:09,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038207846 with entries=84, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038209566
2014-07-22 07:10:10,448 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:10,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40147 synced till here 40144
2014-07-22 07:10:10,504 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038209566 with entries=84, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038210449
2014-07-22 07:10:11,956 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:11,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40230 synced till here 40226
2014-07-22 07:10:12,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038210449 with entries=83, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038211956
2014-07-22 07:10:13,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:13,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038211956 with entries=93, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038213555
2014-07-22 07:10:14,893 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/fb4a34b01b024d61a28ac7027cca9b57 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/fb4a34b01b024d61a28ac7027cca9b57
2014-07-22 07:10:14,911 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:10:14,923 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1ccf96deb35543c89ec1126161482090, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1ccf96deb35543c89ec1126161482090
2014-07-22 07:10:14,928 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2cbf12193f5c4838b70abc15e3898b93, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2cbf12193f5c4838b70abc15e3898b93
2014-07-22 07:10:14,933 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2dfe2a2d51d94ff5add86d31be6189c2, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/2dfe2a2d51d94ff5add86d31be6189c2
2014-07-22 07:10:14,936 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/077e5755c8f94dc9b4a12c45631ae2c2, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/077e5755c8f94dc9b4a12c45631ae2c2
2014-07-22 07:10:14,939 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9fe5afb63e0f43b5869664493d458e0e, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9fe5afb63e0f43b5869664493d458e0e
2014-07-22 07:10:14,942 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/3822aef797904b07810b83fa4e5ac184, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/3822aef797904b07810b83fa4e5ac184
2014-07-22 07:10:14,944 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/252894c5615148b08bbda7e8aa013252, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/252894c5615148b08bbda7e8aa013252
2014-07-22 07:10:14,954 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d60504373db54f91b4042bd422989b4d, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d60504373db54f91b4042bd422989b4d
2014-07-22 07:10:14,957 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/352c16c0101e4bfca0cac63529ca766e, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/352c16c0101e4bfca0cac63529ca766e
2014-07-22 07:10:14,959 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1541ef227b7243e2a4844f3f6bef50a3, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1541ef227b7243e2a4844f3f6bef50a3
2014-07-22 07:10:14,959 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. into fb4a34b01b024d61a28ac7027cca9b57(size=440.6m), total size for store is 3.1g. This selection was in queue for 0sec, and took 1mins, 32sec to execute.
2014-07-22 07:10:14,960 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., storeName=family, fileCount=10, fileSize=501.3m, priority=1976, time=135102739022711; duration=1mins, 32sec
2014-07-22 07:10:14,960 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-22 07:10:14,960 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 2000 blocking
2014-07-22 07:10:14,962 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 613165955 starting at candidate #8 after considering 132 permutations with 110 in ratio
2014-07-22 07:10:14,962 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 9adf623b44aef5d1cfacd411890c83ff - family: Initiating minor compaction
2014-07-22 07:10:14,962 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:10:14,962 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp, totalSize=584.8m
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3ded22a8b3574acf85003be3b5e3c767, keycount=136882, bloomtype=ROW, size=97.5m, encoding=NONE, seqNum=13199
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/231b035db5ea4bf4a4f4e382b73f31b7, keycount=72367, bloomtype=ROW, size=51.6m, encoding=NONE, seqNum=13672
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/25ef051314c74699bf182002b5ec1eef, keycount=131332, bloomtype=ROW, size=93.6m, encoding=NONE, seqNum=14110
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f8cd59fb153e4713ad2c54c1f8db2616, keycount=82363, bloomtype=ROW, size=58.7m, encoding=NONE, seqNum=14511
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b9b84c76d58e4d9eb1cd5bd7b2c036cd, keycount=70426, bloomtype=ROW, size=50.2m, encoding=NONE, seqNum=14887
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cd7b03321d144b37829902818676e6e3, keycount=103649, bloomtype=ROW, size=73.8m, encoding=NONE, seqNum=15273
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e4ba8a8e417c4397afa7cb4137ffcc62, keycount=87623, bloomtype=ROW, size=62.5m, encoding=NONE, seqNum=15688
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/a86bfe980bc64065847f825de646ab56, keycount=55349, bloomtype=ROW, size=39.5m, encoding=NONE, seqNum=15853
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/00e2ebcc50414b47b91e734d9d17e9a3, keycount=47742, bloomtype=ROW, size=34.0m, encoding=NONE, seqNum=16017
2014-07-22 07:10:14,963 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3f72caef6c0e4a2daadc0cd2fa6d4da6, keycount=32822, bloomtype=ROW, size=23.4m, encoding=NONE, seqNum=16175
2014-07-22 07:10:15,121 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:15,417 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:16,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40425 synced till here 40422
2014-07-22 07:10:16,490 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038213555 with entries=102, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038215417
2014-07-22 07:10:16,672 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:10:16,889 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,890 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,895 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,943 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,944 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,944 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,944 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,944 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,944 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,945 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,956 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,957 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:16,957 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,019 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,082 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,146 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,208 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,272 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,335 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:17,398 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:21,889 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,890 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:21,896 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,943 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:21,944 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:21,945 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,945 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,945 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,945 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,945 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,957 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:21,957 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:21,958 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:22,019 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:22,082 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:22,146 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:22,209 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:22,272 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:22,336 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:22,398 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:26,889 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,891 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,896 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,943 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:26,945 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,945 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,945 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,946 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,946 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:10:26,947 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-22 07:10:26,957 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:26,957 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:26,958 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:27,019 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:27,083 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:27,146 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:27,209 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:27,273 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:27,336 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:27,399 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:28,869 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17986, memsize=612.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/dd9ccb00f0604722bc4c1d1f6ec81ba1
2014-07-22 07:10:28,880 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/dd9ccb00f0604722bc4c1d1f6ec81ba1 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/dd9ccb00f0604722bc4c1d1f6ec81ba1
2014-07-22 07:10:28,888 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/dd9ccb00f0604722bc4c1d1f6ec81ba1, entries=2229430, sequenceid=17986, filesize=158.8m
2014-07-22 07:10:28,888 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~612.3m/642058160, currentsize=153.9m/161336880 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 27126ms, sequenceid=17986, compaction requested=true
2014-07-22 07:10:28,889 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-22 07:10:28,889 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11491ms
2014-07-22 07:10:28,889 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,889 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11554ms
2014-07-22 07:10:28,889 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 606.4m
2014-07-22 07:10:28,889 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,889 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11617ms
2014-07-22 07:10:28,890 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,893 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11685ms
2014-07-22 07:10:28,893 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,893 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11748ms
2014-07-22 07:10:28,893 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,894 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11812ms
2014-07-22 07:10:28,894 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,894 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11875ms
2014-07-22 07:10:28,894 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,895 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11938ms
2014-07-22 07:10:28,895 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,895 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11938ms
2014-07-22 07:10:28,895 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,897 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11941ms
2014-07-22 07:10:28,897 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,898 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11953ms
2014-07-22 07:10:28,898 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,898 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11954ms
2014-07-22 07:10:28,898 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,898 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11954ms
2014-07-22 07:10:28,898 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,898 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11954ms
2014-07-22 07:10:28,898 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,901 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11957ms
2014-07-22 07:10:28,901 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,921 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11977ms
2014-07-22 07:10:28,922 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,933 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11990ms
2014-07-22 07:10:28,933 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,933 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12038ms
2014-07-22 07:10:28,933 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,934 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12044ms
2014-07-22 07:10:28,934 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,941 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12053ms
2014-07-22 07:10:28,941 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:28,973 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13662,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038215310,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,043 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13644,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038215398,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,043 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13556,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038215486,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40506 synced till here 40500
2014-07-22 07:10:29,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038215417 with entries=81, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038229174
2014-07-22 07:10:29,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038083672
2014-07-22 07:10:29,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038087228
2014-07-22 07:10:29,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038088594
2014-07-22 07:10:29,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038089954
2014-07-22 07:10:29,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038091399
2014-07-22 07:10:29,586 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14014,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038215571,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,586 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13921,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038215664,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,618 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18001, memsize=574.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/86c9834ec0d248c28fcf681243c4679b
2014-07-22 07:10:29,629 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/86c9834ec0d248c28fcf681243c4679b as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/86c9834ec0d248c28fcf681243c4679b
2014-07-22 07:10:29,637 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/86c9834ec0d248c28fcf681243c4679b, entries=2091340, sequenceid=18001, filesize=149.0m
2014-07-22 07:10:29,638 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~574.4m/602288640, currentsize=119.8m/125648080 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 24748ms, sequenceid=18001, compaction requested=true
2014-07-22 07:10:29,638 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-22 07:10:29,638 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 545.9m
2014-07-22 07:10:29,722 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216531,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,756 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:29,787 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216468,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,787 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13191,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216595,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,932 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13271,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216660,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:29,994 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13240,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216753,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:30,167 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:30,186 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13359,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216826,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:30,260 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:30,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40598 synced till here 40588
2014-07-22 07:10:30,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038229174 with entries=92, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038230261
2014-07-22 07:10:30,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038093181
2014-07-22 07:10:30,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038104847
2014-07-22 07:10:30,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038106089
2014-07-22 07:10:30,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038107382
2014-07-22 07:10:30,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038108783
2014-07-22 07:10:31,411 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14077,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217333,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,411 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14456,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216954,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,412 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217016,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,461 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:10:31,463 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14067,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217396,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,463 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217080,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,479 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14273,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217206,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,479 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217143,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,492 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14222,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038217270,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,501 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038216893,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:31,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:31,586 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40683 synced till here 40679
2014-07-22 07:10:31,629 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038230261 with entries=85, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038231566
2014-07-22 07:10:32,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:32,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40766 synced till here 40763
2014-07-22 07:10:32,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038231566 with entries=83, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038232902
2014-07-22 07:10:34,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:34,260 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40849 synced till here 40846
2014-07-22 07:10:34,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038232902 with entries=83, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038234242
2014-07-22 07:10:35,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:35,749 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40929 synced till here 40925
2014-07-22 07:10:35,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038234242 with entries=80, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038235733
2014-07-22 07:10:38,065 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:38,092 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41020 synced till here 41011
2014-07-22 07:10:38,158 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038235733 with entries=91, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038238065
2014-07-22 07:10:39,640 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:10:39,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:39,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41111 synced till here 41096
2014-07-22 07:10:40,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038238065 with entries=91, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038239919
2014-07-22 07:10:41,314 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:41,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41196 synced till here 41193
2014-07-22 07:10:41,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038239919 with entries=85, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038241314
2014-07-22 07:10:42,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:43,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41282 synced till here 41275
2014-07-22 07:10:43,116 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038241314 with entries=86, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038242993
2014-07-22 07:10:43,282 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,282 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,284 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,289 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,311 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,361 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:10:43,364 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,368 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,369 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,370 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,371 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,372 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,376 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,398 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,414 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,671 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,778 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,869 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:43,951 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:44,034 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:44,126 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:10:48,282 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:48,282 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,284 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,289 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,311 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,365 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:48,368 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,369 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,370 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,372 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,372 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:48,376 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:48,398 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,415 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,672 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:48,779 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:48,869 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:10:48,952 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:49,035 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:49,127 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:10:53,282 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,283 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,285 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:53,290 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,311 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:53,365 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,369 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,370 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:53,371 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:53,373 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:53,373 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:10:53,376 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,398 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:10:53,415 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,672 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,779 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,870 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:53,952 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:54,035 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:54,127 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:10:54,514 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7784, memsize=547.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b24aabdd490b494eabc79a5f408184b6
2014-07-22 07:10:54,527 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b24aabdd490b494eabc79a5f408184b6 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b24aabdd490b494eabc79a5f408184b6
2014-07-22 07:10:54,535 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b24aabdd490b494eabc79a5f408184b6, entries=1993260, sequenceid=7784, filesize=142.0m
2014-07-22 07:10:54,535 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~547.5m/574043440, currentsize=134.7m/141295280 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 24897ms, sequenceid=7784, compaction requested=true
2014-07-22 07:10:54,536 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:94), split_queue=0, merge_queue=0
2014-07-22 07:10:54,536 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10410ms
2014-07-22 07:10:54,536 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,536 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10502ms
2014-07-22 07:10:54,536 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 622.6m
2014-07-22 07:10:54,536 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,536 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10585ms
2014-07-22 07:10:54,536 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,536 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10667ms
2014-07-22 07:10:54,536 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,537 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10759ms
2014-07-22 07:10:54,537 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,537 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10866ms
2014-07-22 07:10:54,537 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,537 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11123ms
2014-07-22 07:10:54,537 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,549 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11151ms
2014-07-22 07:10:54,549 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,555 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11180ms
2014-07-22 07:10:54,555 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,557 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11186ms
2014-07-22 07:10:54,558 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,558 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11186ms
2014-07-22 07:10:54,558 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,569 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11199ms
2014-07-22 07:10:54,569 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,569 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11200ms
2014-07-22 07:10:54,570 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,570 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11202ms
2014-07-22 07:10:54,570 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,570 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11206ms
2014-07-22 07:10:54,570 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,577 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11266ms
2014-07-22 07:10:54,577 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,585 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11296ms
2014-07-22 07:10:54,585 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,585 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11301ms
2014-07-22 07:10:54,586 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,586 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11304ms
2014-07-22 07:10:54,586 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,588 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11307ms
2014-07-22 07:10:54,634 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:10:54,639 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13122,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038241516,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:54,789 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038241598,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:54,948 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13279,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038241668,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:55,285 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:55,287 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:55,790 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14051,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038241738,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:55,795 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41378 synced till here 41367
2014-07-22 07:10:55,887 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038242993 with entries=96, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038255288
2014-07-22 07:10:55,955 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038241896,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:55,956 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038242831,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,187 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13324,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038242863,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,188 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038241812,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,315 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13272,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243042,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,548 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13586,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038242961,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,674 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18072, memsize=606.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/da7c8b299fdb44cea66b202f1891aa75
2014-07-22 07:10:56,694 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/da7c8b299fdb44cea66b202f1891aa75 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/da7c8b299fdb44cea66b202f1891aa75
2014-07-22 07:10:56,717 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/da7c8b299fdb44cea66b202f1891aa75, entries=2207890, sequenceid=18072, filesize=157.2m
2014-07-22 07:10:56,718 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~606.4m/635854480, currentsize=163.1m/170978320 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 27828ms, sequenceid=18072, compaction requested=true
2014-07-22 07:10:56,718 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:95), split_queue=0, merge_queue=0
2014-07-22 07:10:56,718 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 573.5m
2014-07-22 07:10:56,758 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:56,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41473 synced till here 41458
2014-07-22 07:10:56,880 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12762,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038244117,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,881 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13679,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243200,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,880 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243117,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:56,888 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13480,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243407,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:57,558 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038255288 with entries=95, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038256759
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038110243
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038111686
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038113132
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038114691
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038115354
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038116661
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038128781
2014-07-22 07:10:57,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038130022
2014-07-22 07:10:57,578 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13547,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038244031,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:57,578 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13632,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243946,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:57,611 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13749,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243861,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:57,611 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14302,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243308,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:57,672 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243771,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:57,672 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038243667,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:10:58,042 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:10:58,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:58,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41559 synced till here 41552
2014-07-22 07:10:58,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038256759 with entries=86, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038258177
2014-07-22 07:10:59,677 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:10:59,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41641 synced till here 41638
2014-07-22 07:10:59,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038258177 with entries=82, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038259678
2014-07-22 07:11:01,245 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:01,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41721 synced till here 41720
2014-07-22 07:11:01,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038259678 with entries=80, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038261246
2014-07-22 07:11:02,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:02,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41803 synced till here 41799
2014-07-22 07:11:02,795 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038261246 with entries=82, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038262752
2014-07-22 07:11:04,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:04,350 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41886 synced till here 41879
2014-07-22 07:11:04,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038262752 with entries=83, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038264325
2014-07-22 07:11:06,074 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:06,093 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41974 synced till here 41963
2014-07-22 07:11:06,135 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:11:06,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038264325 with entries=88, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038266075
2014-07-22 07:11:06,468 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:11:07,644 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:07,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42065 synced till here 42058
2014-07-22 07:11:07,733 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038266075 with entries=91, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038267645
2014-07-22 07:11:08,022 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,029 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,029 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,032 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,037 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,056 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,058 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,072 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,075 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,078 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,088 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,090 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,090 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,108 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,171 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:08,989 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:09,025 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:09,087 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:09,151 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:09,216 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:13,023 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:13,029 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,030 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,033 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,037 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,057 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,058 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,073 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:13,075 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,078 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,088 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,090 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,090 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,109 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:13,171 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:14,149 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5062ms
2014-07-22 07:11:14,149 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5161ms
2014-07-22 07:11:14,149 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5124ms
2014-07-22 07:11:14,151 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:14,216 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:18,023 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,029 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:11:18,030 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,033 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,038 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,057 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,059 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,073 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,076 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,078 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:11:18,088 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:11:18,090 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:11:18,091 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:11:18,109 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:18,172 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:19,149 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10062ms
2014-07-22 07:11:19,149 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10161ms
2014-07-22 07:11:19,150 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10125ms
2014-07-22 07:11:19,152 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:11:19,216 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:11:21,528 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7892, memsize=575.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f47fec479356476f86da19c6c451a1fd
2014-07-22 07:11:21,540 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/f47fec479356476f86da19c6c451a1fd as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f47fec479356476f86da19c6c451a1fd
2014-07-22 07:11:22,527 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7880, memsize=622.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/dd1738c0248d43afba8e4cc8c5e1901e
2014-07-22 07:11:22,538 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/dd1738c0248d43afba8e4cc8c5e1901e as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/dd1738c0248d43afba8e4cc8c5e1901e
2014-07-22 07:11:22,601 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/f47fec479356476f86da19c6c451a1fd, entries=2093690, sequenceid=7892, filesize=149.1m
2014-07-22 07:11:22,601 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~575.0m/602964640, currentsize=107.0m/112207840 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 25883ms, sequenceid=7892, compaction requested=true
2014-07-22 07:11:22,602 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:96), split_queue=0, merge_queue=0
2014-07-22 07:11:22,602 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13386ms
2014-07-22 07:11:22,602 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,602 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 544.9m
2014-07-22 07:11:22,602 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13451ms
2014-07-22 07:11:22,602 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,602 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13577ms
2014-07-22 07:11:22,603 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,603 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13615ms
2014-07-22 07:11:22,603 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,605 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13518ms
2014-07-22 07:11:22,605 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,609 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14436ms
2014-07-22 07:11:22,609 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,609 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14501ms
2014-07-22 07:11:22,609 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,610 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14520ms
2014-07-22 07:11:22,611 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,611 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14521ms
2014-07-22 07:11:22,611 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,611 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14523ms
2014-07-22 07:11:22,611 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,611 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14533ms
2014-07-22 07:11:22,611 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,611 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14536ms
2014-07-22 07:11:22,611 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,614 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14542ms
2014-07-22 07:11:22,615 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,625 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14567ms
2014-07-22 07:11:22,625 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,629 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14573ms
2014-07-22 07:11:22,629 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,630 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14592ms
2014-07-22 07:11:22,630 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,630 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14598ms
2014-07-22 07:11:22,630 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,631 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14602ms
2014-07-22 07:11:22,631 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,633 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14604ms
2014-07-22 07:11:22,634 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,637 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14615ms
2014-07-22 07:11:22,637 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:22,658 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/dd1738c0248d43afba8e4cc8c5e1901e, entries=2266820, sequenceid=7880, filesize=161.4m
2014-07-22 07:11:22,662 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~622.6m/652825840, currentsize=138.0m/144750080 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 28125ms, sequenceid=7880, compaction requested=true
2014-07-22 07:11:22,662 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:97), split_queue=0, merge_queue=0
2014-07-22 07:11:22,662 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 507.2m
2014-07-22 07:11:22,671 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038266080,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:22,710 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16553,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038266156,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:22,977 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:22,980 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16653,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038266326,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:22,984 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16742,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038266242,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:23,005 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42151 synced till here 42144
2014-07-22 07:11:23,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038267645 with entries=86, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038282978
2014-07-22 07:11:23,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038133458
2014-07-22 07:11:23,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038136541
2014-07-22 07:11:23,059 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038138401
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038139857
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038141472
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038142980
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038154565
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038155496
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038156889
2014-07-22 07:11:23,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038158165
2014-07-22 07:11:23,117 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:23,207 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:11:23,288 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:11:23,326 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16013,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267312,"queuetimems":14,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:23,326 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16074,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267251,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:23,937 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16433,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267503,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,144 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16461,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267682,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,146 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267597,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,146 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16735,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267410,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,179 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:24,180 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16365,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267815,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42238 synced till here 42229
2014-07-22 07:11:24,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038282978 with entries=87, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038284180
2014-07-22 07:11:24,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:24,471 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267996,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,471 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16564,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038267907,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,593 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15444,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038269148,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,594 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15508,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038269085,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,596 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16429,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038268166,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,593 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15378,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038269214,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,593 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16508,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038268084,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,630 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038268986,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:24,630 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15606,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038269023,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:25,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:25,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42324 synced till here 42321
2014-07-22 07:11:25,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038284180 with entries=86, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038285631
2014-07-22 07:11:25,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:26,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:26,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42404 synced till here 42403
2014-07-22 07:11:26,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038285631 with entries=80, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038286842
2014-07-22 07:11:26,871 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:27,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:27,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42483 synced till here 42481
2014-07-22 07:11:28,309 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038286842 with entries=79, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038287495
2014-07-22 07:11:28,310 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:29,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:29,185 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42566 synced till here 42564
2014-07-22 07:11:29,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038287495 with entries=83, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038289151
2014-07-22 07:11:29,229 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:30,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:30,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42645 synced till here 42644
2014-07-22 07:11:30,749 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038289151 with entries=79, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038290715
2014-07-22 07:11:30,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:32,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:32,225 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42729 synced till here 42725
2014-07-22 07:11:32,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038290715 with entries=84, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038292205
2014-07-22 07:11:32,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:33,876 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:33,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42808 synced till here 42807
2014-07-22 07:11:33,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038292205 with entries=79, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038293876
2014-07-22 07:11:33,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:34,017 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:11:35,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:35,578 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42893 synced till here 42886
2014-07-22 07:11:35,635 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038293876 with entries=85, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038295566
2014-07-22 07:11:35,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:35,974 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:35,975 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:35,976 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:35,976 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:35,985 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:35,989 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,002 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,007 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,016 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,808 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,835 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,896 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:36,960 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,025 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,087 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,152 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,215 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,278 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,342 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:37,406 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:40,974 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:40,976 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:40,976 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:40,976 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:40,985 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:40,990 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:41,003 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:41,380 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:41,381 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5364ms
2014-07-22 07:11:41,808 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:41,836 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:41,897 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:41,961 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:42,025 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:42,088 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:42,153 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:42,215 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:42,279 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:42,342 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:11:42,406 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:11:45,456 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18277, memsize=508.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/9c0d57649b1c4fc79e78e2edb66b1033
2014-07-22 07:11:45,465 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/9c0d57649b1c4fc79e78e2edb66b1033 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9c0d57649b1c4fc79e78e2edb66b1033
2014-07-22 07:11:45,472 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9c0d57649b1c4fc79e78e2edb66b1033, entries=1852500, sequenceid=18277, filesize=131.9m
2014-07-22 07:11:45,473 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~508.8m/533504240, currentsize=139.4m/146144240 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 22811ms, sequenceid=18277, compaction requested=true
2014-07-22 07:11:45,473 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:98), split_queue=0, merge_queue=0
2014-07-22 07:11:45,473 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8067ms
2014-07-22 07:11:45,474 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,474 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 579.2m
2014-07-22 07:11:45,474 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8133ms
2014-07-22 07:11:45,474 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,474 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8196ms
2014-07-22 07:11:45,474 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,474 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8259ms
2014-07-22 07:11:45,474 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,477 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8325ms
2014-07-22 07:11:45,477 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,479 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8392ms
2014-07-22 07:11:45,480 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,485 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8460ms
2014-07-22 07:11:45,486 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,486 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8526ms
2014-07-22 07:11:45,486 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,486 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8590ms
2014-07-22 07:11:45,486 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,487 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8651ms
2014-07-22 07:11:45,487 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,487 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8679ms
2014-07-22 07:11:45,487 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,488 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9472ms
2014-07-22 07:11:45,488 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,489 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9482ms
2014-07-22 07:11:45,489 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,490 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9488ms
2014-07-22 07:11:45,490 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,491 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9502ms
2014-07-22 07:11:45,491 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,492 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9507ms
2014-07-22 07:11:45,492 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,496 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9520ms
2014-07-22 07:11:45,496 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,497 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9521ms
2014-07-22 07:11:45,497 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,505 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9530ms
2014-07-22 07:11:45,505 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,506 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9531ms
2014-07-22 07:11:45,506 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:11:45,550 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10306,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295243,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:46,062 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10722,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295339,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,066 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10657,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295408,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42984 synced till here 42975
2014-07-22 07:11:46,107 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:11:46,134 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038295566 with entries=91, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038306058
2014-07-22 07:11:46,134 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:46,138 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10653,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295485,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,178 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:11:46,537 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295700,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,537 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10922,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295614,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,584 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11032,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295551,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,728 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295891,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:46,825 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18303, memsize=544.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/a7fad8c7ffb845a6a81878e878241ef0
2014-07-22 07:11:46,836 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/a7fad8c7ffb845a6a81878e878241ef0 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/a7fad8c7ffb845a6a81878e878241ef0
2014-07-22 07:11:46,838 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:46,863 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/a7fad8c7ffb845a6a81878e878241ef0, entries=1983890, sequenceid=18303, filesize=141.3m
2014-07-22 07:11:46,863 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~544.9m/571345120, currentsize=165.2m/173221440 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 24261ms, sequenceid=18303, compaction requested=true
2014-07-22 07:11:46,864 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-22 07:11:46,864 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 566.2m
2014-07-22 07:11:46,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43074 synced till here 43064
2014-07-22 07:11:46,912 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10953,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038295959,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,494 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038306058 with entries=90, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038306839
2014-07-22 07:11:47,494 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:47,660 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038296806,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,660 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10701,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038296958,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,690 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10476,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038297213,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,698 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10358,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038297339,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,745 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10721,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038297023,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,849 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10953,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038296895,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,849 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11015,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038296833,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,850 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10573,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038297276,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,850 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10765,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038297085,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:47,854 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038297404,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:11:48,080 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:48,134 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:11:50,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43341 synced till here 43333
2014-07-22 07:11:50,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038306839 with entries=267, filesize=209.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038308081
2014-07-22 07:11:50,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:52,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:52,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43428 synced till here 43417
2014-07-22 07:11:52,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038308081 with entries=87, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038312310
2014-07-22 07:11:52,412 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:53,782 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:11:53,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:53,896 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43513 synced till here 43505
2014-07-22 07:11:53,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038312310 with entries=85, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038313874
2014-07-22 07:11:53,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:55,464 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:55,503 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43601 synced till here 43593
2014-07-22 07:11:55,546 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:11:55,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038313874 with entries=88, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038315464
2014-07-22 07:11:55,571 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:55,748 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:11:56,958 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,960 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,960 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,960 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,986 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:11:56,991 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,991 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,991 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:56,992 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43684 synced till here 43678
2014-07-22 07:11:57,014 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,036 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,037 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,039 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,040 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,040 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,040 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038315464 with entries=83, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038316987
2014-07-22 07:11:57,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:11:57,078 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,142 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,206 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,269 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:11:57,333 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:01,958 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:01,960 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:01,960 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:01,961 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:01,991 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:01,991 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:01,992 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:01,992 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:02,014 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,036 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,037 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,040 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:02,040 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:02,040 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,040 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,079 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:02,142 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,206 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,231 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/41c1e60cc33346c8a24ca48cc1718109 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/41c1e60cc33346c8a24ca48cc1718109
2014-07-22 07:12:02,244 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:12:02,254 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3ded22a8b3574acf85003be3b5e3c767, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3ded22a8b3574acf85003be3b5e3c767
2014-07-22 07:12:02,256 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/231b035db5ea4bf4a4f4e382b73f31b7, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/231b035db5ea4bf4a4f4e382b73f31b7
2014-07-22 07:12:02,258 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/25ef051314c74699bf182002b5ec1eef, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/25ef051314c74699bf182002b5ec1eef
2014-07-22 07:12:02,260 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f8cd59fb153e4713ad2c54c1f8db2616, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f8cd59fb153e4713ad2c54c1f8db2616
2014-07-22 07:12:02,261 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b9b84c76d58e4d9eb1cd5bd7b2c036cd, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b9b84c76d58e4d9eb1cd5bd7b2c036cd
2014-07-22 07:12:02,270 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:02,290 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cd7b03321d144b37829902818676e6e3, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cd7b03321d144b37829902818676e6e3
2014-07-22 07:12:02,293 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e4ba8a8e417c4397afa7cb4137ffcc62, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e4ba8a8e417c4397afa7cb4137ffcc62
2014-07-22 07:12:02,294 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/a86bfe980bc64065847f825de646ab56, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/a86bfe980bc64065847f825de646ab56
2014-07-22 07:12:02,296 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/00e2ebcc50414b47b91e734d9d17e9a3, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/00e2ebcc50414b47b91e734d9d17e9a3
2014-07-22 07:12:02,298 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3f72caef6c0e4a2daadc0cd2fa6d4da6, to hdfs://master:54310/hbase/archive/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/3f72caef6c0e4a2daadc0cd2fa6d4da6
2014-07-22 07:12:02,298 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. into 41c1e60cc33346c8a24ca48cc1718109(size=494.7m), total size for store is 3.1g. This selection was in queue for 0sec, and took 1mins, 47sec to execute.
2014-07-22 07:12:02,298 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., storeName=family, fileCount=10, fileSize=584.8m, priority=1978, time=135195352806964; duration=1mins, 47sec
2014-07-22 07:12:02,299 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-22 07:12:02,299 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 2000 blocking
2014-07-22 07:12:02,300 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 711801533 starting at candidate #6 after considering 140 permutations with 98 in ratio
2014-07-22 07:12:02,300 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 708b12ffe5692a8a792bd1bf752b8516 - family: Initiating minor compaction
2014-07-22 07:12:02,301 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:12:02,301 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp, totalSize=678.8m
2014-07-22 07:12:02,301 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/81b965e4e38b4bb99c795276e0f94ba5, keycount=86037, bloomtype=ROW, size=61.3m, encoding=NONE, seqNum=8884
2014-07-22 07:12:02,301 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bf96ae81429e4c0c85aae1fe7b099744, keycount=68376, bloomtype=ROW, size=48.8m, encoding=NONE, seqNum=9266
2014-07-22 07:12:02,301 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7af41fb7b9e049b5aa5ce5890b0a6c03, keycount=110405, bloomtype=ROW, size=78.6m, encoding=NONE, seqNum=9646
2014-07-22 07:12:02,301 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bb2900d3d3aa42659202e06ffe35d9a4, keycount=97307, bloomtype=ROW, size=69.3m, encoding=NONE, seqNum=10089
2014-07-22 07:12:02,301 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/c65c9f29319b4fb78f5846b9c73221d4, keycount=82672, bloomtype=ROW, size=58.9m, encoding=NONE, seqNum=10440
2014-07-22 07:12:02,302 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/88dc6e86718e4aa9a43f131553c1c59b, keycount=103620, bloomtype=ROW, size=73.8m, encoding=NONE, seqNum=10857
2014-07-22 07:12:02,302 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/df19b37c54844c5e8b85f5d90ec2dd01, keycount=53224, bloomtype=ROW, size=37.9m, encoding=NONE, seqNum=11121
2014-07-22 07:12:02,302 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5a7fb74819fd43e798938d6fe0b5c50b, keycount=127586, bloomtype=ROW, size=90.9m, encoding=NONE, seqNum=11624
2014-07-22 07:12:02,302 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5720111f9f124599aced3b249c50e4f4, keycount=108057, bloomtype=ROW, size=77.0m, encoding=NONE, seqNum=12145
2014-07-22 07:12:02,302 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d336419c0ebb4e8aafb27f5dce8463c0, keycount=115764, bloomtype=ROW, size=82.4m, encoding=NONE, seqNum=12636
2014-07-22 07:12:02,333 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:02,641 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:12:06,960 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:06,960 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:12:06,961 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:06,961 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:06,992 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:12:06,992 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:06,992 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:06,992 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,014 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:12:07,037 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:12:07,038 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,040 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,040 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,040 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:12:07,041 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,079 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,143 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,206 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:12:07,270 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:07,333 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:12:09,192 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18360, memsize=579.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/c6391749c1bf4a739757501ebc174381
2014-07-22 07:12:09,200 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/c6391749c1bf4a739757501ebc174381 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/c6391749c1bf4a739757501ebc174381
2014-07-22 07:12:09,207 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/c6391749c1bf4a739757501ebc174381, entries=2108820, sequenceid=18360, filesize=150.2m
2014-07-22 07:12:09,208 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~579.2m/607324400, currentsize=125.8m/131888000 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 23734ms, sequenceid=18360, compaction requested=true
2014-07-22 07:12:09,208 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-22 07:12:09,208 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11876ms
2014-07-22 07:12:09,208 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,208 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 553.4m
2014-07-22 07:12:09,208 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11939ms
2014-07-22 07:12:09,208 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,208 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12002ms
2014-07-22 07:12:09,209 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,209 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12067ms
2014-07-22 07:12:09,209 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,213 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12135ms
2014-07-22 07:12:09,213 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,213 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12173ms
2014-07-22 07:12:09,214 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,214 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12174ms
2014-07-22 07:12:09,214 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,214 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12175ms
2014-07-22 07:12:09,214 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,217 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12178ms
2014-07-22 07:12:09,217 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,217 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12180ms
2014-07-22 07:12:09,218 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,222 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12186ms
2014-07-22 07:12:09,222 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,222 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12208ms
2014-07-22 07:12:09,222 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,222 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12231ms
2014-07-22 07:12:09,222 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,222 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12231ms
2014-07-22 07:12:09,222 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,229 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12238ms
2014-07-22 07:12:09,229 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,229 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12238ms
2014-07-22 07:12:09,229 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,230 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12270ms
2014-07-22 07:12:09,230 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,230 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12270ms
2014-07-22 07:12:09,230 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,237 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12277ms
2014-07-22 07:12:09,237 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,237 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12279ms
2014-07-22 07:12:09,238 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:09,420 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14057,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315362,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:09,420 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315167,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:09,482 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315423,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:09,596 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14036,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315559,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:09,668 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14174,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315492,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:09,769 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:12:09,793 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14169,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315624,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,074 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315690,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:10,294 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43777 synced till here 43765
2014-07-22 07:12:10,365 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315755,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,365 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14531,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038315833,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,373 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038316987 with entries=93, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038330263
2014-07-22 07:12:10,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:10,550 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13809,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038316740,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,610 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13901,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038316709,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,693 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038316877,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,693 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13751,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038316941,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:10,825 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14011,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038316811,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,674 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14597,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038317076,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,722 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14709,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038317012,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,762 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038317331,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,762 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14622,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038317140,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,762 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038317267,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,772 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14568,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038317204,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:11,794 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:11,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43863 synced till here 43856
2014-07-22 07:12:11,869 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038330263 with entries=86, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038331794
2014-07-22 07:12:11,869 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:13,332 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:13,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43952 synced till here 43942
2014-07-22 07:12:13,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038331794 with entries=89, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038333333
2014-07-22 07:12:13,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:13,558 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18367, memsize=567.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/77761c13a7514b7e8eca1f7ddf6678d2
2014-07-22 07:12:13,571 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/77761c13a7514b7e8eca1f7ddf6678d2 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/77761c13a7514b7e8eca1f7ddf6678d2
2014-07-22 07:12:13,579 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/77761c13a7514b7e8eca1f7ddf6678d2, entries=2067260, sequenceid=18367, filesize=147.2m
2014-07-22 07:12:13,579 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~567.8m/595354720, currentsize=147.2m/154355120 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 26715ms, sequenceid=18367, compaction requested=true
2014-07-22 07:12:13,580 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-22 07:12:13,580 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 593.9m
2014-07-22 07:12:14,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:14,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44037 synced till here 44030
2014-07-22 07:12:14,961 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:12:14,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038333333 with entries=85, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038334900
2014-07-22 07:12:14,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:15,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:15,758 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44122 synced till here 44116
2014-07-22 07:12:15,804 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038334900 with entries=85, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038335733
2014-07-22 07:12:15,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:17,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:18,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44240 synced till here 44236
2014-07-22 07:12:19,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038335733 with entries=118, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038337222
2014-07-22 07:12:19,855 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:21,388 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:21,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44327 synced till here 44314
2014-07-22 07:12:21,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038337222 with entries=87, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038341389
2014-07-22 07:12:21,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:22,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:22,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44419 synced till here 44408
2014-07-22 07:12:22,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038341389 with entries=92, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038342709
2014-07-22 07:12:22,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:12:22,944 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:12:23,374 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,376 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,376 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,376 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,377 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,377 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,377 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:23,381 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,268 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,325 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,392 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,476 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,550 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,645 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,721 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,806 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,891 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:24,963 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:25,035 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:25,104 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:28,736 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5354ms
2014-07-22 07:12:28,737 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-22 07:12:28,737 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5361ms
2014-07-22 07:12:28,737 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5361ms
2014-07-22 07:12:28,738 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-22 07:12:28,738 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-22 07:12:28,738 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-22 07:12:28,738 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5362ms
2014-07-22 07:12:29,268 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,325 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,392 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,476 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,550 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,645 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,721 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:29,806 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:29,892 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:29,964 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:30,035 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:30,105 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:33,612 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18429, memsize=553.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/a5e326ae09cb47c2b9e864a3ac5b931f
2014-07-22 07:12:33,623 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/a5e326ae09cb47c2b9e864a3ac5b931f as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/a5e326ae09cb47c2b9e864a3ac5b931f
2014-07-22 07:12:33,632 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/a5e326ae09cb47c2b9e864a3ac5b931f, entries=2014940, sequenceid=18429, filesize=143.5m
2014-07-22 07:12:33,633 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~553.4m/580287200, currentsize=141.3m/148206400 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 24425ms, sequenceid=18429, compaction requested=true
2014-07-22 07:12:33,633 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:101), split_queue=0, merge_queue=0
2014-07-22 07:12:33,633 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8529ms
2014-07-22 07:12:33,633 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 309.7m
2014-07-22 07:12:33,633 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,634 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8599ms
2014-07-22 07:12:33,634 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,634 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8671ms
2014-07-22 07:12:33,635 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,639 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8748ms
2014-07-22 07:12:33,639 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,640 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8834ms
2014-07-22 07:12:33,640 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,640 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8919ms
2014-07-22 07:12:33,640 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,641 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8996ms
2014-07-22 07:12:33,641 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,645 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9095ms
2014-07-22 07:12:33,645 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,645 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9169ms
2014-07-22 07:12:33,646 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,646 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9254ms
2014-07-22 07:12:33,646 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,646 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9321ms
2014-07-22 07:12:33,646 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,647 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9379ms
2014-07-22 07:12:33,647 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,649 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10273ms
2014-07-22 07:12:33,649 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,650 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10273ms
2014-07-22 07:12:33,650 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,651 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10274ms
2014-07-22 07:12:33,651 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,652 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10275ms
2014-07-22 07:12:33,652 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,652 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10276ms
2014-07-22 07:12:33,652 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,657 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10281ms
2014-07-22 07:12:33,657 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,658 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10283ms
2014-07-22 07:12:33,658 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,658 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10277ms
2014-07-22 07:12:33,659 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:33,678 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11156,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038342521,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:33,685 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11085,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038342599,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:34,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:34,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44500 synced till here 44498
2014-07-22 07:12:34,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038342709 with entries=81, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038354129
2014-07-22 07:12:34,250 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11434,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038342816,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:34,294 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:12:34,546 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038342880,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:34,564 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11619,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038342944,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:35,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:35,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44590 synced till here 44577
2014-07-22 07:12:35,109 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12085,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038343024,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:35,111 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:12:35,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038354129 with entries=90, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038355035
2014-07-22 07:12:35,675 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10644,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038345031,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:35,675 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12498,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038343177,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:35,676 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038343090,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,087 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11368,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344718,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,088 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11821,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344266,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,087 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344323,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,130 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11240,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344889,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,134 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344639,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,135 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344547,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,135 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11663,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344472,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,160 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11057,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038345102,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,168 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11367,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344801,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,168 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344958,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,168 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11781,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038344387,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:12:36,231 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:36,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44678 synced till here 44676
2014-07-22 07:12:36,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038355035 with entries=88, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038356232
2014-07-22 07:12:37,771 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:37,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038356232 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038357772
2014-07-22 07:12:39,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:39,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44838 synced till here 44835
2014-07-22 07:12:39,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038357772 with entries=82, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038359319
2014-07-22 07:12:39,522 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8167, memsize=593.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/d21d5cdb0e4243728b2476ba39416305
2014-07-22 07:12:39,540 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/d21d5cdb0e4243728b2476ba39416305 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/d21d5cdb0e4243728b2476ba39416305
2014-07-22 07:12:39,551 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/d21d5cdb0e4243728b2476ba39416305, entries=2162220, sequenceid=8167, filesize=154.0m
2014-07-22 07:12:39,552 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~593.9m/622702960, currentsize=153.0m/160400160 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 25972ms, sequenceid=8167, compaction requested=true
2014-07-22 07:12:39,552 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-22 07:12:39,552 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 608.2m
2014-07-22 07:12:41,115 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:41,126 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:12:41,156 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44924 synced till here 44918
2014-07-22 07:12:41,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038359319 with entries=86, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038361116
2014-07-22 07:12:42,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:42,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45007 synced till here 45003
2014-07-22 07:12:42,773 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038361116 with entries=83, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038362721
2014-07-22 07:12:44,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:44,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45089 synced till here 45088
2014-07-22 07:12:44,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038362721 with entries=82, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038364329
2014-07-22 07:12:44,879 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:12:45,711 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:45,741 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45172 synced till here 45170
2014-07-22 07:12:45,793 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038364329 with entries=83, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038365712
2014-07-22 07:12:47,511 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:47,787 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,788 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,789 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,813 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,815 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,841 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,848 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,860 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,878 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,879 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:47,885 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,049 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,125 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,215 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,297 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,372 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,461 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,529 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,601 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:48,667 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:49,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038365712 with entries=111, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038367516
2014-07-22 07:12:51,108 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8192, memsize=309.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/cc95a3fe6df946e99ff1ef6c138df53a
2014-07-22 07:12:51,122 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/cc95a3fe6df946e99ff1ef6c138df53a as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/cc95a3fe6df946e99ff1ef6c138df53a
2014-07-22 07:12:51,131 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/cc95a3fe6df946e99ff1ef6c138df53a, entries=1127660, sequenceid=8192, filesize=80.3m
2014-07-22 07:12:51,131 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~309.7m/324735280, currentsize=41.7m/43737520 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 17498ms, sequenceid=8192, compaction requested=true
2014-07-22 07:12:51,131 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:103), split_queue=0, merge_queue=0
2014-07-22 07:12:51,131 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2464ms
2014-07-22 07:12:51,132 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,132 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 656.2m
2014-07-22 07:12:51,132 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2531ms
2014-07-22 07:12:51,132 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,132 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2603ms
2014-07-22 07:12:51,132 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,132 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2671ms
2014-07-22 07:12:51,132 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,138 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2766ms
2014-07-22 07:12:51,138 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,138 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2841ms
2014-07-22 07:12:51,138 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,138 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2923ms
2014-07-22 07:12:51,138 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,139 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3014ms
2014-07-22 07:12:51,139 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,143 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3095ms
2014-07-22 07:12:51,144 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,144 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3259ms
2014-07-22 07:12:51,144 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,144 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3266ms
2014-07-22 07:12:51,144 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,145 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3266ms
2014-07-22 07:12:51,145 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,146 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3286ms
2014-07-22 07:12:51,147 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,147 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3299ms
2014-07-22 07:12:51,147 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,148 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3306ms
2014-07-22 07:12:51,148 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,148 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3333ms
2014-07-22 07:12:51,148 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,148 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3335ms
2014-07-22 07:12:51,148 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,153 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3365ms
2014-07-22 07:12:51,191 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,192 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3404ms
2014-07-22 07:12:51,192 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,192 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3405ms
2014-07-22 07:12:51,192 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:12:51,725 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:12:51,956 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:52,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45371 synced till here 45360
2014-07-22 07:12:52,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038367516 with entries=88, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038371957
2014-07-22 07:12:52,095 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038159930
2014-07-22 07:12:52,095 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038163650
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038165073
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038166606
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038168514
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038176213
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038177782
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038178509
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038182570
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038183952
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038185593
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038186927
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038202247
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038203651
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038204977
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038206359
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038207846
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038209566
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038210449
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038211956
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038213555
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038215417
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038229174
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038230261
2014-07-22 07:12:52,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038231566
2014-07-22 07:12:52,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038232902
2014-07-22 07:12:52,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038234242
2014-07-22 07:12:52,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038235733
2014-07-22 07:12:52,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038238065
2014-07-22 07:12:52,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038239919
2014-07-22 07:12:52,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038241314
2014-07-22 07:12:53,203 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:12:53,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:12:53,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45455 synced till here 45454
2014-07-22 07:12:53,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038371957 with entries=84, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038373273
2014-07-22 07:12:53,672 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:53,677 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:53,683 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,239 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,259 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,260 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,275 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,288 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,304 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,355 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,421 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,494 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,562 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,634 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,701 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,765 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,827 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:54,925 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:55,007 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:55,084 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:12:58,672 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:58,677 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:58,683 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:59,239 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:59,260 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,261 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,276 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,289 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,305 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,355 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:59,422 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:59,495 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,563 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:59,634 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,702 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,765 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:12:59,828 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:12:59,925 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:00,007 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:00,084 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:03,673 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:03,678 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:03,684 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,240 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,260 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,261 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:13:04,276 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,289 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,305 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,356 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,422 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,495 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,713 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10011ms
2014-07-22 07:13:04,713 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10151ms
2014-07-22 07:13:04,713 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10080ms
2014-07-22 07:13:04,765 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:13:04,828 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:04,926 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:05,008 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:13:05,084 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:13:05,499 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8275, memsize=611.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/6ccaaa66e78e4e2c8347eb560b209641
2014-07-22 07:13:05,509 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/6ccaaa66e78e4e2c8347eb560b209641 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6ccaaa66e78e4e2c8347eb560b209641
2014-07-22 07:13:05,517 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/6ccaaa66e78e4e2c8347eb560b209641, entries=2225140, sequenceid=8275, filesize=158.5m
2014-07-22 07:13:05,518 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~611.1m/640822080, currentsize=107.3m/112487280 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 25966ms, sequenceid=8275, compaction requested=true
2014-07-22 07:13:05,518 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:104), split_queue=0, merge_queue=0
2014-07-22 07:13:05,518 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10435ms
2014-07-22 07:13:05,518 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,518 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 580.0m
2014-07-22 07:13:05,518 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10511ms
2014-07-22 07:13:05,519 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,519 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10594ms
2014-07-22 07:13:05,519 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,519 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10692ms
2014-07-22 07:13:05,519 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,521 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10756ms
2014-07-22 07:13:05,521 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,521 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10888ms
2014-07-22 07:13:05,521 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,529 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10967ms
2014-07-22 07:13:05,530 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,533 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10832ms
2014-07-22 07:13:05,533 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,533 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11039ms
2014-07-22 07:13:05,534 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,534 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11113ms
2014-07-22 07:13:05,534 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,534 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11179ms
2014-07-22 07:13:05,534 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,534 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11230ms
2014-07-22 07:13:05,534 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,534 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11246ms
2014-07-22 07:13:05,534 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,534 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11259ms
2014-07-22 07:13:05,534 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,535 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11276ms
2014-07-22 07:13:05,535 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,537 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11278ms
2014-07-22 07:13:05,537 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,538 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11299ms
2014-07-22 07:13:05,538 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,541 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11858ms
2014-07-22 07:13:05,541 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,541 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11865ms
2014-07-22 07:13:05,541 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,547 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11874ms
2014-07-22 07:13:05,547 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:05,568 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12434,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373133,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:05,651 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12582,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373068,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:05,803 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12595,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373207,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:05,911 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:05,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45540 synced till here 45531
2014-07-22 07:13:06,025 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038373273 with entries=85, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038385912
2014-07-22 07:13:06,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038242993
2014-07-22 07:13:06,025 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038255288
2014-07-22 07:13:06,121 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:13:06,950 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373500,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,116 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:07,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45622 synced till here 45614
2014-07-22 07:13:07,199 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13557,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373642,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,199 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13769,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373430,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,200 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038373572,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038385912 with entries=82, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038387116
2014-07-22 07:13:07,374 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12610,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374763,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,396 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12316,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038375079,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,396 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12474,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374921,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,397 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12571,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374825,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,564 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12864,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374699,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,565 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13211,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374353,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,585 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12581,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038375003,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,585 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13165,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374419,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,585 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374258,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,585 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374287,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,593 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13034,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374558,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,610 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374492,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:07,610 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12978,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038374631,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:08,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:08,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45710 synced till here 45705
2014-07-22 07:13:08,644 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038387116 with entries=88, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038388528
2014-07-22 07:13:10,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:10,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45791 synced till here 45790
2014-07-22 07:13:10,191 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038388528 with entries=81, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038390142
2014-07-22 07:13:10,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:10,887 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45874 synced till here 45870
2014-07-22 07:13:11,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038390142 with entries=83, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038390868
2014-07-22 07:13:12,172 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,173 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,173 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,173 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,174 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,180 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,187 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,187 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,187 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,205 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,207 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,214 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,223 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,251 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,320 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,384 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,450 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,515 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,580 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:12,644 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:17,173 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,173 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,174 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,174 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-22 07:13:17,175 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:17,180 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:17,187 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,187 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:17,187 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:17,191 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8315, memsize=656.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/162ba57426c84d64adb3d3cc6a8be4a8
2014-07-22 07:13:17,200 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/162ba57426c84d64adb3d3cc6a8be4a8 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/162ba57426c84d64adb3d3cc6a8be4a8
2014-07-22 07:13:17,206 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,207 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,207 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/162ba57426c84d64adb3d3cc6a8be4a8, entries=2389240, sequenceid=8315, filesize=170.2m
2014-07-22 07:13:17,207 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~656.2m/688081120, currentsize=110.1m/115432640 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 26075ms, sequenceid=8315, compaction requested=true
2014-07-22 07:13:17,208 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:105), split_queue=0, merge_queue=0
2014-07-22 07:13:17,208 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-22 07:13:17,208 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,208 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-22 07:13:17,208 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,208 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 657.3m
2014-07-22 07:13:17,208 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5021ms
2014-07-22 07:13:17,208 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,208 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5021ms
2014-07-22 07:13:17,208 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,208 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5022ms
2014-07-22 07:13:17,208 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,214 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:17,214 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,221 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5041ms
2014-07-22 07:13:17,221 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,221 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5047ms
2014-07-22 07:13:17,222 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,223 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:17,223 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,233 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5061ms
2014-07-22 07:13:17,233 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,233 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5060ms
2014-07-22 07:13:17,233 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,234 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5061ms
2014-07-22 07:13:17,234 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,234 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5062ms
2014-07-22 07:13:17,234 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,235 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4590ms
2014-07-22 07:13:17,235 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,235 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4655ms
2014-07-22 07:13:17,235 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,245 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4730ms
2014-07-22 07:13:17,245 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,245 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4795ms
2014-07-22 07:13:17,246 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,246 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4862ms
2014-07-22 07:13:17,246 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,252 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:17,252 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,253 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4933ms
2014-07-22 07:13:17,253 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:17,656 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:17,885 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:13:18,645 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46038 synced till here 46025
2014-07-22 07:13:20,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038390868 with entries=164, filesize=131.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038397656
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038256759
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038258177
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038259678
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038261246
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038262752
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038264325
2014-07-22 07:13:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038266075
2014-07-22 07:13:21,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:21,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46127 synced till here 46120
2014-07-22 07:13:21,721 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038397656 with entries=89, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038401622
2014-07-22 07:13:22,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:22,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46215 synced till here 46210
2014-07-22 07:13:23,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038401622 with entries=88, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038402971
2014-07-22 07:13:24,511 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:24,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46298 synced till here 46293
2014-07-22 07:13:24,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038402971 with entries=83, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038404511
2014-07-22 07:13:25,771 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:13:26,106 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,134 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:26,138 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,142 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,143 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,150 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46381 synced till here 46376
2014-07-22 07:13:26,151 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,176 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,179 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,180 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,180 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,180 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038404511 with entries=83, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038406134
2014-07-22 07:13:26,203 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,219 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,220 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,313 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,387 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,471 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,556 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,636 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,712 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:26,797 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:31,107 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:31,139 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:31,143 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:31,143 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:31,151 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:31,176 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18677, memsize=580.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/4b167154c05148698638eb90e44e5e40
2014-07-22 07:13:31,176 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:31,180 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:31,180 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:31,180 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:31,180 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:31,188 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/4b167154c05148698638eb90e44e5e40 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/4b167154c05148698638eb90e44e5e40
2014-07-22 07:13:31,197 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/4b167154c05148698638eb90e44e5e40, entries=2111870, sequenceid=18677, filesize=150.4m
2014-07-22 07:13:31,197 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~580.0m/608201680, currentsize=155.3m/162792720 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 25679ms, sequenceid=18677, compaction requested=true
2014-07-22 07:13:31,198 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-22 07:13:31,198 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5018ms
2014-07-22 07:13:31,198 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,198 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5018ms
2014-07-22 07:13:31,198 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 592.1m
2014-07-22 07:13:31,198 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,198 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5019ms
2014-07-22 07:13:31,198 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,198 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5019ms
2014-07-22 07:13:31,199 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,203 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5027ms
2014-07-22 07:13:31,203 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,203 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5052ms
2014-07-22 07:13:31,203 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,203 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5060ms
2014-07-22 07:13:31,203 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,205 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-22 07:13:31,205 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,205 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5067ms
2014-07-22 07:13:31,205 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,207 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5101ms
2014-07-22 07:13:31,208 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,208 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4411ms
2014-07-22 07:13:31,208 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,209 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4497ms
2014-07-22 07:13:31,209 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,209 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4573ms
2014-07-22 07:13:31,209 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,231 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4653ms
2014-07-22 07:13:31,231 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,231 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4760ms
2014-07-22 07:13:31,231 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,232 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4845ms
2014-07-22 07:13:31,232 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,232 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4919ms
2014-07-22 07:13:31,232 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,234 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5013ms
2014-07-22 07:13:31,234 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,235 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5015ms
2014-07-22 07:13:31,235 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,235 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5032ms
2014-07-22 07:13:31,235 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:31,830 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:13:32,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:32,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46473 synced till here 46459
2014-07-22 07:13:32,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038406134 with entries=92, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038412350
2014-07-22 07:13:33,828 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:33,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46562 synced till here 46548
2014-07-22 07:13:33,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038412350 with entries=89, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038413828
2014-07-22 07:13:34,775 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:34,797 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038413828 with entries=83, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038414775
2014-07-22 07:13:36,044 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:36,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038414775 with entries=78, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038416045
2014-07-22 07:13:36,966 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:13:37,103 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,108 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,115 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,130 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,133 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,145 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,145 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,145 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,149 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,165 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,211 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,279 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,344 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,411 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,477 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,545 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,612 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,679 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,745 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:37,811 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:42,103 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,108 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,115 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,131 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,134 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,145 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,145 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,146 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,149 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,166 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,211 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,279 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,345 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,412 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,477 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,545 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,613 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:13:42,679 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,745 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:42,811 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:13:45,346 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18701, memsize=657.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/f10b1a90c7c14d62bc199740a520f644
2014-07-22 07:13:45,356 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/f10b1a90c7c14d62bc199740a520f644 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/f10b1a90c7c14d62bc199740a520f644
2014-07-22 07:13:45,365 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/f10b1a90c7c14d62bc199740a520f644, entries=2393180, sequenceid=18701, filesize=170.4m
2014-07-22 07:13:45,365 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~657.3m/689216640, currentsize=145.2m/152267600 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 28157ms, sequenceid=18701, compaction requested=true
2014-07-22 07:13:45,366 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-22 07:13:45,366 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 637.1m
2014-07-22 07:13:45,366 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7555ms
2014-07-22 07:13:45,366 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,367 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7621ms
2014-07-22 07:13:45,367 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,373 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7694ms
2014-07-22 07:13:45,373 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,374 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7762ms
2014-07-22 07:13:45,374 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,374 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7829ms
2014-07-22 07:13:45,374 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,377 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7900ms
2014-07-22 07:13:45,377 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,378 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7966ms
2014-07-22 07:13:45,378 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,379 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8034ms
2014-07-22 07:13:45,379 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,379 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8101ms
2014-07-22 07:13:45,379 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,379 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8168ms
2014-07-22 07:13:45,379 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,380 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8215ms
2014-07-22 07:13:45,380 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,382 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8232ms
2014-07-22 07:13:45,382 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,383 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8237ms
2014-07-22 07:13:45,383 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,389 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8244ms
2014-07-22 07:13:45,389 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,390 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8244ms
2014-07-22 07:13:45,390 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,391 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8257ms
2014-07-22 07:13:45,391 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,391 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8261ms
2014-07-22 07:13:45,391 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,392 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8276ms
2014-07-22 07:13:45,392 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,397 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8289ms
2014-07-22 07:13:45,397 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,398 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8294ms
2014-07-22 07:13:45,398 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:45,605 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:45,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46811 synced till here 46804
2014-07-22 07:13:45,982 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038416045 with entries=88, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038425605
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038267645
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038282978
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038284180
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038285631
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038286842
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038287495
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038289151
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038290715
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038292205
2014-07-22 07:13:45,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038293876
2014-07-22 07:13:45,996 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:13:47,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:47,388 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46898 synced till here 46888
2014-07-22 07:13:47,462 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038425605 with entries=87, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038427357
2014-07-22 07:13:47,993 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10249,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417743,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,056 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10580,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417475,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,057 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10648,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417408,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,081 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10937,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417143,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,082 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10273,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417809,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,082 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10539,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417543,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,084 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417209,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,082 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417677,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,082 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10806,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417276,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,086 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10476,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417610,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,086 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038417342,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:13:48,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:48,127 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46983 synced till here 46980
2014-07-22 07:13:48,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038427357 with entries=85, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038428106
2014-07-22 07:13:48,164 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:13:49,824 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:50,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47080 synced till here 47077
2014-07-22 07:13:50,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038428106 with entries=97, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038429824
2014-07-22 07:13:51,341 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:51,357 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47159 synced till here 47158
2014-07-22 07:13:51,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038429824 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038431341
2014-07-22 07:13:52,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:52,904 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:52,918 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:52,948 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,003 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,004 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,004 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,005 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,005 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,005 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,005 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,016 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,083 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:53,148 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,214 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,243 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,308 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,376 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,443 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,547 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,653 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:13:54,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038431341 with entries=86, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038432882
2014-07-22 07:13:56,471 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18743, memsize=592.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/85d9fc1059d247918d264bc63998a31e
2014-07-22 07:13:56,480 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/85d9fc1059d247918d264bc63998a31e as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/85d9fc1059d247918d264bc63998a31e
2014-07-22 07:13:56,487 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/85d9fc1059d247918d264bc63998a31e, entries=2155850, sequenceid=18743, filesize=153.5m
2014-07-22 07:13:56,488 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~592.1m/620868240, currentsize=149.4m/156635360 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 25290ms, sequenceid=18743, compaction requested=true
2014-07-22 07:13:56,488 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-22 07:13:56,488 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1835ms
2014-07-22 07:13:56,488 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,488 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 618.4m
2014-07-22 07:13:56,489 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1942ms
2014-07-22 07:13:56,489 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,489 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2046ms
2014-07-22 07:13:56,489 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,489 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2113ms
2014-07-22 07:13:56,489 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,489 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2181ms
2014-07-22 07:13:56,489 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,497 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2254ms
2014-07-22 07:13:56,497 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,497 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2283ms
2014-07-22 07:13:56,497 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,497 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3349ms
2014-07-22 07:13:56,497 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,497 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3414ms
2014-07-22 07:13:56,497 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,510 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3493ms
2014-07-22 07:13:56,510 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,510 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3505ms
2014-07-22 07:13:56,510 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,511 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3506ms
2014-07-22 07:13:56,511 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,511 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3507ms
2014-07-22 07:13:56,511 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,512 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3508ms
2014-07-22 07:13:56,512 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,512 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3508ms
2014-07-22 07:13:56,512 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,512 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3508ms
2014-07-22 07:13:56,512 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,513 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3509ms
2014-07-22 07:13:56,513 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,522 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3573ms
2014-07-22 07:13:56,522 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,523 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3605ms
2014-07-22 07:13:56,523 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:56,524 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3619ms
2014-07-22 07:13:56,524 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:13:57,913 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:13:58,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:58,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47329 synced till here 47320
2014-07-22 07:13:58,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038432882 with entries=84, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038438127
2014-07-22 07:13:58,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038295566
2014-07-22 07:13:58,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038306058
2014-07-22 07:13:59,501 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:13:59,522 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47418 synced till here 47407
2014-07-22 07:13:59,578 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:13:59,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038438127 with entries=89, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038439502
2014-07-22 07:14:01,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:01,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038439502 with entries=98, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038441082
2014-07-22 07:14:01,815 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:01,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47596 synced till here 47592
2014-07-22 07:14:01,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038441082 with entries=80, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038441816
2014-07-22 07:14:03,398 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,402 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,420 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,421 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,428 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,436 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,443 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,444 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,452 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,481 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,482 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,482 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,501 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,564 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,628 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:03,693 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:04,678 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:04,743 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:08,205 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/09609d6088844a7f81063e6ebc884a29 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/09609d6088844a7f81063e6ebc884a29
2014-07-22 07:14:08,217 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:14:08,226 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/81b965e4e38b4bb99c795276e0f94ba5, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/81b965e4e38b4bb99c795276e0f94ba5
2014-07-22 07:14:08,241 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bf96ae81429e4c0c85aae1fe7b099744, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bf96ae81429e4c0c85aae1fe7b099744
2014-07-22 07:14:08,243 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7af41fb7b9e049b5aa5ce5890b0a6c03, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/7af41fb7b9e049b5aa5ce5890b0a6c03
2014-07-22 07:14:08,246 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bb2900d3d3aa42659202e06ffe35d9a4, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/bb2900d3d3aa42659202e06ffe35d9a4
2014-07-22 07:14:08,248 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/c65c9f29319b4fb78f5846b9c73221d4, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/c65c9f29319b4fb78f5846b9c73221d4
2014-07-22 07:14:08,250 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/88dc6e86718e4aa9a43f131553c1c59b, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/88dc6e86718e4aa9a43f131553c1c59b
2014-07-22 07:14:08,252 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/df19b37c54844c5e8b85f5d90ec2dd01, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/df19b37c54844c5e8b85f5d90ec2dd01
2014-07-22 07:14:08,254 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5a7fb74819fd43e798938d6fe0b5c50b, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5a7fb74819fd43e798938d6fe0b5c50b
2014-07-22 07:14:08,256 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5720111f9f124599aced3b249c50e4f4, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/5720111f9f124599aced3b249c50e4f4
2014-07-22 07:14:08,258 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d336419c0ebb4e8aafb27f5dce8463c0, to hdfs://master:54310/hbase/archive/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/d336419c0ebb4e8aafb27f5dce8463c0
2014-07-22 07:14:08,259 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. into 09609d6088844a7f81063e6ebc884a29(size=593.8m), total size for store is 3.3g. This selection was in queue for 0sec, and took 2mins, 5sec to execute.
2014-07-22 07:14:08,259 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., storeName=family, fileCount=10, fileSize=678.8m, priority=1977, time=135302691189655; duration=2mins, 5sec
2014-07-22 07:14:08,259 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-22 07:14:08,260 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 2000 blocking
2014-07-22 07:14:08,261 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 766787393 starting at candidate #4 after considering 132 permutations with 105 in ratio
2014-07-22 07:14:08,261 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: d29123f6203691d46817543c7ec8a423 - family: Initiating minor compaction
2014-07-22 07:14:08,261 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:14:08,262 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp, totalSize=731.3m
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/02ce2fb6f04e44c2a342336cd7a12783, keycount=63953, bloomtype=ROW, size=45.6m, encoding=NONE, seqNum=7710
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/95c1c4f39c2642e5a08b8b73448092ae, keycount=97001, bloomtype=ROW, size=69.1m, encoding=NONE, seqNum=8043
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/00f6d33998674401839b3ae62fa5521c, keycount=157206, bloomtype=ROW, size=112.0m, encoding=NONE, seqNum=8625
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/42ab5240f0084e7db74ce55fe06584d3, keycount=90883, bloomtype=ROW, size=64.7m, encoding=NONE, seqNum=9098
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/8c042cefef50456196f097646bea6225, keycount=126812, bloomtype=ROW, size=90.3m, encoding=NONE, seqNum=9587
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/56ebd5ce142f4191b60194ef3c8fe744, keycount=107950, bloomtype=ROW, size=76.9m, encoding=NONE, seqNum=10167
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/5a9a8906c7a34a01ae2e02d0e0199167, keycount=92754, bloomtype=ROW, size=66.1m, encoding=NONE, seqNum=10645
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6c69f1e18641455ca4f78f0c8fea49fe, keycount=73827, bloomtype=ROW, size=52.6m, encoding=NONE, seqNum=11024
2014-07-22 07:14:08,262 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/4f8d04600c5d4ac392d0888c939fea01, keycount=117818, bloomtype=ROW, size=83.9m, encoding=NONE, seqNum=11384
2014-07-22 07:14:08,263 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/c41798491fc74568830862894e016796, keycount=98370, bloomtype=ROW, size=70.0m, encoding=NONE, seqNum=11837
2014-07-22 07:14:08,399 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,402 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,421 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:08,421 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:08,428 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:08,437 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,443 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:08,445 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,452 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:08,477 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:14:08,482 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,482 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,483 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,501 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:08,565 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,629 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:08,694 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:09,679 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:09,743 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:13,376 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18778, memsize=637.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/1d5fb8fbc8f1457a9090a0f327a7a194
2014-07-22 07:14:13,391 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/1d5fb8fbc8f1457a9090a0f327a7a194 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/1d5fb8fbc8f1457a9090a0f327a7a194
2014-07-22 07:14:13,398 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/1d5fb8fbc8f1457a9090a0f327a7a194, entries=2319570, sequenceid=18778, filesize=165.2m
2014-07-22 07:14:13,399 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~637.1m/668016320, currentsize=150.3m/157618000 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 28033ms, sequenceid=18778, compaction requested=true
2014-07-22 07:14:13,399 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:13,399 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,399 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-22 07:14:13,400 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8656ms
2014-07-22 07:14:13,400 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,400 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 639.4m
2014-07-22 07:14:13,400 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8722ms
2014-07-22 07:14:13,400 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,400 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9707ms
2014-07-22 07:14:13,400 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,400 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9772ms
2014-07-22 07:14:13,400 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,401 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9837ms
2014-07-22 07:14:13,401 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,406 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-22 07:14:13,406 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,406 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9905ms
2014-07-22 07:14:13,406 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,406 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9924ms
2014-07-22 07:14:13,407 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,407 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9926ms
2014-07-22 07:14:13,407 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,407 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9926ms
2014-07-22 07:14:13,407 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,407 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9955ms
2014-07-22 07:14:13,407 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,407 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9963ms
2014-07-22 07:14:13,408 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,408 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9965ms
2014-07-22 07:14:13,408 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,421 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:13,421 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,422 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9985ms
2014-07-22 07:14:13,422 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,423 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9994ms
2014-07-22 07:14:13,423 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,430 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-22 07:14:13,430 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:13,472 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:13,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47680 synced till here 47676
2014-07-22 07:14:13,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038441816 with entries=84, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038453472
2014-07-22 07:14:13,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038306839
2014-07-22 07:14:13,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038308081
2014-07-22 07:14:13,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038312310
2014-07-22 07:14:13,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038313874
2014-07-22 07:14:13,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038315464
2014-07-22 07:14:13,704 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11849,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038441854,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:13,704 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11916,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038441787,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:13,718 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10846,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038442871,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:13,718 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038442831,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:14,014 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10999,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443014,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:14,017 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10935,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443081,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:14,019 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038442946,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:14,588 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:14:14,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:14,972 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11820,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443151,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,014 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47766 synced till here 47757
2014-07-22 07:14:15,060 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11842,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443217,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,061 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11768,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443293,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038453472 with entries=86, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038454971
2014-07-22 07:14:15,120 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11750,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443369,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,480 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443434,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,515 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10773,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038444741,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,515 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10838,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038444676,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,515 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443562,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,554 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11927,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443626,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,554 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11863,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443690,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:15,554 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038443498,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:16,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:16,547 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47854 synced till here 47845
2014-07-22 07:14:16,583 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:14:16,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038454971 with entries=88, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038456530
2014-07-22 07:14:18,244 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:18,271 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47943 synced till here 47935
2014-07-22 07:14:18,627 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038456530 with entries=89, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038458244
2014-07-22 07:14:20,207 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:20,239 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48035 synced till here 48027
2014-07-22 07:14:20,299 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038458244 with entries=92, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038460208
2014-07-22 07:14:21,678 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,680 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,687 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,695 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,699 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,710 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,710 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:21,723 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,726 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,730 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,743 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,760 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,763 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,829 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,895 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:21,964 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:22,035 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:22,094 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:23,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038460208 with entries=81, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038461721
2014-07-22 07:14:24,303 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18828, memsize=618.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/22368bbbcbac4ba590f89706334ecc38
2014-07-22 07:14:24,320 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/22368bbbcbac4ba590f89706334ecc38 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/22368bbbcbac4ba590f89706334ecc38
2014-07-22 07:14:24,331 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/22368bbbcbac4ba590f89706334ecc38, entries=2251630, sequenceid=18828, filesize=160.3m
2014-07-22 07:14:24,332 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~618.4m/648449760, currentsize=143.8m/150803920 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 27844ms, sequenceid=18828, compaction requested=true
2014-07-22 07:14:24,333 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:109), split_queue=0, merge_queue=0
2014-07-22 07:14:24,333 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2239ms
2014-07-22 07:14:24,333 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,334 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 560.8m
2014-07-22 07:14:24,334 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2299ms
2014-07-22 07:14:24,334 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,334 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2370ms
2014-07-22 07:14:24,334 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,335 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2440ms
2014-07-22 07:14:24,335 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,335 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2506ms
2014-07-22 07:14:24,335 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,335 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2572ms
2014-07-22 07:14:24,335 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,335 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2575ms
2014-07-22 07:14:24,335 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,336 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2593ms
2014-07-22 07:14:24,336 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,345 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2616ms
2014-07-22 07:14:24,345 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,346 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2620ms
2014-07-22 07:14:24,346 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,346 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2623ms
2014-07-22 07:14:24,346 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,347 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2636ms
2014-07-22 07:14:24,347 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,354 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2643ms
2014-07-22 07:14:24,354 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,354 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2655ms
2014-07-22 07:14:24,354 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,355 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2660ms
2014-07-22 07:14:24,355 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,356 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2668ms
2014-07-22 07:14:24,356 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,357 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2677ms
2014-07-22 07:14:24,357 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:24,357 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2679ms
2014-07-22 07:14:24,357 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:25,386 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:14:25,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:25,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48206 synced till here 48202
2014-07-22 07:14:25,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038461721 with entries=90, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038465659
2014-07-22 07:14:25,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038316987
2014-07-22 07:14:25,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038330263
2014-07-22 07:14:25,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038331794
2014-07-22 07:14:26,904 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:14:26,955 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:26,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48288 synced till here 48286
2014-07-22 07:14:26,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038465659 with entries=82, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038466956
2014-07-22 07:14:28,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:28,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48368 synced till here 48367
2014-07-22 07:14:28,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038466956 with entries=80, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038468262
2014-07-22 07:14:29,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:29,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48451 synced till here 48447
2014-07-22 07:14:29,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038468262 with entries=83, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038469079
2014-07-22 07:14:30,380 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:30,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48532 synced till here 48528
2014-07-22 07:14:31,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038469079 with entries=81, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038470380
2014-07-22 07:14:31,294 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,297 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,310 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,311 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,327 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,335 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,335 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,352 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,365 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,366 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,418 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,429 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,500 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,584 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,665 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,745 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,822 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:31,908 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:36,034 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.92 MB, free=3.95 GB, max=3.96 GB, blocks=9, accesses=680998, hits=83704, hitRatio=12.29%, , cachingAccesses=83740, cachingHits=83674, cachingHitsRatio=99.92%, evictions=0, evicted=57, evictedPerRun=Infinity
2014-07-22 07:14:36,294 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,297 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,311 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,311 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,327 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,336 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,337 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,352 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,366 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,366 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,419 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,429 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,500 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,585 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,666 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:36,745 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,822 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:14:36,909 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:14:41,295 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,298 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:14:41,311 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,311 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,328 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:14:41,336 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,337 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:14:41,352 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:14:41,366 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,366 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,419 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,430 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,675 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10010ms
2014-07-22 07:14:41,676 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10176ms
2014-07-22 07:14:41,676 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10092ms
2014-07-22 07:14:41,745 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:14:41,809 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8581, memsize=639.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/22542a6f8b8345979d99ae2bd454f3cc
2014-07-22 07:14:41,821 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/22542a6f8b8345979d99ae2bd454f3cc as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/22542a6f8b8345979d99ae2bd454f3cc
2014-07-22 07:14:41,823 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:14:41,837 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/22542a6f8b8345979d99ae2bd454f3cc, entries=2327880, sequenceid=8581, filesize=165.8m
2014-07-22 07:14:41,838 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~639.4m/670411200, currentsize=150.1m/157416000 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 28437ms, sequenceid=8581, compaction requested=true
2014-07-22 07:14:41,838 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:110), split_queue=0, merge_queue=0
2014-07-22 07:14:41,838 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10016ms
2014-07-22 07:14:41,838 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,838 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10093ms
2014-07-22 07:14:41,838 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 561.9m
2014-07-22 07:14:41,838 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,838 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10254ms
2014-07-22 07:14:41,839 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,839 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10339ms
2014-07-22 07:14:41,839 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,839 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10174ms
2014-07-22 07:14:41,839 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,842 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10413ms
2014-07-22 07:14:41,842 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,845 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10427ms
2014-07-22 07:14:41,845 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,847 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10482ms
2014-07-22 07:14:41,848 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,848 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10483ms
2014-07-22 07:14:41,848 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,849 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10497ms
2014-07-22 07:14:41,849 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,853 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10518ms
2014-07-22 07:14:41,853 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,853 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10518ms
2014-07-22 07:14:41,854 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,854 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10527ms
2014-07-22 07:14:41,854 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,857 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10547ms
2014-07-22 07:14:41,857 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,861 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10551ms
2014-07-22 07:14:41,861 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,861 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10564ms
2014-07-22 07:14:41,861 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,865 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10571ms
2014-07-22 07:14:41,865 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:41,869 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9961ms
2014-07-22 07:14:41,869 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:42,018 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038469911,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:42,142 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038469975,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:42,296 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12250,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038470046,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:42,325 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12213,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038470111,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:42,378 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038470239,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:42,400 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:14:42,487 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:42,518 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48617 synced till here 48607
2014-07-22 07:14:42,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038470380 with entries=85, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038482487
2014-07-22 07:14:42,607 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038333333
2014-07-22 07:14:42,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038334900
2014-07-22 07:14:42,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038335733
2014-07-22 07:14:42,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038337222
2014-07-22 07:14:42,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038341389
2014-07-22 07:14:42,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:42,680 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12506,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038470173,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:42,680 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12373,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038470306,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,523 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13148,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038470374,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,662 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12413,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471249,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,662 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471216,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,825 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12411,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471414,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:43,910 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12328,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471581,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,910 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12414,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471495,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,914 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471818,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,914 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471662,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,914 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12580,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471333,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,914 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471904,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48709 synced till here 48705
2014-07-22 07:14:43,934 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12193,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038471741,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:14:43,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038482487 with entries=92, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038483885
2014-07-22 07:14:43,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:45,016 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:14:45,305 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:45,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48813 synced till here 48811
2014-07-22 07:14:45,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038483885 with entries=104, filesize=82.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038485305
2014-07-22 07:14:45,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:47,129 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:47,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48896 synced till here 48893
2014-07-22 07:14:47,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038485305 with entries=83, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038487130
2014-07-22 07:14:47,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:48,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:48,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48982 synced till here 48975
2014-07-22 07:14:48,864 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038487130 with entries=86, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038488800
2014-07-22 07:14:48,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:48,899 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,901 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,937 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,938 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,940 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,966 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,966 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,966 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,967 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,980 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:48,981 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:49,031 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:49,061 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8638, memsize=560.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/d10ebaaf62434d8192f85139a6843d0b
2014-07-22 07:14:49,072 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/d10ebaaf62434d8192f85139a6843d0b as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/d10ebaaf62434d8192f85139a6843d0b
2014-07-22 07:14:49,080 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/d10ebaaf62434d8192f85139a6843d0b, entries=2041860, sequenceid=8638, filesize=145.4m
2014-07-22 07:14:49,081 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~560.8m/588040000, currentsize=149.6m/156863840 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 24747ms, sequenceid=8638, compaction requested=true
2014-07-22 07:14:49,081 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-22 07:14:49,081 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 50ms
2014-07-22 07:14:49,081 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,081 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 100ms
2014-07-22 07:14:49,081 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,081 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 603.4m
2014-07-22 07:14:49,081 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 101ms
2014-07-22 07:14:49,081 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,081 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 114ms
2014-07-22 07:14:49,081 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,082 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 116ms
2014-07-22 07:14:49,082 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,082 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 116ms
2014-07-22 07:14:49,082 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,082 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 116ms
2014-07-22 07:14:49,082 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,084 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 144ms
2014-07-22 07:14:49,086 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,086 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 148ms
2014-07-22 07:14:49,086 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,091 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 154ms
2014-07-22 07:14:49,091 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,091 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 190ms
2014-07-22 07:14:49,091 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:49,091 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 192ms
2014-07-22 07:14:49,092 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:14:50,471 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:14:50,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:51,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49122 synced till here 49110
2014-07-22 07:14:52,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038488800 with entries=140, filesize=111.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038490573
2014-07-22 07:14:52,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:52,410 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:14:52,731 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:52,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49208 synced till here 49201
2014-07-22 07:14:53,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038490573 with entries=86, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038492731
2014-07-22 07:14:53,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:54,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:54,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49291 synced till here 49287
2014-07-22 07:14:54,266 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038492731 with entries=83, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038494195
2014-07-22 07:14:54,266 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:55,811 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:14:55,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49375 synced till here 49369
2014-07-22 07:14:55,920 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,923 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,924 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,930 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038494195 with entries=84, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038495812
2014-07-22 07:14:55,930 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,930 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:14:55,946 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,968 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,988 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,990 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:55,998 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:56,009 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:56,009 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:56,009 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:56,031 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:56,125 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:56,222 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:57,249 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:57,277 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:14:57,344 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:00,921 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:00,923 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:00,924 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:00,930 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:00,947 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:00,968 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:00,988 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:00,990 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:00,998 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:01,009 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:01,010 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:01,010 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:01,031 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:01,125 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:01,222 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:02,250 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:02,277 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:02,344 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:05,922 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,924 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,925 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,931 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,947 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,969 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,988 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:05,991 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:15:05,998 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:06,010 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:15:06,010 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:06,011 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:15:06,031 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:15:06,125 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:15:06,223 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:06,766 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8679, memsize=561.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/9217512199af4cb89e979387f2f39edb
2014-07-22 07:15:06,776 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/9217512199af4cb89e979387f2f39edb as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9217512199af4cb89e979387f2f39edb
2014-07-22 07:15:06,784 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/9217512199af4cb89e979387f2f39edb, entries=2045780, sequenceid=8679, filesize=145.7m
2014-07-22 07:15:06,784 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~561.9m/589168400, currentsize=144.2m/151256160 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 24946ms, sequenceid=8679, compaction requested=true
2014-07-22 07:15:06,784 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:112), split_queue=0, merge_queue=0
2014-07-22 07:15:06,785 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10563ms
2014-07-22 07:15:06,785 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,785 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 592.4m
2014-07-22 07:15:06,785 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10660ms
2014-07-22 07:15:06,785 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,786 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10754ms
2014-07-22 07:15:06,786 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,786 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10777ms
2014-07-22 07:15:06,786 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,786 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10777ms
2014-07-22 07:15:06,786 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,792 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10783ms
2014-07-22 07:15:06,792 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,792 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10795ms
2014-07-22 07:15:06,792 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,793 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10803ms
2014-07-22 07:15:06,793 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,802 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10815ms
2014-07-22 07:15:06,802 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,809 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10841ms
2014-07-22 07:15:06,809 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,817 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10871ms
2014-07-22 07:15:06,817 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,817 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10887ms
2014-07-22 07:15:06,818 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,818 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10894ms
2014-07-22 07:15:06,818 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,818 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10895ms
2014-07-22 07:15:06,818 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,818 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10898ms
2014-07-22 07:15:06,818 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,833 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9489ms
2014-07-22 07:15:06,833 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,834 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9558ms
2014-07-22 07:15:06,834 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,842 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12661,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038494180,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:06,845 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9596ms
2014-07-22 07:15:06,845 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:06,998 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12750,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038494248,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,459 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038494313,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,724 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:15:07,725 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495177,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,732 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12342,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495390,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,732 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12598,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495134,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,738 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12494,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495244,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,753 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:15:07,810 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12497,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495313,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:07,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:07,925 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49461 synced till here 49455
2014-07-22 07:15:07,966 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12355,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495610,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:08,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038495812 with entries=86, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038507906
2014-07-22 07:15:08,001 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:08,122 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12401,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495721,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:08,234 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12380,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495853,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,032 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038496121,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,033 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12816,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038496217,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,033 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11691,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038497342,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,062 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038495943,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,062 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11816,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038497246,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,100 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11825,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038497275,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,147 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13123,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038496024,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:09,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:09,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49544 synced till here 49541
2014-07-22 07:15:09,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038507906 with entries=83, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038509169
2014-07-22 07:15:09,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:09,701 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:15:10,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:10,652 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49630 synced till here 49624
2014-07-22 07:15:10,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038509169 with entries=86, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038510613
2014-07-22 07:15:10,701 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:12,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:12,256 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038510613 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038512230
2014-07-22 07:15:12,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:12,789 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,798 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,807 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,818 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,824 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,826 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,852 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,860 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,892 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:12,953 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:13,017 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:13,081 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:13,146 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:14,074 DEBUG [RS_OPEN_META-slave1:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2014-07-22 07:15:14,082 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:14,109 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:14,173 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:14,191 INFO  [RS_OPEN_META-slave1:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406034912792.meta with entries=29, filesize=12.4k; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038514077.meta
2014-07-22 07:15:14,237 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:14,301 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:15,125 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 12949
2014-07-22 07:15:15,702 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19069, memsize=603.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/60966ba679444443bc7973df4882d8d6
2014-07-22 07:15:15,713 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/60966ba679444443bc7973df4882d8d6 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/60966ba679444443bc7973df4882d8d6
2014-07-22 07:15:15,724 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/60966ba679444443bc7973df4882d8d6, entries=2197150, sequenceid=19069, filesize=156.4m
2014-07-22 07:15:15,725 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~603.4m/632762000, currentsize=133.7m/140147680 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 26644ms, sequenceid=19069, compaction requested=true
2014-07-22 07:15:15,725 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:113), split_queue=0, merge_queue=0
2014-07-22 07:15:15,726 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 584.3m
2014-07-22 07:15:15,726 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1424ms
2014-07-22 07:15:15,726 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,726 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1489ms
2014-07-22 07:15:15,726 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,727 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1553ms
2014-07-22 07:15:15,727 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,727 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1618ms
2014-07-22 07:15:15,727 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,727 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1645ms
2014-07-22 07:15:15,727 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,728 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2582ms
2014-07-22 07:15:15,728 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,729 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2647ms
2014-07-22 07:15:15,729 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,729 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2712ms
2014-07-22 07:15:15,729 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,733 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2780ms
2014-07-22 07:15:15,733 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,734 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2841ms
2014-07-22 07:15:15,734 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,734 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2874ms
2014-07-22 07:15:15,735 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,735 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2883ms
2014-07-22 07:15:15,735 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,738 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2912ms
2014-07-22 07:15:15,739 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,739 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2915ms
2014-07-22 07:15:15,739 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,740 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2921ms
2014-07-22 07:15:15,740 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,740 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2933ms
2014-07-22 07:15:15,740 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,740 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2942ms
2014-07-22 07:15:15,740 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,741 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2952ms
2014-07-22 07:15:15,741 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:15,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:15,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49796 synced till here 49786
2014-07-22 07:15:15,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038512230 with entries=86, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038515870
2014-07-22 07:15:15,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:16,774 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:15:16,982 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:17,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49880 synced till here 49872
2014-07-22 07:15:17,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038515870 with entries=84, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038516982
2014-07-22 07:15:17,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:18,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:18,885 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50004 synced till here 50003
2014-07-22 07:15:19,260 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038516982 with entries=124, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038518437
2014-07-22 07:15:19,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:19,414 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:15:20,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:20,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50091 synced till here 50085
2014-07-22 07:15:20,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038518437 with entries=87, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038520554
2014-07-22 07:15:20,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:21,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:21,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50175 synced till here 50171
2014-07-22 07:15:22,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038520554 with entries=84, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038521963
2014-07-22 07:15:22,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:22,132 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,138 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,145 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,151 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,159 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,168 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,170 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,173 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,183 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,224 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,243 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,308 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,373 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,439 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:22,506 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:23,506 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:23,539 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:23,603 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:25,126 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 10205
2014-07-22 07:15:27,132 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,139 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,145 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,151 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,160 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,169 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,170 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,174 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,184 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,224 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,243 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,309 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:27,374 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,440 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:27,506 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:28,506 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:28,539 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:28,603 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:32,133 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,139 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,146 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,152 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,160 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,169 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,171 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,174 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,184 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,225 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,243 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:15:32,309 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,338 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19085, memsize=592.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/34fad0066cd2405b8ac764fb9e10c13d
2014-07-22 07:15:32,348 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/34fad0066cd2405b8ac764fb9e10c13d as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/34fad0066cd2405b8ac764fb9e10c13d
2014-07-22 07:15:32,359 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/34fad0066cd2405b8ac764fb9e10c13d, entries=2156750, sequenceid=19085, filesize=153.6m
2014-07-22 07:15:32,359 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~592.4m/621126320, currentsize=140.0m/146789440 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 25574ms, sequenceid=19085, compaction requested=true
2014-07-22 07:15:32,360 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:114), split_queue=0, merge_queue=0
2014-07-22 07:15:32,360 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10052ms
2014-07-22 07:15:32,360 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,360 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 587.1m
2014-07-22 07:15:32,360 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10117ms
2014-07-22 07:15:32,360 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,360 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10136ms
2014-07-22 07:15:32,361 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,361 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10178ms
2014-07-22 07:15:32,361 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,361 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10188ms
2014-07-22 07:15:32,361 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,365 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10195ms
2014-07-22 07:15:32,366 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,366 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10198ms
2014-07-22 07:15:32,366 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,366 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10207ms
2014-07-22 07:15:32,366 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,373 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10222ms
2014-07-22 07:15:32,373 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,374 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:15:32,374 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,381 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10237ms
2014-07-22 07:15:32,381 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,381 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10243ms
2014-07-22 07:15:32,381 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,382 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10249ms
2014-07-22 07:15:32,382 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,382 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8779ms
2014-07-22 07:15:32,383 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,383 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8844ms
2014-07-22 07:15:32,383 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,397 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8891ms
2014-07-22 07:15:32,397 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,398 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9891ms
2014-07-22 07:15:32,398 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,398 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9959ms
2014-07-22 07:15:32,398 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:32,718 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038520815,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:32,836 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11239,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038521596,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:32,836 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038521634,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:33,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:33,424 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:15:33,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50265 synced till here 50250
2014-07-22 07:15:33,603 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11861,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038521741,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:33,604 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11785,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038521819,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:33,613 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038521963 with entries=90, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038533413
2014-07-22 07:15:33,614 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:33,765 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038521889,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:33,823 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522022,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:33,875 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11920,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038521954,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,101 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522241,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,101 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522096,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,130 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522306,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:34,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50350 synced till here 50342
2014-07-22 07:15:34,266 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10728,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038523537,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,266 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11761,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522504,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,268 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12099,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522168,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,268 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038523601,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,268 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11830,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522437,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,268 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11897,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038522371,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:34,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038533413 with entries=85, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038534224
2014-07-22 07:15:34,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:35,120 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038523504,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:15:35,126 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 8652
2014-07-22 07:15:35,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:35,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50433 synced till here 50430
2014-07-22 07:15:35,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038534224 with entries=83, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038535704
2014-07-22 07:15:35,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:37,058 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:15:37,360 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:37,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50513 synced till here 50511
2014-07-22 07:15:37,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038535704 with entries=80, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038537360
2014-07-22 07:15:37,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=69, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:38,811 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:38,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50596 synced till here 50594
2014-07-22 07:15:38,875 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038537360 with entries=83, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038538812
2014-07-22 07:15:38,876 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=70, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:15:38,943 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,944 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,946 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,949 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,955 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,957 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,966 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,970 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,977 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:38,997 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:39,002 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:39,067 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:39,131 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:39,193 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:39,257 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:39,321 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:40,396 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:40,423 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:41,559 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19121, memsize=584.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/5cd72559982c4672a58fb949f4ded922
2014-07-22 07:15:41,567 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/5cd72559982c4672a58fb949f4ded922 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/5cd72559982c4672a58fb949f4ded922
2014-07-22 07:15:41,575 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/5cd72559982c4672a58fb949f4ded922, entries=2127360, sequenceid=19121, filesize=151.5m
2014-07-22 07:15:41,575 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~584.3m/612661600, currentsize=143.8m/150775680 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 25849ms, sequenceid=19121, compaction requested=true
2014-07-22 07:15:41,575 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:115), split_queue=0, merge_queue=0
2014-07-22 07:15:41,575 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1152ms
2014-07-22 07:15:41,576 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,576 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1181ms
2014-07-22 07:15:41,576 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 317.8m
2014-07-22 07:15:41,576 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,576 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2256ms
2014-07-22 07:15:41,576 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,589 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2332ms
2014-07-22 07:15:41,589 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,589 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2396ms
2014-07-22 07:15:41,590 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,590 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2459ms
2014-07-22 07:15:41,590 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,590 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2523ms
2014-07-22 07:15:41,591 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,600 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2598ms
2014-07-22 07:15:41,601 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,601 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2604ms
2014-07-22 07:15:41,601 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,601 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2624ms
2014-07-22 07:15:41,601 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,604 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2634ms
2014-07-22 07:15:41,604 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,604 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2638ms
2014-07-22 07:15:41,604 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,604 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2647ms
2014-07-22 07:15:41,605 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,605 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2650ms
2014-07-22 07:15:41,605 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,605 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2656ms
2014-07-22 07:15:41,605 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,606 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2659ms
2014-07-22 07:15:41,606 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,606 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2663ms
2014-07-22 07:15:41,607 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,607 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2664ms
2014-07-22 07:15:41,607 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:41,947 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:15:42,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:42,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50683 synced till here 50674
2014-07-22 07:15:42,256 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038538812 with entries=87, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038542131
2014-07-22 07:15:43,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:43,646 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50770 synced till here 50764
2014-07-22 07:15:43,711 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038542131 with entries=87, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038543628
2014-07-22 07:15:45,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:45,127 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 14455
2014-07-22 07:15:45,293 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:15:46,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50879 synced till here 50875
2014-07-22 07:15:46,321 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038543628 with entries=109, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038545047
2014-07-22 07:15:47,036 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:47,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50967 synced till here 50958
2014-07-22 07:15:48,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038545047 with entries=88, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038547037
2014-07-22 07:15:48,466 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,466 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,466 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,468 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,471 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,473 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,490 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,490 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,491 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,517 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,518 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,519 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,526 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,540 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,604 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,669 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,732 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:48,796 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:53,466 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,466 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,466 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,469 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:53,471 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,474 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:53,490 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,491 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:53,492 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:53,517 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,518 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,519 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,526 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,540 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:53,605 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:15:53,669 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,733 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:53,796 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:15:55,126 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 19678
2014-07-22 07:15:55,516 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8874, memsize=317.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/78ecfe1e3ede4250b821feae12b927c8
2014-07-22 07:15:55,525 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/78ecfe1e3ede4250b821feae12b927c8 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/78ecfe1e3ede4250b821feae12b927c8
2014-07-22 07:15:55,533 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/78ecfe1e3ede4250b821feae12b927c8, entries=1157030, sequenceid=8874, filesize=82.4m
2014-07-22 07:15:55,534 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~317.8m/333193120, currentsize=21.1m/22076080 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 13958ms, sequenceid=8874, compaction requested=true
2014-07-22 07:15:55,534 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:116), split_queue=0, merge_queue=0
2014-07-22 07:15:55,534 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6738ms
2014-07-22 07:15:55,534 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,534 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6802ms
2014-07-22 07:15:55,534 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 647.4m
2014-07-22 07:15:55,534 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,535 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6866ms
2014-07-22 07:15:55,535 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,537 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6933ms
2014-07-22 07:15:55,537 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,537 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6998ms
2014-07-22 07:15:55,538 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,541 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7015ms
2014-07-22 07:15:55,541 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,545 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7026ms
2014-07-22 07:15:55,546 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,546 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7028ms
2014-07-22 07:15:55,546 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,546 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7029ms
2014-07-22 07:15:55,546 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,546 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7055ms
2014-07-22 07:15:55,546 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,549 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7059ms
2014-07-22 07:15:55,549 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,549 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7059ms
2014-07-22 07:15:55,550 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,561 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7088ms
2014-07-22 07:15:55,561 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,561 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7090ms
2014-07-22 07:15:55,562 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,563 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7095ms
2014-07-22 07:15:55,563 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,566 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7099ms
2014-07-22 07:15:55,566 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,566 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7100ms
2014-07-22 07:15:55,566 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,567 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7101ms
2014-07-22 07:15:55,567 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:15:55,814 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:55,988 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51051 synced till here 51046
2014-07-22 07:15:56,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038547037 with entries=84, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038555814
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038342709
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038354129
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038355035
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038356232
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038357772
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038359319
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038361116
2014-07-22 07:15:56,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038362721
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038364329
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038365712
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038367516
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038371957
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038373273
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038385912
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038387116
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038388528
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038390142
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038390868
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038397656
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038401622
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038402971
2014-07-22 07:15:56,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038404511
2014-07-22 07:15:56,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038406134
2014-07-22 07:15:56,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038412350
2014-07-22 07:15:56,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038413828
2014-07-22 07:15:56,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038414775
2014-07-22 07:15:56,341 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:15:56,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:56,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51136 synced till here 51134
2014-07-22 07:15:56,785 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038555814 with entries=85, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038556734
2014-07-22 07:15:58,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:15:58,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51220 synced till here 51216
2014-07-22 07:15:58,191 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038556734 with entries=84, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038558131
2014-07-22 07:15:58,294 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,295 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,315 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,321 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,343 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,344 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,344 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,348 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,350 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,364 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:58,377 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,263 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,290 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,353 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,417 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,480 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,544 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:15:59,607 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:00,069 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19158, memsize=587.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/cdce83efd79946da926a40c9cc5cd9aa
2014-07-22 07:16:00,082 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/cdce83efd79946da926a40c9cc5cd9aa as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/cdce83efd79946da926a40c9cc5cd9aa
2014-07-22 07:16:00,095 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/cdce83efd79946da926a40c9cc5cd9aa, entries=2137710, sequenceid=19158, filesize=152.2m
2014-07-22 07:16:00,095 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~587.1m/615644480, currentsize=178.4m/187050560 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 27735ms, sequenceid=19158, compaction requested=true
2014-07-22 07:16:00,095 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-22 07:16:00,096 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 489ms
2014-07-22 07:16:00,096 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 617.0m
2014-07-22 07:16:00,096 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,096 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 552ms
2014-07-22 07:16:00,096 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,097 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 616ms
2014-07-22 07:16:00,097 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,097 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 681ms
2014-07-22 07:16:00,097 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,098 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 745ms
2014-07-22 07:16:00,099 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,099 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 809ms
2014-07-22 07:16:00,099 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,099 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 836ms
2014-07-22 07:16:00,099 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,105 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1728ms
2014-07-22 07:16:00,105 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,106 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1742ms
2014-07-22 07:16:00,106 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,106 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1756ms
2014-07-22 07:16:00,106 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,121 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1773ms
2014-07-22 07:16:00,121 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,122 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1777ms
2014-07-22 07:16:00,122 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,122 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1778ms
2014-07-22 07:16:00,122 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,123 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1779ms
2014-07-22 07:16:00,123 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,123 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1802ms
2014-07-22 07:16:00,123 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,124 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1808ms
2014-07-22 07:16:00,124 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,124 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1829ms
2014-07-22 07:16:00,124 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,124 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1830ms
2014-07-22 07:16:00,125 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:00,418 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:16:00,678 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:00,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:00,713 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51305 synced till here 51296
2014-07-22 07:16:00,831 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038558131 with entries=85, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038560695
2014-07-22 07:16:00,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038416045
2014-07-22 07:16:00,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038425605
2014-07-22 07:16:00,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038427357
2014-07-22 07:16:00,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038428106
2014-07-22 07:16:00,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038429824
2014-07-22 07:16:00,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038431341
2014-07-22 07:16:02,332 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:02,347 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51395 synced till here 51385
2014-07-22 07:16:02,442 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038560695 with entries=90, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038562332
2014-07-22 07:16:03,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:03,840 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51485 synced till here 51475
2014-07-22 07:16:03,921 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038562332 with entries=90, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038563817
2014-07-22 07:16:05,127 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 22205
2014-07-22 07:16:05,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:05,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038563817 with entries=88, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038565229
2014-07-22 07:16:06,780 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,783 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:06,800 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,806 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51654 synced till here 51650
2014-07-22 07:16:06,819 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,840 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,840 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,863 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038565229 with entries=81, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038566798
2014-07-22 07:16:06,874 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,883 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:06,938 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:07,002 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:07,066 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:07,129 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:07,194 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:07,257 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:07,320 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:11,780 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,783 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,801 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:11,806 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,819 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,840 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,840 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,863 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,874 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,883 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:11,939 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:12,003 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:12,067 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:12,130 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:12,194 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:12,258 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:12,320 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:15,214 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 13744
2014-07-22 07:16:16,781 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:16,784 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,801 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:16,807 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,819 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,841 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,841 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:16,863 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,874 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,883 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:16,939 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:17,003 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:17,067 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:17,130 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:17,195 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:17,258 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:17,321 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:21,782 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:16:21,784 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:21,801 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:21,807 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:21,820 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:21,841 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:21,842 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-22 07:16:21,864 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:21,875 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-22 07:16:21,883 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-22 07:16:21,939 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,003 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,067 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,131 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,195 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,258 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,302 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19247, memsize=647.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/cc6512f0edf048a0ac76ffd438556894
2014-07-22 07:16:22,311 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/cc6512f0edf048a0ac76ffd438556894 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/cc6512f0edf048a0ac76ffd438556894
2014-07-22 07:16:22,321 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-22 07:16:22,838 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/cc6512f0edf048a0ac76ffd438556894, entries=2357160, sequenceid=19247, filesize=167.8m
2014-07-22 07:16:22,839 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~647.4m/678844160, currentsize=111.2m/116645760 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 27305ms, sequenceid=19247, compaction requested=true
2014-07-22 07:16:22,839 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-22 07:16:22,839 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15519ms
2014-07-22 07:16:22,840 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,840 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 608.4m
2014-07-22 07:16:22,841 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15584ms
2014-07-22 07:16:22,841 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,841 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15647ms
2014-07-22 07:16:22,842 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,842 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15713ms
2014-07-22 07:16:22,842 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,842 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15776ms
2014-07-22 07:16:22,842 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,843 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/4eb94d53323e4646aac6bdd114e5dc79 as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/4eb94d53323e4646aac6bdd114e5dc79
2014-07-22 07:16:22,845 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15843ms
2014-07-22 07:16:22,845 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,846 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15907ms
2014-07-22 07:16:22,846 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,847 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15963ms
2014-07-22 07:16:22,847 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,847 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15973ms
2014-07-22 07:16:22,847 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,847 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15984ms
2014-07-22 07:16:22,847 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,847 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16007ms
2014-07-22 07:16:22,847 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,847 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16007ms
2014-07-22 07:16:22,847 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,861 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16042ms
2014-07-22 07:16:22,861 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,861 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16055ms
2014-07-22 07:16:22,861 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,865 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16065ms
2014-07-22 07:16:22,865 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,866 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16083ms
2014-07-22 07:16:22,866 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,866 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16086ms
2014-07-22 07:16:22,866 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:22,878 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:16:22,893 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/02ce2fb6f04e44c2a342336cd7a12783, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/02ce2fb6f04e44c2a342336cd7a12783
2014-07-22 07:16:22,897 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/95c1c4f39c2642e5a08b8b73448092ae, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/95c1c4f39c2642e5a08b8b73448092ae
2014-07-22 07:16:22,900 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/00f6d33998674401839b3ae62fa5521c, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/00f6d33998674401839b3ae62fa5521c
2014-07-22 07:16:22,903 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/42ab5240f0084e7db74ce55fe06584d3, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/42ab5240f0084e7db74ce55fe06584d3
2014-07-22 07:16:22,906 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/8c042cefef50456196f097646bea6225, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/8c042cefef50456196f097646bea6225
2014-07-22 07:16:22,908 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/56ebd5ce142f4191b60194ef3c8fe744, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/56ebd5ce142f4191b60194ef3c8fe744
2014-07-22 07:16:22,913 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/5a9a8906c7a34a01ae2e02d0e0199167, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/5a9a8906c7a34a01ae2e02d0e0199167
2014-07-22 07:16:22,914 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17025,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038565888,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:22,918 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6c69f1e18641455ca4f78f0c8fea49fe, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/6c69f1e18641455ca4f78f0c8fea49fe
2014-07-22 07:16:22,922 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/4f8d04600c5d4ac392d0888c939fea01, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/4f8d04600c5d4ac392d0888c939fea01
2014-07-22 07:16:22,926 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/c41798491fc74568830862894e016796, to hdfs://master:54310/hbase/archive/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/c41798491fc74568830862894e016796
2014-07-22 07:16:22,926 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. into 4eb94d53323e4646aac6bdd114e5dc79(size=646.5m), total size for store is 3.5g. This selection was in queue for 0sec, and took 2mins, 14sec to execute.
2014-07-22 07:16:22,927 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., storeName=family, fileCount=10, fileSize=731.3m, priority=1978, time=135428651896395; duration=2mins, 14sec
2014-07-22 07:16:22,927 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-22 07:16:22,927 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 2000 blocking
2014-07-22 07:16:22,929 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1379471074 starting at candidate #2 after considering 124 permutations with 91 in ratio
2014-07-22 07:16:22,929 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 9fefab8f11c8e58bf455cb6ad77b765c - family: Initiating minor compaction
2014-07-22 07:16:22,929 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:16:22,930 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp, totalSize=1.3g
2014-07-22 07:16:22,930 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/a93d44377bc14801bf4ca2bad5572628, keycount=153983, bloomtype=ROW, size=109.7m, encoding=NONE, seqNum=3858
2014-07-22 07:16:22,930 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/4882bf7a2c3b40a2948cf0d2ea032397, keycount=883517, bloomtype=ROW, size=629.3m, encoding=NONE, seqNum=8195
2014-07-22 07:16:22,930 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/d292b381c1f14bf186b0460426280367, keycount=105872, bloomtype=ROW, size=75.4m, encoding=NONE, seqNum=8695
2014-07-22 07:16:22,930 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/71a95375fa85497fba3f5f3d7db11df3, keycount=98472, bloomtype=ROW, size=70.1m, encoding=NONE, seqNum=9207
2014-07-22 07:16:22,930 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3bae8a7b79d84068bed5795b80db58cb, keycount=138159, bloomtype=ROW, size=98.4m, encoding=NONE, seqNum=9791
2014-07-22 07:16:22,931 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/03858644134e4df7b435aaba4bd9d0fe, keycount=119657, bloomtype=ROW, size=85.2m, encoding=NONE, seqNum=10382
2014-07-22 07:16:22,931 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/aa47e61d44994378a37717573f7370c7, keycount=103721, bloomtype=ROW, size=73.8m, encoding=NONE, seqNum=10986
2014-07-22 07:16:22,931 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/69604728e239407a8668dd5af18d1d34, keycount=90416, bloomtype=ROW, size=64.4m, encoding=NONE, seqNum=11191
2014-07-22 07:16:22,931 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/1ab8253e1fd947daa42b003703f25997, keycount=96029, bloomtype=ROW, size=68.4m, encoding=NONE, seqNum=11606
2014-07-22 07:16:22,931 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/fd2ce35f53a746e6a016678942461d35, keycount=57185, bloomtype=ROW, size=40.8m, encoding=NONE, seqNum=11997
2014-07-22 07:16:23,093 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8979, memsize=617.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/653e26c3f987485e80ec729c22747c06
2014-07-22 07:16:23,098 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:23,105 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/653e26c3f987485e80ec729c22747c06 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/653e26c3f987485e80ec729c22747c06
2014-07-22 07:16:23,125 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/653e26c3f987485e80ec729c22747c06, entries=2246570, sequenceid=8979, filesize=159.9m
2014-07-22 07:16:23,126 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~617.0m/646994320, currentsize=71.8m/75301840 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 23030ms, sequenceid=8979, compaction requested=true
2014-07-22 07:16:23,126 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-22 07:16:23,126 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 536.6m
2014-07-22 07:16:23,312 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16947,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566364,"queuetimems":378,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:23,312 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566398,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:23,493 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:16:23,498 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:23,656 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:23,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51740 synced till here 51731
2014-07-22 07:16:23,703 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17103,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566600,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:23,703 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566462,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:23,704 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17168,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566535,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:23,726 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17061,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566665,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:23,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038566798 with entries=86, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038583656
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038432882
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038438127
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038439502
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038441082
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038441816
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038453472
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038454971
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038456530
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038458244
2014-07-22 07:16:23,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038460208
2014-07-22 07:16:23,810 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:24,462 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17721,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566740,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,698 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17379,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038567318,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,698 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17570,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038567127,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,698 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038567000,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,699 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17895,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566804,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,699 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17508,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038567191,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,777 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17840,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566936,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,809 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17553,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038567255,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,809 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17937,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038566871,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,809 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038567064,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:24,955 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:24,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51825 synced till here 51823
2014-07-22 07:16:25,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038583656 with entries=85, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038584955
2014-07-22 07:16:26,049 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 10824
2014-07-22 07:16:26,444 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:26,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51908 synced till here 51902
2014-07-22 07:16:26,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038584955 with entries=83, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038586444
2014-07-22 07:16:28,098 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:28,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51992 synced till here 51988
2014-07-22 07:16:28,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038586444 with entries=84, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038588098
2014-07-22 07:16:29,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:29,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52077 synced till here 52072
2014-07-22 07:16:29,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038588098 with entries=85, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038589549
2014-07-22 07:16:31,282 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:31,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52162 synced till here 52153
2014-07-22 07:16:31,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038589549 with entries=85, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038591282
2014-07-22 07:16:32,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:32,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52247 synced till here 52242
2014-07-22 07:16:32,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038591282 with entries=85, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038592884
2014-07-22 07:16:34,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:34,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52333 synced till here 52328
2014-07-22 07:16:34,520 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038592884 with entries=86, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038594432
2014-07-22 07:16:36,087 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 20238
2014-07-22 07:16:36,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:36,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52412 synced till here 52408
2014-07-22 07:16:36,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038594432 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038596148
2014-07-22 07:16:36,761 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:36,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52494 synced till here 52491
2014-07-22 07:16:36,801 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:16:36,809 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038596148 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038596761
2014-07-22 07:16:37,945 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,946 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,965 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,974 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,986 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,987 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,988 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,988 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:37,995 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,002 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,008 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,050 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,114 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,179 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,243 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,308 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:38,386 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:16:42,945 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:42,947 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:42,965 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:42,974 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:42,988 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:42,988 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:42,988 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:42,989 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:42,995 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:43,002 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:43,008 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:43,051 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:43,115 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:43,179 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:43,244 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:43,309 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:16:43,386 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:16:46,088 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 15008
2014-07-22 07:16:47,946 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:47,947 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:47,965 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:47,975 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:47,988 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:16:47,988 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:47,989 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:47,989 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:47,996 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,003 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,010 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,051 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,115 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,180 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:16:48,244 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,309 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:16:48,386 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:16:48,446 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9028, memsize=539.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/b5b16536edc6479dbccbc173bc179618
2014-07-22 07:16:48,455 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/b5b16536edc6479dbccbc173bc179618 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b5b16536edc6479dbccbc173bc179618
2014-07-22 07:16:48,462 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/b5b16536edc6479dbccbc173bc179618, entries=1964930, sequenceid=9028, filesize=139.9m
2014-07-22 07:16:48,462 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~539.7m/565883280, currentsize=147.3m/154420160 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 25336ms, sequenceid=9028, compaction requested=true
2014-07-22 07:16:48,463 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-22 07:16:48,463 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10077ms
2014-07-22 07:16:48,463 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,463 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10155ms
2014-07-22 07:16:48,463 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,463 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 23.2k
2014-07-22 07:16:48,463 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10220ms
2014-07-22 07:16:48,463 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,463 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10285ms
2014-07-22 07:16:48,464 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,464 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10350ms
2014-07-22 07:16:48,464 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,464 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10414ms
2014-07-22 07:16:48,464 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,465 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10457ms
2014-07-22 07:16:48,465 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,466 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:48,466 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10464ms
2014-07-22 07:16:48,466 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,469 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10475ms
2014-07-22 07:16:48,469 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,469 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10481ms
2014-07-22 07:16:48,470 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,470 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10482ms
2014-07-22 07:16:48,470 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,470 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10483ms
2014-07-22 07:16:48,470 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,478 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10492ms
2014-07-22 07:16:48,478 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,478 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10504ms
2014-07-22 07:16:48,478 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,478 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10513ms
2014-07-22 07:16:48,478 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,478 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10532ms
2014-07-22 07:16:48,478 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,478 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10533ms
2014-07-22 07:16:48,479 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:16:48,503 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11942,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038596561,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:48,504 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7470, memsize=16.1k, hasBloomFilter=false, into tmp file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/f132381b8ad04f7abd617458f2887787
2014-07-22 07:16:48,516 INFO  [MemStoreFlusher.0] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for f132381b8ad04f7abd617458f2887787
2014-07-22 07:16:48,518 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12039,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038596479,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:48,519 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/f132381b8ad04f7abd617458f2887787 as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/f132381b8ad04f7abd617458f2887787
2014-07-22 07:16:48,533 INFO  [MemStoreFlusher.0] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for f132381b8ad04f7abd617458f2887787
2014-07-22 07:16:48,533 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/f132381b8ad04f7abd617458f2887787, entries=68, sequenceid=7470, filesize=8.6k
2014-07-22 07:16:48,534 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~23.2k/23808, currentsize=0.0/0 for region hbase:meta,,1.1588230740 in 71ms, sequenceid=7470, compaction requested=false
2014-07-22 07:16:48,534 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 611.7m
2014-07-22 07:16:48,664 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038596632,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:48,874 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:48,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52582 synced till here 52574
2014-07-22 07:16:48,960 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038596761 with entries=88, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038608875
2014-07-22 07:16:49,065 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12339,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038596725,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:49,065 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038596796,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:49,842 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:49,910 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038597785,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,035 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038597645,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,035 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12323,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038597711,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,050 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12201,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038597848,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,182 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12266,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038597916,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:50,242 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11859,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038598382,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,306 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12065,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038598241,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,398 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12413,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038597984,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,398 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12349,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038598048,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,445 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038598305,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,488 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12375,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038598112,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:50,517 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12340,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038598176,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:16:51,644 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:16:51,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52743 synced till here 52741
2014-07-22 07:16:51,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038608875 with entries=161, filesize=125.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038610221
2014-07-22 07:16:53,319 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9031, memsize=608.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/4873f9383a3848af8298948258d62922
2014-07-22 07:16:53,337 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/4873f9383a3848af8298948258d62922 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4873f9383a3848af8298948258d62922
2014-07-22 07:16:53,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:53,346 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/4873f9383a3848af8298948258d62922, entries=2215250, sequenceid=9031, filesize=157.7m
2014-07-22 07:16:53,346 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~608.4m/637974880, currentsize=200.6m/210300560 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 30506ms, sequenceid=9031, compaction requested=true
2014-07-22 07:16:53,346 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-22 07:16:53,347 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 591.1m
2014-07-22 07:16:53,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52824 synced till here 52821
2014-07-22 07:16:53,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038610221 with entries=81, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038613340
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038461721
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038465659
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038466956
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038468262
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038469079
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038470380
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038482487
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038483885
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038485305
2014-07-22 07:16:53,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038487130
2014-07-22 07:16:53,846 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:16:53,962 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:53,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52905 synced till here 52903
2014-07-22 07:16:53,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038613340 with entries=81, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038613962
2014-07-22 07:16:55,374 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:55,391 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52987 synced till here 52983
2014-07-22 07:16:55,447 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038613962 with entries=82, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038615375
2014-07-22 07:16:56,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:57,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53072 synced till here 53067
2014-07-22 07:16:57,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038615375 with entries=85, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038616968
2014-07-22 07:16:58,599 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:16:58,788 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:16:58,803 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53154 synced till here 53150
2014-07-22 07:16:58,840 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038616968 with entries=82, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038618788
2014-07-22 07:16:58,878 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:17:00,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:00,354 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53237 synced till here 53235
2014-07-22 07:17:00,387 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038618788 with entries=83, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038620321
2014-07-22 07:17:01,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:01,958 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53318 synced till here 53314
2014-07-22 07:17:01,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038620321 with entries=81, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038621937
2014-07-22 07:17:02,168 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,208 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,217 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,362 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,441 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,527 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,611 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,689 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,769 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,836 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,901 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:02,987 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:04,036 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:04,062 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:04,124 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:04,188 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:04,252 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:07,169 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,208 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:07,217 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:07,363 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,442 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,527 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:07,612 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,690 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,770 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,837 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,901 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:07,987 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:09,036 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:09,062 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:09,124 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:09,317 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5065ms
2014-07-22 07:17:09,317 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5129ms
2014-07-22 07:17:12,169 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,209 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:12,218 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,363 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,442 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,528 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:12,612 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,691 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,770 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,837 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,902 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:12,987 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:14,037 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:14,063 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:17:14,124 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:14,317 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10065ms
2014-07-22 07:17:14,318 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10130ms
2014-07-22 07:17:15,971 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19471, memsize=622.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/23408cc2c8994baf924329fd8b02796c
2014-07-22 07:17:15,980 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/23408cc2c8994baf924329fd8b02796c as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/23408cc2c8994baf924329fd8b02796c
2014-07-22 07:17:15,987 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/23408cc2c8994baf924329fd8b02796c, entries=2266460, sequenceid=19471, filesize=161.4m
2014-07-22 07:17:15,988 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~622.5m/652722480, currentsize=119.7m/125469360 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 27454ms, sequenceid=19471, compaction requested=true
2014-07-22 07:17:15,988 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:121), split_queue=0, merge_queue=0
2014-07-22 07:17:15,988 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11800ms
2014-07-22 07:17:15,988 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:15,988 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 612.2m
2014-07-22 07:17:15,988 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11736ms
2014-07-22 07:17:15,988 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:15,988 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11864ms
2014-07-22 07:17:15,989 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:15,989 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11928ms
2014-07-22 07:17:15,989 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:15,989 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11953ms
2014-07-22 07:17:15,989 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:15,989 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13002ms
2014-07-22 07:17:15,989 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,001 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13101ms
2014-07-22 07:17:16,001 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,006 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13170ms
2014-07-22 07:17:16,006 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,006 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13237ms
2014-07-22 07:17:16,006 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,009 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13320ms
2014-07-22 07:17:16,009 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,010 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13399ms
2014-07-22 07:17:16,010 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,010 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13483ms
2014-07-22 07:17:16,010 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,011 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13569ms
2014-07-22 07:17:16,011 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,011 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13649ms
2014-07-22 07:17:16,011 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,011 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13794ms
2014-07-22 07:17:16,011 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,011 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13803ms
2014-07-22 07:17:16,011 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,021 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13853ms
2014-07-22 07:17:16,021 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:16,042 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14522,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038621520,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:16,219 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14669,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038621550,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:16,489 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038621678,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:16,608 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:17:16,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:16,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53401 synced till here 53393
2014-07-22 07:17:16,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038621937 with entries=83, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038636614
2014-07-22 07:17:16,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038488800
2014-07-22 07:17:16,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038490573
2014-07-22 07:17:16,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038492731
2014-07-22 07:17:16,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038494195
2014-07-22 07:17:17,738 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13678,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038624059,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:17,818 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13632,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038624186,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:17,826 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038624122,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:17,954 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:17,969 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15445,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622523,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:17,970 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15205,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622764,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:17,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53486 synced till here 53482
2014-07-22 07:17:17,995 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038636614 with entries=85, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038637954
2014-07-22 07:17:18,024 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15125,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622899,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,024 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13991,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038624033,"queuetimems":969,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,025 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15338,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622686,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,025 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622834,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,024 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15587,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622437,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,025 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15416,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622608,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,025 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15667,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622357,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,025 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15046,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038622978,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,025 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13774,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038624250,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:18,271 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19467, memsize=591.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/9d2efa7574944f23a5fbdbb0f6cab462
2014-07-22 07:17:18,280 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/9d2efa7574944f23a5fbdbb0f6cab462 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9d2efa7574944f23a5fbdbb0f6cab462
2014-07-22 07:17:18,287 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9d2efa7574944f23a5fbdbb0f6cab462, entries=2152090, sequenceid=19467, filesize=153.2m
2014-07-22 07:17:18,288 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~591.1m/619783760, currentsize=118.2m/123905520 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 24941ms, sequenceid=19467, compaction requested=true
2014-07-22 07:17:18,288 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-22 07:17:18,288 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 572.1m
2014-07-22 07:17:19,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:19,357 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53570 synced till here 53567
2014-07-22 07:17:19,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038637954 with entries=84, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038639340
2014-07-22 07:17:19,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038495812
2014-07-22 07:17:19,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038507906
2014-07-22 07:17:19,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038509169
2014-07-22 07:17:19,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038510613
2014-07-22 07:17:19,444 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:17:20,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:20,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53659 synced till here 53650
2014-07-22 07:17:21,310 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038639340 with entries=89, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038640782
2014-07-22 07:17:22,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:22,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53742 synced till here 53734
2014-07-22 07:17:22,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038640782 with entries=83, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038642875
2014-07-22 07:17:24,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:25,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53896 synced till here 53892
2014-07-22 07:17:25,925 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038642875 with entries=154, filesize=120.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038644277
2014-07-22 07:17:26,710 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:26,730 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53980 synced till here 53970
2014-07-22 07:17:27,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038644277 with entries=84, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038646710
2014-07-22 07:17:28,426 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:28,444 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54067 synced till here 54062
2014-07-22 07:17:28,509 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038646710 with entries=87, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038648427
2014-07-22 07:17:29,500 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:17:30,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:30,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54149 synced till here 54144
2014-07-22 07:17:30,112 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038648427 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038650047
2014-07-22 07:17:31,231 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,232 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,233 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,235 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,264 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,266 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,270 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,276 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,300 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,300 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,307 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,317 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,383 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,447 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,511 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,575 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:31,637 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:36,231 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,232 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,233 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:36,235 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,264 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,267 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:36,270 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,276 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,300 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,300 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,307 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,318 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:36,384 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:17:36,447 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,511 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,575 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:36,637 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:17:41,325 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10007ms
2014-07-22 07:17:41,325 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10093ms
2014-07-22 07:17:41,326 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10094ms
2014-07-22 07:17:41,326 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10094ms
2014-07-22 07:17:41,326 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10091ms
2014-07-22 07:17:41,326 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10060ms
2014-07-22 07:17:41,327 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10062ms
2014-07-22 07:17:41,327 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10057ms
2014-07-22 07:17:41,327 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10027ms
2014-07-22 07:17:41,327 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10051ms
2014-07-22 07:17:41,328 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10028ms
2014-07-22 07:17:41,328 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10021ms
2014-07-22 07:17:41,384 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:41,448 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:17:41,511 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:41,575 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:41,638 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:17:42,767 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19517, memsize=612.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/95cfa00329a849a6901d6b20a1e78f44
2014-07-22 07:17:42,777 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/95cfa00329a849a6901d6b20a1e78f44 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/95cfa00329a849a6901d6b20a1e78f44
2014-07-22 07:17:42,787 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/95cfa00329a849a6901d6b20a1e78f44, entries=2229060, sequenceid=19517, filesize=158.7m
2014-07-22 07:17:42,788 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~612.2m/641952800, currentsize=147.8m/155006480 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 26799ms, sequenceid=19517, compaction requested=true
2014-07-22 07:17:42,788 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-22 07:17:42,788 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11151ms
2014-07-22 07:17:42,788 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,788 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 544.2m
2014-07-22 07:17:42,788 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11213ms
2014-07-22 07:17:42,788 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,788 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11277ms
2014-07-22 07:17:42,789 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,789 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11342ms
2014-07-22 07:17:42,789 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,789 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11406ms
2014-07-22 07:17:42,789 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,794 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11487ms
2014-07-22 07:17:42,794 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,797 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11497ms
2014-07-22 07:17:42,798 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,798 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11522ms
2014-07-22 07:17:42,798 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,798 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11498ms
2014-07-22 07:17:42,798 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,798 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11528ms
2014-07-22 07:17:42,799 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,809 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11545ms
2014-07-22 07:17:42,809 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,809 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11543ms
2014-07-22 07:17:42,809 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,825 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11590ms
2014-07-22 07:17:42,825 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,826 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11594ms
2014-07-22 07:17:42,826 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,829 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11598ms
2014-07-22 07:17:42,829 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,830 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11598ms
2014-07-22 07:17:42,830 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:42,830 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11513ms
2014-07-22 07:17:42,830 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:17:43,005 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13225,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038649779,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,005 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13391,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038649613,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,007 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13306,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038649700,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,246 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038649862,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:43,317 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54233 synced till here 54228
2014-07-22 07:17:43,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038650047 with entries=84, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038663276
2014-07-22 07:17:43,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038512230
2014-07-22 07:17:43,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038515870
2014-07-22 07:17:43,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038516982
2014-07-22 07:17:43,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038518437
2014-07-22 07:17:43,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038520554
2014-07-22 07:17:43,403 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13461,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038649941,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,403 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:17:43,567 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13400,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038650166,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,568 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13547,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038650021,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:43,627 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13527,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038650100,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,126 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13028,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651098,"queuetimems":3,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,161 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:17:44,354 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19529, memsize=572.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/1690adbab9684200aff6332024c4353c
2014-07-22 07:17:44,367 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/1690adbab9684200aff6332024c4353c as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/1690adbab9684200aff6332024c4353c
2014-07-22 07:17:44,379 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/1690adbab9684200aff6332024c4353c, entries=2082960, sequenceid=19529, filesize=148.3m
2014-07-22 07:17:44,379 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~572.1m/599876240, currentsize=136.8m/143469280 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 26091ms, sequenceid=19529, compaction requested=true
2014-07-22 07:17:44,379 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-22 07:17:44,379 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 520.6m
2014-07-22 07:17:44,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:44,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54322 synced till here 54314
2014-07-22 07:17:44,597 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038663276 with entries=89, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038664531
2014-07-22 07:17:44,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038521963
2014-07-22 07:17:44,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038533413
2014-07-22 07:17:44,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038534224
2014-07-22 07:17:44,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038535704
2014-07-22 07:17:44,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038537360
2014-07-22 07:17:44,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:44,690 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13377,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651313,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,690 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13487,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651203,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,692 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651381,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,692 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13566,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651125,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,692 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651572,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,745 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13235,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651509,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,745 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13299,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651445,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:44,745 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13109,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038651635,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:17:45,452 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:17:45,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:45,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038664531 with entries=86, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038665844
2014-07-22 07:17:45,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:47,261 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:47,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54489 synced till here 54486
2014-07-22 07:17:47,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038665844 with entries=81, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038667261
2014-07-22 07:17:47,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:48,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:49,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54602 synced till here 54598
2014-07-22 07:17:49,069 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038667261 with entries=113, filesize=90.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038668715
2014-07-22 07:17:49,070 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:50,374 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:50,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54684 synced till here 54681
2014-07-22 07:17:50,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038668715 with entries=82, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038670375
2014-07-22 07:17:50,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:51,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:51,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54774 synced till here 54763
2014-07-22 07:17:54,800 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038670375 with entries=90, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038671822
2014-07-22 07:17:54,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:55,292 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:17:55,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:55,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54857 synced till here 54850
2014-07-22 07:17:55,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038671822 with entries=83, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038675397
2014-07-22 07:17:55,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:56,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:17:56,798 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54938 synced till here 54936
2014-07-22 07:17:56,840 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038675397 with entries=81, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038676768
2014-07-22 07:17:56,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:17:58,186 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:17:58,190 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,191 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,199 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,218 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,227 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,230 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,231 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,237 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,858 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,924 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:58,991 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:59,058 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:59,127 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:59,193 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:59,260 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:59,326 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:17:59,393 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:03,190 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,191 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,199 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,218 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,227 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,231 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:03,231 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,237 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:03,859 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:03,925 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:03,991 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:04,059 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:04,127 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:04,194 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:04,260 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:04,327 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:04,394 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:06,365 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19599, memsize=544.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/c86d35eb86914edabb1a734bfb2903e0
2014-07-22 07:18:06,375 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/c86d35eb86914edabb1a734bfb2903e0 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/c86d35eb86914edabb1a734bfb2903e0
2014-07-22 07:18:06,383 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/c86d35eb86914edabb1a734bfb2903e0, entries=1981540, sequenceid=19599, filesize=141.2m
2014-07-22 07:18:06,383 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~544.2m/570666880, currentsize=146.1m/153165760 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 23595ms, sequenceid=19599, compaction requested=true
2014-07-22 07:18:06,383 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:125), split_queue=0, merge_queue=0
2014-07-22 07:18:06,384 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6991ms
2014-07-22 07:18:06,384 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,384 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 579.3m
2014-07-22 07:18:06,384 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7058ms
2014-07-22 07:18:06,384 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,384 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7124ms
2014-07-22 07:18:06,384 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,385 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7191ms
2014-07-22 07:18:06,385 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,385 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7258ms
2014-07-22 07:18:06,385 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,385 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7327ms
2014-07-22 07:18:06,385 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,388 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7398ms
2014-07-22 07:18:06,388 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,397 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7473ms
2014-07-22 07:18:06,397 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,398 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7540ms
2014-07-22 07:18:06,398 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,402 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8166ms
2014-07-22 07:18:06,402 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,403 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8171ms
2014-07-22 07:18:06,403 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,403 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8173ms
2014-07-22 07:18:06,403 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,404 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8177ms
2014-07-22 07:18:06,404 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,411 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8193ms
2014-07-22 07:18:06,411 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,419 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8220ms
2014-07-22 07:18:06,419 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,420 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8228ms
2014-07-22 07:18:06,420 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,421 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8230ms
2014-07-22 07:18:06,421 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:06,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:06,595 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55031 synced till here 55020
2014-07-22 07:18:06,842 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038676768 with entries=93, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038686566
2014-07-22 07:18:06,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:07,032 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038676936,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:07,117 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038677069,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:07,137 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:18:07,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:07,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55116 synced till here 55108
2014-07-22 07:18:07,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038686566 with entries=85, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038687651
2014-07-22 07:18:07,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:08,552 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038678225,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:08,769 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9322, memsize=530.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b3fac95d3a1b4ad09fa86fbcb1c280f0
2014-07-22 07:18:08,780 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b3fac95d3a1b4ad09fa86fbcb1c280f0 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b3fac95d3a1b4ad09fa86fbcb1c280f0
2014-07-22 07:18:08,790 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b3fac95d3a1b4ad09fa86fbcb1c280f0, entries=1930320, sequenceid=9322, filesize=137.5m
2014-07-22 07:18:08,790 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~530.2m/555916800, currentsize=147.8m/155014560 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 24411ms, sequenceid=9322, compaction requested=true
2014-07-22 07:18:08,790 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-22 07:18:08,791 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 602.7m
2014-07-22 07:18:08,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:08,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55205 synced till here 55204
2014-07-22 07:18:09,026 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038687651 with entries=89, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038688961
2014-07-22 07:18:09,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:10,017 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:18:10,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:10,407 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55288 synced till here 55285
2014-07-22 07:18:10,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038688961 with entries=83, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038690391
2014-07-22 07:18:10,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:11,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:12,020 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55373 synced till here 55366
2014-07-22 07:18:12,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038690391 with entries=85, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038691978
2014-07-22 07:18:12,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:13,807 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:13,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55464 synced till here 55456
2014-07-22 07:18:13,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038691978 with entries=91, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038693807
2014-07-22 07:18:13,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:15,392 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:18:15,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:15,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55586 synced till here 55580
2014-07-22 07:18:15,819 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038693807 with entries=122, filesize=93.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038695423
2014-07-22 07:18:15,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:17,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:17,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55669 synced till here 55664
2014-07-22 07:18:17,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038695423 with entries=83, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038697390
2014-07-22 07:18:17,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:17,590 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:18:19,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:19,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55753 synced till here 55749
2014-07-22 07:18:19,106 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038697390 with entries=84, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038699050
2014-07-22 07:18:19,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:19,216 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,220 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,228 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,247 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,260 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,260 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,262 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,274 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,275 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,286 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,287 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,324 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,389 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,453 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:19,517 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:24,217 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,220 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:24,228 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:24,247 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:24,260 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:24,261 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,262 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,275 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,275 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,287 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,287 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,325 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:24,389 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:24,454 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:24,518 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:29,217 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,221 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,228 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:18:29,247 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:18:29,260 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:18:29,261 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,263 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,275 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,275 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,287 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,288 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:18:29,325 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,389 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:18:29,454 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:29,518 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:31,959 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9405, memsize=579.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7a318aa909a04938bdbe214e9e074dc8
2014-07-22 07:18:31,971 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7a318aa909a04938bdbe214e9e074dc8 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7a318aa909a04938bdbe214e9e074dc8
2014-07-22 07:18:31,980 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7a318aa909a04938bdbe214e9e074dc8, entries=2109330, sequenceid=9405, filesize=150.2m
2014-07-22 07:18:31,980 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~579.3m/607469920, currentsize=130.3m/136649760 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 25596ms, sequenceid=9405, compaction requested=true
2014-07-22 07:18:31,981 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:127), split_queue=0, merge_queue=0
2014-07-22 07:18:31,981 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12464ms
2014-07-22 07:18:31,981 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,981 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 544.6m
2014-07-22 07:18:31,981 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12528ms
2014-07-22 07:18:31,982 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,982 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12593ms
2014-07-22 07:18:31,982 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,982 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12658ms
2014-07-22 07:18:31,982 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,982 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12696ms
2014-07-22 07:18:31,982 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,982 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12696ms
2014-07-22 07:18:31,982 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,983 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12708ms
2014-07-22 07:18:31,983 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,984 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12710ms
2014-07-22 07:18:31,984 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,985 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12724ms
2014-07-22 07:18:31,985 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,986 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12725ms
2014-07-22 07:18:31,986 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,997 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12737ms
2014-07-22 07:18:31,997 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,998 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12751ms
2014-07-22 07:18:31,998 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,998 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12770ms
2014-07-22 07:18:31,998 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:31,998 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12778ms
2014-07-22 07:18:31,998 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:32,001 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12785ms
2014-07-22 07:18:32,001 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:32,135 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038697417,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,300 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038697714,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,303 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14679,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038697623,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,345 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038698717,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,524 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13835,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038698688,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,524 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038698850,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,570 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13785,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038698785,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,585 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:18:32,591 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:32,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55832 synced till here 55830
2014-07-22 07:18:32,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038699050 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038712591
2014-07-22 07:18:32,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:32,713 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:18:32,744 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13716,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699027,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:32,914 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13817,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699097,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,007 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13555,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699451,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,044 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13528,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699515,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,072 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699256,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,093 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13925,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699168,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,108 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699387,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,125 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038699322,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:33,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:33,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55913 synced till here 55911
2014-07-22 07:18:33,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038712591 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038713792
2014-07-22 07:18:33,831 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:35,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:35,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55994 synced till here 55991
2014-07-22 07:18:35,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038713792 with entries=81, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038715223
2014-07-22 07:18:35,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:35,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:35,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038715223 with entries=82, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038715885
2014-07-22 07:18:35,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:36,999 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9418, memsize=604.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/5288155c4bf14389a8746ab67fb768f6
2014-07-22 07:18:37,012 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/5288155c4bf14389a8746ab67fb768f6 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5288155c4bf14389a8746ab67fb768f6
2014-07-22 07:18:37,022 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/5288155c4bf14389a8746ab67fb768f6, entries=2200220, sequenceid=9418, filesize=156.7m
2014-07-22 07:18:37,023 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~604.3m/633645360, currentsize=159.7m/167443440 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 28232ms, sequenceid=9418, compaction requested=true
2014-07-22 07:18:37,023 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:128), split_queue=0, merge_queue=0
2014-07-22 07:18:37,024 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 568.7m
2014-07-22 07:18:37,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:37,319 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56160 synced till here 56159
2014-07-22 07:18:37,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038715885 with entries=84, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038717296
2014-07-22 07:18:37,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:37,531 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:18:38,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:38,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56243 synced till here 56237
2014-07-22 07:18:38,760 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038717296 with entries=83, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038718691
2014-07-22 07:18:38,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:40,280 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:40,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56324 synced till here 56323
2014-07-22 07:18:40,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038718691 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038720281
2014-07-22 07:18:40,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:41,804 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:41,862 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56408 synced till here 56405
2014-07-22 07:18:41,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038720281 with entries=84, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038721805
2014-07-22 07:18:41,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:43,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:43,483 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56490 synced till here 56488
2014-07-22 07:18:43,518 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038721805 with entries=82, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038723445
2014-07-22 07:18:43,519 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:43,651 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:18:45,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:45,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56573 synced till here 56565
2014-07-22 07:18:45,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038723445 with entries=83, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038725162
2014-07-22 07:18:45,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:18:45,462 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,463 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,477 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,491 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,507 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,524 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,525 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,525 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,532 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,537 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,551 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,639 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,722 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:45,800 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:18:50,463 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,464 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,477 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:50,492 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,508 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,525 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,525 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,525 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:50,533 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,537 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:50,552 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:50,639 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:50,722 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:18:50,800 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:18:55,463 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,464 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,478 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:18:55,492 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,509 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,525 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,525 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,526 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,534 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-22 07:18:55,538 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:18:55,552 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,640 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,723 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:55,800 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:18:56,449 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19824, memsize=544.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/eb34631d3f794003909f639524e73f72
2014-07-22 07:18:56,463 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/eb34631d3f794003909f639524e73f72 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/eb34631d3f794003909f639524e73f72
2014-07-22 07:18:56,479 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/eb34631d3f794003909f639524e73f72, entries=1982890, sequenceid=19824, filesize=141.3m
2014-07-22 07:18:56,480 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~544.6m/571056400, currentsize=142.2m/149134320 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 24499ms, sequenceid=19824, compaction requested=true
2014-07-22 07:18:56,480 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:129), split_queue=0, merge_queue=0
2014-07-22 07:18:56,480 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10681ms
2014-07-22 07:18:56,480 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,481 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 310.0m
2014-07-22 07:18:56,481 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10759ms
2014-07-22 07:18:56,481 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,481 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10842ms
2014-07-22 07:18:56,481 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,481 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10930ms
2014-07-22 07:18:56,481 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,489 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10952ms
2014-07-22 07:18:56,489 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,489 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10957ms
2014-07-22 07:18:56,490 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,490 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10965ms
2014-07-22 07:18:56,490 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,490 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10966ms
2014-07-22 07:18:56,490 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,501 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10977ms
2014-07-22 07:18:56,501 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,501 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10994ms
2014-07-22 07:18:56,501 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,502 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11011ms
2014-07-22 07:18:56,502 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,502 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11025ms
2014-07-22 07:18:56,503 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,504 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11041ms
2014-07-22 07:18:56,504 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,505 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12729,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038723775,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,513 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11051ms
2014-07-22 07:18:56,513 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:18:56,536 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12830,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038723705,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,539 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12897,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038723641,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,673 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038723841,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,820 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11839,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038724980,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,832 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:18:56,855 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12947,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038723906,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,930 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11978,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038724952,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:56,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:57,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56660 synced till here 56654
2014-07-22 07:18:57,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038725162 with entries=87, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038736980
2014-07-22 07:18:57,761 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:18:57,788 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725292,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:57,788 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12428,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725360,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:57,906 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725457,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:57,970 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12423,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725546,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:57,970 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12254,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725715,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:58,014 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12217,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725796,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:58,016 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12381,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038725634,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:18:58,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:58,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56743 synced till here 56740
2014-07-22 07:18:58,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038736980 with entries=83, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038738174
2014-07-22 07:18:59,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:18:59,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038738174 with entries=79, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038739649
2014-07-22 07:19:01,072 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:01,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56906 synced till here 56902
2014-07-22 07:19:01,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038739649 with entries=84, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038741072
2014-07-22 07:19:02,507 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,508 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,512 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,513 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,526 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,526 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,531 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,535 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:02,560 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,561 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,562 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,572 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56985 synced till here 56983
2014-07-22 07:19:02,591 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,593 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:02,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038741072 with entries=79, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038742555
2014-07-22 07:19:02,617 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:03,248 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19837, memsize=570.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/25232c0eec024975abde4b6ed2d3bbe2
2014-07-22 07:19:03,266 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/25232c0eec024975abde4b6ed2d3bbe2 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/25232c0eec024975abde4b6ed2d3bbe2
2014-07-22 07:19:03,279 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/25232c0eec024975abde4b6ed2d3bbe2, entries=2076110, sequenceid=19837, filesize=147.9m
2014-07-22 07:19:03,279 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~570.2m/597903600, currentsize=147.7m/154847280 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 26256ms, sequenceid=19837, compaction requested=true
2014-07-22 07:19:03,280 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-22 07:19:03,280 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 663ms
2014-07-22 07:19:03,280 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,280 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 687ms
2014-07-22 07:19:03,280 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 628.4m
2014-07-22 07:19:03,280 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,280 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 689ms
2014-07-22 07:19:03,280 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,280 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 718ms
2014-07-22 07:19:03,280 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,281 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 721ms
2014-07-22 07:19:03,281 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,281 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 722ms
2014-07-22 07:19:03,282 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,282 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 747ms
2014-07-22 07:19:03,282 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,282 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 751ms
2014-07-22 07:19:03,282 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,282 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 756ms
2014-07-22 07:19:03,282 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,292 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 766ms
2014-07-22 07:19:03,292 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,292 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 779ms
2014-07-22 07:19:03,292 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,292 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 780ms
2014-07-22 07:19:03,292 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,292 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 784ms
2014-07-22 07:19:03,293 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:03,293 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 786ms
2014-07-22 07:19:03,293 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:04,585 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:19:04,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:04,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57068 synced till here 57066
2014-07-22 07:19:04,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038742555 with entries=83, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038744705
2014-07-22 07:19:06,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:06,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57152 synced till here 57150
2014-07-22 07:19:06,154 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038744705 with entries=84, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038746081
2014-07-22 07:19:07,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:07,723 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57234 synced till here 57227
2014-07-22 07:19:07,779 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038746081 with entries=82, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038747706
2014-07-22 07:19:08,124 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:19:09,244 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:09,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57318 synced till here 57310
2014-07-22 07:19:09,318 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038747706 with entries=84, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038749244
2014-07-22 07:19:09,745 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,749 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,757 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,765 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,773 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,779 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,787 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,792 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,797 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,806 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,861 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:09,924 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:10,863 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:10,891 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:12,675 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9540, memsize=310.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/aa830d67b73f43a38578afe78f0efa3d
2014-07-22 07:19:12,685 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/aa830d67b73f43a38578afe78f0efa3d as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/aa830d67b73f43a38578afe78f0efa3d
2014-07-22 07:19:12,694 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/aa830d67b73f43a38578afe78f0efa3d, entries=1128670, sequenceid=9540, filesize=80.4m
2014-07-22 07:19:12,694 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~310.0m/325029360, currentsize=40.6m/42605680 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 16214ms, sequenceid=9540, compaction requested=true
2014-07-22 07:19:12,695 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-22 07:19:12,695 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1804ms
2014-07-22 07:19:12,695 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,695 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 665.3m
2014-07-22 07:19:12,695 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1832ms
2014-07-22 07:19:12,695 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,695 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2771ms
2014-07-22 07:19:12,695 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,695 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2834ms
2014-07-22 07:19:12,695 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,696 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2889ms
2014-07-22 07:19:12,696 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,697 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2900ms
2014-07-22 07:19:12,697 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,702 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2909ms
2014-07-22 07:19:12,702 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,702 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2915ms
2014-07-22 07:19:12,702 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,703 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2924ms
2014-07-22 07:19:12,703 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,703 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2930ms
2014-07-22 07:19:12,703 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,703 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2938ms
2014-07-22 07:19:12,704 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,706 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2949ms
2014-07-22 07:19:12,706 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,706 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2957ms
2014-07-22 07:19:12,706 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,706 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2961ms
2014-07-22 07:19:12,706 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:12,903 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:12,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57405 synced till here 57404
2014-07-22 07:19:12,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038749244 with entries=87, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038752903
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038538812
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038542131
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038543628
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038545047
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038547037
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038555814
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038556734
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038558131
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038560695
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038562332
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038563817
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038565229
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038566798
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038583656
2014-07-22 07:19:12,966 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038584955
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038586444
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038588098
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038589549
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038591282
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038592884
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038594432
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038596148
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038596761
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038608875
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038610221
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038613340
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038613962
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038615375
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038616968
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038618788
2014-07-22 07:19:12,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038620321
2014-07-22 07:19:13,276 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:19:14,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:14,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57526 synced till here 57518
2014-07-22 07:19:14,645 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038752903 with entries=121, filesize=95.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038754363
2014-07-22 07:19:16,108 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,126 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,146 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,165 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,166 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,192 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,196 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,196 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,196 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,217 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,217 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,217 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,256 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:16,320 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:21,109 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:21,127 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:21,147 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,166 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:21,166 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,192 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,196 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,197 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,197 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:21,217 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,217 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:21,218 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:21,257 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:21,320 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:26,109 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,127 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,147 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,166 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,167 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,193 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,197 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:19:26,197 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,197 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,217 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:19:26,217 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:19:26,218 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,257 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:26,321 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:19:29,312 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19924, memsize=628.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/373dd3ce7cca45dfa5cf8ef06e851bf6
2014-07-22 07:19:29,324 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/373dd3ce7cca45dfa5cf8ef06e851bf6 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/373dd3ce7cca45dfa5cf8ef06e851bf6
2014-07-22 07:19:29,332 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/373dd3ce7cca45dfa5cf8ef06e851bf6, entries=2287920, sequenceid=19924, filesize=162.9m
2014-07-22 07:19:29,332 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~628.4m/658901760, currentsize=107.1m/112346640 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 26052ms, sequenceid=19924, compaction requested=true
2014-07-22 07:19:29,332 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:132), split_queue=0, merge_queue=0
2014-07-22 07:19:29,333 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13013ms
2014-07-22 07:19:29,333 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,333 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13077ms
2014-07-22 07:19:29,333 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 587.3m
2014-07-22 07:19:29,333 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,333 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13116ms
2014-07-22 07:19:29,333 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,333 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13116ms
2014-07-22 07:19:29,333 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,333 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13116ms
2014-07-22 07:19:29,333 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,334 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13138ms
2014-07-22 07:19:29,334 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,337 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13141ms
2014-07-22 07:19:29,337 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,345 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13149ms
2014-07-22 07:19:29,345 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,349 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13157ms
2014-07-22 07:19:29,349 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,349 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13183ms
2014-07-22 07:19:29,349 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,349 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13184ms
2014-07-22 07:19:29,350 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,350 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13204ms
2014-07-22 07:19:29,350 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,350 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13224ms
2014-07-22 07:19:29,350 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,350 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13242ms
2014-07-22 07:19:29,350 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:29,399 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:29,403 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14937,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038754464,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:29,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57607 synced till here 57604
2014-07-22 07:19:29,470 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038754363 with entries=81, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038769399
2014-07-22 07:19:29,470 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038621937
2014-07-22 07:19:29,470 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038636614
2014-07-22 07:19:29,475 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14846,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038754628,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:29,603 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:19:29,883 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15089,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038754793,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:29,952 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15229,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038754722,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:29,952 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14217,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038755734,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:29,967 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038755764,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,009 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14174,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038755834,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,076 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14154,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038755921,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,134 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:19:30,302 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038755989,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,374 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14317,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038756056,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:30,468 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57691 synced till here 57685
2014-07-22 07:19:30,528 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038769399 with entries=84, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038770446
2014-07-22 07:19:30,661 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038756189,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,661 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14536,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038756124,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,661 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14406,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038756254,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:30,667 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14348,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038756318,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:31,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:31,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57782 synced till here 57774
2014-07-22 07:19:32,042 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038770446 with entries=91, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038771964
2014-07-22 07:19:33,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:33,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57865 synced till here 57860
2014-07-22 07:19:33,648 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038771964 with entries=83, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038773566
2014-07-22 07:19:35,115 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:35,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57950 synced till here 57949
2014-07-22 07:19:35,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038773566 with entries=85, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038775115
2014-07-22 07:19:36,501 DEBUG [LruStats #0] hfile.LruBlockCache: Total=6.24 MB, free=3.95 GB, max=3.96 GB, blocks=21, accesses=766921, hits=115971, hitRatio=15.12%, , cachingAccesses=116015, cachingHits=115925, cachingHitsRatio=99.92%, evictions=0, evicted=69, evictedPerRun=Infinity
2014-07-22 07:19:36,701 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:36,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58033 synced till here 58031
2014-07-22 07:19:36,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038775115 with entries=83, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038776701
2014-07-22 07:19:36,791 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,793 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,799 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,845 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,854 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,854 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,856 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,869 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,869 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,870 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,882 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,907 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:36,969 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:39,184 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19960, memsize=665.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/e61f2c9fe054462ebe9167b36fa4cf3c
2014-07-22 07:19:39,198 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/e61f2c9fe054462ebe9167b36fa4cf3c as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e61f2c9fe054462ebe9167b36fa4cf3c
2014-07-22 07:19:39,211 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/e61f2c9fe054462ebe9167b36fa4cf3c, entries=2422420, sequenceid=19960, filesize=172.5m
2014-07-22 07:19:39,211 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~665.3m/697636960, currentsize=111.0m/116377840 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 26516ms, sequenceid=19960, compaction requested=true
2014-07-22 07:19:39,212 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-22 07:19:39,212 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2243ms
2014-07-22 07:19:39,212 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,212 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 639.4m
2014-07-22 07:19:39,212 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2305ms
2014-07-22 07:19:39,212 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,213 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2330ms
2014-07-22 07:19:39,213 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,213 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2343ms
2014-07-22 07:19:39,214 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,214 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2345ms
2014-07-22 07:19:39,214 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,226 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2357ms
2014-07-22 07:19:39,226 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,226 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2370ms
2014-07-22 07:19:39,227 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,227 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2373ms
2014-07-22 07:19:39,228 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,229 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2374ms
2014-07-22 07:19:39,229 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,229 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2384ms
2014-07-22 07:19:39,229 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,233 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2434ms
2014-07-22 07:19:39,233 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,234 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2440ms
2014-07-22 07:19:39,234 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:39,234 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2443ms
2014-07-22 07:19:39,234 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:40,367 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:19:40,425 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:40,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58114 synced till here 58113
2014-07-22 07:19:40,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038776701 with entries=81, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038780425
2014-07-22 07:19:40,480 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038637954
2014-07-22 07:19:40,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038639340
2014-07-22 07:19:40,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038640782
2014-07-22 07:19:40,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038642875
2014-07-22 07:19:40,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038644277
2014-07-22 07:19:40,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038646710
2014-07-22 07:19:40,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038648427
2014-07-22 07:19:41,903 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:41,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58198 synced till here 58194
2014-07-22 07:19:41,964 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038780425 with entries=84, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038781903
2014-07-22 07:19:43,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:43,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58279 synced till here 58275
2014-07-22 07:19:43,341 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038781903 with entries=81, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038783281
2014-07-22 07:19:44,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:44,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58358 synced till here 58357
2014-07-22 07:19:44,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038783281 with entries=79, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038784704
2014-07-22 07:19:46,111 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:46,133 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58439 synced till here 58438
2014-07-22 07:19:46,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038784704 with entries=81, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038786111
2014-07-22 07:19:46,538 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:19:46,747 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,747 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,766 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,767 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,773 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,795 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,797 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,797 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,797 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,805 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,859 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:46,922 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:47,965 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:19:51,747 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:51,748 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:51,767 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:51,767 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:51,773 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:51,796 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:51,797 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:51,798 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:51,798 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:51,805 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:51,860 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:51,923 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:19:52,966 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:19:56,158 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19980, memsize=587.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/c9d88f7e1a404b81bb41e6bc0a417376
2014-07-22 07:19:56,176 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/c9d88f7e1a404b81bb41e6bc0a417376 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/c9d88f7e1a404b81bb41e6bc0a417376
2014-07-22 07:19:56,185 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/c9d88f7e1a404b81bb41e6bc0a417376, entries=2138500, sequenceid=19980, filesize=152.3m
2014-07-22 07:19:56,186 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~587.3m/615870960, currentsize=157.6m/165210400 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 26853ms, sequenceid=19980, compaction requested=true
2014-07-22 07:19:56,186 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-22 07:19:56,186 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8221ms
2014-07-22 07:19:56,187 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,187 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 599.2m
2014-07-22 07:19:56,187 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9265ms
2014-07-22 07:19:56,187 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,187 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9328ms
2014-07-22 07:19:56,187 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,187 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9382ms
2014-07-22 07:19:56,187 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,201 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9404ms
2014-07-22 07:19:56,201 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,201 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9404ms
2014-07-22 07:19:56,202 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,202 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9405ms
2014-07-22 07:19:56,202 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,202 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9407ms
2014-07-22 07:19:56,202 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,202 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9429ms
2014-07-22 07:19:56,203 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,203 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9437ms
2014-07-22 07:19:56,203 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,208 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9442ms
2014-07-22 07:19:56,208 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,208 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9461ms
2014-07-22 07:19:56,208 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,208 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9462ms
2014-07-22 07:19:56,208 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:19:56,234 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10064,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786170,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:56,346 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:56,361 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58524 synced till here 58519
2014-07-22 07:19:56,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038786111 with entries=85, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038796347
2014-07-22 07:19:56,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038650047
2014-07-22 07:19:56,410 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786079,"queuetimems":578,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:56,414 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10178,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786235,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:56,678 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10286,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786391,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:56,772 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:19:57,341 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10876,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786464,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,342 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10811,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786530,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,467 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786666,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,467 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10868,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786598,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,470 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10738,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786732,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,522 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:57,548 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58606 synced till here 58602
2014-07-22 07:19:57,587 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786793,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038796347 with entries=82, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038797522
2014-07-22 07:19:57,622 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10764,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786857,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:57,645 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10724,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038786920,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:19:58,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:19:58,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58690 synced till here 58686
2014-07-22 07:19:59,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038797522 with entries=84, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038798951
2014-07-22 07:20:00,548 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:00,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58775 synced till here 58771
2014-07-22 07:20:00,632 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038798951 with entries=85, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038800548
2014-07-22 07:20:02,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:02,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58859 synced till here 58857
2014-07-22 07:20:02,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038800548 with entries=84, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038802138
2014-07-22 07:20:02,379 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:20:02,615 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,616 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,637 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,659 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,659 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,659 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,661 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,666 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,670 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,672 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,729 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,794 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:02,859 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:07,127 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9737, memsize=639.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/ae84393e2646478283ea5b5c7c956f67
2014-07-22 07:20:07,137 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/ae84393e2646478283ea5b5c7c956f67 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/ae84393e2646478283ea5b5c7c956f67
2014-07-22 07:20:07,145 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/ae84393e2646478283ea5b5c7c956f67, entries=2328100, sequenceid=9737, filesize=165.8m
2014-07-22 07:20:07,146 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~639.4m/670473920, currentsize=150.6m/157905520 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 27934ms, sequenceid=9737, compaction requested=true
2014-07-22 07:20:07,146 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:135), split_queue=0, merge_queue=0
2014-07-22 07:20:07,146 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 642.7m
2014-07-22 07:20:07,147 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4287ms
2014-07-22 07:20:07,147 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,147 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4353ms
2014-07-22 07:20:07,147 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,148 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4419ms
2014-07-22 07:20:07,148 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,148 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4476ms
2014-07-22 07:20:07,148 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,155 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4485ms
2014-07-22 07:20:07,155 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,156 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4490ms
2014-07-22 07:20:07,156 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,156 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4495ms
2014-07-22 07:20:07,156 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,156 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4497ms
2014-07-22 07:20:07,156 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,156 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4497ms
2014-07-22 07:20:07,157 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,157 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4498ms
2014-07-22 07:20:07,158 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,158 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4521ms
2014-07-22 07:20:07,158 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,161 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4545ms
2014-07-22 07:20:07,161 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,163 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4547ms
2014-07-22 07:20:07,163 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:07,350 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:07,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58938 synced till here 58937
2014-07-22 07:20:07,391 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038802138 with entries=79, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038807350
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038663276
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038664531
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038665844
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038667261
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038668715
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038670375
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038671822
2014-07-22 07:20:07,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038675397
2014-07-22 07:20:08,413 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:20:08,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:08,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59019 synced till here 59015
2014-07-22 07:20:08,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038807350 with entries=81, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038808530
2014-07-22 07:20:09,821 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:20:10,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:10,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59101 synced till here 59097
2014-07-22 07:20:10,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038808530 with entries=82, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038810014
2014-07-22 07:20:11,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:11,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59182 synced till here 59180
2014-07-22 07:20:11,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038810014 with entries=81, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038811502
2014-07-22 07:20:12,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:12,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59263 synced till here 59262
2014-07-22 07:20:12,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038811502 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038812952
2014-07-22 07:20:13,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:13,650 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59346 synced till here 59341
2014-07-22 07:20:13,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038812952 with entries=83, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038813623
2014-07-22 07:20:14,492 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,492 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,519 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,521 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,521 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,523 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,525 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,553 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,556 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,556 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,558 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,594 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:14,676 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:19,493 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,493 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:19,519 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,521 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,522 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:19,523 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:19,525 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,553 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,556 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,557 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:19,558 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,594 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:19,676 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:22,983 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9794, memsize=599.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/125768e84195455aa7b082cafd8fa5f0
2014-07-22 07:20:23,020 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/125768e84195455aa7b082cafd8fa5f0 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/125768e84195455aa7b082cafd8fa5f0
2014-07-22 07:20:23,340 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/125768e84195455aa7b082cafd8fa5f0, entries=2181630, sequenceid=9794, filesize=155.4m
2014-07-22 07:20:23,341 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~599.2m/628293200, currentsize=150.5m/157862720 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 27154ms, sequenceid=9794, compaction requested=true
2014-07-22 07:20:23,341 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-22 07:20:23,341 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8666ms
2014-07-22 07:20:23,341 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,342 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 619.8m
2014-07-22 07:20:23,343 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8748ms
2014-07-22 07:20:23,343 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,343 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8785ms
2014-07-22 07:20:23,343 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,344 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8787ms
2014-07-22 07:20:23,344 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,344 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8788ms
2014-07-22 07:20:23,344 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,345 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8791ms
2014-07-22 07:20:23,345 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,345 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8820ms
2014-07-22 07:20:23,345 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,347 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8825ms
2014-07-22 07:20:23,347 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,353 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8832ms
2014-07-22 07:20:23,353 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,354 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8833ms
2014-07-22 07:20:23,354 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,363 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8844ms
2014-07-22 07:20:23,363 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,365 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8873ms
2014-07-22 07:20:23,365 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,366 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8874ms
2014-07-22 07:20:23,366 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:23,439 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10236,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813201,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:23,543 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813272,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:23,638 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813348,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:23,867 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10452,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813414,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,028 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10545,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813482,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,068 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:24,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59426 synced till here 59420
2014-07-22 07:20:24,143 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:20:24,158 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038813623 with entries=80, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038824069
2014-07-22 07:20:24,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038676768
2014-07-22 07:20:24,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038686566
2014-07-22 07:20:24,282 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10734,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813547,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,434 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038814388,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,459 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10105,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038814353,"queuetimems":661,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,481 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10860,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038813620,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,481 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10027,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038814453,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:24,577 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10053,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038814523,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:25,409 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:25,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59511 synced till here 59508
2014-07-22 07:20:25,469 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038824069 with entries=85, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038825410
2014-07-22 07:20:25,648 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:20:26,050 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:26,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59591 synced till here 59589
2014-07-22 07:20:26,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038825410 with entries=80, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038826051
2014-07-22 07:20:27,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:27,351 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59673 synced till here 59670
2014-07-22 07:20:27,398 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038826051 with entries=82, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038827329
2014-07-22 07:20:29,155 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:29,184 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59756 synced till here 59751
2014-07-22 07:20:29,239 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038827329 with entries=83, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038829155
2014-07-22 07:20:30,224 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/ae2d44d8dd364c068fb85d91623aa91f as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ae2d44d8dd364c068fb85d91623aa91f
2014-07-22 07:20:30,267 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:20:30,281 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/a93d44377bc14801bf4ca2bad5572628, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/a93d44377bc14801bf4ca2bad5572628
2014-07-22 07:20:30,284 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/4882bf7a2c3b40a2948cf0d2ea032397, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/4882bf7a2c3b40a2948cf0d2ea032397
2014-07-22 07:20:30,287 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/d292b381c1f14bf186b0460426280367, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/d292b381c1f14bf186b0460426280367
2014-07-22 07:20:30,291 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/71a95375fa85497fba3f5f3d7db11df3, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/71a95375fa85497fba3f5f3d7db11df3
2014-07-22 07:20:30,294 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3bae8a7b79d84068bed5795b80db58cb, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/3bae8a7b79d84068bed5795b80db58cb
2014-07-22 07:20:30,298 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/03858644134e4df7b435aaba4bd9d0fe, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/03858644134e4df7b435aaba4bd9d0fe
2014-07-22 07:20:30,301 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/aa47e61d44994378a37717573f7370c7, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/aa47e61d44994378a37717573f7370c7
2014-07-22 07:20:30,302 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,302 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,303 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,304 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/69604728e239407a8668dd5af18d1d34, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/69604728e239407a8668dd5af18d1d34
2014-07-22 07:20:30,308 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/1ab8253e1fd947daa42b003703f25997, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/1ab8253e1fd947daa42b003703f25997
2014-07-22 07:20:30,311 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/fd2ce35f53a746e6a016678942461d35, to hdfs://master:54310/hbase/archive/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/fd2ce35f53a746e6a016678942461d35
2014-07-22 07:20:30,311 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. into ae2d44d8dd364c068fb85d91623aa91f(size=1.2g), total size for store is 3.8g. This selection was in queue for 0sec, and took 4mins, 7sec to execute.
2014-07-22 07:20:30,311 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., storeName=family, fileCount=10, fileSize=1.3g, priority=1979, time=135563319835333; duration=4mins, 7sec
2014-07-22 07:20:30,312 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-22 07:20:30,313 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 2000 blocking
2014-07-22 07:20:30,315 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1537851618 starting at candidate #11 after considering 124 permutations with 96 in ratio
2014-07-22 07:20:30,315 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 5688494b49c628b8cf95eecd57a989f3 - family: Initiating minor compaction
2014-07-22 07:20:30,315 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:20:30,316 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp, totalSize=1.4g
2014-07-22 07:20:30,316 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,316 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/747a94e63aa742398f307a2262b602e6, keycount=126402, bloomtype=ROW, size=90.0m, encoding=NONE, seqNum=16406
2014-07-22 07:20:30,316 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d4180b9282524ca6a06e645761b5d7fa, keycount=214966, bloomtype=ROW, size=153.2m, encoding=NONE, seqNum=16787
2014-07-22 07:20:30,316 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/0f5e25130e96459c8dd8fb73be017802, keycount=196738, bloomtype=ROW, size=140.1m, encoding=NONE, seqNum=17136
2014-07-22 07:20:30,316 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1d479adeba0d43a8bfc900901b392552, keycount=234104, bloomtype=ROW, size=166.7m, encoding=NONE, seqNum=17551
2014-07-22 07:20:30,316 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/b22b47f14e2d434e9ed6acf9dd1f752a, keycount=224029, bloomtype=ROW, size=159.5m, encoding=NONE, seqNum=17948
2014-07-22 07:20:30,316 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9c0d57649b1c4fc79e78e2edb66b1033, keycount=185250, bloomtype=ROW, size=131.9m, encoding=NONE, seqNum=18277
2014-07-22 07:20:30,317 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/f10b1a90c7c14d62bc199740a520f644, keycount=239318, bloomtype=ROW, size=170.4m, encoding=NONE, seqNum=18701
2014-07-22 07:20:30,317 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/34fad0066cd2405b8ac764fb9e10c13d, keycount=215675, bloomtype=ROW, size=153.6m, encoding=NONE, seqNum=19085
2014-07-22 07:20:30,317 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9d2efa7574944f23a5fbdbb0f6cab462, keycount=215209, bloomtype=ROW, size=153.2m, encoding=NONE, seqNum=19467
2014-07-22 07:20:30,317 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/25232c0eec024975abde4b6ed2d3bbe2, keycount=207611, bloomtype=ROW, size=147.9m, encoding=NONE, seqNum=19837
2014-07-22 07:20:30,319 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,331 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,331 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,337 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,364 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,366 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,432 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,497 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:20:30,501 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:30,567 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:34,305 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9835, memsize=642.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/31e77f883cff47bcb6ae7cbdf5d968dd
2014-07-22 07:20:34,317 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/31e77f883cff47bcb6ae7cbdf5d968dd as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/31e77f883cff47bcb6ae7cbdf5d968dd
2014-07-22 07:20:34,326 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/31e77f883cff47bcb6ae7cbdf5d968dd, entries=2340040, sequenceid=9835, filesize=166.6m
2014-07-22 07:20:34,326 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~642.7m/673912560, currentsize=147.4m/154606080 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 27180ms, sequenceid=9835, compaction requested=true
2014-07-22 07:20:34,327 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-22 07:20:34,327 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3760ms
2014-07-22 07:20:34,327 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,327 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 628.4m
2014-07-22 07:20:34,337 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3836ms
2014-07-22 07:20:34,337 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,349 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3917ms
2014-07-22 07:20:34,349 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,350 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3983ms
2014-07-22 07:20:34,350 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,350 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3986ms
2014-07-22 07:20:34,350 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,350 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4013ms
2014-07-22 07:20:34,351 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,352 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4020ms
2014-07-22 07:20:34,352 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,354 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4022ms
2014-07-22 07:20:34,354 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,355 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4037ms
2014-07-22 07:20:34,355 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,355 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4039ms
2014-07-22 07:20:34,355 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,362 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4058ms
2014-07-22 07:20:34,362 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,362 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4060ms
2014-07-22 07:20:34,362 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:34,363 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4061ms
2014-07-22 07:20:34,363 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:35,143 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:35,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59840 synced till here 59835
2014-07-22 07:20:35,229 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038829155 with entries=84, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038835143
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038687651
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038688961
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038690391
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038691978
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038693807
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038695423
2014-07-22 07:20:35,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038697390
2014-07-22 07:20:35,283 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:20:36,442 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:36,470 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59927 synced till here 59924
2014-07-22 07:20:36,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038835143 with entries=87, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038836443
2014-07-22 07:20:37,826 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:20:37,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:37,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60013 synced till here 60010
2014-07-22 07:20:37,993 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038836443 with entries=86, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038837924
2014-07-22 07:20:39,465 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:39,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60095 synced till here 60092
2014-07-22 07:20:39,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038837924 with entries=82, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038839465
2014-07-22 07:20:40,933 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:40,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60179 synced till here 60174
2014-07-22 07:20:40,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038839465 with entries=84, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038840934
2014-07-22 07:20:41,409 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,411 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,412 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,418 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,425 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,438 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,438 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,450 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,450 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,457 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,463 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:41,470 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:46,410 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:46,412 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:46,412 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,419 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,425 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,438 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:20:46,438 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,450 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,450 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,457 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,463 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:46,470 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:20:49,937 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20225, memsize=619.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/3634d6db60f04f60899c043420a91f4e
2014-07-22 07:20:49,950 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/3634d6db60f04f60899c043420a91f4e as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/3634d6db60f04f60899c043420a91f4e
2014-07-22 07:20:49,959 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/3634d6db60f04f60899c043420a91f4e, entries=2256820, sequenceid=20225, filesize=160.7m
2014-07-22 07:20:49,959 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~619.8m/649945280, currentsize=149.7m/156953040 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 26618ms, sequenceid=20225, compaction requested=true
2014-07-22 07:20:49,959 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:137), split_queue=0, merge_queue=0
2014-07-22 07:20:49,959 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8489ms
2014-07-22 07:20:49,959 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,959 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 558.6m
2014-07-22 07:20:49,959 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8496ms
2014-07-22 07:20:49,960 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,965 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8508ms
2014-07-22 07:20:49,965 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,966 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8515ms
2014-07-22 07:20:49,966 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,966 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8516ms
2014-07-22 07:20:49,966 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,966 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8528ms
2014-07-22 07:20:49,966 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,973 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8536ms
2014-07-22 07:20:49,973 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,978 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8553ms
2014-07-22 07:20:49,978 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,978 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8560ms
2014-07-22 07:20:49,978 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,981 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8569ms
2014-07-22 07:20:49,982 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:49,982 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8571ms
2014-07-22 07:20:49,982 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:50,005 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8596ms
2014-07-22 07:20:50,006 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:20:50,107 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10020,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038840086,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:50,164 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:50,170 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038840148,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:50,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60260 synced till here 60256
2014-07-22 07:20:50,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038840934 with entries=81, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038850164
2014-07-22 07:20:50,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038699050
2014-07-22 07:20:50,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038712591
2014-07-22 07:20:50,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038713792
2014-07-22 07:20:50,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038715223
2014-07-22 07:20:50,358 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10146,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038840211,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:20:50,476 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:20:51,609 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:52,239 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60413 synced till here 60408
2014-07-22 07:20:52,268 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:20:53,219 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038850164 with entries=153, filesize=121.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038851609
2014-07-22 07:20:54,038 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:54,923 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60511 synced till here 60508
2014-07-22 07:20:54,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038851609 with entries=98, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038854039
2014-07-22 07:20:55,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:55,651 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60592 synced till here 60589
2014-07-22 07:20:55,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038854039 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038855628
2014-07-22 07:20:56,952 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:56,958 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:56,965 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:56,979 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:56,997 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:56,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:20:56,999 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:57,003 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:57,011 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:57,020 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:57,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60670 synced till here 60669
2014-07-22 07:20:57,039 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038855628 with entries=78, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038856999
2014-07-22 07:20:57,039 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:57,059 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:20:57,088 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:01,152 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20243, memsize=628.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/5e4eb22f47334f0aaa626f23fad737ac
2014-07-22 07:21:01,165 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/5e4eb22f47334f0aaa626f23fad737ac as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/5e4eb22f47334f0aaa626f23fad737ac
2014-07-22 07:21:01,179 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/5e4eb22f47334f0aaa626f23fad737ac, entries=2287980, sequenceid=20243, filesize=162.9m
2014-07-22 07:21:01,179 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~628.4m/658920320, currentsize=152.5m/159898400 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 26852ms, sequenceid=20243, compaction requested=true
2014-07-22 07:21:01,180 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:138), split_queue=0, merge_queue=0
2014-07-22 07:21:01,180 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4092ms
2014-07-22 07:21:01,180 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,180 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 563.5m
2014-07-22 07:21:01,180 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4121ms
2014-07-22 07:21:01,180 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,181 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4141ms
2014-07-22 07:21:01,181 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,181 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4161ms
2014-07-22 07:21:01,182 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,182 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4171ms
2014-07-22 07:21:01,183 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,183 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4180ms
2014-07-22 07:21:01,183 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,183 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4184ms
2014-07-22 07:21:01,184 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,184 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4187ms
2014-07-22 07:21:01,184 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,184 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4205ms
2014-07-22 07:21:01,185 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,185 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4220ms
2014-07-22 07:21:01,186 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,194 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4237ms
2014-07-22 07:21:01,194 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,199 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4244ms
2014-07-22 07:21:01,199 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:01,755 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:21:02,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:02,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60752 synced till here 60751
2014-07-22 07:21:02,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038856999 with entries=82, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038862421
2014-07-22 07:21:02,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038715885
2014-07-22 07:21:02,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038717296
2014-07-22 07:21:02,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038718691
2014-07-22 07:21:02,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038720281
2014-07-22 07:21:02,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038721805
2014-07-22 07:21:02,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038723445
2014-07-22 07:21:02,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:03,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:03,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60835 synced till here 60831
2014-07-22 07:21:03,946 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038862421 with entries=83, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038863866
2014-07-22 07:21:03,946 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=50, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:04,230 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:21:04,554 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:05,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60916 synced till here 60915
2014-07-22 07:21:05,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038863866 with entries=81, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038864555
2014-07-22 07:21:05,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=51, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:06,021 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:06,057 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61000 synced till here 60993
2014-07-22 07:21:06,168 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038864555 with entries=84, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038866022
2014-07-22 07:21:06,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=52, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:07,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:07,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61083 synced till here 61079
2014-07-22 07:21:07,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038866022 with entries=83, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038867906
2014-07-22 07:21:07,976 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=53, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:09,019 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,021 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,028 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,039 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,042 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,049 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,062 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,070 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,073 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,075 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,082 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:09,134 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:14,020 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:14,021 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:14,028 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:14,039 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:14,043 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:14,049 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:14,062 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:14,071 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:14,073 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:14,076 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:14,082 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:14,135 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:15,575 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20286, memsize=558.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/bfe0660191e64bf7b35e99e5caea6629
2014-07-22 07:21:15,587 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/bfe0660191e64bf7b35e99e5caea6629 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/bfe0660191e64bf7b35e99e5caea6629
2014-07-22 07:21:15,596 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/bfe0660191e64bf7b35e99e5caea6629, entries=2033810, sequenceid=20286, filesize=144.9m
2014-07-22 07:21:15,597 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~558.6m/585721520, currentsize=151.1m/158445280 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 25637ms, sequenceid=20286, compaction requested=true
2014-07-22 07:21:15,597 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:139), split_queue=0, merge_queue=0
2014-07-22 07:21:15,597 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6463ms
2014-07-22 07:21:15,597 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,597 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 605.4m
2014-07-22 07:21:15,597 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6515ms
2014-07-22 07:21:15,598 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,598 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6523ms
2014-07-22 07:21:15,598 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,599 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6526ms
2014-07-22 07:21:15,600 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,600 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6530ms
2014-07-22 07:21:15,600 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,600 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6538ms
2014-07-22 07:21:15,600 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,601 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6552ms
2014-07-22 07:21:15,601 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,602 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6559ms
2014-07-22 07:21:15,602 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,602 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6563ms
2014-07-22 07:21:15,602 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,603 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6574ms
2014-07-22 07:21:15,603 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,604 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6584ms
2014-07-22 07:21:15,604 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:15,606 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6587ms
2014-07-22 07:21:15,607 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:16,154 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:16,175 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:21:16,191 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61164 synced till here 61163
2014-07-22 07:21:16,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038867906 with entries=81, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038876155
2014-07-22 07:21:16,235 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=54, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:17,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:17,552 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61246 synced till here 61245
2014-07-22 07:21:17,571 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038876155 with entries=82, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038877530
2014-07-22 07:21:17,571 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=55, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:18,537 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:21:18,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:19,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61329 synced till here 61324
2014-07-22 07:21:19,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038877530 with entries=83, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038878978
2014-07-22 07:21:19,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=56, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:20,732 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:20,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61417 synced till here 61415
2014-07-22 07:21:21,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038878978 with entries=88, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038880732
2014-07-22 07:21:21,282 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=57, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:22,562 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:22,572 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,593 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,593 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,594 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,594 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,662 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,664 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,664 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,664 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,674 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:22,701 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:23,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038880732 with entries=83, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038882569
2014-07-22 07:21:23,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=58, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:26,018 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20325, memsize=563.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/43f16d835a004750973e313ad3b62adf
2014-07-22 07:21:26,031 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/43f16d835a004750973e313ad3b62adf as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/43f16d835a004750973e313ad3b62adf
2014-07-22 07:21:26,041 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/43f16d835a004750973e313ad3b62adf, entries=2051810, sequenceid=20325, filesize=146.1m
2014-07-22 07:21:26,041 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~563.5m/590904960, currentsize=144.7m/151685840 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 24861ms, sequenceid=20325, compaction requested=true
2014-07-22 07:21:26,041 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-22 07:21:26,042 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3341ms
2014-07-22 07:21:26,042 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,042 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 594.1m
2014-07-22 07:21:26,042 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3368ms
2014-07-22 07:21:26,042 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,042 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3378ms
2014-07-22 07:21:26,042 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,051 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3387ms
2014-07-22 07:21:26,051 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,052 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3387ms
2014-07-22 07:21:26,052 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,052 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3390ms
2014-07-22 07:21:26,052 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,052 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3458ms
2014-07-22 07:21:26,052 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,052 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3458ms
2014-07-22 07:21:26,052 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,053 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3460ms
2014-07-22 07:21:26,053 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,061 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3468ms
2014-07-22 07:21:26,061 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,062 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3489ms
2014-07-22 07:21:26,062 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,062 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3501ms
2014-07-22 07:21:26,062 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:26,253 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e.
2014-07-22 07:21:26,603 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:21:27,097 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:27,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61584 synced till here 61583
2014-07-22 07:21:27,164 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038882569 with entries=84, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038887097
2014-07-22 07:21:27,667 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=59, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:28,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:28,372 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61669 synced till here 61662
2014-07-22 07:21:28,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038887097 with entries=85, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038888339
2014-07-22 07:21:28,440 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=60, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:29,592 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:21:29,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:29,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61753 synced till here 61752
2014-07-22 07:21:29,934 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038888339 with entries=84, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038889901
2014-07-22 07:21:29,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=61, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:31,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:31,341 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61837 synced till here 61835
2014-07-22 07:21:31,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038889901 with entries=84, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038891324
2014-07-22 07:21:31,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=62, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:32,516 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,516 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,531 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,531 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,543 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,547 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,547 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,559 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,560 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,566 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:32,572 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:37,516 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,517 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,531 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,531 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,544 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:37,547 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,547 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,560 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:21:37,560 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,566 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:37,572 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:21:41,158 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20373, memsize=605.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/ebc18f9236d747828b81abf7b6ae730a
2014-07-22 07:21:41,170 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/ebc18f9236d747828b81abf7b6ae730a as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ebc18f9236d747828b81abf7b6ae730a
2014-07-22 07:21:41,178 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/ebc18f9236d747828b81abf7b6ae730a, entries=2204320, sequenceid=20373, filesize=156.9m
2014-07-22 07:21:41,179 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~605.4m/634827520, currentsize=132.4m/138869920 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 25582ms, sequenceid=20373, compaction requested=true
2014-07-22 07:21:41,179 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-22 07:21:41,179 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8607ms
2014-07-22 07:21:41,179 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,180 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 585.1m
2014-07-22 07:21:41,180 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8614ms
2014-07-22 07:21:41,180 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,180 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8620ms
2014-07-22 07:21:41,180 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,181 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8622ms
2014-07-22 07:21:41,181 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,185 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8638ms
2014-07-22 07:21:41,185 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,185 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8638ms
2014-07-22 07:21:41,186 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,189 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8646ms
2014-07-22 07:21:41,189 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,190 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8658ms
2014-07-22 07:21:41,190 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,190 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8659ms
2014-07-22 07:21:41,190 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,193 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8677ms
2014-07-22 07:21:41,194 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,194 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8678ms
2014-07-22 07:21:41,194 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:41,357 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038891276,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:21:41,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:41,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61920 synced till here 61916
2014-07-22 07:21:41,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038891324 with entries=83, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038901565
2014-07-22 07:21:41,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=63, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:41,789 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038891670,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:21:41,790 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10211,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038891578,"queuetimems":2,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:21:42,085 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:21:42,405 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:42,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62002 synced till here 62001
2014-07-22 07:21:42,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038901565 with entries=82, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038902405
2014-07-22 07:21:42,443 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=64, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:43,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:43,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62083 synced till here 62080
2014-07-22 07:21:43,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038902405 with entries=81, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038903714
2014-07-22 07:21:43,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=65, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:45,269 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:21:45,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:46,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62190 synced till here 62187
2014-07-22 07:21:46,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038903714 with entries=107, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038905317
2014-07-22 07:21:46,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=66, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:47,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:47,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62281 synced till here 62273
2014-07-22 07:21:47,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038905317 with entries=91, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038907181
2014-07-22 07:21:47,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=67, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:48,293 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,300 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,311 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,319 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,338 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,348 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,354 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,364 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:48,427 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:50,295 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10121, memsize=594.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/6b7b35bed44c44078622985bba71aa57
2014-07-22 07:21:50,306 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/6b7b35bed44c44078622985bba71aa57 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6b7b35bed44c44078622985bba71aa57
2014-07-22 07:21:50,313 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/6b7b35bed44c44078622985bba71aa57, entries=2163100, sequenceid=10121, filesize=154.0m
2014-07-22 07:21:50,313 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~594.1m/622954560, currentsize=140.1m/146881680 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 24271ms, sequenceid=10121, compaction requested=true
2014-07-22 07:21:50,314 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:142), split_queue=0, merge_queue=0
2014-07-22 07:21:50,314 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1887ms
2014-07-22 07:21:50,314 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,314 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 583.2m
2014-07-22 07:21:50,315 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1951ms
2014-07-22 07:21:50,315 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,315 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1961ms
2014-07-22 07:21:50,315 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,315 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1967ms
2014-07-22 07:21:50,316 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,316 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1978ms
2014-07-22 07:21:50,316 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,316 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1997ms
2014-07-22 07:21:50,316 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,325 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2014ms
2014-07-22 07:21:50,325 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,325 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2025ms
2014-07-22 07:21:50,326 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:50,333 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2040ms
2014-07-22 07:21:50,333 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:21:51,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:51,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62368 synced till here 62365
2014-07-22 07:21:51,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038907181 with entries=87, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038911274
2014-07-22 07:21:51,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=68, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:51,385 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:21:52,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:53,518 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62523 synced till here 62522
2014-07-22 07:21:54,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038911274 with entries=155, filesize=121.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038912834
2014-07-22 07:21:54,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=69, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:55,315 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:21:55,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:55,372 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62603 synced till here 62602
2014-07-22 07:21:55,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038912834 with entries=80, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038915352
2014-07-22 07:21:55,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=70, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:56,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:21:56,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62680 synced till here 62679
2014-07-22 07:21:56,860 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038915352 with entries=77, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038916817
2014-07-22 07:21:56,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=71, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:21:58,133 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,137 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,151 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,160 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,164 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,165 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,186 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,186 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:21:58,187 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:03,133 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:03,137 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:03,151 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:03,160 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:03,165 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:03,165 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:03,187 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:03,187 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:03,187 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:06,975 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10173, memsize=585.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/73d50c7e169e4f4493891be30238d87a
2014-07-22 07:22:06,994 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/73d50c7e169e4f4493891be30238d87a as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/73d50c7e169e4f4493891be30238d87a
2014-07-22 07:22:07,010 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/73d50c7e169e4f4493891be30238d87a, entries=2130180, sequenceid=10173, filesize=151.7m
2014-07-22 07:22:07,010 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~585.1m/613474560, currentsize=142.2m/149130880 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 25831ms, sequenceid=10173, compaction requested=true
2014-07-22 07:22:07,011 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-22 07:22:07,011 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8824ms
2014-07-22 07:22:07,011 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,011 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e., current region memstore size 318.3m
2014-07-22 07:22:07,012 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8825ms
2014-07-22 07:22:07,012 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,012 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8826ms
2014-07-22 07:22:07,012 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,012 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8848ms
2014-07-22 07:22:07,012 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,012 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8848ms
2014-07-22 07:22:07,013 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,013 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8853ms
2014-07-22 07:22:07,013 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,013 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8862ms
2014-07-22 07:22:07,013 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,014 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8877ms
2014-07-22 07:22:07,014 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,021 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8889ms
2014-07-22 07:22:07,021 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:07,037 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038916909,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:07,197 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10191,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038917005,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:07,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:07,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62762 synced till here 62758
2014-07-22 07:22:07,420 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038917137,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:07,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038916817 with entries=82, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038927370
2014-07-22 07:22:07,642 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:22:08,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:08,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62845 synced till here 62841
2014-07-22 07:22:08,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038927370 with entries=83, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038928241
2014-07-22 07:22:09,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:09,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038928241 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038929882
2014-07-22 07:22:11,224 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:22:11,284 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:11,309 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038929882 with entries=82, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038931285
2014-07-22 07:22:12,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:12,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63091 synced till here 63087
2014-07-22 07:22:12,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038931285 with entries=86, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038932694
2014-07-22 07:22:14,008 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,025 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,033 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,042 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,050 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,051 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,086 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:14,138 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:15,007 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10214, memsize=583.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8ea8500dfd0c40c4a8bec7feccbdcd66
2014-07-22 07:22:15,024 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/8ea8500dfd0c40c4a8bec7feccbdcd66 as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8ea8500dfd0c40c4a8bec7feccbdcd66
2014-07-22 07:22:15,039 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/8ea8500dfd0c40c4a8bec7feccbdcd66, entries=2123380, sequenceid=10214, filesize=151.3m
2014-07-22 07:22:15,039 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~583.2m/611516800, currentsize=143.5m/150512400 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 24725ms, sequenceid=10214, compaction requested=true
2014-07-22 07:22:15,040 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-22 07:22:15,040 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 902ms
2014-07-22 07:22:15,040 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,040 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 954ms
2014-07-22 07:22:15,040 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 646.0m
2014-07-22 07:22:15,040 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,040 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 989ms
2014-07-22 07:22:15,040 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,040 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 990ms
2014-07-22 07:22:15,040 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,041 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 999ms
2014-07-22 07:22:15,041 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,042 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1009ms
2014-07-22 07:22:15,042 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,042 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1017ms
2014-07-22 07:22:15,042 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,042 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1034ms
2014-07-22 07:22:15,042 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:15,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:15,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63171 synced till here 63170
2014-07-22 07:22:15,184 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038932694 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038935152
2014-07-22 07:22:16,298 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:22:16,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:16,985 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63286 synced till here 63285
2014-07-22 07:22:17,947 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038935152 with entries=115, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038936617
2014-07-22 07:22:18,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:19,710 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63380 synced till here 63378
2014-07-22 07:22:19,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038936617 with entries=94, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038938939
2014-07-22 07:22:20,168 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f.
2014-07-22 07:22:20,572 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:20,595 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038938939 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038940573
2014-07-22 07:22:22,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:22,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63540 synced till here 63537
2014-07-22 07:22:22,078 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038940573 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038942019
2014-07-22 07:22:22,922 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:22,935 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:22,951 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:22,954 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:22,964 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:22,972 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:22,972 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:23,021 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:23,538 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10225, memsize=318.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/a49c057a1a414bf2887ea7365eca82c5
2014-07-22 07:22:23,552 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/.tmp/a49c057a1a414bf2887ea7365eca82c5 as hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/a49c057a1a414bf2887ea7365eca82c5
2014-07-22 07:22:23,562 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcd7cee994fe8eb603588f61ee109e/family/a49c057a1a414bf2887ea7365eca82c5, entries=1158880, sequenceid=10225, filesize=82.5m
2014-07-22 07:22:23,562 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~318.3m/333725760, currentsize=42.6m/44662480 for region usertable,user9,1406035254793.a1bcd7cee994fe8eb603588f61ee109e. in 16551ms, sequenceid=10225, compaction requested=true
2014-07-22 07:22:23,563 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-22 07:22:23,563 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 542ms
2014-07-22 07:22:23,563 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,563 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 591ms
2014-07-22 07:22:23,563 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 646.0m
2014-07-22 07:22:23,563 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,563 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 591ms
2014-07-22 07:22:23,563 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,563 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 599ms
2014-07-22 07:22:23,563 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,563 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 610ms
2014-07-22 07:22:23,563 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,563 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 612ms
2014-07-22 07:22:23,564 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,564 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 629ms
2014-07-22 07:22:23,564 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:23,574 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 653ms
2014-07-22 07:22:23,574 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:24,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:24,109 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63622 synced till here 63619
2014-07-22 07:22:24,112 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:22:24,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038942019 with entries=82, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038944085
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038725162
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038736980
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038738174
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038739649
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038741072
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038742555
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038744705
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038746081
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038747706
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038749244
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038752903
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038754363
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038769399
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038770446
2014-07-22 07:22:24,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038771964
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038773566
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038775115
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038776701
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038780425
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038781903
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038783281
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038784704
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038786111
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038796347
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038797522
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038798951
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038800548
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038802138
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038807350
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038808530
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038810014
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038811502
2014-07-22 07:22:24,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038812952
2014-07-22 07:22:25,678 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:25,694 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63702 synced till here 63701
2014-07-22 07:22:25,718 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038944085 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038945678
2014-07-22 07:22:27,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:27,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63787 synced till here 63786
2014-07-22 07:22:27,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038945678 with entries=85, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038947219
2014-07-22 07:22:27,262 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:27,275 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:27,282 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:27,297 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:27,303 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:27,319 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:27,368 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:32,262 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:32,276 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:32,283 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:32,297 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:32,303 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:32,319 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:22:32,369 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:22:37,263 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:22:37,276 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:22:37,284 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:22:37,298 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:22:37,303 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:22:37,319 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-22 07:22:37,369 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-22 07:22:40,791 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20645, memsize=646.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/88bc00c517b548f79f9a8664541aab39
2014-07-22 07:22:40,801 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/88bc00c517b548f79f9a8664541aab39 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/88bc00c517b548f79f9a8664541aab39
2014-07-22 07:22:40,810 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/88bc00c517b548f79f9a8664541aab39, entries=2351930, sequenceid=20645, filesize=167.5m
2014-07-22 07:22:40,810 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~646.0m/677336960, currentsize=107.9m/113137760 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 25770ms, sequenceid=20645, compaction requested=true
2014-07-22 07:22:40,811 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:146), split_queue=0, merge_queue=0
2014-07-22 07:22:40,811 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13443ms
2014-07-22 07:22:40,811 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 608.7m
2014-07-22 07:22:40,811 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,811 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13492ms
2014-07-22 07:22:40,811 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,811 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13508ms
2014-07-22 07:22:40,811 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,820 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13523ms
2014-07-22 07:22:40,820 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,821 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13539ms
2014-07-22 07:22:40,821 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,821 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13546ms
2014-07-22 07:22:40,821 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,821 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13559ms
2014-07-22 07:22:40,821 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:40,850 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14072,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038946777,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,202 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14208,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038946993,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,268 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616.
2014-07-22 07:22:41,302 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038947060,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,394 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14241,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038947152,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,441 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14204,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038947236,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,483 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038947366,"queuetimems":0,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,497 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14196,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:54396","starttimems":1406038947301,"queuetimems":1,"class":"HRegionServer","responsesize":32771,"method":"Multi"}
2014-07-22 07:22:41,572 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:22:41,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:41,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038947219 with entries=81, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038961709
2014-07-22 07:22:41,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038813623
2014-07-22 07:22:41,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038824069
2014-07-22 07:22:41,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038825410
2014-07-22 07:22:41,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038826051
2014-07-22 07:22:41,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038827329
2014-07-22 07:22:43,154 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:43,189 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63950 synced till here 63949
2014-07-22 07:22:43,205 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038961709 with entries=82, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038963155
2014-07-22 07:22:44,648 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:44,669 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64035 synced till here 64033
2014-07-22 07:22:44,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038963155 with entries=85, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038964648
2014-07-22 07:22:46,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:46,879 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038964648 with entries=112, filesize=88.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038966396
2014-07-22 07:22:48,583 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:48,913 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:48,922 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:48,942 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:48,976 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:49,505 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20663, memsize=646.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/6ec78a9a38ad4588ad89654b12a76940
2014-07-22 07:22:49,509 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:49,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038966396 with entries=105, filesize=82.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038968583
2014-07-22 07:22:49,521 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/6ec78a9a38ad4588ad89654b12a76940 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/6ec78a9a38ad4588ad89654b12a76940
2014-07-22 07:22:49,535 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/6ec78a9a38ad4588ad89654b12a76940, entries=2352010, sequenceid=20663, filesize=167.5m
2014-07-22 07:22:49,535 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~646.0m/677359520, currentsize=115.3m/120890400 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 25972ms, sequenceid=20663, compaction requested=true
2014-07-22 07:22:49,535 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-22 07:22:49,535 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26ms
2014-07-22 07:22:49,535 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:49,536 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 560ms
2014-07-22 07:22:49,536 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 613.0m
2014-07-22 07:22:49,536 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:49,536 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 594ms
2014-07-22 07:22:49,536 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:49,536 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 614ms
2014-07-22 07:22:49,536 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:49,536 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 623ms
2014-07-22 07:22:49,536 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:22:50,066 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:22:50,736 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:50,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038968583 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038970736
2014-07-22 07:22:50,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038829155
2014-07-22 07:22:50,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038835143
2014-07-22 07:22:50,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038836443
2014-07-22 07:22:50,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038837924
2014-07-22 07:22:50,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038839465
2014-07-22 07:22:52,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:52,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038970736 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038972272
2014-07-22 07:22:53,810 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:53,830 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64489 synced till here 64488
2014-07-22 07:22:53,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038972272 with entries=80, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038973812
2014-07-22 07:22:55,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:55,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64569 synced till here 64567
2014-07-22 07:22:55,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038973812 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038975445
2014-07-22 07:22:57,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:22:57,057 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64648 synced till here 64647
2014-07-22 07:22:57,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038975445 with entries=79, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038977042
2014-07-22 07:22:57,463 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516.
2014-07-22 07:22:58,366 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:58,370 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:58,375 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:58,411 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:22:58,427 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:03,366 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:23:03,371 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:23:03,375 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:23:03,412 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:23:03,427 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:23:04,773 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20682, memsize=608.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/57911b00f44b4cfdaf225c4a3ac95802
2014-07-22 07:23:04,784 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/57911b00f44b4cfdaf225c4a3ac95802 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/57911b00f44b4cfdaf225c4a3ac95802
2014-07-22 07:23:04,792 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/57911b00f44b4cfdaf225c4a3ac95802, entries=2216380, sequenceid=20682, filesize=157.8m
2014-07-22 07:23:04,792 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~608.7m/638301360, currentsize=154.9m/162464160 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 23981ms, sequenceid=20682, compaction requested=true
2014-07-22 07:23:04,793 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-22 07:23:04,793 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6366ms
2014-07-22 07:23:04,793 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:04,793 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6382ms
2014-07-22 07:23:04,793 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 616.5m
2014-07-22 07:23:04,793 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:04,793 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6419ms
2014-07-22 07:23:04,793 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:04,805 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6435ms
2014-07-22 07:23:04,805 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:04,808 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6442ms
2014-07-22 07:23:04,808 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:05,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:05,215 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038977042 with entries=79, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038985187
2014-07-22 07:23:05,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038840934
2014-07-22 07:23:05,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038850164
2014-07-22 07:23:05,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038851609
2014-07-22 07:23:05,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038854039
2014-07-22 07:23:05,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038855628
2014-07-22 07:23:05,475 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:23:06,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:06,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64807 synced till here 64805
2014-07-22 07:23:06,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038985187 with entries=80, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038986787
2014-07-22 07:23:08,468 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:08,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64887 synced till here 64885
2014-07-22 07:23:08,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038986787 with entries=80, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038988468
2014-07-22 07:23:09,961 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:10,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64990 synced till here 64989
2014-07-22 07:23:10,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038988468 with entries=103, filesize=81.8m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038989961
2014-07-22 07:23:11,977 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3.
2014-07-22 07:23:11,985 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:12,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038989961 with entries=79, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038991985
2014-07-22 07:23:13,262 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:13,272 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:13,281 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:13,291 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:13,313 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:13,890 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20725, memsize=613.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/d57a14804afa4504a1f6f2b75d65251d
2014-07-22 07:23:13,906 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/d57a14804afa4504a1f6f2b75d65251d as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/d57a14804afa4504a1f6f2b75d65251d
2014-07-22 07:23:13,918 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/d57a14804afa4504a1f6f2b75d65251d, entries=2231910, sequenceid=20725, filesize=159.0m
2014-07-22 07:23:13,918 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~613.0m/642770560, currentsize=151.3m/158637440 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 24382ms, sequenceid=20725, compaction requested=true
2014-07-22 07:23:13,919 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:149), split_queue=0, merge_queue=0
2014-07-22 07:23:13,919 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 606ms
2014-07-22 07:23:13,919 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:13,919 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 628ms
2014-07-22 07:23:13,919 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 622.3m
2014-07-22 07:23:13,919 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:13,919 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 638ms
2014-07-22 07:23:13,919 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:13,925 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 653ms
2014-07-22 07:23:13,925 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:13,925 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 663ms
2014-07-22 07:23:13,926 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:14,155 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:14,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038991985 with entries=87, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038994155
2014-07-22 07:23:14,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038856999
2014-07-22 07:23:14,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038862421
2014-07-22 07:23:14,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038863866
2014-07-22 07:23:14,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038864555
2014-07-22 07:23:14,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038866022
2014-07-22 07:23:14,969 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:23:15,922 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:16,860 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65270 synced till here 65269
2014-07-22 07:23:16,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038994155 with entries=114, filesize=86.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038995922
2014-07-22 07:23:17,357 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:23:18,501 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:18,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65355 synced till here 65354
2014-07-22 07:23:18,655 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038995922 with entries=85, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038998501
2014-07-22 07:23:20,629 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:20,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65436 synced till here 65435
2014-07-22 07:23:20,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038998501 with entries=81, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039000629
2014-07-22 07:23:22,395 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:22,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039000629 with entries=79, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039002395
2014-07-22 07:23:23,205 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:23,209 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:23,232 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:23,260 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1406034875944: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-22 07:23:28,205 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-22 07:23:28,210 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:23:28,233 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:23:28,261 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-22 07:23:28,445 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20775, memsize=616.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/756332d62f784b66ba3fefdc5e6878f3
2014-07-22 07:23:28,456 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/.tmp/756332d62f784b66ba3fefdc5e6878f3 as hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/756332d62f784b66ba3fefdc5e6878f3
2014-07-22 07:23:28,463 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fefab8f11c8e58bf455cb6ad77b765c/family/756332d62f784b66ba3fefdc5e6878f3, entries=2244500, sequenceid=20775, filesize=159.9m
2014-07-22 07:23:28,463 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~616.5m/646398320, currentsize=148.0m/155138880 for region usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c. in 23670ms, sequenceid=20775, compaction requested=true
2014-07-22 07:23:28,464 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-22 07:23:28,464 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5204ms
2014-07-22 07:23:28,464 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:28,464 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5232ms
2014-07-22 07:23:28,464 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:28,464 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f., current region memstore size 621.0m
2014-07-22 07:23:28,464 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5255ms
2014-07-22 07:23:28,464 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:28,477 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5272ms
2014-07-22 07:23:28,477 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1406034875944
2014-07-22 07:23:29,026 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:23:29,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:29,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65594 synced till here 65593
2014-07-22 07:23:29,327 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039002395 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039009095
2014-07-22 07:23:29,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038867906
2014-07-22 07:23:29,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038876155
2014-07-22 07:23:29,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038877530
2014-07-22 07:23:29,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038878978
2014-07-22 07:23:29,327 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038880732
2014-07-22 07:23:30,679 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:30,698 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039009095 with entries=84, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039010680
2014-07-22 07:23:32,512 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423.
2014-07-22 07:23:33,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:33,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65757 synced till here 65756
2014-07-22 07:23:33,246 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039010680 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039013205
2014-07-22 07:23:35,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:35,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039013205 with entries=78, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039015424
2014-07-22 07:23:37,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:37,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039015424 with entries=76, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039017724
2014-07-22 07:23:38,125 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10527, memsize=622.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b93e993362094fb38b02dca3196aa2a0
2014-07-22 07:23:38,141 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/.tmp/b93e993362094fb38b02dca3196aa2a0 as hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b93e993362094fb38b02dca3196aa2a0
2014-07-22 07:23:38,153 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/86ea69fe85336d05b86e4198e206c41d/family/b93e993362094fb38b02dca3196aa2a0, entries=2265630, sequenceid=10527, filesize=161.4m
2014-07-22 07:23:38,154 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~622.3m/652483120, currentsize=134.8m/141309440 for region usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d. in 24235ms, sequenceid=10527, compaction requested=true
2014-07-22 07:23:38,154 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-22 07:23:38,154 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616., current region memstore size 615.4m
2014-07-22 07:23:38,749 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:23:39,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:39,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039017724 with entries=79, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039019873
2014-07-22 07:23:39,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038882569
2014-07-22 07:23:39,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038887097
2014-07-22 07:23:39,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038888339
2014-07-22 07:23:39,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038889901
2014-07-22 07:23:41,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:43,173 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66112 synced till here 66110
2014-07-22 07:23:43,196 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039019873 with entries=122, filesize=96.1m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039021969
2014-07-22 07:23:45,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:45,155 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66191 synced till here 66190
2014-07-22 07:23:45,167 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039021969 with entries=79, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039025117
2014-07-22 07:23:45,644 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c.
2014-07-22 07:23:47,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:47,178 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039025117 with entries=78, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039027159
2014-07-22 07:23:49,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:49,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66347 synced till here 66346
2014-07-22 07:23:49,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039027159 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039029294
2014-07-22 07:23:51,105 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10578, memsize=621.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7aeebd7724bd47fb9baafa39dbc211e8
2014-07-22 07:23:51,122 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/.tmp/7aeebd7724bd47fb9baafa39dbc211e8 as hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7aeebd7724bd47fb9baafa39dbc211e8
2014-07-22 07:23:51,140 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6a9abfa0046dd16d723f3fe367c1c68f/family/7aeebd7724bd47fb9baafa39dbc211e8, entries=2261000, sequenceid=10578, filesize=161.0m
2014-07-22 07:23:51,140 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~621.0m/651149680, currentsize=144.0m/151025600 for region usertable,user2,1406035254793.6a9abfa0046dd16d723f3fe367c1c68f. in 22676ms, sequenceid=10578, compaction requested=true
2014-07-22 07:23:51,141 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:152), split_queue=0, merge_queue=0
2014-07-22 07:23:51,141 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516., current region memstore size 552.0m
2014-07-22 07:23:51,594 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:51,622 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:23:51,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039029294 with entries=83, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039031594
2014-07-22 07:23:51,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038891324
2014-07-22 07:23:51,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038901565
2014-07-22 07:23:51,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038902405
2014-07-22 07:23:51,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038903714
2014-07-22 07:23:51,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038905317
2014-07-22 07:23:54,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:54,742 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66509 synced till here 66508
2014-07-22 07:23:54,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039031594 with entries=79, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039034727
2014-07-22 07:23:57,418 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:23:57,452 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039034727 with entries=77, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039037418
2014-07-22 07:23:59,032 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d.
2014-07-22 07:24:00,105 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10615, memsize=615.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/43f89fbc88cc467db5170c4d6af63cce
2014-07-22 07:24:00,119 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/.tmp/43f89fbc88cc467db5170c4d6af63cce as hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/43f89fbc88cc467db5170c4d6af63cce
2014-07-22 07:24:00,126 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/753f5973e99ebd3e7e2bc45781eaf616/family/43f89fbc88cc467db5170c4d6af63cce, entries=2240810, sequenceid=10615, filesize=159.6m
2014-07-22 07:24:00,127 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~615.4m/645334240, currentsize=126.4m/132583200 for region usertable,user6,1406035254793.753f5973e99ebd3e7e2bc45781eaf616. in 21973ms, sequenceid=10615, compaction requested=true
2014-07-22 07:24:00,127 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-22 07:24:00,127 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., current region memstore size 525.5m
2014-07-22 07:24:00,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:24:00,421 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66664 synced till here 66663
2014-07-22 07:24:00,430 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039037418 with entries=78, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039040402
2014-07-22 07:24:00,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038907181
2014-07-22 07:24:00,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038911274
2014-07-22 07:24:00,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038912834
2014-07-22 07:24:00,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406038915352
2014-07-22 07:24:00,460 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:24:00,560 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:24:03,180 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-22 07:24:03,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039040402 with entries=78, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1406034875944/slave1%2C60020%2C1406034875944.1406039043180
2014-07-22 07:24:03,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): a1bcd7cee994fe8eb603588f61ee109e
2014-07-22 07:24:09,404 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21005, memsize=552.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/6fd2e97da8934bdbbf1fba6ee9572fd8
2014-07-22 07:24:09,415 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/.tmp/6fd2e97da8934bdbbf1fba6ee9572fd8 as hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/6fd2e97da8934bdbbf1fba6ee9572fd8
2014-07-22 07:24:09,425 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/708b12ffe5692a8a792bd1bf752b8516/family/6fd2e97da8934bdbbf1fba6ee9572fd8, entries=2009770, sequenceid=21005, filesize=143.2m
2014-07-22 07:24:09,426 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~552.0m/578797120, currentsize=64.8m/67986480 for region usertable,user1,1406035254793.708b12ffe5692a8a792bd1bf752b8516. in 18285ms, sequenceid=21005, compaction requested=true
2014-07-22 07:24:09,427 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-22 07:24:09,427 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff., current region memstore size 512.1m
2014-07-22 07:24:09,886 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:24:17,397 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21006, memsize=525.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/c1beeb378e4d4bcf9df583e33de84bf1
2014-07-22 07:24:17,409 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/c1beeb378e4d4bcf9df583e33de84bf1 as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/c1beeb378e4d4bcf9df583e33de84bf1
2014-07-22 07:24:17,418 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/c1beeb378e4d4bcf9df583e33de84bf1, entries=1913300, sequenceid=21006, filesize=136.3m
2014-07-22 07:24:17,419 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~525.5m/551015200, currentsize=24.4m/25631280 for region usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. in 17292ms, sequenceid=21006, compaction requested=true
2014-07-22 07:24:17,419 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:155), split_queue=0, merge_queue=0
2014-07-22 07:24:17,419 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423., current region memstore size 434.8m
2014-07-22 07:24:17,769 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:24:25,173 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21017, memsize=512.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/e598837808d349508faa961233a00861
2014-07-22 07:24:25,184 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp/e598837808d349508faa961233a00861 as hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e598837808d349508faa961233a00861
2014-07-22 07:24:25,191 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/e598837808d349508faa961233a00861, entries=1864480, sequenceid=21017, filesize=132.8m
2014-07-22 07:24:25,191 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~512.1m/536954720, currentsize=0.0/0 for region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. in 15764ms, sequenceid=21017, compaction requested=true
2014-07-22 07:24:25,192 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:156), split_queue=0, merge_queue=0
2014-07-22 07:24:25,192 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1406035254793.9fefab8f11c8e58bf455cb6ad77b765c., current region memstore size 360.0m
2014-07-22 07:24:25,476 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:24:31,446 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21009, memsize=434.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/afff35408b74429288f1e6a47ee822ec
2014-07-22 07:24:31,466 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/.tmp/afff35408b74429288f1e6a47ee822ec as hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/afff35408b74429288f1e6a47ee822ec
2014-07-22 07:24:31,481 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d29123f6203691d46817543c7ec8a423/family/afff35408b74429288f1e6a47ee822ec, entries=1583200, sequenceid=21009, filesize=112.8m
2014-07-22 07:24:31,482 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~434.8m/455948800, currentsize=0.0/0 for region usertable,user5,1406035254793.d29123f6203691d46817543c7ec8a423. in 14063ms, sequenceid=21009, compaction requested=true
2014-07-22 07:24:31,483 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-22 07:24:31,483 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1406035254793.86ea69fe85336d05b86e4198e206c41d., current region memstore size 285.9m
2014-07-22 07:24:31,695 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-22 07:24:33,386 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/.tmp/8ee973779fc640099e01c0292cadf0dd as hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/8ee973779fc640099e01c0292cadf0dd
2014-07-22 07:24:33,409 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Removing store files after compaction...
2014-07-22 07:24:33,424 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/747a94e63aa742398f307a2262b602e6, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/747a94e63aa742398f307a2262b602e6
2014-07-22 07:24:33,427 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d4180b9282524ca6a06e645761b5d7fa, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/d4180b9282524ca6a06e645761b5d7fa
2014-07-22 07:24:33,430 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/0f5e25130e96459c8dd8fb73be017802, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/0f5e25130e96459c8dd8fb73be017802
2014-07-22 07:24:33,433 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1d479adeba0d43a8bfc900901b392552, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/1d479adeba0d43a8bfc900901b392552
2014-07-22 07:24:33,437 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/b22b47f14e2d434e9ed6acf9dd1f752a, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/b22b47f14e2d434e9ed6acf9dd1f752a
2014-07-22 07:24:33,442 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9c0d57649b1c4fc79e78e2edb66b1033, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9c0d57649b1c4fc79e78e2edb66b1033
2014-07-22 07:24:33,445 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/f10b1a90c7c14d62bc199740a520f644, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/f10b1a90c7c14d62bc199740a520f644
2014-07-22 07:24:33,451 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/34fad0066cd2405b8ac764fb9e10c13d, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/34fad0066cd2405b8ac764fb9e10c13d
2014-07-22 07:24:33,455 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9d2efa7574944f23a5fbdbb0f6cab462, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/9d2efa7574944f23a5fbdbb0f6cab462
2014-07-22 07:24:33,459 DEBUG [regionserver60020-smallCompactions-1406034914114] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/25232c0eec024975abde4b6ed2d3bbe2, to hdfs://master:54310/hbase/archive/data/default/usertable/5688494b49c628b8cf95eecd57a989f3/family/25232c0eec024975abde4b6ed2d3bbe2
2014-07-22 07:24:33,460 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3. into 8ee973779fc640099e01c0292cadf0dd(size=1.4g), total size for store is 4.3g. This selection was in queue for 0sec, and took 4mins, 3sec to execute.
2014-07-22 07:24:33,460 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1406035254793.5688494b49c628b8cf95eecd57a989f3., storeName=family, fileCount=10, fileSize=1.4g, priority=1979, time=135810705736929; duration=4mins, 3sec
2014-07-22 07:24:33,460 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-22 07:24:33,460 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 2000 blocking
2014-07-22 07:24:33,462 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1577395679 starting at candidate #9 after considering 132 permutations with 110 in ratio
2014-07-22 07:24:33,462 DEBUG [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: 9adf623b44aef5d1cfacd411890c83ff - family: Initiating minor compaction
2014-07-22 07:24:33,462 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HRegion: Starting compaction on family in region usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff.
2014-07-22 07:24:33,462 INFO  [regionserver60020-smallCompactions-1406034914114] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user4,1406035254793.9adf623b44aef5d1cfacd411890c83ff. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/.tmp, totalSize=1.5g
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/b3e2fc90205e4862b25f891e5d1e4cb2, keycount=148276, bloomtype=ROW, size=105.7m, encoding=NONE, seqNum=16439
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/7c466ff054094ccda1a375e41aeafb68, keycount=224121, bloomtype=ROW, size=159.6m, encoding=NONE, seqNum=16836
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/f332663ce38a4cffb2dc1836de3108e0, keycount=212601, bloomtype=ROW, size=151.4m, encoding=NONE, seqNum=17213
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/cf0071d088214503b220bf5b063313d3, keycount=213393, bloomtype=ROW, size=151.9m, encoding=NONE, seqNum=17591
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/dd9ccb00f0604722bc4c1d1f6ec81ba1, keycount=222943, bloomtype=ROW, size=158.8m, encoding=NONE, seqNum=17986
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/c6391749c1bf4a739757501ebc174381, keycount=210882, bloomtype=ROW, size=150.2m, encoding=NONE, seqNum=18360
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/85d9fc1059d247918d264bc63998a31e, keycount=215585, bloomtype=ROW, size=153.5m, encoding=NONE, seqNum=18743
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/5cd72559982c4672a58fb949f4ded922, keycount=212736, bloomtype=ROW, size=151.5m, encoding=NONE, seqNum=19121
2014-07-22 07:24:33,463 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/95cfa00329a849a6901d6b20a1e78f44, keycount=222906, bloomtype=ROW, size=158.7m, encoding=NONE, seqNum=19517
2014-07-22 07:24:33,464 DEBUG [regionserver60020-smallCompactions-1406034914114] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9adf623b44aef5d1cfacd411890c83ff/family/373dd3ce7cca45dfa5cf8ef06e851bf6, keycount=228792, bloomtype=ROW, size=162.9m, encoding=NONE, seqNum=19924
2014-07-22 07:24:33,622 DEBUG [regionserver60020-smallCompactions-1406034914114] util.FSUtils: DFS Client does not support most favored nodes create; using default create
