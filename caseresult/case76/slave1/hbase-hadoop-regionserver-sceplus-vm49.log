Fri Jul 11 01:12:02 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-11 01:12:03,258 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-11 01:12:03,258 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-11 01:12:03,258 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-11 01:12:03,480 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-11 01:12:03,480 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-11 01:12:03,480 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-11 01:12:03,480 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 45734 22
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-11 01:12:03,481 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 45734 9.1.143.59 22
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-11 01:12:03,482 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-11 01:12:03,484 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-11 01:12:03,484 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=232
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-11 01:12:03,485 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-11 01:12:03,486 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-11 01:12:03,488 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-11 01:12:03,488 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-11 01:12:03,720 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-11 01:12:04,171 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-11 01:12:04,275 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-11 01:12:04,287 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-11 01:12:04,349 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-11 01:12:04,350 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-11 01:12:04,350 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-11 01:12:04,356 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-11 01:12:04,361 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-11 01:12:04,447 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-11 01:12:04,447 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-11 01:12:04,451 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-11 01:12:04,454 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-11 01:12:04,528 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-11 01:12:04,588 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-11 01:12:04,598 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-11 01:12:04,600 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-11 01:12:04,600 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-11 01:12:04,600 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-11 01:12:04,921 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-11 01:12:04,969 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-11 01:12:04,969 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-11 01:12:04,969 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-11 01:12:04,969 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-11 01:12:04,969 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-11 01:12:04,970 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-11 01:12:04,971 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-11 01:12:05,004 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-11 01:12:05,006 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-11 01:12:05,011 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-11 01:12:05,020 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147247aa9e90001, negotiated timeout = 90000
2014-07-11 01:12:36,522 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x602703, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-11 01:12:36,524 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x602703 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-11 01:12:36,524 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-11 01:12:36,524 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-11 01:12:36,527 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147247aa9e90003, negotiated timeout = 90000
2014-07-11 01:12:36,815 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@64dc0427
2014-07-11 01:12:36,819 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-11 01:12:36,826 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-11 01:12:36,842 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-11 01:12:36,880 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-11 01:12:36,887 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-11 01:12:36,891 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-11 01:12:36,913 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405066322787 with port=60020, startcode=1405066324372
2014-07-11 01:12:37,242 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-11 01:12:37,242 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-11 01:12:37,243 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-11 01:12:37,271 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-11 01:12:37,280 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372
2014-07-11 01:12:37,322 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-11 01:12:37,334 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-11 01:12:37,435 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066357341
2014-07-11 01:12:37,452 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-11 01:12:37,457 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-11 01:12:37,461 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-11 01:12:37,466 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-11 01:12:37,469 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-11 01:12:37,469 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-11 01:12:37,469 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-11 01:12:37,469 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-11 01:12:37,469 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-11 01:12:37,477 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1405066324628, slave1,60020,1405066324372] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1405066324628, slave1,60020,1405066324372]
2014-07-11 01:12:37,500 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-11 01:12:37,502 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x68275748, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-11 01:12:37,503 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x68275748 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-11 01:12:37,503 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-11 01:12:37,504 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-11 01:12:37,508 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x47247aab1f0003, negotiated timeout = 90000
2014-07-11 01:12:37,516 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-11 01:12:37,517 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-11 01:12:37,567 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405066324372, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x147247aa9e90001
2014-07-11 01:12:37,567 INFO  [SplitLogWorker-slave1,60020,1405066324372] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405066324372 starting
2014-07-11 01:12:37,567 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-11 01:12:37,568 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405066324372
2014-07-11 01:12:37,568 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405066324372'
2014-07-11 01:12:37,568 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-11 01:12:37,569 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-11 01:12:37,570 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-11 01:12:41,362 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-11 01:12:41,469 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:41,494 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:41,494 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372
2014-07-11 01:12:41,496 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-11 01:12:41,530 INFO  [RS_OPEN_META-slave1:60020-0] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066361499.meta
2014-07-11 01:12:41,552 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-11 01:12:41,574 DEBUG [RS_OPEN_META-slave1:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-11 01:12:41,582 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-11 01:12:41,585 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-11 01:12:41,590 INFO  [RS_OPEN_META-slave1:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-11 01:12:41,590 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-11 01:12:41,591 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-11 01:12:41,663 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:12:41,705 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-11 01:12:41,761 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/af09d6d6a51c424a86a1a3eed3075d88, isReference=false, isBulkLoadResult=false, seqid=4066, majorCompaction=true
2014-07-11 01:12:41,776 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for c2d5a90851fe41ff9fac90e408f30a48
2014-07-11 01:12:41,776 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/c2d5a90851fe41ff9fac90e408f30a48, isReference=false, isBulkLoadResult=false, seqid=4092, majorCompaction=false
2014-07-11 01:12:41,810 DEBUG [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-11 01:12:41,815 INFO  [RS_OPEN_META-slave1:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=4093
2014-07-11 01:12:41,815 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-11 01:12:41,817 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-11 01:12:41,818 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as slave1,60020,1405066324372
2014-07-11 01:12:41,825 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-11 01:12:41,826 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:41,830 DEBUG [RS_OPEN_META-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:41,831 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:41,831 DEBUG [RS_OPEN_META-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on slave1,60020,1405066324372
2014-07-11 01:12:42,204 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:12:42,235 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:12:42,236 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2c9ec51d492f963529797ef469f19224 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:42,238 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:12:42,238 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e40f437ea2cd04f5e80b9966a93834b2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:42,241 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:12:42,241 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f5085e3c4a405ca169db6dcb31b38b29 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:42,242 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 01:12:42,245 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2c9ec51d492f963529797ef469f19224 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:42,245 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e40f437ea2cd04f5e80b9966a93834b2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:42,246 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => e40f437ea2cd04f5e80b9966a93834b2, NAME => 'usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-11 01:12:42,246 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 2c9ec51d492f963529797ef469f19224, NAME => 'usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-11 01:12:42,248 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable e40f437ea2cd04f5e80b9966a93834b2
2014-07-11 01:12:42,248 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f5085e3c4a405ca169db6dcb31b38b29 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:42,248 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:12:42,249 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2c9ec51d492f963529797ef469f19224
2014-07-11 01:12:42,249 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:12:42,249 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => f5085e3c4a405ca169db6dcb31b38b29, NAME => 'usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-11 01:12:42,250 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable f5085e3c4a405ca169db6dcb31b38b29
2014-07-11 01:12:42,250 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:12:42,253 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:12:42,256 INFO  [RS_OPEN_REGION-slave1:60020-1] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-11 01:12:42,258 INFO  [RS_OPEN_REGION-slave1:60020-1] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-11 01:12:42,261 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-11 01:12:42,262 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-11 01:12:42,261 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-11 01:12:42,295 INFO  [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 01:12:42,296 INFO  [StoreOpener-2c9ec51d492f963529797ef469f19224-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 01:12:42,299 INFO  [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 01:12:42,376 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-11 01:12:42,395 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/18dab4721ca340b2ba3709577f4eb8a2, isReference=false, isBulkLoadResult=false, seqid=2037, majorCompaction=false
2014-07-11 01:12:42,397 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/02bef540e445426788c2c47e00d28058, isReference=false, isBulkLoadResult=false, seqid=672, majorCompaction=false
2014-07-11 01:12:42,399 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/02893e97616c4cf3b8a2cdf5dec80485, isReference=false, isBulkLoadResult=false, seqid=2022, majorCompaction=false
2014-07-11 01:12:42,422 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/138e6fda1f494fc6ac6f336f7435cc52, isReference=false, isBulkLoadResult=false, seqid=2827, majorCompaction=false
2014-07-11 01:12:42,434 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-11 01:12:42,434 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/1ac9b438b33748bb8b6dc21f0fa0a93f, isReference=false, isBulkLoadResult=false, seqid=1406, majorCompaction=false
2014-07-11 01:12:42,438 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/10475c1277954cfbbbf8e626dd4b8215, isReference=false, isBulkLoadResult=false, seqid=1174, majorCompaction=false
2014-07-11 01:12:42,467 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/24bb6a2f6ee44ef6bf0695cca568a541, isReference=false, isBulkLoadResult=false, seqid=4408, majorCompaction=false
2014-07-11 01:12:42,472 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/2ff03441c636489982b1dcbdb30f0924, isReference=false, isBulkLoadResult=false, seqid=2537, majorCompaction=false
2014-07-11 01:12:42,472 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/42de3e882a704660b8439b18ac85125a, isReference=false, isBulkLoadResult=false, seqid=4073, majorCompaction=false
2014-07-11 01:12:42,511 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/2aef356290954069b13a8edf31798d5e, isReference=false, isBulkLoadResult=false, seqid=1236, majorCompaction=false
2014-07-11 01:12:42,512 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/33061bff92db4eaeae0227dd8079b21b, isReference=false, isBulkLoadResult=false, seqid=566, majorCompaction=false
2014-07-11 01:12:42,518 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/4df57675f1d84d40858434c6941e788e, isReference=false, isBulkLoadResult=false, seqid=1096, majorCompaction=false
2014-07-11 01:12:42,532 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/2b5884a8cca14a92b9cdb0f22820fb3a, isReference=false, isBulkLoadResult=false, seqid=578, majorCompaction=false
2014-07-11 01:12:42,556 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/3804991da7994caea4ebffc11a9a6ca7, isReference=false, isBulkLoadResult=false, seqid=396, majorCompaction=false
2014-07-11 01:12:42,560 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/50fc3fe988a748e59425d6594eca7358, isReference=false, isBulkLoadResult=false, seqid=3642, majorCompaction=false
2014-07-11 01:12:42,560 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/4c8f34ceaa5a4046815f73d61a49eed8, isReference=false, isBulkLoadResult=false, seqid=3255, majorCompaction=false
2014-07-11 01:12:42,594 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/3b27813f49074338ad1306be6aa6e994, isReference=false, isBulkLoadResult=false, seqid=174, majorCompaction=false
2014-07-11 01:12:42,595 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/655b77eed0e74896990b32353472b0d8, isReference=false, isBulkLoadResult=false, seqid=5347, majorCompaction=false
2014-07-11 01:12:42,605 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/518213efd9a7463f90b1610cffd15a92, isReference=false, isBulkLoadResult=false, seqid=919, majorCompaction=false
2014-07-11 01:12:42,633 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/54c8b9e84ae847d0b6fd6ed2411ca26c, isReference=false, isBulkLoadResult=false, seqid=738, majorCompaction=false
2014-07-11 01:12:42,650 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/6cc2ae556a1e45f58071485a332743df, isReference=false, isBulkLoadResult=false, seqid=2407, majorCompaction=false
2014-07-11 01:12:42,654 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/5444e33562be44968d1d90f668515fb2, isReference=false, isBulkLoadResult=false, seqid=1447, majorCompaction=false
2014-07-11 01:12:42,668 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/89339ab25ff54edf84c049120b0a4714, isReference=false, isBulkLoadResult=false, seqid=4990, majorCompaction=false
2014-07-11 01:12:42,676 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/5709182fef5e4bd39bcc4a59f485b52d, isReference=false, isBulkLoadResult=false, seqid=3193, majorCompaction=false
2014-07-11 01:12:42,680 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/592389c954694fb898dab027f4385622, isReference=false, isBulkLoadResult=false, seqid=1519, majorCompaction=false
2014-07-11 01:12:42,703 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/59e278632b8d44afa8aa6bd0af3c69db, isReference=false, isBulkLoadResult=false, seqid=4201, majorCompaction=false
2014-07-11 01:12:42,705 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/9103e46591c4423d8c3befca84b558c3, isReference=false, isBulkLoadResult=false, seqid=406, majorCompaction=false
2014-07-11 01:12:42,708 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/5ef3a95fffd04274ac2c3f6ce2cb6a1b, isReference=false, isBulkLoadResult=false, seqid=1857, majorCompaction=false
2014-07-11 01:12:42,720 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/5fff10690d18445d8e0542045f728309, isReference=false, isBulkLoadResult=false, seqid=3452, majorCompaction=false
2014-07-11 01:12:42,728 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/941a67989a794296b7c1297c31476ca9, isReference=false, isBulkLoadResult=false, seqid=1601, majorCompaction=false
2014-07-11 01:12:42,729 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/5f0523c386734812b89fb769122ca748, isReference=false, isBulkLoadResult=false, seqid=5342, majorCompaction=false
2014-07-11 01:12:42,752 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/b113be5f84a24b8abdbbc0916d5f3036, isReference=false, isBulkLoadResult=false, seqid=3812, majorCompaction=false
2014-07-11 01:12:42,758 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/7ca367f53a734fabaf508c49fd32fba7, isReference=false, isBulkLoadResult=false, seqid=1342, majorCompaction=false
2014-07-11 01:12:42,763 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/63072c4080d84175b066adc585ca4085, isReference=false, isBulkLoadResult=false, seqid=1275, majorCompaction=false
2014-07-11 01:12:42,780 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/b51081b397cf48499cdbb26fd3391df2, isReference=false, isBulkLoadResult=false, seqid=1768, majorCompaction=false
2014-07-11 01:12:42,790 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/7f82ced9ad114035b67092a093806c6a, isReference=false, isBulkLoadResult=false, seqid=3855, majorCompaction=false
2014-07-11 01:12:42,809 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/6a94313357ef48548f45c228112a2d7d, isReference=false, isBulkLoadResult=false, seqid=301, majorCompaction=false
2014-07-11 01:12:42,813 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/be580ca4a6df4fc2aa1d8a322895d0d6, isReference=false, isBulkLoadResult=false, seqid=2936, majorCompaction=false
2014-07-11 01:12:42,829 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/858c92c5e8684b418740613cae467b5c, isReference=false, isBulkLoadResult=false, seqid=983, majorCompaction=false
2014-07-11 01:12:42,834 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/705d0db83c7346259f78cb7f40e4cf01, isReference=false, isBulkLoadResult=false, seqid=4581, majorCompaction=false
2014-07-11 01:12:42,842 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/be76d47b1acc41f399780e76cf96e9c4, isReference=false, isBulkLoadResult=false, seqid=233, majorCompaction=false
2014-07-11 01:12:42,851 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/9501fbfea70c449e8cd85518d34e6fa9, isReference=false, isBulkLoadResult=false, seqid=5039, majorCompaction=false
2014-07-11 01:12:42,874 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/b72ef0c60b5f4444b8b448098c9f9d25, isReference=false, isBulkLoadResult=false, seqid=1646, majorCompaction=false
2014-07-11 01:12:42,890 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/ce998fc98c78436d94c9874b4f4bcc45, isReference=false, isBulkLoadResult=false, seqid=1053, majorCompaction=false
2014-07-11 01:12:42,896 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/b7f65afd4e264ab387f942223b94f3ca, isReference=false, isBulkLoadResult=false, seqid=5188, majorCompaction=false
2014-07-11 01:12:42,902 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/98b45286ac2f43729a3c9d4ce791ffe1, isReference=false, isBulkLoadResult=false, seqid=3039, majorCompaction=false
2014-07-11 01:12:42,925 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/d2b1d53d906e4c75b164df0b7f90f494, isReference=false, isBulkLoadResult=false, seqid=2348, majorCompaction=false
2014-07-11 01:12:42,937 DEBUG [StoreOpener-e40f437ea2cd04f5e80b9966a93834b2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2/family/f644ec93987c4a7c9d038aec9a7bf102, isReference=false, isBulkLoadResult=false, seqid=747, majorCompaction=false
2014-07-11 01:12:42,950 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/a1193d48f2cc46638ee60fc2c4815fe1, isReference=false, isBulkLoadResult=false, seqid=1700, majorCompaction=false
2014-07-11 01:12:42,951 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/e40f437ea2cd04f5e80b9966a93834b2
2014-07-11 01:12:42,957 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined e40f437ea2cd04f5e80b9966a93834b2; next sequenceid=5348
2014-07-11 01:12:42,957 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e40f437ea2cd04f5e80b9966a93834b2
2014-07-11 01:12:42,961 INFO  [PostOpenDeployTasks:e40f437ea2cd04f5e80b9966a93834b2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:12:42,964 DEBUG [PostOpenDeployTasks:e40f437ea2cd04f5e80b9966a93834b2] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:12:42,967 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-11 01:12:42,967 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-11 01:12:42,972 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:42,973 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:42,973 DEBUG [StoreOpener-f5085e3c4a405ca169db6dcb31b38b29-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29/family/ff0c838fb7d44519b113bb7dbbdd94eb, isReference=false, isBulkLoadResult=false, seqid=505, majorCompaction=false
2014-07-11 01:12:42,979 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2. because compaction request was cancelled
2014-07-11 01:12:42,983 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/df67a338f74e442d921e49d801b27651, isReference=false, isBulkLoadResult=false, seqid=4645, majorCompaction=false
2014-07-11 01:12:42,983 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/f5085e3c4a405ca169db6dcb31b38b29
2014-07-11 01:12:42,989 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined f5085e3c4a405ca169db6dcb31b38b29; next sequenceid=5343
2014-07-11 01:12:42,989 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node f5085e3c4a405ca169db6dcb31b38b29
2014-07-11 01:12:42,990 INFO  [PostOpenDeployTasks:f5085e3c4a405ca169db6dcb31b38b29] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:12:42,991 DEBUG [PostOpenDeployTasks:f5085e3c4a405ca169db6dcb31b38b29] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:12:42,992 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-11 01:12:42,992 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-11 01:12:42,992 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:42,992 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:42,992 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29. because compaction request was cancelled
2014-07-11 01:12:43,030 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/e7b2b2acc7b540a98aaff3b17808b9f6, isReference=false, isBulkLoadResult=false, seqid=5310, majorCompaction=false
2014-07-11 01:12:43,039 DEBUG [StoreOpener-2c9ec51d492f963529797ef469f19224-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224/family/ec052b71d4db4c9a8255cec07f9bc16a, isReference=false, isBulkLoadResult=false, seqid=5351, majorCompaction=false
2014-07-11 01:12:43,044 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2c9ec51d492f963529797ef469f19224
2014-07-11 01:12:43,050 INFO  [PostOpenDeployTasks:e40f437ea2cd04f5e80b9966a93834b2] catalog.MetaEditor: Updated row usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2. with server=slave1,60020,1405066324372
2014-07-11 01:12:43,050 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 2c9ec51d492f963529797ef469f19224; next sequenceid=5352
2014-07-11 01:12:43,050 INFO  [PostOpenDeployTasks:e40f437ea2cd04f5e80b9966a93834b2] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:12:43,051 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2c9ec51d492f963529797ef469f19224
2014-07-11 01:12:43,053 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e40f437ea2cd04f5e80b9966a93834b2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,050 INFO  [PostOpenDeployTasks:f5085e3c4a405ca169db6dcb31b38b29] catalog.MetaEditor: Updated row usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29. with server=slave1,60020,1405066324372
2014-07-11 01:12:43,053 INFO  [PostOpenDeployTasks:f5085e3c4a405ca169db6dcb31b38b29] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:12:43,054 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f5085e3c4a405ca169db6dcb31b38b29 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,055 INFO  [PostOpenDeployTasks:2c9ec51d492f963529797ef469f19224] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:12:43,056 DEBUG [PostOpenDeployTasks:2c9ec51d492f963529797ef469f19224] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:12:43,056 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-11 01:12:43,056 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-11 01:12:43,056 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:43,057 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:43,057 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224. because compaction request was cancelled
2014-07-11 01:12:43,059 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e40f437ea2cd04f5e80b9966a93834b2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,060 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned e40f437ea2cd04f5e80b9966a93834b2 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:43,060 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f5085e3c4a405ca169db6dcb31b38b29 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,060 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2. on slave1,60020,1405066324372
2014-07-11 01:12:43,060 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned f5085e3c4a405ca169db6dcb31b38b29 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:43,060 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29. on slave1,60020,1405066324372
2014-07-11 01:12:43,061 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e468587ab0e54014075f4520dcd9c355 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:43,061 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:43,065 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e468587ab0e54014075f4520dcd9c355 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:43,065 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:43,066 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => e468587ab0e54014075f4520dcd9c355, NAME => 'usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-11 01:12:43,066 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-11 01:12:43,066 INFO  [PostOpenDeployTasks:2c9ec51d492f963529797ef469f19224] catalog.MetaEditor: Updated row usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224. with server=slave1,60020,1405066324372
2014-07-11 01:12:43,066 INFO  [PostOpenDeployTasks:2c9ec51d492f963529797ef469f19224] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:12:43,068 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-11 01:12:43,068 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2c9ec51d492f963529797ef469f19224 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,068 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable e468587ab0e54014075f4520dcd9c355
2014-07-11 01:12:43,068 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 01:12:43,068 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:12:43,072 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2c9ec51d492f963529797ef469f19224 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,073 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 2c9ec51d492f963529797ef469f19224 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:43,073 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224. on slave1,60020,1405066324372
2014-07-11 01:12:43,073 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning bc1bf2a12fb05f36e29f0cabc7669ca2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:43,075 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:12:43,076 INFO  [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 01:12:43,077 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node bc1bf2a12fb05f36e29f0cabc7669ca2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:12:43,078 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => bc1bf2a12fb05f36e29f0cabc7669ca2, NAME => 'usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-11 01:12:43,078 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable bc1bf2a12fb05f36e29f0cabc7669ca2
2014-07-11 01:12:43,079 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:12:43,086 INFO  [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-11 01:12:43,093 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-11 01:12:43,097 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-11 01:12:43,099 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-11 01:12:43,099 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-11 01:12:43,101 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 01:12:43,101 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/011aedd6dae041daa80be8c943fe6e07, isReference=false, isBulkLoadResult=false, seqid=4476, majorCompaction=false
2014-07-11 01:12:43,110 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405066324372
2014-07-11 01:12:43,110 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-11 01:12:43,111 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,114 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,115 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:43,115 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405066324372
2014-07-11 01:12:43,118 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/0f1fad51ab9240c8a7f6ad668ed12543, isReference=false, isBulkLoadResult=false, seqid=1221, majorCompaction=false
2014-07-11 01:12:43,126 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/09144c8b4aa844c8bd968f14d3aa45a5, isReference=false, isBulkLoadResult=false, seqid=1105, majorCompaction=false
2014-07-11 01:12:43,135 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/1acd69b93e49497c9cd79a142381d190, isReference=false, isBulkLoadResult=false, seqid=5350, majorCompaction=false
2014-07-11 01:12:43,141 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/15985a5094ba476c8a206e6d843ca016, isReference=false, isBulkLoadResult=false, seqid=4198, majorCompaction=false
2014-07-11 01:12:43,170 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/227e748340f34aaba554648b03de9cc9, isReference=false, isBulkLoadResult=false, seqid=232, majorCompaction=false
2014-07-11 01:12:43,196 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/274605514a244f809dd5ae7f822a0586, isReference=false, isBulkLoadResult=false, seqid=698, majorCompaction=false
2014-07-11 01:12:43,212 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/5749c3bb832c41f0aa135f3303acc9da, isReference=false, isBulkLoadResult=false, seqid=1777, majorCompaction=false
2014-07-11 01:12:43,216 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/2e0ebd7940ae46e5a63aa430e5d7e44e, isReference=false, isBulkLoadResult=false, seqid=4014, majorCompaction=false
2014-07-11 01:12:43,242 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/7c2631e326b6407a81f843da94bd2440, isReference=false, isBulkLoadResult=false, seqid=2209, majorCompaction=false
2014-07-11 01:12:43,243 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/30b4fcaa8ff24e9da6e50e5d556b26a7, isReference=false, isBulkLoadResult=false, seqid=1654, majorCompaction=false
2014-07-11 01:12:43,274 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/569b55acd10b4e98b694345d60912ffa, isReference=false, isBulkLoadResult=false, seqid=2562, majorCompaction=false
2014-07-11 01:12:43,286 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/7d85ab3ee66348fe801cf8718de83fb7, isReference=false, isBulkLoadResult=false, seqid=661, majorCompaction=false
2014-07-11 01:12:43,301 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/57cff25fcf56423ebbd71785b5dfe490, isReference=false, isBulkLoadResult=false, seqid=2977, majorCompaction=false
2014-07-11 01:12:43,301 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/7f05d132a28b4d62b1c85f28965b746d, isReference=false, isBulkLoadResult=false, seqid=1053, majorCompaction=false
2014-07-11 01:12:43,319 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/820d551387d344848bb0995db43b7a1e, isReference=false, isBulkLoadResult=false, seqid=3410, majorCompaction=false
2014-07-11 01:12:43,334 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/890dfe28afdf4bd1bb0cfa469b91b46a, isReference=false, isBulkLoadResult=false, seqid=1604, majorCompaction=false
2014-07-11 01:12:43,356 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/87a210ada6c449ec8bef21c736a28dac, isReference=false, isBulkLoadResult=false, seqid=1449, majorCompaction=false
2014-07-11 01:12:43,369 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/8d1c1f0a5e9444a3bd3cc66745d43384, isReference=false, isBulkLoadResult=false, seqid=3121, majorCompaction=false
2014-07-11 01:12:43,385 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/a869186487784315ab6c07a87adfa70a, isReference=false, isBulkLoadResult=false, seqid=174, majorCompaction=false
2014-07-11 01:12:43,393 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/994c1e983bdc470184d2005cef95981f, isReference=false, isBulkLoadResult=false, seqid=1387, majorCompaction=false
2014-07-11 01:12:43,413 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/9f0c15303a5a4be3998748c0363b1ee6, isReference=false, isBulkLoadResult=false, seqid=4797, majorCompaction=false
2014-07-11 01:12:43,426 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/b2d4171b22664cf38160849689b91217, isReference=false, isBulkLoadResult=false, seqid=901, majorCompaction=false
2014-07-11 01:12:43,444 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/ae46de3c322f423fa9c6baa67c3d1b82, isReference=false, isBulkLoadResult=false, seqid=834, majorCompaction=false
2014-07-11 01:12:43,457 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/c01f60e81b2c4dd09cee6e5085880c7e, isReference=false, isBulkLoadResult=false, seqid=343, majorCompaction=false
2014-07-11 01:12:43,466 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/ce209d59cfb24b48bd94c0d64f8c83bc, isReference=false, isBulkLoadResult=false, seqid=3647, majorCompaction=false
2014-07-11 01:12:43,474 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/cba959103dcb4cc2a1d919ad40cadfaf, isReference=false, isBulkLoadResult=false, seqid=1871, majorCompaction=false
2014-07-11 01:12:43,499 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/d212f3a5c5ee4ea0bf5149ae90faf1be, isReference=false, isBulkLoadResult=false, seqid=495, majorCompaction=false
2014-07-11 01:12:43,500 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/d1559b188e24407e813df9800801d716, isReference=false, isBulkLoadResult=false, seqid=2238, majorCompaction=false
2014-07-11 01:12:43,508 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/d316d7f3dad44bfc8bf4a78abb8eb913, isReference=false, isBulkLoadResult=false, seqid=5343, majorCompaction=false
2014-07-11 01:12:43,524 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/e185eee2416c47ca849ecbb084c88689, isReference=false, isBulkLoadResult=false, seqid=2769, majorCompaction=false
2014-07-11 01:12:43,532 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/d91bfa9eece94d6e888be80e5a793d1a, isReference=false, isBulkLoadResult=false, seqid=517, majorCompaction=false
2014-07-11 01:12:43,535 DEBUG [StoreOpener-bc1bf2a12fb05f36e29f0cabc7669ca2-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2/family/f54b8e1a144c4188a30faa3541824ab1, isReference=false, isBulkLoadResult=false, seqid=5222, majorCompaction=false
2014-07-11 01:12:43,540 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/bc1bf2a12fb05f36e29f0cabc7669ca2
2014-07-11 01:12:43,543 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined bc1bf2a12fb05f36e29f0cabc7669ca2; next sequenceid=5344
2014-07-11 01:12:43,543 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node bc1bf2a12fb05f36e29f0cabc7669ca2
2014-07-11 01:12:43,546 INFO  [PostOpenDeployTasks:bc1bf2a12fb05f36e29f0cabc7669ca2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:12:43,546 DEBUG [PostOpenDeployTasks:bc1bf2a12fb05f36e29f0cabc7669ca2] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:12:43,546 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-11 01:12:43,546 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-11 01:12:43,546 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:43,546 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:43,546 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2. because compaction request was cancelled
2014-07-11 01:12:43,556 INFO  [PostOpenDeployTasks:bc1bf2a12fb05f36e29f0cabc7669ca2] catalog.MetaEditor: Updated row usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2. with server=slave1,60020,1405066324372
2014-07-11 01:12:43,557 INFO  [PostOpenDeployTasks:bc1bf2a12fb05f36e29f0cabc7669ca2] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:12:43,558 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning bc1bf2a12fb05f36e29f0cabc7669ca2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,558 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/e05c4cfba45049029326c185a8023a16, isReference=false, isBulkLoadResult=false, seqid=1277, majorCompaction=false
2014-07-11 01:12:43,562 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node bc1bf2a12fb05f36e29f0cabc7669ca2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,562 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned bc1bf2a12fb05f36e29f0cabc7669ca2 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:43,562 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2. on slave1,60020,1405066324372
2014-07-11 01:12:43,577 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/eaba82e82704477db005552986ec606c, isReference=false, isBulkLoadResult=false, seqid=4887, majorCompaction=false
2014-07-11 01:12:43,586 DEBUG [StoreOpener-e468587ab0e54014075f4520dcd9c355-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355/family/eb5771f4b40f453e95fd880183db2ebb, isReference=false, isBulkLoadResult=false, seqid=5298, majorCompaction=false
2014-07-11 01:12:43,589 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/e468587ab0e54014075f4520dcd9c355
2014-07-11 01:12:43,592 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined e468587ab0e54014075f4520dcd9c355; next sequenceid=5351
2014-07-11 01:12:43,592 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e468587ab0e54014075f4520dcd9c355
2014-07-11 01:12:43,594 INFO  [PostOpenDeployTasks:e468587ab0e54014075f4520dcd9c355] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:12:43,594 DEBUG [PostOpenDeployTasks:e468587ab0e54014075f4520dcd9c355] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:12:43,594 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-11 01:12:43,595 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-11 01:12:43,595 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:43,595 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:43,595 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355. because compaction request was cancelled
2014-07-11 01:12:43,602 INFO  [PostOpenDeployTasks:e468587ab0e54014075f4520dcd9c355] catalog.MetaEditor: Updated row usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355. with server=slave1,60020,1405066324372
2014-07-11 01:12:43,602 INFO  [PostOpenDeployTasks:e468587ab0e54014075f4520dcd9c355] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:12:43,603 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e468587ab0e54014075f4520dcd9c355 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e468587ab0e54014075f4520dcd9c355 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:12:43,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned e468587ab0e54014075f4520dcd9c355 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:12:43,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355. on slave1,60020,1405066324372
2014-07-11 01:12:47,473 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:12:47,473 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-11 01:12:47,473 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 01:12:47,473 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-11 01:12:47,473 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 01:12:47,473 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:47,473 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 01:12:47,473 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:47,473 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29. because compaction request was cancelled
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355. because compaction request was cancelled
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 19 files from compaction candidates
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:47,474 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:47,475 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224. because compaction request was cancelled
2014-07-11 01:12:47,475 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-11 01:12:47,475 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 01:12:47,475 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-11 01:12:47,475 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:47,475 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:47,475 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2. because compaction request was cancelled
2014-07-11 01:12:47,476 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-11 01:12:47,476 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 17 files from compaction candidates
2014-07-11 01:12:47,476 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-11 01:12:47,476 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-11 01:12:47,476 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Not compacting usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2. because compaction request was cancelled
2014-07-11 01:13:11,086 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Close e468587ab0e54014075f4520dcd9c355, via zk=yes, znode version=0, on null
2014-07-11 01:13:11,086 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Close 2c9ec51d492f963529797ef469f19224, via zk=yes, znode version=0, on null
2014-07-11 01:13:11,086 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close f5085e3c4a405ca169db6dcb31b38b29, via zk=yes, znode version=0, on null
2014-07-11 01:13:11,086 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close e40f437ea2cd04f5e80b9966a93834b2, via zk=yes, znode version=0, on null
2014-07-11 01:13:11,086 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close bc1bf2a12fb05f36e29f0cabc7669ca2, via zk=yes, znode version=0, on null
2014-07-11 01:13:11,090 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:13:11,091 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:13:11,091 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:13:11,093 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.: disabling compactions & flushes
2014-07-11 01:13:11,094 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:13:11,094 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.: disabling compactions & flushes
2014-07-11 01:13:11,094 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:13:11,094 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.: disabling compactions & flushes
2014-07-11 01:13:11,095 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:13:11,147 INFO  [StoreCloserThread-usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.-1] regionserver.HStore: Closed family
2014-07-11 01:13:11,148 INFO  [StoreCloserThread-usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.-1] regionserver.HStore: Closed family
2014-07-11 01:13:11,148 INFO  [StoreCloserThread-usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.-1] regionserver.HStore: Closed family
2014-07-11 01:13:11,151 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:13:11,151 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:13:11,151 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:13:11,151 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e468587ab0e54014075f4520dcd9c355 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,151 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f5085e3c4a405ca169db6dcb31b38b29 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,151 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2c9ec51d492f963529797ef469f19224 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,156 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e468587ab0e54014075f4520dcd9c355 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,156 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355. on slave1,60020,1405066324372
2014-07-11 01:13:11,156 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user3,1405065489083.e468587ab0e54014075f4520dcd9c355.
2014-07-11 01:13:11,156 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f5085e3c4a405ca169db6dcb31b38b29 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29. on slave1,60020,1405066324372
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user8,1405065489083.f5085e3c4a405ca169db6dcb31b38b29.
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2c9ec51d492f963529797ef469f19224 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224. on slave1,60020,1405066324372
2014-07-11 01:13:11,167 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user5,1405065489083.2c9ec51d492f963529797ef469f19224.
2014-07-11 01:13:11,169 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.: disabling compactions & flushes
2014-07-11 01:13:11,169 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:13:11,169 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.: disabling compactions & flushes
2014-07-11 01:13:11,169 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:13:11,178 INFO  [StoreCloserThread-usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.-1] regionserver.HStore: Closed family
2014-07-11 01:13:11,179 INFO  [StoreCloserThread-usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.-1] regionserver.HStore: Closed family
2014-07-11 01:13:11,179 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:13:11,180 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e40f437ea2cd04f5e80b9966a93834b2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,180 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:13:11,180 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning bc1bf2a12fb05f36e29f0cabc7669ca2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,184 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e40f437ea2cd04f5e80b9966a93834b2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,184 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2. on slave1,60020,1405066324372
2014-07-11 01:13:11,185 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user7,1405065489083.e40f437ea2cd04f5e80b9966a93834b2.
2014-07-11 01:13:11,185 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node bc1bf2a12fb05f36e29f0cabc7669ca2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-11 01:13:11,185 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2. on slave1,60020,1405066324372
2014-07-11 01:13:11,185 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user6,1405065489083.bc1bf2a12fb05f36e29f0cabc7669ca2.
2014-07-11 01:13:14,963 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Compacting hbase:meta,,1.1588230740
2014-07-11 01:13:14,964 DEBUG [Priority.RpcServer.handler=9,port=60020] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-11 01:13:14,965 DEBUG [Priority.RpcServer.handler=9,port=60020] regionserver.HStore: 1588230740 - info: Initiating major compaction
2014-07-11 01:13:14,965 DEBUG [Priority.RpcServer.handler=9,port=60020] regionserver.CompactSplitThread: Small Compaction requested: org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext@5e37e4c5; Because: User-triggered major compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:13:14,965 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-07-11 01:13:14,967 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=15.9k
2014-07-11 01:13:14,968 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/af09d6d6a51c424a86a1a3eed3075d88, keycount=71, bloomtype=NONE, size=8.8k, encoding=NONE, seqNum=4066, earliestPutTs=1402645258588
2014-07-11 01:13:14,969 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/c2d5a90851fe41ff9fac90e408f30a48, keycount=53, bloomtype=NONE, size=7.0k, encoding=NONE, seqNum=4092, earliestPutTs=1405065149212
2014-07-11 01:13:14,984 DEBUG [regionserver60020-smallCompactions-1405066362964] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:13:15,065 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/411d309dd74140c1b62e6552f823e660 as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/411d309dd74140c1b62e6552f823e660
2014-07-11 01:13:15,094 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Removing store files after compaction...
2014-07-11 01:13:15,111 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/af09d6d6a51c424a86a1a3eed3075d88, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/af09d6d6a51c424a86a1a3eed3075d88
2014-07-11 01:13:15,115 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/c2d5a90851fe41ff9fac90e408f30a48, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/c2d5a90851fe41ff9fac90e408f30a48
2014-07-11 01:13:15,116 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Completed major compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into 411d309dd74140c1b62e6552f823e660(size=8.8k), total size for store is 8.8k. This selection was in queue for 0sec, and took 0sec to execute.
2014-07-11 01:13:15,119 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=15.9k, priority=1, time=20302391671817; duration=0sec
2014-07-11 01:13:15,120 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:17:04,464 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=61, hits=57, hitRatio=93.44%, , cachingAccesses=59, cachingHits=55, cachingHitsRatio=93.22%, evictions=0, evicted=2, evictedPerRun=Infinity
2014-07-11 01:18:22,498 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:18:22,546 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:18:22,546 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:18:22,547 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9fad4d31d095db592fcf0f508b9eb9f7 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,548 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:18:22,548 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a1bcecf7b391064e180b30d7fec9acaa from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,548 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:18:22,548 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c95022022bef1fbd42d3c48e0aae7a1b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,553 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9fad4d31d095db592fcf0f508b9eb9f7 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,553 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 9fad4d31d095db592fcf0f508b9eb9f7, NAME => 'usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-11 01:18:22,554 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 9fad4d31d095db592fcf0f508b9eb9f7
2014-07-11 01:18:22,554 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:18:22,559 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a1bcecf7b391064e180b30d7fec9acaa from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,559 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c95022022bef1fbd42d3c48e0aae7a1b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,559 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => a1bcecf7b391064e180b30d7fec9acaa, NAME => 'usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-11 01:18:22,560 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => c95022022bef1fbd42d3c48e0aae7a1b, NAME => 'usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-11 01:18:22,560 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a1bcecf7b391064e180b30d7fec9acaa
2014-07-11 01:18:22,560 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:18:22,560 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable c95022022bef1fbd42d3c48e0aae7a1b
2014-07-11 01:18:22,561 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:18:22,563 INFO  [StoreOpener-9fad4d31d095db592fcf0f508b9eb9f7-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:18:22,570 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7
2014-07-11 01:18:22,571 INFO  [StoreOpener-a1bcecf7b391064e180b30d7fec9acaa-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:18:22,571 INFO  [StoreOpener-c95022022bef1fbd42d3c48e0aae7a1b-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:18:22,573 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 9fad4d31d095db592fcf0f508b9eb9f7; next sequenceid=1
2014-07-11 01:18:22,573 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 9fad4d31d095db592fcf0f508b9eb9f7
2014-07-11 01:18:22,574 INFO  [PostOpenDeployTasks:9fad4d31d095db592fcf0f508b9eb9f7] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:18:22,575 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa
2014-07-11 01:18:22,576 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b
2014-07-11 01:18:22,579 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined a1bcecf7b391064e180b30d7fec9acaa; next sequenceid=1
2014-07-11 01:18:22,579 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a1bcecf7b391064e180b30d7fec9acaa
2014-07-11 01:18:22,581 INFO  [PostOpenDeployTasks:a1bcecf7b391064e180b30d7fec9acaa] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:18:22,584 INFO  [PostOpenDeployTasks:9fad4d31d095db592fcf0f508b9eb9f7] catalog.MetaEditor: Updated row usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. with server=slave1,60020,1405066324372
2014-07-11 01:18:22,584 INFO  [PostOpenDeployTasks:9fad4d31d095db592fcf0f508b9eb9f7] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:18:22,584 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 9fad4d31d095db592fcf0f508b9eb9f7 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,588 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 9fad4d31d095db592fcf0f508b9eb9f7 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,588 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 9fad4d31d095db592fcf0f508b9eb9f7 to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:18:22,588 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. on slave1,60020,1405066324372
2014-07-11 01:18:22,588 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6f66926485ddafad14336d1017b554fc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,589 INFO  [PostOpenDeployTasks:a1bcecf7b391064e180b30d7fec9acaa] catalog.MetaEditor: Updated row usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. with server=slave1,60020,1405066324372
2014-07-11 01:18:22,589 INFO  [PostOpenDeployTasks:a1bcecf7b391064e180b30d7fec9acaa] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:18:22,590 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a1bcecf7b391064e180b30d7fec9acaa from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,592 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6f66926485ddafad14336d1017b554fc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,593 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 6f66926485ddafad14336d1017b554fc, NAME => 'usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-11 01:18:22,593 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 6f66926485ddafad14336d1017b554fc
2014-07-11 01:18:22,593 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:18:22,594 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined c95022022bef1fbd42d3c48e0aae7a1b; next sequenceid=1
2014-07-11 01:18:22,595 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node c95022022bef1fbd42d3c48e0aae7a1b
2014-07-11 01:18:22,595 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a1bcecf7b391064e180b30d7fec9acaa from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,595 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned a1bcecf7b391064e180b30d7fec9acaa to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:18:22,595 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. on slave1,60020,1405066324372
2014-07-11 01:18:22,595 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3f27bb71c2d59493f7d68572a85c8b0d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,596 INFO  [PostOpenDeployTasks:c95022022bef1fbd42d3c48e0aae7a1b] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:18:22,600 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3f27bb71c2d59493f7d68572a85c8b0d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-11 01:18:22,601 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 3f27bb71c2d59493f7d68572a85c8b0d, NAME => 'usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-11 01:18:22,601 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 3f27bb71c2d59493f7d68572a85c8b0d
2014-07-11 01:18:22,601 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:18:22,603 INFO  [PostOpenDeployTasks:c95022022bef1fbd42d3c48e0aae7a1b] catalog.MetaEditor: Updated row usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. with server=slave1,60020,1405066324372
2014-07-11 01:18:22,603 INFO  [PostOpenDeployTasks:c95022022bef1fbd42d3c48e0aae7a1b] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:18:22,603 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c95022022bef1fbd42d3c48e0aae7a1b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c95022022bef1fbd42d3c48e0aae7a1b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned c95022022bef1fbd42d3c48e0aae7a1b to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:18:22,608 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. on slave1,60020,1405066324372
2014-07-11 01:18:22,610 INFO  [StoreOpener-6f66926485ddafad14336d1017b554fc-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:18:22,612 INFO  [StoreOpener-3f27bb71c2d59493f7d68572a85c8b0d-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-11 01:18:22,615 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc
2014-07-11 01:18:22,616 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d
2014-07-11 01:18:22,618 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 6f66926485ddafad14336d1017b554fc; next sequenceid=1
2014-07-11 01:18:22,618 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 6f66926485ddafad14336d1017b554fc
2014-07-11 01:18:22,620 INFO  [PostOpenDeployTasks:6f66926485ddafad14336d1017b554fc] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:18:22,625 INFO  [PostOpenDeployTasks:6f66926485ddafad14336d1017b554fc] catalog.MetaEditor: Updated row usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. with server=slave1,60020,1405066324372
2014-07-11 01:18:22,625 INFO  [PostOpenDeployTasks:6f66926485ddafad14336d1017b554fc] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:18:22,626 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 6f66926485ddafad14336d1017b554fc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,637 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 6f66926485ddafad14336d1017b554fc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,637 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 6f66926485ddafad14336d1017b554fc to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:18:22,637 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. on slave1,60020,1405066324372
2014-07-11 01:18:22,657 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 3f27bb71c2d59493f7d68572a85c8b0d; next sequenceid=1
2014-07-11 01:18:22,657 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 3f27bb71c2d59493f7d68572a85c8b0d
2014-07-11 01:18:22,659 INFO  [PostOpenDeployTasks:3f27bb71c2d59493f7d68572a85c8b0d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:18:22,664 INFO  [PostOpenDeployTasks:3f27bb71c2d59493f7d68572a85c8b0d] catalog.MetaEditor: Updated row usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. with server=slave1,60020,1405066324372
2014-07-11 01:18:22,664 INFO  [PostOpenDeployTasks:3f27bb71c2d59493f7d68572a85c8b0d] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:18:22,665 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3f27bb71c2d59493f7d68572a85c8b0d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,668 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147247aa9e90001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3f27bb71c2d59493f7d68572a85c8b0d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-11 01:18:22,668 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 3f27bb71c2d59493f7d68572a85c8b0d to OPENED in zk on slave1,60020,1405066324372
2014-07-11 01:18:22,668 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. on slave1,60020,1405066324372
2014-07-11 01:18:41,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:18:41,957 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 88 synced till here 71
2014-07-11 01:18:42,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066357341 with entries=88, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066721637
2014-07-11 01:18:45,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:18:45,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 168 synced till here 162
2014-07-11 01:18:45,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066721637 with entries=80, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066725264
2014-07-11 01:18:47,001 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:18:47,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 249 synced till here 242
2014-07-11 01:18:47,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066725264 with entries=81, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066727001
2014-07-11 01:18:48,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:18:48,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 330 synced till here 326
2014-07-11 01:18:48,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066727001 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066728746
2014-07-11 01:18:50,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:18:50,396 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 433 synced till here 432
2014-07-11 01:18:50,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066728746 with entries=103, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066730374
2014-07-11 01:19:12,615 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:12,646 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 586 synced till here 584
2014-07-11 01:19:12,712 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066730374 with entries=153, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066752615
2014-07-11 01:19:15,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:15,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 677 synced till here 675
2014-07-11 01:19:15,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066752615 with entries=91, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066755154
2014-07-11 01:19:17,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:17,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 742 synced till here 740
2014-07-11 01:19:17,194 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066755154 with entries=65, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066757023
2014-07-11 01:19:18,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:19,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 820 synced till here 816
2014-07-11 01:19:19,148 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066757023 with entries=78, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066758998
2014-07-11 01:19:21,030 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:21,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 904 synced till here 898
2014-07-11 01:19:21,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066758998 with entries=84, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066761030
2014-07-11 01:19:21,965 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:19:21,967 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., current region memstore size 257.6m
2014-07-11 01:19:22,150 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:19:22,160 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., current region memstore size 256.8m
2014-07-11 01:19:22,322 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:19:22,469 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:19:22,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:22,973 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:19:22,974 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:19:22,985 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-11 01:19:22,989 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:19:23,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 992 synced till here 990
2014-07-11 01:19:23,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066761030 with entries=88, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066762670
2014-07-11 01:19:24,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:24,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066762670 with entries=82, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066764691
2014-07-11 01:19:26,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:26,727 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066764691 with entries=85, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066766700
2014-07-11 01:19:29,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:29,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1239 synced till here 1234
2014-07-11 01:19:29,316 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066766700 with entries=80, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066769139
2014-07-11 01:19:31,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:31,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1334 synced till here 1332
2014-07-11 01:19:32,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066769139 with entries=95, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066771572
2014-07-11 01:19:33,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:33,910 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1417 synced till here 1411
2014-07-11 01:19:33,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066771572 with entries=83, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066773768
2014-07-11 01:19:35,980 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:37,803 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066773768 with entries=165, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066775980
2014-07-11 01:19:38,025 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=197, memsize=261.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/0db79f93e1d74f37b0dcd51616946124
2014-07-11 01:19:38,046 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/0db79f93e1d74f37b0dcd51616946124 as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/0db79f93e1d74f37b0dcd51616946124
2014-07-11 01:19:38,101 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/0db79f93e1d74f37b0dcd51616946124, entries=953390, sequenceid=197, filesize=67.9m
2014-07-11 01:19:38,102 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.8m/274568640, currentsize=160.2m/167981360 for region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. in 15942ms, sequenceid=197, compaction requested=false
2014-07-11 01:19:38,106 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 422.1m
2014-07-11 01:19:38,128 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=196, memsize=260.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/8bef61aa7b80463ab31cce4747f84a62
2014-07-11 01:19:38,151 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/8bef61aa7b80463ab31cce4747f84a62 as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/8bef61aa7b80463ab31cce4747f84a62
2014-07-11 01:19:38,177 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/8bef61aa7b80463ab31cce4747f84a62, entries=948480, sequenceid=196, filesize=67.6m
2014-07-11 01:19:38,177 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.5m/273155840, currentsize=161.1m/168898960 for region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. in 16210ms, sequenceid=196, compaction requested=false
2014-07-11 01:19:38,177 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., current region memstore size 423.0m
2014-07-11 01:19:38,399 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:19:38,451 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:19:51,733 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=321, memsize=422.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/aff021f926e34d00b97bc6691a2f13f1
2014-07-11 01:19:51,761 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/aff021f926e34d00b97bc6691a2f13f1 as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/aff021f926e34d00b97bc6691a2f13f1
2014-07-11 01:19:51,776 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/aff021f926e34d00b97bc6691a2f13f1, entries=1538180, sequenceid=321, filesize=109.6m
2014-07-11 01:19:51,777 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~422.5m/442980880, currentsize=1.2m/1284480 for region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. in 13671ms, sequenceid=321, compaction requested=false
2014-07-11 01:19:51,777 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc., current region memstore size 422.6m
2014-07-11 01:19:51,780 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=321, memsize=423.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/0c813636f843487d86db9b6fd021d85f
2014-07-11 01:19:51,793 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/0c813636f843487d86db9b6fd021d85f as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/0c813636f843487d86db9b6fd021d85f
2014-07-11 01:19:51,804 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/0c813636f843487d86db9b6fd021d85f, entries=1540010, sequenceid=321, filesize=109.7m
2014-07-11 01:19:51,804 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~423.0m/443509120, currentsize=1.3m/1338960 for region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. in 13627ms, sequenceid=321, compaction requested=false
2014-07-11 01:19:52,147 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:19:56,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:19:56,854 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1723 synced till here 1722
2014-07-11 01:19:56,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066775980 with entries=141, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066796835
2014-07-11 01:20:01,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:01,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1819 synced till here 1817
2014-07-11 01:20:02,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066796835 with entries=96, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066801336
2014-07-11 01:20:04,210 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:04,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1899 synced till here 1894
2014-07-11 01:20:04,523 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066801336 with entries=80, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066804210
2014-07-11 01:20:05,636 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:20:05,637 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., current region memstore size 256.0m
2014-07-11 01:20:06,013 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:20:06,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:06,276 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:20:06,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1973 synced till here 1967
2014-07-11 01:20:06,466 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066804210 with entries=74, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066806277
2014-07-11 01:20:08,325 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:08,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2058 synced till here 2050
2014-07-11 01:20:08,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066806277 with entries=85, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066808325
2014-07-11 01:20:10,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:10,089 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2145 synced till here 2137
2014-07-11 01:20:10,231 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066808325 with entries=87, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066810074
2014-07-11 01:20:12,501 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:12,633 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2237 synced till here 2225
2014-07-11 01:20:12,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066810074 with entries=92, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066812501
2014-07-11 01:20:13,598 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=327, memsize=422.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/6f139744ecdb4c9eb99ec1ecaf77e8c6
2014-07-11 01:20:13,739 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/6f139744ecdb4c9eb99ec1ecaf77e8c6 as hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/6f139744ecdb4c9eb99ec1ecaf77e8c6
2014-07-11 01:20:13,758 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/6f139744ecdb4c9eb99ec1ecaf77e8c6, entries=1538530, sequenceid=327, filesize=109.6m
2014-07-11 01:20:13,759 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~422.6m/443087520, currentsize=177.0m/185611680 for region usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. in 21982ms, sequenceid=327, compaction requested=false
2014-07-11 01:20:13,759 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., current region memstore size 349.0m
2014-07-11 01:20:14,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:14,475 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:20:15,131 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2333 synced till here 2329
2014-07-11 01:20:15,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066812501 with entries=96, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066814289
2014-07-11 01:20:15,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066357341
2014-07-11 01:20:15,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066721637
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066725264
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066727001
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066728746
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066730374
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066752615
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066755154
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066757023
2014-07-11 01:20:15,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066758998
2014-07-11 01:20:17,062 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:17,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2407 synced till here 2400
2014-07-11 01:20:17,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066814289 with entries=74, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066817063
2014-07-11 01:20:19,430 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:19,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2483 synced till here 2473
2014-07-11 01:20:19,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066817063 with entries=76, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066819431
2014-07-11 01:20:20,069 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:20:20,371 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:20:20,693 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:20:21,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:21,663 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2559 synced till here 2555
2014-07-11 01:20:21,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066819431 with entries=76, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066821637
2014-07-11 01:20:22,219 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=397, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/51d9fdcb82b34d65a229816d512ec1b8
2014-07-11 01:20:22,234 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/51d9fdcb82b34d65a229816d512ec1b8 as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/51d9fdcb82b34d65a229816d512ec1b8
2014-07-11 01:20:22,255 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/51d9fdcb82b34d65a229816d512ec1b8, entries=932130, sequenceid=397, filesize=66.4m
2014-07-11 01:20:22,255 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.0m/268447040, currentsize=194.6m/204004960 for region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. in 16618ms, sequenceid=397, compaction requested=false
2014-07-11 01:20:22,255 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 288.3m
2014-07-11 01:20:22,627 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:20:23,711 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:23,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2632 synced till here 2627
2014-07-11 01:20:24,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066821637 with entries=73, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066823712
2014-07-11 01:20:25,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:27,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2750 synced till here 2742
2014-07-11 01:20:27,108 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:20:27,258 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066823712 with entries=118, filesize=105.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066825897
2014-07-11 01:20:29,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:29,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2814 synced till here 2813
2014-07-11 01:20:29,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066825897 with entries=64, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066829120
2014-07-11 01:20:32,574 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:32,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2892 synced till here 2884
2014-07-11 01:20:32,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066829120 with entries=78, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066832575
2014-07-11 01:20:34,945 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:35,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2970 synced till here 2966
2014-07-11 01:20:35,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066832575 with entries=78, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066834945
2014-07-11 01:20:37,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:37,830 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3052 synced till here 3046
2014-07-11 01:20:37,900 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066834945 with entries=82, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066837631
2014-07-11 01:20:39,568 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:39,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3126 synced till here 3123
2014-07-11 01:20:39,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066837631 with entries=74, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066839568
2014-07-11 01:20:40,682 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=460, memsize=349.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/ded88fd532b344e1a0f846e808fff3f2
2014-07-11 01:20:40,696 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/ded88fd532b344e1a0f846e808fff3f2 as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/ded88fd532b344e1a0f846e808fff3f2
2014-07-11 01:20:40,708 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/ded88fd532b344e1a0f846e808fff3f2, entries=1270730, sequenceid=460, filesize=90.5m
2014-07-11 01:20:40,708 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~349.0m/365958560, currentsize=289.2m/303248240 for region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. in 26949ms, sequenceid=460, compaction requested=false
2014-07-11 01:20:40,708 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., current region memstore size 469.9m
2014-07-11 01:20:40,849 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:20:41,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:41,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3205 synced till here 3202
2014-07-11 01:20:41,525 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066839568 with entries=79, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066841366
2014-07-11 01:20:41,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066761030
2014-07-11 01:20:41,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066762670
2014-07-11 01:20:41,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066764691
2014-07-11 01:20:41,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066766700
2014-07-11 01:20:41,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066769139
2014-07-11 01:20:41,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066771572
2014-07-11 01:20:41,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066773768
2014-07-11 01:20:41,827 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:20:43,133 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:43,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066841366 with entries=78, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066843133
2014-07-11 01:20:44,322 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=519, memsize=288.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/593e22ba71d546efba524db8a2a52102
2014-07-11 01:20:44,341 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/593e22ba71d546efba524db8a2a52102 as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/593e22ba71d546efba524db8a2a52102
2014-07-11 01:20:44,358 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/593e22ba71d546efba524db8a2a52102, entries=1049580, sequenceid=519, filesize=74.7m
2014-07-11 01:20:44,358 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~288.3m/302270880, currentsize=236.8m/248348640 for region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. in 22103ms, sequenceid=519, compaction requested=false
2014-07-11 01:20:44,359 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc., current region memstore size 521.3m
2014-07-11 01:20:44,827 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:44,847 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3368 synced till here 3364
2014-07-11 01:20:45,134 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066843133 with entries=85, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066844827
2014-07-11 01:20:45,338 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:20:45,987 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:20:47,630 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:20:47,804 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066844827 with entries=108, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066847674
2014-07-11 01:20:58,622 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=634, memsize=471.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/5c0eb21f327a4cdcbb54ce8a5a4104fe
2014-07-11 01:20:58,644 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/5c0eb21f327a4cdcbb54ce8a5a4104fe as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/5c0eb21f327a4cdcbb54ce8a5a4104fe
2014-07-11 01:20:58,685 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/5c0eb21f327a4cdcbb54ce8a5a4104fe, entries=1717710, sequenceid=634, filesize=122.3m
2014-07-11 01:20:58,685 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~471.8m/494687920, currentsize=90.9m/95337280 for region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. in 17977ms, sequenceid=634, compaction requested=false
2014-07-11 01:20:58,686 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., current region memstore size 468.2m
2014-07-11 01:20:59,002 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:21:01,956 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=670, memsize=524.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/d0b49560ae684361bc16aaa761b4bc49
2014-07-11 01:21:01,987 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/d0b49560ae684361bc16aaa761b4bc49 as hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/d0b49560ae684361bc16aaa761b4bc49
2014-07-11 01:21:02,029 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/d0b49560ae684361bc16aaa761b4bc49, entries=1908070, sequenceid=670, filesize=135.8m
2014-07-11 01:21:02,029 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~524.1m/549508080, currentsize=37.6m/39400000 for region usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. in 17670ms, sequenceid=670, compaction requested=false
2014-07-11 01:21:02,031 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., current region memstore size 374.8m
2014-07-11 01:21:02,291 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:21:12,665 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=713, memsize=468.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/6860836a8ca74c3190b8c34b9d4ba4ed
2014-07-11 01:21:12,685 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/6860836a8ca74c3190b8c34b9d4ba4ed as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/6860836a8ca74c3190b8c34b9d4ba4ed
2014-07-11 01:21:12,700 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/6860836a8ca74c3190b8c34b9d4ba4ed, entries=1704580, sequenceid=713, filesize=121.3m
2014-07-11 01:21:12,701 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~468.2m/490904320, currentsize=0.0/0 for region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. in 14015ms, sequenceid=713, compaction requested=true
2014-07-11 01:21:12,702 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-11 01:21:12,702 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-11 01:21:12,702 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 274.5m
2014-07-11 01:21:12,702 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 267745059 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-11 01:21:12,702 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: a1bcecf7b391064e180b30d7fec9acaa - family: Initiating major compaction
2014-07-11 01:21:12,702 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:21:12,703 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp, totalSize=255.3m
2014-07-11 01:21:12,703 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/8bef61aa7b80463ab31cce4747f84a62, keycount=94848, bloomtype=ROW, size=67.6m, encoding=NONE, seqNum=196, earliestPutTs=1405066718645
2014-07-11 01:21:12,703 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/51d9fdcb82b34d65a229816d512ec1b8, keycount=93213, bloomtype=ROW, size=66.4m, encoding=NONE, seqNum=397, earliestPutTs=1405066761993
2014-07-11 01:21:12,703 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/6860836a8ca74c3190b8c34b9d4ba4ed, keycount=170458, bloomtype=ROW, size=121.3m, encoding=NONE, seqNum=713, earliestPutTs=1405066805789
2014-07-11 01:21:12,723 DEBUG [regionserver60020-smallCompactions-1405066362964] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:21:12,879 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:21:12,892 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-11 01:21:12,892 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-11 01:21:13,327 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=713, memsize=374.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/36a96282de8949728275e1b0cb5e7217
2014-07-11 01:21:13,343 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/36a96282de8949728275e1b0cb5e7217 as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/36a96282de8949728275e1b0cb5e7217
2014-07-11 01:21:13,378 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/36a96282de8949728275e1b0cb5e7217, entries=1364520, sequenceid=713, filesize=97.1m
2014-07-11 01:21:13,379 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~374.8m/392971680, currentsize=0.0/0 for region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. in 11348ms, sequenceid=713, compaction requested=true
2014-07-11 01:21:13,379 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-11 01:21:21,140 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=713, memsize=274.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/d5228c24d33d4c069da498771cb0fae5
2014-07-11 01:21:21,152 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/d5228c24d33d4c069da498771cb0fae5 as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/d5228c24d33d4c069da498771cb0fae5
2014-07-11 01:21:21,166 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/d5228c24d33d4c069da498771cb0fae5, entries=999480, sequenceid=713, filesize=71.2m
2014-07-11 01:21:21,167 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~274.5m/287843920, currentsize=0.0/0 for region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. in 8465ms, sequenceid=713, compaction requested=true
2014-07-11 01:21:21,168 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 01:21:44,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:21:44,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3649 synced till here 3648
2014-07-11 01:21:44,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066847674 with entries=173, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066904339
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066775980
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066796835
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066801336
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066804210
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066806277
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066808325
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066810074
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066812501
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066814289
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066817063
2014-07-11 01:21:44,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066819431
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066821637
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066823712
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066825897
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066829120
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066832575
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066834945
2014-07-11 01:21:44,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066837631
2014-07-11 01:21:47,300 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:21:47,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3767 synced till here 3766
2014-07-11 01:21:47,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066904339 with entries=118, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066907300
2014-07-11 01:21:49,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:21:49,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066907300 with entries=74, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066909182
2014-07-11 01:21:49,605 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/5b33ea0fbf8d450f8420a84f224e0f99 as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/5b33ea0fbf8d450f8420a84f224e0f99
2014-07-11 01:21:49,623 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Removing store files after compaction...
2014-07-11 01:21:49,631 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/8bef61aa7b80463ab31cce4747f84a62, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/8bef61aa7b80463ab31cce4747f84a62
2014-07-11 01:21:49,636 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/51d9fdcb82b34d65a229816d512ec1b8, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/51d9fdcb82b34d65a229816d512ec1b8
2014-07-11 01:21:49,639 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/6860836a8ca74c3190b8c34b9d4ba4ed, to hdfs://master:54310/hbase/archive/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/6860836a8ca74c3190b8c34b9d4ba4ed
2014-07-11 01:21:49,639 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. into 5b33ea0fbf8d450f8420a84f224e0f99(size=255.2m), total size for store is 255.2m. This selection was in queue for 0sec, and took 36sec to execute.
2014-07-11 01:21:49,640 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., storeName=family, fileCount=3, fileSize=255.3m, priority=17, time=20780129597020; duration=36sec
2014-07-11 01:21:49,640 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 01:21:49,640 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-11 01:21:49,641 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 268015865 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-11 01:21:49,641 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: 9fad4d31d095db592fcf0f508b9eb9f7 - family: Initiating major compaction
2014-07-11 01:21:49,641 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:21:49,642 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp, totalSize=255.6m
2014-07-11 01:21:49,642 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/0db79f93e1d74f37b0dcd51616946124, keycount=95339, bloomtype=ROW, size=67.9m, encoding=NONE, seqNum=197, earliestPutTs=1405066719920
2014-07-11 01:21:49,642 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/ded88fd532b344e1a0f846e808fff3f2, keycount=127073, bloomtype=ROW, size=90.5m, encoding=NONE, seqNum=460, earliestPutTs=1405066762308
2014-07-11 01:21:49,642 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/36a96282de8949728275e1b0cb5e7217, keycount=136452, bloomtype=ROW, size=97.1m, encoding=NONE, seqNum=713, earliestPutTs=1405066813766
2014-07-11 01:21:49,669 DEBUG [regionserver60020-smallCompactions-1405066362964] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:21:53,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:21:53,366 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066909182 with entries=90, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066913310
2014-07-11 01:21:56,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:21:57,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4027 synced till here 4018
2014-07-11 01:21:57,296 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066913310 with entries=96, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066916706
2014-07-11 01:21:59,008 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:21:59,090 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4124 synced till here 4120
2014-07-11 01:21:59,125 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066916706 with entries=97, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066919009
2014-07-11 01:22:01,450 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:01,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4273 synced till here 4272
2014-07-11 01:22:02,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066919009 with entries=149, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066921451
2014-07-11 01:22:04,462 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=12340, hits=1041, hitRatio=8.43%, , cachingAccesses=1044, cachingHits=1039, cachingHitsRatio=99.52%, evictions=0, evicted=2, evictedPerRun=Infinity
2014-07-11 01:22:07,569 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:22:07,570 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., current region memstore size 258.4m
2014-07-11 01:22:07,777 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:22:08,846 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:08,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4452 synced till here 4447
2014-07-11 01:22:09,259 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066921451 with entries=179, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066928847
2014-07-11 01:22:10,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:11,318 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4564 synced till here 4556
2014-07-11 01:22:11,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066928847 with entries=112, filesize=81.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066930883
2014-07-11 01:22:11,855 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:22:11,856 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc., current region memstore size 256.3m
2014-07-11 01:22:12,161 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:22:12,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:12,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4670 synced till here 4665
2014-07-11 01:22:13,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066930883 with entries=106, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066932913
2014-07-11 01:22:14,621 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:22:14,848 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:22:15,010 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:22:15,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:15,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4769 synced till here 4764
2014-07-11 01:22:15,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066932913 with entries=99, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066935151
2014-07-11 01:22:16,836 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:16,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4879 synced till here 4875
2014-07-11 01:22:17,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066935151 with entries=110, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066936837
2014-07-11 01:22:18,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:19,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066936837 with entries=122, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066938675
2014-07-11 01:22:20,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:20,958 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5097 synced till here 5083
2014-07-11 01:22:21,164 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066938675 with entries=96, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066940943
2014-07-11 01:22:22,552 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=878, memsize=258.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/eba7ca0abc1c409184734ce2e414f379
2014-07-11 01:22:22,564 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/eba7ca0abc1c409184734ce2e414f379 as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/eba7ca0abc1c409184734ce2e414f379
2014-07-11 01:22:22,576 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/eba7ca0abc1c409184734ce2e414f379, entries=940940, sequenceid=878, filesize=67.1m
2014-07-11 01:22:22,576 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.4m/270983920, currentsize=184.1m/193066880 for region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. in 15006ms, sequenceid=878, compaction requested=true
2014-07-11 01:22:22,662 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-11 01:22:22,662 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., current region memstore size 361.6m
2014-07-11 01:22:22,996 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:23,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5173 synced till here 5172
2014-07-11 01:22:23,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066940943 with entries=76, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066942996
2014-07-11 01:22:23,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066839568
2014-07-11 01:22:23,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066841366
2014-07-11 01:22:23,168 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:22:24,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:25,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5256 synced till here 5251
2014-07-11 01:22:25,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066942996 with entries=83, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066944921
2014-07-11 01:22:27,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:27,048 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5326 synced till here 5320
2014-07-11 01:22:27,172 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066944921 with entries=70, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066947030
2014-07-11 01:22:28,053 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=921, memsize=256.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/e1e373d0cfb147849d59fc887aaf6482
2014-07-11 01:22:28,071 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/e1e373d0cfb147849d59fc887aaf6482 as hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/e1e373d0cfb147849d59fc887aaf6482
2014-07-11 01:22:28,083 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/e1e373d0cfb147849d59fc887aaf6482, entries=933110, sequenceid=921, filesize=66.5m
2014-07-11 01:22:28,083 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.3m/268726400, currentsize=198.2m/207801280 for region usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. in 16227ms, sequenceid=921, compaction requested=true
2014-07-11 01:22:28,083 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 01:22:28,084 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., current region memstore size 426.1m
2014-07-11 01:22:28,464 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:22:29,209 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:29,225 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:22:29,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5393 synced till here 5389
2014-07-11 01:22:29,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066947030 with entries=67, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066949210
2014-07-11 01:22:29,439 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066843133
2014-07-11 01:22:29,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066844827
2014-07-11 01:22:32,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:32,355 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5459 synced till here 5457
2014-07-11 01:22:32,376 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066949210 with entries=66, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066952219
2014-07-11 01:22:33,994 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:22:34,455 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:34,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5521 synced till here 5520
2014-07-11 01:22:34,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066952219 with entries=62, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066954456
2014-07-11 01:22:36,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:36,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5587 synced till here 5583
2014-07-11 01:22:36,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066954456 with entries=66, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066956262
2014-07-11 01:22:37,876 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:38,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5650 synced till here 5649
2014-07-11 01:22:38,672 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066956262 with entries=63, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066957876
2014-07-11 01:22:40,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:40,618 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5732 synced till here 5711
2014-07-11 01:22:40,955 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066957876 with entries=82, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066960184
2014-07-11 01:22:42,159 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:42,215 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5800 synced till here 5792
2014-07-11 01:22:42,312 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066960184 with entries=68, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066962159
2014-07-11 01:22:44,282 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:44,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5866 synced till here 5862
2014-07-11 01:22:44,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066962159 with entries=66, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066964282
2014-07-11 01:22:46,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:46,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5948 synced till here 5939
2014-07-11 01:22:47,120 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1040, memsize=361.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/ed19b15256a441aba78378207d2244e5
2014-07-11 01:22:47,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066964282 with entries=82, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066966594
2014-07-11 01:22:47,315 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/ed19b15256a441aba78378207d2244e5 as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/ed19b15256a441aba78378207d2244e5
2014-07-11 01:22:47,333 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/ed19b15256a441aba78378207d2244e5, entries=1316630, sequenceid=1040, filesize=93.8m
2014-07-11 01:22:47,334 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~361.6m/379179760, currentsize=290.5m/304630400 for region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. in 24672ms, sequenceid=1040, compaction requested=false
2014-07-11 01:22:47,334 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 639.4m
2014-07-11 01:22:47,630 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:22:48,875 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:22:49,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:49,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6033 synced till here 6022
2014-07-11 01:22:50,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066966594 with entries=85, filesize=85.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066969861
2014-07-11 01:22:50,715 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/589d8380904e426998ccd9b6297de8c1 as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/589d8380904e426998ccd9b6297de8c1
2014-07-11 01:22:51,369 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Removing store files after compaction...
2014-07-11 01:22:51,507 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/0db79f93e1d74f37b0dcd51616946124, to hdfs://master:54310/hbase/archive/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/0db79f93e1d74f37b0dcd51616946124
2014-07-11 01:22:51,512 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/ded88fd532b344e1a0f846e808fff3f2, to hdfs://master:54310/hbase/archive/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/ded88fd532b344e1a0f846e808fff3f2
2014-07-11 01:22:51,536 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/36a96282de8949728275e1b0cb5e7217, to hdfs://master:54310/hbase/archive/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/36a96282de8949728275e1b0cb5e7217
2014-07-11 01:22:51,536 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. into 589d8380904e426998ccd9b6297de8c1(size=255.5m), total size for store is 255.5m. This selection was in queue for 0sec, and took 1mins, 1sec to execute.
2014-07-11 01:22:51,537 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., storeName=family, fileCount=3, fileSize=255.6m, priority=17, time=20817068098118; duration=1mins, 1sec
2014-07-11 01:22:51,537 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 01:22:51,537 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-11 01:22:51,538 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 267927113 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-11 01:22:51,538 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: 3f27bb71c2d59493f7d68572a85c8b0d - family: Initiating major compaction
2014-07-11 01:22:51,538 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:22:51,539 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp, totalSize=255.5m
2014-07-11 01:22:51,539 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/aff021f926e34d00b97bc6691a2f13f1, keycount=153818, bloomtype=ROW, size=109.6m, encoding=NONE, seqNum=321, earliestPutTs=1405066720676
2014-07-11 01:22:51,539 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/593e22ba71d546efba524db8a2a52102, keycount=104958, bloomtype=ROW, size=74.7m, encoding=NONE, seqNum=519, earliestPutTs=1405066778196
2014-07-11 01:22:51,540 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/d5228c24d33d4c069da498771cb0fae5, keycount=99948, bloomtype=ROW, size=71.2m, encoding=NONE, seqNum=713, earliestPutTs=1405066822448
2014-07-11 01:22:51,563 DEBUG [regionserver60020-smallCompactions-1405066362964] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:22:52,143 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:52,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6113 synced till here 6100
2014-07-11 01:22:52,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066969861 with entries=80, filesize=79.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066972143
2014-07-11 01:22:54,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:54,341 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6188 synced till here 6178
2014-07-11 01:22:54,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066972143 with entries=75, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066974318
2014-07-11 01:22:56,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:56,459 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6250 synced till here 6249
2014-07-11 01:22:56,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066974318 with entries=62, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066976442
2014-07-11 01:22:58,349 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1080, memsize=429.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/1e0a82394f054e86834cd3830315d9f3
2014-07-11 01:22:58,363 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/1e0a82394f054e86834cd3830315d9f3 as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/1e0a82394f054e86834cd3830315d9f3
2014-07-11 01:22:58,367 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:22:58,543 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/1e0a82394f054e86834cd3830315d9f3, entries=1564630, sequenceid=1080, filesize=111.5m
2014-07-11 01:22:58,545 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~429.7m/450601120, currentsize=343.9m/360600000 for region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. in 30461ms, sequenceid=1080, compaction requested=false
2014-07-11 01:22:58,546 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., current region memstore size 599.0m
2014-07-11 01:22:58,550 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6314 synced till here 6312
2014-07-11 01:22:58,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066976442 with entries=64, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066978368
2014-07-11 01:22:59,002 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:23:00,538 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:23:01,238 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:01,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6395 synced till here 6392
2014-07-11 01:23:02,014 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066978368 with entries=81, filesize=81.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066981239
2014-07-11 01:23:03,793 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:03,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6475 synced till here 6467
2014-07-11 01:23:04,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066981239 with entries=80, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066983793
2014-07-11 01:23:06,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:06,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6549 synced till here 6545
2014-07-11 01:23:06,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066983793 with entries=74, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066986178
2014-07-11 01:23:08,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:08,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6633 synced till here 6630
2014-07-11 01:23:09,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066986178 with entries=84, filesize=84.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066988818
2014-07-11 01:23:10,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:10,536 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066988818 with entries=63, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066990495
2014-07-11 01:23:12,595 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:12,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6764 synced till here 6757
2014-07-11 01:23:12,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066990495 with entries=68, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066992596
2014-07-11 01:23:15,012 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:15,144 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6837 synced till here 6828
2014-07-11 01:23:15,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066992596 with entries=73, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066995013
2014-07-11 01:23:17,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:17,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6914 synced till here 6904
2014-07-11 01:23:17,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066995013 with entries=77, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066997604
2014-07-11 01:23:20,036 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:20,224 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6985 synced till here 6982
2014-07-11 01:23:20,273 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066997604 with entries=71, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067000037
2014-07-11 01:23:21,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:22,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067000037 with entries=63, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067001836
2014-07-11 01:23:22,997 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:22,999 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,023 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,041 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,058 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,180 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,200 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,201 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,228 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,234 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,242 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,416 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,481 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,657 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,696 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,742 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:23,982 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,024 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,078 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,285 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,332 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,388 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,598 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,636 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,683 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,902 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:24,951 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:25,000 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:25,251 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:25,286 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:23:43,500 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18213ms
2014-07-11 01:23:43,500 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18249ms
2014-07-11 01:23:43,500 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18500ms
2014-07-11 01:23:43,501 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18598ms
2014-07-11 01:23:43,501 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19424ms
2014-07-11 01:23:43,501 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18550ms
2014-07-11 01:23:43,502 WARN  [regionserver60020] util.Sleeper: We slept 17878ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-11 01:23:43,502 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20444ms
2014-07-11 01:23:43,502 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20503ms
2014-07-11 01:23:43,502 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 25589ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-11 01:23:43,502 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 25590ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-11 01:23:43,502 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20323ms
2014-07-11 01:23:43,504 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20305ms
2014-07-11 01:23:43,504 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20303ms
2014-07-11 01:23:43,505 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20277ms
2014-07-11 01:23:43,507 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20274ms
2014-07-11 01:23:43,507 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20265ms
2014-07-11 01:23:43,508 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20092ms
2014-07-11 01:23:43,508 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20027ms
2014-07-11 01:23:43,509 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19852ms
2014-07-11 01:23:43,510 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19813ms
2014-07-11 01:23:43,510 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19768ms
2014-07-11 01:23:43,510 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19529ms
2014-07-11 01:23:43,511 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19487ms
2014-07-11 01:23:43,511 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19123ms
2014-07-11 01:23:43,511 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19226ms
2014-07-11 01:23:43,511 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19179ms
2014-07-11 01:23:43,511 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18913ms
2014-07-11 01:23:43,511 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18875ms
2014-07-11 01:23:43,512 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18828ms
2014-07-11 01:23:43,512 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20515ms
2014-07-11 01:23:43,512 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20489ms
2014-07-11 01:23:43,512 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20471ms
2014-07-11 01:23:43,605 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17757ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=17805ms
2014-07-11 01:23:48,500 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23214ms
2014-07-11 01:23:48,500 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23500ms
2014-07-11 01:23:48,501 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23249ms
2014-07-11 01:23:48,501 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23599ms
2014-07-11 01:23:48,502 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24424ms
2014-07-11 01:23:48,502 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23551ms
2014-07-11 01:23:48,502 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25444ms
2014-07-11 01:23:48,502 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25503ms
2014-07-11 01:23:48,504 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25325ms
2014-07-11 01:23:48,505 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25306ms
2014-07-11 01:23:48,505 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25304ms
2014-07-11 01:23:48,507 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25279ms
2014-07-11 01:23:48,507 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25274ms
2014-07-11 01:23:48,508 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25266ms
2014-07-11 01:23:48,508 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25092ms
2014-07-11 01:23:48,509 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25028ms
2014-07-11 01:23:48,509 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24852ms
2014-07-11 01:23:48,510 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24814ms
2014-07-11 01:23:48,510 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24768ms
2014-07-11 01:23:48,511 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24530ms
2014-07-11 01:23:48,511 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24487ms
2014-07-11 01:23:48,511 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24123ms
2014-07-11 01:23:48,511 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24226ms
2014-07-11 01:23:48,511 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24179ms
2014-07-11 01:23:48,511 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23913ms
2014-07-11 01:23:48,512 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23876ms
2014-07-11 01:23:48,512 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23829ms
2014-07-11 01:23:48,512 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25515ms
2014-07-11 01:23:48,512 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25489ms
2014-07-11 01:23:48,512 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25471ms
2014-07-11 01:23:49,230 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1196, memsize=641.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/6267fff28c794b318f7e5b5803fa4b66
2014-07-11 01:23:49,249 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/6267fff28c794b318f7e5b5803fa4b66 as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/6267fff28c794b318f7e5b5803fa4b66
2014-07-11 01:23:49,265 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/6267fff28c794b318f7e5b5803fa4b66, entries=2334600, sequenceid=1196, filesize=166.2m
2014-07-11 01:23:49,266 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~641.2m/672343440, currentsize=405.8m/425462160 for region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. in 61931ms, sequenceid=1196, compaction requested=false
2014-07-11 01:23:49,266 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26225ms
2014-07-11 01:23:49,266 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,266 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc., current region memstore size 824.0m
2014-07-11 01:23:49,266 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26243ms
2014-07-11 01:23:49,266 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,266 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26269ms
2014-07-11 01:23:49,266 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,266 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24583ms
2014-07-11 01:23:49,267 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,268 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24632ms
2014-07-11 01:23:49,268 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,268 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24670ms
2014-07-11 01:23:49,268 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,269 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24937ms
2014-07-11 01:23:49,269 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,269 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24984ms
2014-07-11 01:23:49,269 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,269 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24881ms
2014-07-11 01:23:49,269 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,269 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25245ms
2014-07-11 01:23:49,269 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,269 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25288ms
2014-07-11 01:23:49,269 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,272 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25530ms
2014-07-11 01:23:49,272 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,272 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25576ms
2014-07-11 01:23:49,272 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,272 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25615ms
2014-07-11 01:23:49,272 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,273 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25792ms
2014-07-11 01:23:49,273 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,273 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25857ms
2014-07-11 01:23:49,273 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,274 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26032ms
2014-07-11 01:23:49,274 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,275 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26042ms
2014-07-11 01:23:49,275 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,276 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26048ms
2014-07-11 01:23:49,276 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,276 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26075ms
2014-07-11 01:23:49,276 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,277 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26078ms
2014-07-11 01:23:49,277 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26098ms
2014-07-11 01:23:49,277 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,277 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26278ms
2014-07-11 01:23:49,277 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,278 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26220ms
2014-07-11 01:23:49,278 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,278 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24327ms
2014-07-11 01:23:49,278 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,279 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25202ms
2014-07-11 01:23:49,279 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,279 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24377ms
2014-07-11 01:23:49,279 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,281 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24030ms
2014-07-11 01:23:49,281 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,282 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24282ms
2014-07-11 01:23:49,282 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,282 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23996ms
2014-07-11 01:23:49,282 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:23:49,511 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:23:50,470 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27365,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002020,"queuetimems":1,"class":"HRegionServer","responsesize":23416,"method":"Multi"}
2014-07-11 01:23:50,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:50,652 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28387,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002264,"queuetimems":1,"class":"HRegionServer","responsesize":23311,"method":"Multi"}
2014-07-11 01:23:50,704 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067001836 with entries=61, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067030650
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066847674
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066904339
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066907300
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066909182
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066913310
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066916706
2014-07-11 01:23:50,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066919009
2014-07-11 01:23:50,755 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28533,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002222,"queuetimems":0,"class":"HRegionServer","responsesize":22547,"method":"Multi"}
2014-07-11 01:23:50,798 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28164,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002633,"queuetimems":0,"class":"HRegionServer","responsesize":23454,"method":"Multi"}
2014-07-11 01:23:50,956 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28545,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002410,"queuetimems":0,"class":"HRegionServer","responsesize":22975,"method":"Multi"}
2014-07-11 01:23:50,975 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:23:51,354 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28892,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002461,"queuetimems":1,"class":"HRegionServer","responsesize":22941,"method":"Multi"}
2014-07-11 01:23:51,478 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002978,"queuetimems":122,"class":"HRegionServer","responsesize":23489,"method":"Multi"}
2014-07-11 01:23:51,483 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067002803,"queuetimems":1,"class":"HRegionServer","responsesize":23204,"method":"Multi"}
2014-07-11 01:23:51,823 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:52,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7180 synced till here 7173
2014-07-11 01:23:52,458 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003020,"queuetimems":1,"class":"HRegionServer","responsesize":23379,"method":"Multi"}
2014-07-11 01:23:52,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067030650 with entries=71, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067031824
2014-07-11 01:23:52,618 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27372,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067005246,"queuetimems":190,"class":"HRegionServer","responsesize":22955,"method":"Multi"}
2014-07-11 01:23:52,741 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004633,"queuetimems":0,"class":"HRegionServer","responsesize":23338,"method":"Multi"}
2014-07-11 01:23:52,741 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28355,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004385,"queuetimems":0,"class":"HRegionServer","responsesize":23331,"method":"Multi"}
2014-07-11 01:23:52,906 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27908,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004997,"queuetimems":1,"class":"HRegionServer","responsesize":19148,"method":"Multi"}
2014-07-11 01:23:52,910 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29215,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003694,"queuetimems":1,"class":"HRegionServer","responsesize":23320,"method":"Multi"}
2014-07-11 01:23:52,922 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29750,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003171,"queuetimems":1,"class":"HRegionServer","responsesize":23408,"method":"Multi"}
2014-07-11 01:23:52,924 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28902,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004021,"queuetimems":1,"class":"HRegionServer","responsesize":23285,"method":"Multi"}
2014-07-11 01:23:52,924 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28329,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004595,"queuetimems":0,"class":"HRegionServer","responsesize":22558,"method":"Multi"}
2014-07-11 01:23:53,206 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004948,"queuetimems":1,"class":"HRegionServer","responsesize":22857,"method":"Multi"}
2014-07-11 01:23:53,210 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27926,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067005283,"queuetimems":1,"class":"HRegionServer","responsesize":22963,"method":"Multi"}
2014-07-11 01:23:53,210 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003740,"queuetimems":1,"class":"HRegionServer","responsesize":23566,"method":"Multi"}
2014-07-11 01:23:53,211 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29798,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003413,"queuetimems":1,"class":"HRegionServer","responsesize":22770,"method":"Multi"}
2014-07-11 01:23:53,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:53,344 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29063,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004281,"queuetimems":0,"class":"HRegionServer","responsesize":23668,"method":"Multi"}
2014-07-11 01:23:53,345 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29866,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003478,"queuetimems":1,"class":"HRegionServer","responsesize":23583,"method":"Multi"}
2014-07-11 01:23:53,349 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29020,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004329,"queuetimems":0,"class":"HRegionServer","responsesize":23120,"method":"Multi"}
2014-07-11 01:23:53,352 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29810,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003541,"queuetimems":0,"class":"HRegionServer","responsesize":23580,"method":"Multi"}
2014-07-11 01:23:53,347 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":30118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003228,"queuetimems":0,"class":"HRegionServer","responsesize":22583,"method":"Multi"}
2014-07-11 01:23:53,346 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29272,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004074,"queuetimems":0,"class":"HRegionServer","responsesize":23638,"method":"Multi"}
2014-07-11 01:23:53,346 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29560,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067003785,"queuetimems":1,"class":"HRegionServer","responsesize":23772,"method":"Multi"}
2014-07-11 01:23:53,345 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28664,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004680,"queuetimems":0,"class":"HRegionServer","responsesize":23514,"method":"Multi"}
2014-07-11 01:23:53,346 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28447,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067004898,"queuetimems":1,"class":"HRegionServer","responsesize":23147,"method":"Multi"}
2014-07-11 01:23:54,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7255 synced till here 7252
2014-07-11 01:23:54,283 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067031824 with entries=75, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067033343
2014-07-11 01:23:54,882 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1267, memsize=602.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/c39951192c0048948fc66abf8ae38bdb
2014-07-11 01:23:54,896 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/c39951192c0048948fc66abf8ae38bdb as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/c39951192c0048948fc66abf8ae38bdb
2014-07-11 01:23:54,913 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/c39951192c0048948fc66abf8ae38bdb, entries=2194340, sequenceid=1267, filesize=156.2m
2014-07-11 01:23:54,913 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~602.7m/631951040, currentsize=357.0m/374352000 for region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. in 56367ms, sequenceid=1267, compaction requested=true
2014-07-11 01:23:54,914 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 01:23:54,915 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., current region memstore size 773.7m
2014-07-11 01:23:55,023 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:23:55,172 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:55,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7322 synced till here 7318
2014-07-11 01:23:55,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067033343 with entries=67, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067035172
2014-07-11 01:23:55,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066921451
2014-07-11 01:23:55,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066928847
2014-07-11 01:23:56,142 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:23:56,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:57,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7404 synced till here 7402
2014-07-11 01:23:57,440 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067035172 with entries=82, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067036538
2014-07-11 01:23:58,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:23:58,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7470 synced till here 7468
2014-07-11 01:23:58,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067036538 with entries=66, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067038432
2014-07-11 01:24:00,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:00,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7535 synced till here 7533
2014-07-11 01:24:01,006 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067038432 with entries=65, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067040223
2014-07-11 01:24:01,722 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:02,379 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7603 synced till here 7598
2014-07-11 01:24:02,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067040223 with entries=68, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067041722
2014-07-11 01:24:03,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:03,227 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7666 synced till here 7665
2014-07-11 01:24:03,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067041722 with entries=63, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067043196
2014-07-11 01:24:04,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:04,708 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067043196 with entries=61, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067044681
2014-07-11 01:24:05,422 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,424 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,443 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,454 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,474 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,476 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,490 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,522 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,565 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,609 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,651 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,695 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,737 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,782 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,824 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,866 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,907 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,950 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:05,995 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:06,042 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:06,085 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:06,130 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:06,187 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:06,230 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:06,273 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:10,422 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,424 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,443 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,455 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:10,474 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,476 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,490 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,523 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:10,565 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,609 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,651 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,695 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,737 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,782 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,824 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,866 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,908 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:10,951 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:10,995 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:11,042 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:11,086 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:11,130 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:11,187 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:11,231 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:11,274 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:11,824 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/b3e42693f9a741e5847205c8898871ae as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/b3e42693f9a741e5847205c8898871ae
2014-07-11 01:24:11,842 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Removing store files after compaction...
2014-07-11 01:24:11,853 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/aff021f926e34d00b97bc6691a2f13f1, to hdfs://master:54310/hbase/archive/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/aff021f926e34d00b97bc6691a2f13f1
2014-07-11 01:24:11,859 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/593e22ba71d546efba524db8a2a52102, to hdfs://master:54310/hbase/archive/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/593e22ba71d546efba524db8a2a52102
2014-07-11 01:24:11,863 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/d5228c24d33d4c069da498771cb0fae5, to hdfs://master:54310/hbase/archive/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/d5228c24d33d4c069da498771cb0fae5
2014-07-11 01:24:11,863 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. into b3e42693f9a741e5847205c8898871ae(size=255.4m), total size for store is 421.6m. This selection was in queue for 0sec, and took 1mins, 20sec to execute.
2014-07-11 01:24:11,863 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., storeName=family, fileCount=3, fileSize=255.5m, priority=17, time=20878965042012; duration=1mins, 20sec
2014-07-11 01:24:11,863 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 01:24:11,864 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-11 01:24:11,864 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 477418790 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-11 01:24:11,864 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: c95022022bef1fbd42d3c48e0aae7a1b - family: Initiating major compaction
2014-07-11 01:24:11,864 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HRegion: Starting compaction on family in region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:24:11,864 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp, totalSize=455.3m
2014-07-11 01:24:11,865 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/0c813636f843487d86db9b6fd021d85f, keycount=154001, bloomtype=ROW, size=109.7m, encoding=NONE, seqNum=321, earliestPutTs=1405066720819
2014-07-11 01:24:11,865 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/5c0eb21f327a4cdcbb54ce8a5a4104fe, keycount=171771, bloomtype=ROW, size=122.3m, encoding=NONE, seqNum=634, earliestPutTs=1405066778209
2014-07-11 01:24:11,865 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/eba7ca0abc1c409184734ce2e414f379, keycount=94094, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=878, earliestPutTs=1405066840778
2014-07-11 01:24:11,865 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/c39951192c0048948fc66abf8ae38bdb, keycount=219434, bloomtype=ROW, size=156.2m, encoding=NONE, seqNum=1267, earliestPutTs=1405066927639
2014-07-11 01:24:11,922 DEBUG [regionserver60020-smallCompactions-1405066362964] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:24:15,423 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,424 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,444 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,455 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,475 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,476 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,490 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,523 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,566 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,609 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,652 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,695 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,737 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,782 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,825 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,866 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:15,908 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,951 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:15,996 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:16,043 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:16,086 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:16,130 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:16,187 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-11 01:24:16,231 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:16,274 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-11 01:24:20,424 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,425 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-11 01:24:20,444 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,455 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,475 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,477 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,490 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-11 01:24:20,523 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,566 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,610 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-11 01:24:20,652 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,696 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,738 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,783 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,825 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,867 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,908 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,952 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:20,996 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:21,058 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15016ms
2014-07-11 01:24:21,087 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-11 01:24:21,131 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:21,187 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-11 01:24:21,231 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:21,274 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-11 01:24:22,629 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1416, memsize=824.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/016b94e4c23f4c1f80b05a22707cdde5
2014-07-11 01:24:22,649 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/016b94e4c23f4c1f80b05a22707cdde5 as hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/016b94e4c23f4c1f80b05a22707cdde5
2014-07-11 01:24:22,663 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/016b94e4c23f4c1f80b05a22707cdde5, entries=3000230, sequenceid=1416, filesize=213.5m
2014-07-11 01:24:22,664 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~824.0m/864045840, currentsize=250.4m/262590000 for region usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. in 33398ms, sequenceid=1416, compaction requested=true
2014-07-11 01:24:22,664 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-11 01:24:22,664 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16391ms
2014-07-11 01:24:22,664 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,664 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16434ms
2014-07-11 01:24:22,664 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., current region memstore size 867.7m
2014-07-11 01:24:22,664 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,664 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16477ms
2014-07-11 01:24:22,665 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,665 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16536ms
2014-07-11 01:24:22,665 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,665 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16580ms
2014-07-11 01:24:22,665 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,665 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16623ms
2014-07-11 01:24:22,665 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,669 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16674ms
2014-07-11 01:24:22,669 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,669 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16719ms
2014-07-11 01:24:22,669 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,673 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16766ms
2014-07-11 01:24:22,673 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,673 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16807ms
2014-07-11 01:24:22,673 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,675 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16851ms
2014-07-11 01:24:22,675 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,675 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16893ms
2014-07-11 01:24:22,676 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,676 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16939ms
2014-07-11 01:24:22,676 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,676 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16981ms
2014-07-11 01:24:22,676 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,677 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17026ms
2014-07-11 01:24:22,677 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,679 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17070ms
2014-07-11 01:24:22,680 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,680 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17115ms
2014-07-11 01:24:22,680 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,680 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17158ms
2014-07-11 01:24:22,680 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,682 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17192ms
2014-07-11 01:24:22,682 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,682 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17206ms
2014-07-11 01:24:22,682 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,683 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17209ms
2014-07-11 01:24:22,683 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,683 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17229ms
2014-07-11 01:24:22,683 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,683 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17240ms
2014-07-11 01:24:22,683 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,683 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17259ms
2014-07-11 01:24:22,683 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,685 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17263ms
2014-07-11 01:24:22,685 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:22,782 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067044750,"queuetimems":1,"class":"HRegionServer","responsesize":23031,"method":"Multi"}
2014-07-11 01:24:23,023 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18175,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067044848,"queuetimems":1,"class":"HRegionServer","responsesize":23335,"method":"Multi"}
2014-07-11 01:24:23,217 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:23,262 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1471, memsize=777.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/aac3fca98f184566998c21a5716a1817
2014-07-11 01:24:23,278 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/aac3fca98f184566998c21a5716a1817 as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/aac3fca98f184566998c21a5716a1817
2014-07-11 01:24:23,290 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/aac3fca98f184566998c21a5716a1817, entries=2830440, sequenceid=1471, filesize=201.5m
2014-07-11 01:24:23,290 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~777.4m/815144240, currentsize=200.7m/210432480 for region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. in 28375ms, sequenceid=1471, compaction requested=true
2014-07-11 01:24:23,290 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-11 01:24:23,291 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 660.6m
2014-07-11 01:24:23,304 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:24:23,306 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18375,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067044930,"queuetimems":1,"class":"HRegionServer","responsesize":23315,"method":"Multi"}
2014-07-11 01:24:23,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7811 synced till here 7794
2014-07-11 01:24:23,443 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18062,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045380,"queuetimems":0,"class":"HRegionServer","responsesize":23421,"method":"Multi"}
2014-07-11 01:24:23,443 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045366,"queuetimems":1,"class":"HRegionServer","responsesize":23557,"method":"Multi"}
2014-07-11 01:24:23,482 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:24:23,541 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067044681 with entries=84, filesize=84.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067063217
2014-07-11 01:24:23,541 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066930883
2014-07-11 01:24:23,541 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066932913
2014-07-11 01:24:23,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066935151
2014-07-11 01:24:23,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066936837
2014-07-11 01:24:23,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066938675
2014-07-11 01:24:23,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066940943
2014-07-11 01:24:23,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066942996
2014-07-11 01:24:23,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066944921
2014-07-11 01:24:24,726 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067046271,"queuetimems":0,"class":"HRegionServer","responsesize":23179,"method":"Multi"}
2014-07-11 01:24:24,879 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:24:25,126 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:25,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7880 synced till here 7873
2014-07-11 01:24:25,270 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067046083,"queuetimems":0,"class":"HRegionServer","responsesize":23495,"method":"Multi"}
2014-07-11 01:24:25,270 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19042,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067046227,"queuetimems":0,"class":"HRegionServer","responsesize":23473,"method":"Multi"}
2014-07-11 01:24:25,270 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19576,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045693,"queuetimems":1,"class":"HRegionServer","responsesize":23428,"method":"Multi"}
2014-07-11 01:24:25,280 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067063217 with entries=69, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067065126
2014-07-11 01:24:25,517 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045520,"queuetimems":0,"class":"HRegionServer","responsesize":23409,"method":"Multi"}
2014-07-11 01:24:26,585 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21164,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045421,"queuetimems":0,"class":"HRegionServer","responsesize":23703,"method":"Multi"}
2014-07-11 01:24:26,585 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20458,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067046127,"queuetimems":1,"class":"HRegionServer","responsesize":22922,"method":"Multi"}
2014-07-11 01:24:26,586 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21023,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045563,"queuetimems":0,"class":"HRegionServer","responsesize":23224,"method":"Multi"}
2014-07-11 01:24:26,586 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20722,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045864,"queuetimems":1,"class":"HRegionServer","responsesize":22675,"method":"Multi"}
2014-07-11 01:24:26,587 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20852,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045735,"queuetimems":0,"class":"HRegionServer","responsesize":22792,"method":"Multi"}
2014-07-11 01:24:26,587 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20682,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045905,"queuetimems":0,"class":"HRegionServer","responsesize":22896,"method":"Multi"}
2014-07-11 01:24:26,587 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21115,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045472,"queuetimems":0,"class":"HRegionServer","responsesize":22748,"method":"Multi"}
2014-07-11 01:24:26,585 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045649,"queuetimems":0,"class":"HRegionServer","responsesize":23166,"method":"Multi"}
2014-07-11 01:24:26,588 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20595,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045993,"queuetimems":0,"class":"HRegionServer","responsesize":23471,"method":"Multi"}
2014-07-11 01:24:26,591 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20406,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067046184,"queuetimems":0,"class":"HRegionServer","responsesize":23359,"method":"Multi"}
2014-07-11 01:24:26,591 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20769,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045822,"queuetimems":0,"class":"HRegionServer","responsesize":23385,"method":"Multi"}
2014-07-11 01:24:26,591 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20812,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045779,"queuetimems":0,"class":"HRegionServer","responsesize":23463,"method":"Multi"}
2014-07-11 01:24:26,585 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20979,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045606,"queuetimems":0,"class":"HRegionServer","responsesize":23509,"method":"Multi"}
2014-07-11 01:24:26,591 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20551,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067046040,"queuetimems":0,"class":"HRegionServer","responsesize":23566,"method":"Multi"}
2014-07-11 01:24:26,592 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067045948,"queuetimems":0,"class":"HRegionServer","responsesize":23468,"method":"Multi"}
2014-07-11 01:24:27,014 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:27,030 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7945 synced till here 7942
2014-07-11 01:24:27,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067065126 with entries=65, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067067014
2014-07-11 01:24:28,550 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:28,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8009 synced till here 8007
2014-07-11 01:24:28,586 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067067014 with entries=64, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067068550
2014-07-11 01:24:28,626 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:24:31,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:31,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8071 synced till here 8069
2014-07-11 01:24:31,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067068550 with entries=62, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067071119
2014-07-11 01:24:32,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:33,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8164 synced till here 8163
2014-07-11 01:24:33,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067071119 with entries=93, filesize=90.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067072864
2014-07-11 01:24:34,819 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:34,840 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8235 synced till here 8228
2014-07-11 01:24:34,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067072864 with entries=71, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067074819
2014-07-11 01:24:36,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:36,583 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8310 synced till here 8300
2014-07-11 01:24:36,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067074819 with entries=75, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067076484
2014-07-11 01:24:38,059 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:38,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8376 synced till here 8373
2014-07-11 01:24:38,131 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067076484 with entries=66, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067078059
2014-07-11 01:24:39,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:40,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8451 synced till here 8449
2014-07-11 01:24:40,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067078059 with entries=75, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067079979
2014-07-11 01:24:41,807 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:41,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8525 synced till here 8524
2014-07-11 01:24:41,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067079979 with entries=74, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067081807
2014-07-11 01:24:43,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:43,789 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067081807 with entries=63, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067083318
2014-07-11 01:24:45,203 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,203 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,219 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:45,224 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8654 synced till here 8651
2014-07-11 01:24:45,247 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,260 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,262 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,264 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,267 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067083318 with entries=66, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067085221
2014-07-11 01:24:45,292 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,313 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,384 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,454 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,513 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,557 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,602 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,648 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,695 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:45,742 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,671 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,686 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,723 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,767 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,824 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,886 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,933 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:46,985 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:24:50,203 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,203 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,219 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,224 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,247 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,260 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,262 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,264 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,292 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,313 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,384 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,455 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,513 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,557 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,602 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,648 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,695 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:50,742 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:51,712 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5026ms
2014-07-11 01:24:51,713 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5042ms
2014-07-11 01:24:51,723 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:51,767 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:51,824 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:51,887 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:24:51,933 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:51,985 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:24:53,286 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1562, memsize=664.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/5f4a4276ee884980948b45532386e20a
2014-07-11 01:24:53,309 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/5f4a4276ee884980948b45532386e20a as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/5f4a4276ee884980948b45532386e20a
2014-07-11 01:24:53,327 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/5f4a4276ee884980948b45532386e20a, entries=2418830, sequenceid=1562, filesize=172.3m
2014-07-11 01:24:53,328 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~664.3m/696605440, currentsize=313.8m/329083200 for region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. in 30037ms, sequenceid=1562, compaction requested=true
2014-07-11 01:24:53,328 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-11 01:24:53,329 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., current region memstore size 845.2m
2014-07-11 01:24:53,330 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6344ms
2014-07-11 01:24:53,330 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,330 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6397ms
2014-07-11 01:24:53,330 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,330 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6444ms
2014-07-11 01:24:53,331 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,331 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6507ms
2014-07-11 01:24:53,331 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,331 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6564ms
2014-07-11 01:24:53,331 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,332 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6609ms
2014-07-11 01:24:53,332 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,332 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6661ms
2014-07-11 01:24:53,332 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,333 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6647ms
2014-07-11 01:24:53,333 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,333 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7591ms
2014-07-11 01:24:53,333 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,341 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7646ms
2014-07-11 01:24:53,341 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,341 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7693ms
2014-07-11 01:24:53,341 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,341 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7739ms
2014-07-11 01:24:53,341 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,342 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7785ms
2014-07-11 01:24:53,343 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,343 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7830ms
2014-07-11 01:24:53,343 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,346 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7892ms
2014-07-11 01:24:53,347 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,348 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7963ms
2014-07-11 01:24:53,348 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,349 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8035ms
2014-07-11 01:24:53,349 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,350 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8057ms
2014-07-11 01:24:53,350 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,355 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8091ms
2014-07-11 01:24:53,356 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,357 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8094ms
2014-07-11 01:24:53,357 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,358 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8097ms
2014-07-11 01:24:53,358 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,359 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8111ms
2014-07-11 01:24:53,359 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,360 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8135ms
2014-07-11 01:24:53,360 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,361 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8142ms
2014-07-11 01:24:53,361 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,362 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8158ms
2014-07-11 01:24:53,362 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,362 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8159ms
2014-07-11 01:24:53,363 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:24:53,453 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:24:54,107 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:24:54,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:54,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8722 synced till here 8718
2014-07-11 01:24:54,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067085221 with entries=68, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067094138
2014-07-11 01:24:55,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:55,656 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10393,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085262,"queuetimems":1,"class":"HRegionServer","responsesize":23040,"method":"Multi"}
2014-07-11 01:24:55,669 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8801 synced till here 8786
2014-07-11 01:24:55,737 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10285,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085451,"queuetimems":0,"class":"HRegionServer","responsesize":23003,"method":"Multi"}
2014-07-11 01:24:55,738 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10092,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085645,"queuetimems":0,"class":"HRegionServer","responsesize":23303,"method":"Multi"}
2014-07-11 01:24:55,739 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10521,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085217,"queuetimems":1,"class":"HRegionServer","responsesize":23270,"method":"Multi"}
2014-07-11 01:24:55,740 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10139,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085600,"queuetimems":1,"class":"HRegionServer","responsesize":22967,"method":"Multi"}
2014-07-11 01:24:55,740 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085692,"queuetimems":0,"class":"HRegionServer","responsesize":23428,"method":"Multi"}
2014-07-11 01:24:55,784 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10472,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085311,"queuetimems":1,"class":"HRegionServer","responsesize":23389,"method":"Multi"}
2014-07-11 01:24:55,786 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10404,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085381,"queuetimems":0,"class":"HRegionServer","responsesize":23406,"method":"Multi"}
2014-07-11 01:24:55,786 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10275,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085510,"queuetimems":0,"class":"HRegionServer","responsesize":23263,"method":"Multi"}
2014-07-11 01:24:55,787 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:44965","starttimems":1405067085555,"queuetimems":1,"class":"HRegionServer","responsesize":23534,"method":"Multi"}
2014-07-11 01:24:55,794 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067094138 with entries=79, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067095655
2014-07-11 01:24:57,076 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:57,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8875 synced till here 8873
2014-07-11 01:24:57,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067095655 with entries=74, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067097076
2014-07-11 01:24:58,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:24:58,527 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8937 synced till here 8936
2014-07-11 01:24:58,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067097076 with entries=62, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067098514
2014-07-11 01:25:00,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:00,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067098514 with entries=71, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067100242
2014-07-11 01:25:00,477 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:00,500 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:00,504 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:00,792 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:00,861 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:00,927 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:00,990 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,067 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,146 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,198 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,265 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,323 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1558, memsize=867.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/4ce935a5c5d645a9ac79adf364882520
2014-07-11 01:25:01,330 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,335 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/4ce935a5c5d645a9ac79adf364882520 as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/4ce935a5c5d645a9ac79adf364882520
2014-07-11 01:25:01,368 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:01,369 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/4ce935a5c5d645a9ac79adf364882520, entries=3159220, sequenceid=1558, filesize=224.9m
2014-07-11 01:25:01,370 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~867.7m/909829280, currentsize=452.2m/474159440 for region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. in 38706ms, sequenceid=1558, compaction requested=true
2014-07-11 01:25:01,370 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-11 01:25:01,370 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2ms
2014-07-11 01:25:01,370 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,370 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 40ms
2014-07-11 01:25:01,370 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc., current region memstore size 704.6m
2014-07-11 01:25:01,370 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,370 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 105ms
2014-07-11 01:25:01,370 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,371 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 173ms
2014-07-11 01:25:01,371 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,371 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 225ms
2014-07-11 01:25:01,371 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,371 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 304ms
2014-07-11 01:25:01,371 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,373 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 383ms
2014-07-11 01:25:01,373 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,373 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 447ms
2014-07-11 01:25:01,373 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,373 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 512ms
2014-07-11 01:25:01,373 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,373 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 581ms
2014-07-11 01:25:01,373 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,382 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 878ms
2014-07-11 01:25:01,382 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,382 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 882ms
2014-07-11 01:25:01,382 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,382 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 905ms
2014-07-11 01:25:01,382 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:01,453 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7.
2014-07-11 01:25:01,835 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:25:01,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:02,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9098 synced till here 9081
2014-07-11 01:25:02,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067100242 with entries=90, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067101921
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066947030
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066949210
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066952219
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066954456
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066956262
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066957876
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066960184
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066962159
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066964282
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066966594
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066969861
2014-07-11 01:25:02,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066972143
2014-07-11 01:25:02,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066974318
2014-07-11 01:25:02,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066976442
2014-07-11 01:25:03,668 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:03,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9172 synced till here 9170
2014-07-11 01:25:03,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067101921 with entries=74, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067103669
2014-07-11 01:25:04,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:04,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9239 synced till here 9238
2014-07-11 01:25:04,990 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067103669 with entries=67, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067104919
2014-07-11 01:25:06,261 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:06,279 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9310 synced till here 9308
2014-07-11 01:25:06,303 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067104919 with entries=71, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067106261
2014-07-11 01:25:07,598 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:08,366 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067106261 with entries=109, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067107598
2014-07-11 01:25:19,285 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:19,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9539 synced till here 9537
2014-07-11 01:25:19,547 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067107598 with entries=120, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067119286
2014-07-11 01:25:20,807 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,810 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,816 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,831 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,861 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,870 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,896 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,918 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:20,983 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,078 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,165 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,227 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,273 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,303 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,369 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,431 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,479 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:21,969 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:22,872 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:23,669 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:25,632 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1735, memsize=845.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/71e6b55d6fe54179b4c2627b7f211129
2014-07-11 01:25:25,648 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/71e6b55d6fe54179b4c2627b7f211129 as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/71e6b55d6fe54179b4c2627b7f211129
2014-07-11 01:25:25,664 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/71e6b55d6fe54179b4c2627b7f211129, entries=3077410, sequenceid=1735, filesize=219.1m
2014-07-11 01:25:25,665 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~845.2m/886271280, currentsize=306.2m/321105360 for region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. in 32336ms, sequenceid=1735, compaction requested=false
2014-07-11 01:25:25,665 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1996ms
2014-07-11 01:25:25,665 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,665 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa., current region memstore size 787.3m
2014-07-11 01:25:25,665 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2793ms
2014-07-11 01:25:25,665 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,666 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3697ms
2014-07-11 01:25:25,666 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,667 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4188ms
2014-07-11 01:25:25,667 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,667 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4236ms
2014-07-11 01:25:25,667 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,668 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4298ms
2014-07-11 01:25:25,668 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,668 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4365ms
2014-07-11 01:25:25,668 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,669 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4396ms
2014-07-11 01:25:25,669 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,669 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4442ms
2014-07-11 01:25:25,669 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,670 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4505ms
2014-07-11 01:25:25,670 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,671 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4593ms
2014-07-11 01:25:25,673 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,673 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4690ms
2014-07-11 01:25:25,673 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,675 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4756ms
2014-07-11 01:25:25,675 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,676 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4779ms
2014-07-11 01:25:25,676 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,677 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4806ms
2014-07-11 01:25:25,677 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,677 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4816ms
2014-07-11 01:25:25,677 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,677 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4846ms
2014-07-11 01:25:25,677 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,677 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4861ms
2014-07-11 01:25:25,677 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,678 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4869ms
2014-07-11 01:25:25,678 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,678 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4871ms
2014-07-11 01:25:25,678 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:25,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:25,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9661 synced till here 9652
2014-07-11 01:25:25,834 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b.
2014-07-11 01:25:25,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067119286 with entries=122, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067125729
2014-07-11 01:25:25,865 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066978368
2014-07-11 01:25:25,865 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066981239
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066983793
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066986178
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066988818
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066990495
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066992596
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066995013
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405066997604
2014-07-11 01:25:25,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067000037
2014-07-11 01:25:26,116 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1808, memsize=704.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/8709ed3b16314974b1f13acff16775ca
2014-07-11 01:25:26,133 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp/8709ed3b16314974b1f13acff16775ca as hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/8709ed3b16314974b1f13acff16775ca
2014-07-11 01:25:26,148 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/8709ed3b16314974b1f13acff16775ca, entries=2565500, sequenceid=1808, filesize=182.6m
2014-07-11 01:25:26,149 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~704.6m/738841200, currentsize=177.0m/185626560 for region usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. in 24779ms, sequenceid=1808, compaction requested=true
2014-07-11 01:25:26,149 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-11 01:25:26,149 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 619.8m
2014-07-11 01:25:26,658 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:25:26,917 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:26,942 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067125729 with entries=71, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067126918
2014-07-11 01:25:26,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067001836
2014-07-11 01:25:26,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067030650
2014-07-11 01:25:26,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067031824
2014-07-11 01:25:27,074 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:25:28,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:28,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9795 synced till here 9793
2014-07-11 01:25:28,723 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067126918 with entries=63, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067128652
2014-07-11 01:25:29,961 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:29,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067128652 with entries=64, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067129961
2014-07-11 01:25:30,342 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:25:30,544 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/c9971ae8e0e2440696e7f437a7f564dc as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/c9971ae8e0e2440696e7f437a7f564dc
2014-07-11 01:25:30,570 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Removing store files after compaction...
2014-07-11 01:25:30,576 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/0c813636f843487d86db9b6fd021d85f, to hdfs://master:54310/hbase/archive/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/0c813636f843487d86db9b6fd021d85f
2014-07-11 01:25:30,579 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/5c0eb21f327a4cdcbb54ce8a5a4104fe, to hdfs://master:54310/hbase/archive/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/5c0eb21f327a4cdcbb54ce8a5a4104fe
2014-07-11 01:25:30,584 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/eba7ca0abc1c409184734ce2e414f379, to hdfs://master:54310/hbase/archive/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/eba7ca0abc1c409184734ce2e414f379
2014-07-11 01:25:30,586 DEBUG [regionserver60020-smallCompactions-1405066362964] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/c39951192c0048948fc66abf8ae38bdb, to hdfs://master:54310/hbase/archive/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/c39951192c0048948fc66abf8ae38bdb
2014-07-11 01:25:30,586 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. into c9971ae8e0e2440696e7f437a7f564dc(size=455.1m), total size for store is 674.3m. This selection was in queue for 0sec, and took 1mins, 18sec to execute.
2014-07-11 01:25:30,586 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., storeName=family, fileCount=4, fileSize=455.3m, priority=16, time=20959291325697; duration=1mins, 18sec
2014-07-11 01:25:30,587 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-11 01:25:30,587 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-11 01:25:30,587 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 742452528 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-11 01:25:30,587 DEBUG [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: 6f66926485ddafad14336d1017b554fc - family: Initiating major compaction
2014-07-11 01:25:30,587 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc.
2014-07-11 01:25:30,588 INFO  [regionserver60020-smallCompactions-1405066362964] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/.tmp, totalSize=708.1m
2014-07-11 01:25:30,588 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/6f139744ecdb4c9eb99ec1ecaf77e8c6, keycount=153853, bloomtype=ROW, size=109.6m, encoding=NONE, seqNum=327, earliestPutTs=1405066721346
2014-07-11 01:25:30,588 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/d0b49560ae684361bc16aaa761b4bc49, keycount=190807, bloomtype=ROW, size=135.8m, encoding=NONE, seqNum=670, earliestPutTs=1405066794641
2014-07-11 01:25:30,588 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/e1e373d0cfb147849d59fc887aaf6482, keycount=93311, bloomtype=ROW, size=66.5m, encoding=NONE, seqNum=921, earliestPutTs=1405066844524
2014-07-11 01:25:30,588 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/016b94e4c23f4c1f80b05a22707cdde5, keycount=300023, bloomtype=ROW, size=213.5m, encoding=NONE, seqNum=1416, earliestPutTs=1405066931962
2014-07-11 01:25:30,588 DEBUG [regionserver60020-smallCompactions-1405066362964] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/6f66926485ddafad14336d1017b554fc/family/8709ed3b16314974b1f13acff16775ca, keycount=256550, bloomtype=ROW, size=182.6m, encoding=NONE, seqNum=1808, earliestPutTs=1405067029279
2014-07-11 01:25:30,755 DEBUG [regionserver60020-smallCompactions-1405066362964] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:25:31,310 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:31,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9929 synced till here 9926
2014-07-11 01:25:31,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067129961 with entries=70, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067131311
2014-07-11 01:25:32,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:32,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9996 synced till here 9995
2014-07-11 01:25:32,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067131311 with entries=67, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067132279
2014-07-11 01:25:33,608 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:33,642 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10058 synced till here 10057
2014-07-11 01:25:33,664 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067132279 with entries=62, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067133609
2014-07-11 01:25:35,064 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:35,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10133 synced till here 10132
2014-07-11 01:25:35,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067133609 with entries=75, filesize=74.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067135064
2014-07-11 01:25:36,844 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:37,627 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10203 synced till here 10201
2014-07-11 01:25:37,655 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067135064 with entries=70, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067136845
2014-07-11 01:25:38,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:38,492 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067136845 with entries=64, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067138435
2014-07-11 01:25:39,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:40,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10343 synced till here 10333
2014-07-11 01:25:41,121 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067138435 with entries=76, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067139970
2014-07-11 01:25:41,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10416 synced till here 10410
2014-07-11 01:25:42,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067139970 with entries=73, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067141952
2014-07-11 01:25:43,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:43,697 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10491 synced till here 10484
2014-07-11 01:25:43,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067141952 with entries=75, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067143603
2014-07-11 01:25:44,616 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,647 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,656 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,666 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,686 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,722 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,772 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,818 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:44,899 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405066324372: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-11 01:25:49,616 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:25:49,648 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:25:49,656 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:25:49,666 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:25:49,687 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:25:49,723 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:25:49,773 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:25:49,819 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-11 01:25:49,899 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-11 01:25:51,966 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1945, memsize=630.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/7a6682fe767443c9a00d08b57ec7e22b
2014-07-11 01:25:51,987 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/.tmp/7a6682fe767443c9a00d08b57ec7e22b as hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/7a6682fe767443c9a00d08b57ec7e22b
2014-07-11 01:25:52,006 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/3f27bb71c2d59493f7d68572a85c8b0d/family/7a6682fe767443c9a00d08b57ec7e22b, entries=2296330, sequenceid=1945, filesize=163.4m
2014-07-11 01:25:52,007 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~630.7m/661323040, currentsize=298.4m/312888240 for region usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d. in 25858ms, sequenceid=1945, compaction requested=true
2014-07-11 01:25:52,007 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-11 01:25:52,007 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7108ms
2014-07-11 01:25:52,007 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,007 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7., current region memstore size 936.4m
2014-07-11 01:25:52,007 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7189ms
2014-07-11 01:25:52,007 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,008 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7236ms
2014-07-11 01:25:52,008 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,008 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7286ms
2014-07-11 01:25:52,008 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,009 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7323ms
2014-07-11 01:25:52,009 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,009 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7343ms
2014-07-11 01:25:52,009 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,009 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7353ms
2014-07-11 01:25:52,009 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,010 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7363ms
2014-07-11 01:25:52,010 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,010 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7394ms
2014-07-11 01:25:52,010 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405066324372
2014-07-11 01:25:52,345 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d.
2014-07-11 01:25:52,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:52,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10560 synced till here 10553
2014-07-11 01:25:52,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067143603 with entries=69, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067152654
2014-07-11 01:25:52,951 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:25:54,267 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:54,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10627 synced till here 10624
2014-07-11 01:25:54,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067152654 with entries=67, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067154268
2014-07-11 01:25:55,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:55,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10693 synced till here 10691
2014-07-11 01:25:55,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067154268 with entries=66, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067155913
2014-07-11 01:25:57,647 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1938, memsize=787.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/02ca9407204748f698dc779356a04a1e
2014-07-11 01:25:57,664 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/.tmp/02ca9407204748f698dc779356a04a1e as hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/02ca9407204748f698dc779356a04a1e
2014-07-11 01:25:57,678 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a1bcecf7b391064e180b30d7fec9acaa/family/02ca9407204748f698dc779356a04a1e, entries=2866710, sequenceid=1938, filesize=204.1m
2014-07-11 01:25:57,679 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~787.3m/825589920, currentsize=385.5m/404243680 for region usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa. in 32014ms, sequenceid=1938, compaction requested=true
2014-07-11 01:25:57,679 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-11 01:25:57,679 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b., current region memstore size 694.1m
2014-07-11 01:25:57,680 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405066702530.a1bcecf7b391064e180b30d7fec9acaa.
2014-07-11 01:25:58,407 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:25:58,496 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-11 01:25:58,524 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067155913 with entries=71, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067158496
2014-07-11 01:25:58,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067033343
2014-07-11 01:25:58,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067035172
2014-07-11 01:25:58,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067036538
2014-07-11 01:25:58,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067038432
2014-07-11 01:25:58,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067040223
2014-07-11 01:25:58,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067041722
2014-07-11 01:25:58,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405066324372/slave1%2C60020%2C1405066324372.1405067043196
2014-07-11 01:26:19,399 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2157, memsize=694.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/13f4eedebdf44b4eaa9698f632bfaefe
2014-07-11 01:26:19,420 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/.tmp/13f4eedebdf44b4eaa9698f632bfaefe as hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/13f4eedebdf44b4eaa9698f632bfaefe
2014-07-11 01:26:19,433 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c95022022bef1fbd42d3c48e0aae7a1b/family/13f4eedebdf44b4eaa9698f632bfaefe, entries=2527280, sequenceid=2157, filesize=179.9m
2014-07-11 01:26:19,433 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~694.1m/727834480, currentsize=13.6m/14272880 for region usertable,user4,1405066702530.c95022022bef1fbd42d3c48e0aae7a1b. in 21754ms, sequenceid=2157, compaction requested=true
2014-07-11 01:26:19,433 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-11 01:26:19,434 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405066702530.6f66926485ddafad14336d1017b554fc., current region memstore size 576.9m
2014-07-11 01:26:19,805 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-11 01:26:21,893 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2113, memsize=936.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/08e3b3e58e9e4eafb914830ccc36ae3e
2014-07-11 01:26:21,909 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/.tmp/08e3b3e58e9e4eafb914830ccc36ae3e as hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/08e3b3e58e9e4eafb914830ccc36ae3e
2014-07-11 01:26:21,926 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/9fad4d31d095db592fcf0f508b9eb9f7/family/08e3b3e58e9e4eafb914830ccc36ae3e, entries=3409450, sequenceid=2113, filesize=242.6m
2014-07-11 01:26:21,926 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~936.4m/981894320, currentsize=89.3m/93666000 for region usertable,user2,1405066702530.9fad4d31d095db592fcf0f508b9eb9f7. in 29919ms, sequenceid=2113, compaction requested=true
2014-07-11 01:26:21,927 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-11 01:26:21,927 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405066702530.3f27bb71c2d59493f7d68572a85c8b0d., current region memstore size 387.4m
2014-07-11 01:26:22,176 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
