Thu Jul 10 23:23:11 PDT 2014 Starting regionserver on sceplus-vm48
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-10 23:23:11,829 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-10 23:23:11,830 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-10 23:23:11,830 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-10 23:23:12,049 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-10 23:23:12,049 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-10 23:23:12,049 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-10 23:23:12,049 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm48.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 54418 22
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-10 23:23:12,050 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-10 23:23:12,051 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-10 23:23:12,051 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-10 23:23:12,051 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 54418 9.1.143.58 22
2014-07-10 23:23:12,051 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-10 23:23:12,051 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-10 23:23:12,051 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-10 23:23:12,053 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=327
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm48.log
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-10 23:23:12,054 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-10 23:23:12,055 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm48
2014-07-10 23:23:12,055 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-10 23:23:12,057 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-10 23:23:12,057 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm48.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-10 23:23:12,271 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm48.almaden.ibm.com/9.1.143.58:60020 HConnection server-to-server retries=350
2014-07-10 23:23:12,641 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm48.almaden.ibm.com/9.1.143.58:60020: started 10 reader(s).
2014-07-10 23:23:12,718 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-10 23:23:12,730 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-10 23:23:12,792 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-10 23:23:12,793 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-10 23:23:12,794 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-10 23:23:12,798 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-10 23:23:12,803 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-10 23:23:12,881 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-10 23:23:12,882 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-10 23:23:12,886 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-10 23:23:12,889 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-10 23:23:12,963 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-10 23:23:13,032 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-10 23:23:13,041 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-10 23:23:13,043 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-10 23:23:13,043 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-10 23:23:13,043 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-10 23:23:13,354 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm48.almaden.ibm.com
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-10 23:23:13,400 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-10 23:23:13,403 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 23:23:13,403 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-10 23:23:13,424 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 23:23:13,427 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 23:23:13,432 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-10 23:23:13,452 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x1472416fcb00000, negotiated timeout = 90000
2014-07-10 23:23:44,538 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x32767bcf, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 23:23:44,539 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x32767bcf connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 23:23:44,540 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 23:23:44,541 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-10 23:23:44,544 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x1472416fcb00002, negotiated timeout = 90000
2014-07-10 23:23:44,791 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4fa3fd6d
2014-07-10 23:23:44,797 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-10 23:23:44,802 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-10 23:23:44,824 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-10 23:23:44,855 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-10 23:23:44,860 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-10 23:23:44,864 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-10 23:23:44,883 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405059790945 with port=60020, startcode=1405059792813
2014-07-10 23:23:45,244 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-10 23:23:45,244 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-10 23:23:45,269 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-10 23:23:45,276 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:45,320 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-10 23:23:45,334 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-10 23:23:45,454 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405059825344
2014-07-10 23:23:45,469 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-10 23:23:45,474 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-10 23:23:45,478 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-10 23:23:45,482 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-10 23:23:45,485 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-sceplus-vm48:60020, corePoolSize=3, maxPoolSize=3
2014-07-10 23:23:45,485 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-sceplus-vm48:60020, corePoolSize=1, maxPoolSize=1
2014-07-10 23:23:45,485 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-sceplus-vm48:60020, corePoolSize=3, maxPoolSize=3
2014-07-10 23:23:45,485 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-sceplus-vm48:60020, corePoolSize=1, maxPoolSize=1
2014-07-10 23:23:45,485 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-sceplus-vm48:60020, corePoolSize=2, maxPoolSize=2
2014-07-10 23:23:45,495 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1405059792813, slave1,60020,1405059792766] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1405059792813, slave1,60020,1405059792766]
2014-07-10 23:23:45,520 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-10 23:23:45,522 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x19dcef1a, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-10 23:23:45,523 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x19dcef1a connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-10 23:23:45,523 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-10 23:23:45,524 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-10 23:23:45,527 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x1472416fcb00004, negotiated timeout = 90000
2014-07-10 23:23:45,533 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-10 23:23:45,533 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-10 23:23:45,576 INFO  [regionserver60020] regionserver.HRegionServer: Serving as sceplus-vm48.almaden.ibm.com,60020,1405059792813, RpcServer on sceplus-vm48.almaden.ibm.com/9.1.143.58:60020, sessionid=0x1472416fcb00000
2014-07-10 23:23:45,576 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,60020,1405059792813] regionserver.SplitLogWorker: SplitLogWorker sceplus-vm48.almaden.ibm.com,60020,1405059792813 starting
2014-07-10 23:23:45,576 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-10 23:23:45,576 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:45,576 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'sceplus-vm48.almaden.ibm.com,60020,1405059792813'
2014-07-10 23:23:45,576 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-10 23:23:45,578 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-10 23:23:45,579 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-10 23:23:49,398 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-07-10 23:23:49,515 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:49,539 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:49,539 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:49,542 INFO  [RS_OPEN_META-sceplus-vm48:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-10 23:23:49,572 INFO  [RS_OPEN_META-sceplus-vm48:60020-0] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405059829547.meta
2014-07-10 23:23:49,596 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-10 23:23:49,618 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-07-10 23:23:49,625 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-07-10 23:23:49,628 INFO  [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-07-10 23:23:49,634 INFO  [RS_OPEN_META-sceplus-vm48:60020-0] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-10 23:23:49,634 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-07-10 23:23:49,634 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-07-10 23:23:49,707 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 23:23:49,745 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-10 23:23:49,796 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/3689b3d261524e7aa3ebf58fc3629915, isReference=false, isBulkLoadResult=false, seqid=3910, majorCompaction=true
2014-07-10 23:23:49,814 INFO  [StoreFileOpenerThread-info-1] regionserver.StoreFile$Reader: Loaded Delete Family Bloom (CompoundBloomFilter) metadata for d432e6b1319c4785b23ec6282d68c7d4
2014-07-10 23:23:49,814 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/d432e6b1319c4785b23ec6282d68c7d4, isReference=false, isBulkLoadResult=false, seqid=3936, majorCompaction=false
2014-07-10 23:23:49,852 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/meta/1588230740
2014-07-10 23:23:49,858 INFO  [RS_OPEN_META-sceplus-vm48:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=3937
2014-07-10 23:23:49,859 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-07-10 23:23:49,863 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-07-10 23:23:49,864 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:49,874 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-07-10 23:23:49,874 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:49,882 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:49,882 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:49,882 DEBUG [RS_OPEN_META-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,216 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:23:50,248 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:23:50,250 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 682479f17fefd754e837eac1f4a02b9c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,251 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:23:50,251 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8b4421efdcff210abdc3f35add55c82e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,251 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:23:50,252 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:23:50,252 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cc31f80bbbe5b6320cd17177b1be6a63 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,258 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 682479f17fefd754e837eac1f4a02b9c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,258 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => 682479f17fefd754e837eac1f4a02b9c, NAME => 'usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-10 23:23:50,259 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8b4421efdcff210abdc3f35add55c82e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,259 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Opening region: {ENCODED => 8b4421efdcff210abdc3f35add55c82e, NAME => 'usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-10 23:23:50,260 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 682479f17fefd754e837eac1f4a02b9c
2014-07-10 23:23:50,260 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cc31f80bbbe5b6320cd17177b1be6a63 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,260 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:23:50,260 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 8b4421efdcff210abdc3f35add55c82e
2014-07-10 23:23:50,260 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Instantiated usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:23:50,261 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => cc31f80bbbe5b6320cd17177b1be6a63, NAME => 'usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-10 23:23:50,262 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable cc31f80bbbe5b6320cd17177b1be6a63
2014-07-10 23:23:50,263 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:23:50,267 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-10 23:23:50,268 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-10 23:23:50,270 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-10 23:23:50,271 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-10 23:23:50,271 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-10 23:23:50,308 INFO  [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 23:23:50,309 INFO  [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 23:23:50,311 INFO  [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 23:23:50,341 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-10 23:23:50,343 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/02b4b6d590fd4d4d99bcfd790cb07d37, isReference=false, isBulkLoadResult=false, seqid=2331, majorCompaction=false
2014-07-10 23:23:50,355 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/0cfa70b058104fe493ad0818c74506e8, isReference=false, isBulkLoadResult=false, seqid=780, majorCompaction=false
2014-07-10 23:23:50,359 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/10b4e8913fca43d7adda09e939651cf5, isReference=false, isBulkLoadResult=false, seqid=1816, majorCompaction=false
2014-07-10 23:23:50,390 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/270e553fc71040fdada348b6ca73b17f, isReference=false, isBulkLoadResult=false, seqid=311, majorCompaction=false
2014-07-10 23:23:50,397 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/440a9208f6914e9280eaea06f9586921, isReference=false, isBulkLoadResult=false, seqid=1155, majorCompaction=false
2014-07-10 23:23:50,410 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/314dedcb5d174d2bbe11027584f27f0f, isReference=false, isBulkLoadResult=false, seqid=2169, majorCompaction=false
2014-07-10 23:23:50,415 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-10 23:23:50,416 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/6e9086a0eba14414b909b7ab72bfd58e, isReference=false, isBulkLoadResult=false, seqid=2329, majorCompaction=false
2014-07-10 23:23:50,426 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/129c8e09808f4d5a88c7b44ae58656ec, isReference=false, isBulkLoadResult=false, seqid=289, majorCompaction=false
2014-07-10 23:23:50,430 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/4514f47867744d37ae5183eee2469ae7, isReference=false, isBulkLoadResult=false, seqid=570, majorCompaction=false
2014-07-10 23:23:50,437 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/275cde3891c5405189c5ffdc2623efd1, isReference=false, isBulkLoadResult=false, seqid=2292, majorCompaction=false
2014-07-10 23:23:50,441 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/758e33d8831146acae9b73be3f72fec5, isReference=false, isBulkLoadResult=false, seqid=2107, majorCompaction=false
2014-07-10 23:23:50,463 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/61edb5e03cc243c88655fc347959c724, isReference=false, isBulkLoadResult=false, seqid=1087, majorCompaction=false
2014-07-10 23:23:50,472 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/81c4a59973074083bbeb9e99e16fe5a2, isReference=false, isBulkLoadResult=false, seqid=376, majorCompaction=false
2014-07-10 23:23:50,472 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/5371d403010a4550864bebcf6f3402f5, isReference=false, isBulkLoadResult=false, seqid=168, majorCompaction=false
2014-07-10 23:23:50,487 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/6b0daf32477e4ef9afafceb6959563fd, isReference=false, isBulkLoadResult=false, seqid=1318, majorCompaction=false
2014-07-10 23:23:50,492 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/587d24087b4541e9b9c681870a9cc8f2, isReference=false, isBulkLoadResult=false, seqid=1872, majorCompaction=false
2014-07-10 23:23:50,495 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/8edb8fe21e734c52b37e3d8e18e55c40, isReference=false, isBulkLoadResult=false, seqid=190, majorCompaction=false
2014-07-10 23:23:50,508 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/78d779c11f844f7c92557760a05f43a3, isReference=false, isBulkLoadResult=false, seqid=2009, majorCompaction=false
2014-07-10 23:23:50,513 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/6a869559b00c4c87ab9759b86efa25aa, isReference=false, isBulkLoadResult=false, seqid=812, majorCompaction=false
2014-07-10 23:23:50,519 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/b1cff6bab8b14852a747cfe69e64c809, isReference=false, isBulkLoadResult=false, seqid=1422, majorCompaction=false
2014-07-10 23:23:50,528 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/78dc69a8570c4314bfffba4897eeae5e, isReference=false, isBulkLoadResult=false, seqid=2340, majorCompaction=false
2014-07-10 23:23:50,547 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/7fa5e3fdbc3149948ef7e19590454c69, isReference=false, isBulkLoadResult=false, seqid=1152, majorCompaction=false
2014-07-10 23:23:50,553 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/bb9912254e7d4dada4205af31393f3b4, isReference=false, isBulkLoadResult=false, seqid=619, majorCompaction=false
2014-07-10 23:23:50,557 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/b2b0a7cf2d9846e0901396754d370caa, isReference=false, isBulkLoadResult=false, seqid=166, majorCompaction=false
2014-07-10 23:23:50,578 DEBUG [StoreOpener-cc31f80bbbe5b6320cd17177b1be6a63-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63/family/d5524567895642d9ab43e1d685300595, isReference=false, isBulkLoadResult=false, seqid=926, majorCompaction=false
2014-07-10 23:23:50,586 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/cc31f80bbbe5b6320cd17177b1be6a63
2014-07-10 23:23:50,586 DEBUG [StoreOpener-682479f17fefd754e837eac1f4a02b9c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c/family/eb4391108c45431db17134c6b2370cb3, isReference=false, isBulkLoadResult=false, seqid=1477, majorCompaction=false
2014-07-10 23:23:50,592 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/682479f17fefd754e837eac1f4a02b9c
2014-07-10 23:23:50,593 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined cc31f80bbbe5b6320cd17177b1be6a63; next sequenceid=2330
2014-07-10 23:23:50,593 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node cc31f80bbbe5b6320cd17177b1be6a63
2014-07-10 23:23:50,595 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/c608b4f116284f54b8316521e78569ab, isReference=false, isBulkLoadResult=false, seqid=1605, majorCompaction=false
2014-07-10 23:23:50,597 INFO  [PostOpenDeployTasks:cc31f80bbbe5b6320cd17177b1be6a63] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:23:50,598 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined 682479f17fefd754e837eac1f4a02b9c; next sequenceid=2332
2014-07-10 23:23:50,598 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 682479f17fefd754e837eac1f4a02b9c
2014-07-10 23:23:50,600 INFO  [PostOpenDeployTasks:682479f17fefd754e837eac1f4a02b9c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:23:50,601 DEBUG [PostOpenDeployTasks:cc31f80bbbe5b6320cd17177b1be6a63] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:23:50,602 DEBUG [PostOpenDeployTasks:682479f17fefd754e837eac1f4a02b9c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 23:23:50,605 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-10 23:23:50,605 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-10 23:23:50,608 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:50,608 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:50,610 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63. because compaction request was cancelled
2014-07-10 23:23:50,611 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-10 23:23:50,611 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-10 23:23:50,611 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:50,611 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:50,611 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c. because compaction request was cancelled
2014-07-10 23:23:50,659 DEBUG [StoreOpener-8b4421efdcff210abdc3f35add55c82e-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e/family/ea9074a2e24c4ccebf48928f34baa1bc, isReference=false, isBulkLoadResult=false, seqid=525, majorCompaction=false
2014-07-10 23:23:50,662 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/8b4421efdcff210abdc3f35add55c82e
2014-07-10 23:23:50,666 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Onlined 8b4421efdcff210abdc3f35add55c82e; next sequenceid=2341
2014-07-10 23:23:50,666 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 8b4421efdcff210abdc3f35add55c82e
2014-07-10 23:23:50,669 INFO  [PostOpenDeployTasks:8b4421efdcff210abdc3f35add55c82e] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:23:50,669 DEBUG [PostOpenDeployTasks:8b4421efdcff210abdc3f35add55c82e] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:23:50,669 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-10 23:23:50,670 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-10 23:23:50,670 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:50,670 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:50,670 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e. because compaction request was cancelled
2014-07-10 23:23:50,748 INFO  [PostOpenDeployTasks:682479f17fefd754e837eac1f4a02b9c] catalog.MetaEditor: Updated row usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,748 INFO  [PostOpenDeployTasks:cc31f80bbbe5b6320cd17177b1be6a63] catalog.MetaEditor: Updated row usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,748 INFO  [PostOpenDeployTasks:8b4421efdcff210abdc3f35add55c82e] catalog.MetaEditor: Updated row usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,750 INFO  [PostOpenDeployTasks:cc31f80bbbe5b6320cd17177b1be6a63] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:23:50,748 INFO  [PostOpenDeployTasks:682479f17fefd754e837eac1f4a02b9c] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:23:50,750 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cc31f80bbbe5b6320cd17177b1be6a63 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:50,750 INFO  [PostOpenDeployTasks:8b4421efdcff210abdc3f35add55c82e] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:23:50,751 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 682479f17fefd754e837eac1f4a02b9c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:50,752 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8b4421efdcff210abdc3f35add55c82e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:50,757 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cc31f80bbbe5b6320cd17177b1be6a63 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:50,757 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned cc31f80bbbe5b6320cd17177b1be6a63 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,758 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 682479f17fefd754e837eac1f4a02b9c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:50,758 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned 682479f17fefd754e837eac1f4a02b9c to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,758 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,758 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,759 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning acca1e7e36977b29d8ccf778b373c938 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8b4421efdcff210abdc3f35add55c82e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:50,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Transitioned 8b4421efdcff210abdc3f35add55c82e to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cae54b46b61fcdebc567d409f45c45bc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Opened usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:50,765 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node acca1e7e36977b29d8ccf778b373c938 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,766 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => acca1e7e36977b29d8ccf778b373c938, NAME => 'usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-10 23:23:50,766 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cae54b46b61fcdebc567d409f45c45bc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:23:50,767 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable acca1e7e36977b29d8ccf778b373c938
2014-07-10 23:23:50,767 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => cae54b46b61fcdebc567d409f45c45bc, NAME => 'usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-10 23:23:50,767 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:23:50,768 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable cae54b46b61fcdebc567d409f45c45bc
2014-07-10 23:23:50,768 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:23:50,775 INFO  [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 23:23:50,776 INFO  [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-10 23:23:50,797 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/08d6451966a640e2a8bd8b9b9fd83c88, isReference=false, isBulkLoadResult=false, seqid=953, majorCompaction=false
2014-07-10 23:23:50,808 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/0435d61601a7400885e939b2681f5df2, isReference=false, isBulkLoadResult=false, seqid=3806, majorCompaction=false
2014-07-10 23:23:50,818 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/228ebf15bd854103800a24670190f544, isReference=false, isBulkLoadResult=false, seqid=5112, majorCompaction=false
2014-07-10 23:23:50,821 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/297f0f88b7ae441c96cb55f6282a5a68, isReference=false, isBulkLoadResult=false, seqid=2017, majorCompaction=false
2014-07-10 23:23:50,843 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/37dd89eb49ab4aefb957171972c8df93, isReference=false, isBulkLoadResult=false, seqid=1481, majorCompaction=false
2014-07-10 23:23:50,852 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/43bcf5540a714ca0933dbcc43a9e39b5, isReference=false, isBulkLoadResult=false, seqid=3118, majorCompaction=false
2014-07-10 23:23:50,866 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/39bac36c51d04b8fad2f183ae0b378e5, isReference=false, isBulkLoadResult=false, seqid=3511, majorCompaction=false
2014-07-10 23:23:50,875 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/4ca46d76447241a2b67d3fe489a9714d, isReference=false, isBulkLoadResult=false, seqid=4476, majorCompaction=false
2014-07-10 23:23:50,895 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/3fc600dedef942c98a3a87f18d4a4b97, isReference=false, isBulkLoadResult=false, seqid=2784, majorCompaction=false
2014-07-10 23:23:50,901 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/520e243b4e9f4be0afeea2c3b785c3b0, isReference=false, isBulkLoadResult=false, seqid=1570, majorCompaction=false
2014-07-10 23:23:50,909 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/5e82da513f1e42299877f8632a111529, isReference=false, isBulkLoadResult=false, seqid=5106, majorCompaction=false
2014-07-10 23:23:50,924 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/b7343a7190ba4c54a3572c6e638c6229, isReference=false, isBulkLoadResult=false, seqid=2291, majorCompaction=false
2014-07-10 23:23:50,928 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/9f094a476b1d4425a6c1db94094ff72f, isReference=false, isBulkLoadResult=false, seqid=4154, majorCompaction=false
2014-07-10 23:23:50,952 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/c1fe650a0bc248d8bed2ad1cb8c50a17, isReference=false, isBulkLoadResult=false, seqid=1051, majorCompaction=false
2014-07-10 23:23:50,962 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/c111b7f273d148a2a308bfdf04985957, isReference=false, isBulkLoadResult=false, seqid=199, majorCompaction=false
2014-07-10 23:23:50,971 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/d822d5b28f3746aa85de37cb09f6ab57, isReference=false, isBulkLoadResult=false, seqid=479, majorCompaction=false
2014-07-10 23:23:50,987 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/d4f87f3f5522422689ae2d144c55115a, isReference=false, isBulkLoadResult=false, seqid=422, majorCompaction=false
2014-07-10 23:23:50,994 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/f9c32c8884a84b79af1bddb203391bdc, isReference=false, isBulkLoadResult=false, seqid=206, majorCompaction=false
2014-07-10 23:23:50,996 DEBUG [StoreOpener-cae54b46b61fcdebc567d409f45c45bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc/family/ef2f550f16cc47e8850658acaca00139, isReference=false, isBulkLoadResult=false, seqid=4868, majorCompaction=false
2014-07-10 23:23:51,001 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/cae54b46b61fcdebc567d409f45c45bc
2014-07-10 23:23:51,003 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined cae54b46b61fcdebc567d409f45c45bc; next sequenceid=5107
2014-07-10 23:23:51,004 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node cae54b46b61fcdebc567d409f45c45bc
2014-07-10 23:23:51,005 DEBUG [StoreOpener-acca1e7e36977b29d8ccf778b373c938-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938/family/fbf01e33b6044f9fb5a727487ee8db27, isReference=false, isBulkLoadResult=false, seqid=5130, majorCompaction=false
2014-07-10 23:23:51,006 INFO  [PostOpenDeployTasks:cae54b46b61fcdebc567d409f45c45bc] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:23:51,007 DEBUG [PostOpenDeployTasks:cae54b46b61fcdebc567d409f45c45bc] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:23:51,007 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-10 23:23:51,008 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-10 23:23:51,008 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:51,008 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:51,008 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/acca1e7e36977b29d8ccf778b373c938
2014-07-10 23:23:51,008 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc. because compaction request was cancelled
2014-07-10 23:23:51,010 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined acca1e7e36977b29d8ccf778b373c938; next sequenceid=5131
2014-07-10 23:23:51,010 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node acca1e7e36977b29d8ccf778b373c938
2014-07-10 23:23:51,013 INFO  [PostOpenDeployTasks:acca1e7e36977b29d8ccf778b373c938] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:23:51,013 DEBUG [PostOpenDeployTasks:acca1e7e36977b29d8ccf778b373c938] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:23:51,014 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-10 23:23:51,014 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-10 23:23:51,014 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:51,014 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:51,014 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938. because compaction request was cancelled
2014-07-10 23:23:51,019 INFO  [PostOpenDeployTasks:cae54b46b61fcdebc567d409f45c45bc] catalog.MetaEditor: Updated row usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:51,019 INFO  [PostOpenDeployTasks:cae54b46b61fcdebc567d409f45c45bc] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:23:51,020 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cae54b46b61fcdebc567d409f45c45bc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:51,026 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cae54b46b61fcdebc567d409f45c45bc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:51,026 INFO  [PostOpenDeployTasks:acca1e7e36977b29d8ccf778b373c938] catalog.MetaEditor: Updated row usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:51,026 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned cae54b46b61fcdebc567d409f45c45bc to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:51,026 INFO  [PostOpenDeployTasks:acca1e7e36977b29d8ccf778b373c938] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:23:51,027 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:51,027 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning acca1e7e36977b29d8ccf778b373c938 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:51,038 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node acca1e7e36977b29d8ccf778b373c938 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:23:51,038 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned acca1e7e36977b29d8ccf778b373c938 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:51,038 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:23:55,489 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:23:55,490 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-10 23:23:55,490 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-10 23:23:55,490 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 23:23:55,490 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:55,490 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:55,490 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 23:23:55,491 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e. because compaction request was cancelled
2014-07-10 23:23:55,491 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 23:23:55,491 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-10 23:23:55,491 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-10 23:23:55,491 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 23:23:55,491 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:55,491 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:55,492 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc. because compaction request was cancelled
2014-07-10 23:23:55,492 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-10 23:23:55,492 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 10 files from compaction candidates
2014-07-10 23:23:55,492 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:55,493 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:55,493 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938. because compaction request was cancelled
2014-07-10 23:23:55,493 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-10 23:23:55,493 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-10 23:23:55,493 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:55,493 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:55,494 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c. because compaction request was cancelled
2014-07-10 23:23:55,494 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-10 23:23:55,494 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-10 23:23:55,494 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-10 23:23:55,494 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-10 23:23:55,494 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Not compacting usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63. because compaction request was cancelled
2014-07-10 23:24:19,552 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Close 8b4421efdcff210abdc3f35add55c82e, via zk=yes, znode version=0, on null
2014-07-10 23:24:19,552 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Close cc31f80bbbe5b6320cd17177b1be6a63, via zk=yes, znode version=0, on null
2014-07-10 23:24:19,552 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close acca1e7e36977b29d8ccf778b373c938, via zk=yes, znode version=0, on null
2014-07-10 23:24:19,553 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 682479f17fefd754e837eac1f4a02b9c, via zk=yes, znode version=0, on null
2014-07-10 23:24:19,553 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close cae54b46b61fcdebc567d409f45c45bc, via zk=yes, znode version=0, on null
2014-07-10 23:24:19,556 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Processing close of usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:24:19,556 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Processing close of usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:24:19,556 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Processing close of usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:24:19,559 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closing usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.: disabling compactions & flushes
2014-07-10 23:24:19,559 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Updates disabled for region usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:24:19,561 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closing usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.: disabling compactions & flushes
2014-07-10 23:24:19,561 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Updates disabled for region usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:24:19,561 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closing usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.: disabling compactions & flushes
2014-07-10 23:24:19,562 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Updates disabled for region usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:24:19,599 INFO  [StoreCloserThread-usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.-1] regionserver.HStore: Closed family
2014-07-10 23:24:19,599 INFO  [StoreCloserThread-usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.-1] regionserver.HStore: Closed family
2014-07-10 23:24:19,600 INFO  [StoreCloserThread-usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.-1] regionserver.HStore: Closed family
2014-07-10 23:24:19,603 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closed usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:24:19,603 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closed usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:24:19,603 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning acca1e7e36977b29d8ccf778b373c938 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,603 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closed usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:24:19,603 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 8b4421efdcff210abdc3f35add55c82e from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,603 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 682479f17fefd754e837eac1f4a02b9c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,612 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node acca1e7e36977b29d8ccf778b373c938 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,612 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:24:19,612 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Closed usertable,user4,1405059181586.acca1e7e36977b29d8ccf778b373c938.
2014-07-10 23:24:19,612 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Processing close of usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 8b4421efdcff210abdc3f35add55c82e from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Closed usertable,user1,1405059181585.8b4421efdcff210abdc3f35add55c82e.
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Processing close of usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 682479f17fefd754e837eac1f4a02b9c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:24:19,613 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Closed usertable,user2,1405059181585.682479f17fefd754e837eac1f4a02b9c.
2014-07-10 23:24:19,614 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closing usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.: disabling compactions & flushes
2014-07-10 23:24:19,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Updates disabled for region usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:24:19,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closing usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.: disabling compactions & flushes
2014-07-10 23:24:19,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Updates disabled for region usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:24:19,618 INFO  [StoreCloserThread-usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.-1] regionserver.HStore: Closed family
2014-07-10 23:24:19,618 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closed usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:24:19,619 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cc31f80bbbe5b6320cd17177b1be6a63 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,619 INFO  [StoreCloserThread-usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.-1] regionserver.HStore: Closed family
2014-07-10 23:24:19,620 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closed usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:24:19,620 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cae54b46b61fcdebc567d409f45c45bc from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,624 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cc31f80bbbe5b6320cd17177b1be6a63 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,624 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:24:19,624 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Closed usertable,user3,1405059181585.cc31f80bbbe5b6320cd17177b1be6a63.
2014-07-10 23:24:19,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cae54b46b61fcdebc567d409f45c45bc from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-10 23:24:19,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:24:19,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Closed usertable,user5,1405059181586.cae54b46b61fcdebc567d409f45c45bc.
2014-07-10 23:24:22,346 INFO  [Priority.RpcServer.handler=9,port=60020] regionserver.HRegionServer: Compacting hbase:meta,,1.1588230740
2014-07-10 23:24:22,347 DEBUG [Priority.RpcServer.handler=9,port=60020] compactions.RatioBasedCompactionPolicy: Selecting compaction from 2 store files, 0 compacting, 2 eligible, 20 blocking
2014-07-10 23:24:22,348 DEBUG [Priority.RpcServer.handler=9,port=60020] regionserver.HStore: 1588230740 - info: Initiating major compaction
2014-07-10 23:24:22,348 DEBUG [Priority.RpcServer.handler=9,port=60020] regionserver.CompactSplitThread: Small Compaction requested: org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext@3e6bb568; Because: User-triggered major compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:24:22,349 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HRegion: Starting compaction on info in region hbase:meta,,1.1588230740
2014-07-10 23:24:22,350 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Starting compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into tmpdir=hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp, totalSize=16.1k
2014-07-10 23:24:22,352 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/3689b3d261524e7aa3ebf58fc3629915, keycount=71, bloomtype=NONE, size=9.1k, encoding=NONE, seqNum=3910, earliestPutTs=1402645258588
2014-07-10 23:24:22,352 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/d432e6b1319c4785b23ec6282d68c7d4, keycount=53, bloomtype=NONE, size=7.0k, encoding=NONE, seqNum=3936, earliestPutTs=1405058841115
2014-07-10 23:24:22,365 DEBUG [regionserver60020-smallCompactions-1405059830600] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:24:22,434 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/hbase/meta/1588230740/.tmp/1278feae739d4057a7f81015ddde37c0 as hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/1278feae739d4057a7f81015ddde37c0
2014-07-10 23:24:22,463 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Removing store files after compaction...
2014-07-10 23:24:22,478 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/3689b3d261524e7aa3ebf58fc3629915, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/3689b3d261524e7aa3ebf58fc3629915
2014-07-10 23:24:22,482 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/hbase/meta/1588230740/info/d432e6b1319c4785b23ec6282d68c7d4, to hdfs://master:54310/hbase/archive/data/hbase/meta/1588230740/info/d432e6b1319c4785b23ec6282d68c7d4
2014-07-10 23:24:22,483 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Completed major compaction of 2 file(s) in info of hbase:meta,,1.1588230740 into 1278feae739d4057a7f81015ddde37c0(size=9.0k), total size for store is 9.0k. This selection was in queue for 0sec, and took 0sec to execute.
2014-07-10 23:24:22,487 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Completed compaction: Request = regionName=hbase:meta,,1.1588230740, storeName=info, fileCount=2, fileSize=16.1k, priority=1, time=13778738855096; duration=0sec
2014-07-10 23:24:22,487 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:28:12,899 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=0, accesses=77, hits=74, hitRatio=96.10%, , cachingAccesses=74, cachingHits=71, cachingHitsRatio=95.94%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 23:29:29,813 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:29:29,824 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:29:29,824 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2f0a37e0c2bb48c75813e7844f62e799 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,825 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:29:29,825 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5efb4c8cc936a019263d5b128583c6c6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,826 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:29:29,827 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Open usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:29:29,827 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2f8b7bbfe3f11e72550880324064a38c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,831 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2f0a37e0c2bb48c75813e7844f62e799 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,831 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5efb4c8cc936a019263d5b128583c6c6 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,832 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Opening region: {ENCODED => 2f0a37e0c2bb48c75813e7844f62e799, NAME => 'usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-10 23:29:29,832 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => 5efb4c8cc936a019263d5b128583c6c6, NAME => 'usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-10 23:29:29,833 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2f8b7bbfe3f11e72550880324064a38c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,833 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2f0a37e0c2bb48c75813e7844f62e799
2014-07-10 23:29:29,833 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5efb4c8cc936a019263d5b128583c6c6
2014-07-10 23:29:29,833 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => 2f8b7bbfe3f11e72550880324064a38c, NAME => 'usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-10 23:29:29,834 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:29:29,834 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Instantiated usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:29:29,834 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:29:29,835 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:29:29,845 INFO  [StoreOpener-2f0a37e0c2bb48c75813e7844f62e799-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 23:29:29,847 INFO  [StoreOpener-5efb4c8cc936a019263d5b128583c6c6-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 23:29:29,848 INFO  [StoreOpener-2f8b7bbfe3f11e72550880324064a38c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 23:29:29,852 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799
2014-07-10 23:29:29,853 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6
2014-07-10 23:29:29,854 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:29:29,856 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Onlined 2f0a37e0c2bb48c75813e7844f62e799; next sequenceid=1
2014-07-10 23:29:29,856 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2f0a37e0c2bb48c75813e7844f62e799
2014-07-10 23:29:29,857 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined 5efb4c8cc936a019263d5b128583c6c6; next sequenceid=1
2014-07-10 23:29:29,857 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5efb4c8cc936a019263d5b128583c6c6
2014-07-10 23:29:29,858 INFO  [PostOpenDeployTasks:2f0a37e0c2bb48c75813e7844f62e799] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:29:29,858 INFO  [PostOpenDeployTasks:5efb4c8cc936a019263d5b128583c6c6] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:29:29,871 INFO  [PostOpenDeployTasks:5efb4c8cc936a019263d5b128583c6c6] catalog.MetaEditor: Updated row usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,871 INFO  [PostOpenDeployTasks:5efb4c8cc936a019263d5b128583c6c6] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:29:29,873 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5efb4c8cc936a019263d5b128583c6c6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,873 INFO  [PostOpenDeployTasks:2f0a37e0c2bb48c75813e7844f62e799] catalog.MetaEditor: Updated row usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,873 INFO  [PostOpenDeployTasks:2f0a37e0c2bb48c75813e7844f62e799] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:29:29,874 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2f0a37e0c2bb48c75813e7844f62e799 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,877 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5efb4c8cc936a019263d5b128583c6c6 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,877 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned 5efb4c8cc936a019263d5b128583c6c6 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,877 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,878 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e472980be441986b612f83054b0dc330 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,880 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2f0a37e0c2bb48c75813e7844f62e799 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,880 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Transitioned 2f0a37e0c2bb48c75813e7844f62e799 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,881 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Opened usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,881 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a17619b4327f9b5610de972e6da3dce2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,882 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e472980be441986b612f83054b0dc330 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,883 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => e472980be441986b612f83054b0dc330, NAME => 'usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-10 23:29:29,883 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable e472980be441986b612f83054b0dc330
2014-07-10 23:29:29,884 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:29:29,886 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined 2f8b7bbfe3f11e72550880324064a38c; next sequenceid=1
2014-07-10 23:29:29,886 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a17619b4327f9b5610de972e6da3dce2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-10 23:29:29,886 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:29:29,886 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Opening region: {ENCODED => a17619b4327f9b5610de972e6da3dce2, NAME => 'usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-10 23:29:29,887 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable a17619b4327f9b5610de972e6da3dce2
2014-07-10 23:29:29,887 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Instantiated usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:29:29,887 INFO  [PostOpenDeployTasks:2f8b7bbfe3f11e72550880324064a38c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:29:29,894 INFO  [StoreOpener-e472980be441986b612f83054b0dc330-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 23:29:29,895 INFO  [StoreOpener-a17619b4327f9b5610de972e6da3dce2-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-10 23:29:29,901 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330
2014-07-10 23:29:29,902 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2
2014-07-10 23:29:29,904 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined e472980be441986b612f83054b0dc330; next sequenceid=1
2014-07-10 23:29:29,904 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e472980be441986b612f83054b0dc330
2014-07-10 23:29:29,904 INFO  [PostOpenDeployTasks:2f8b7bbfe3f11e72550880324064a38c] catalog.MetaEditor: Updated row usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,904 INFO  [PostOpenDeployTasks:2f8b7bbfe3f11e72550880324064a38c] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:29:29,905 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2f8b7bbfe3f11e72550880324064a38c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,907 INFO  [PostOpenDeployTasks:e472980be441986b612f83054b0dc330] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:29:29,918 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2f8b7bbfe3f11e72550880324064a38c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,918 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned 2f8b7bbfe3f11e72550880324064a38c to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,918 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,924 INFO  [PostOpenDeployTasks:e472980be441986b612f83054b0dc330] catalog.MetaEditor: Updated row usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,925 INFO  [PostOpenDeployTasks:e472980be441986b612f83054b0dc330] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:29:29,925 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e472980be441986b612f83054b0dc330 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,931 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e472980be441986b612f83054b0dc330 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,931 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned e472980be441986b612f83054b0dc330 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,931 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,941 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Onlined a17619b4327f9b5610de972e6da3dce2; next sequenceid=1
2014-07-10 23:29:29,941 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node a17619b4327f9b5610de972e6da3dce2
2014-07-10 23:29:29,948 INFO  [PostOpenDeployTasks:a17619b4327f9b5610de972e6da3dce2] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:29:29,959 INFO  [PostOpenDeployTasks:a17619b4327f9b5610de972e6da3dce2] catalog.MetaEditor: Updated row usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. with server=sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,960 INFO  [PostOpenDeployTasks:a17619b4327f9b5610de972e6da3dce2] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:29:29,962 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning a17619b4327f9b5610de972e6da3dce2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,967 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x1472416fcb00000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node a17619b4327f9b5610de972e6da3dce2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-10 23:29:29,967 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Transitioned a17619b4327f9b5610de972e6da3dce2 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:29,968 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Opened usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. on sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:29:47,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:29:47,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 87 synced till here 75
2014-07-10 23:29:48,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405059825344 with entries=87, filesize=72.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060187865
2014-07-10 23:29:50,535 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:29:50,558 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 183 synced till here 181
2014-07-10 23:29:50,591 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060187865 with entries=96, filesize=63.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060190536
2014-07-10 23:30:23,989 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:30:24,132 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 270 synced till here 263
2014-07-10 23:30:24,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060190536 with entries=87, filesize=65.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060223989
2014-07-10 23:30:26,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:30:26,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060223989 with entries=86, filesize=62.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060226278
2014-07-10 23:30:30,545 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:30:30,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 440 synced till here 439
2014-07-10 23:30:30,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060226278 with entries=84, filesize=61.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060230545
2014-07-10 23:31:03,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:03,589 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 526 synced till here 523
2014-07-10 23:31:03,749 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060230545 with entries=86, filesize=64.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060263541
2014-07-10 23:31:06,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:06,214 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 612 synced till here 611
2014-07-10 23:31:06,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060263541 with entries=86, filesize=62.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060266085
2014-07-10 23:31:24,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:24,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060266085 with entries=84, filesize=61.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060284386
2014-07-10 23:31:27,307 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:28,231 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060284386 with entries=96, filesize=71.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060287307
2014-07-10 23:31:28,800 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:31:28,803 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., current region memstore size 256.2m
2014-07-10 23:31:28,876 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:31:28,876 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., current region memstore size 256.3m
2014-07-10 23:31:29,014 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:31:29,057 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:31:29,191 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:31:29,253 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:31:29,338 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-10 23:31:30,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:30,092 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 877 synced till here 875
2014-07-10 23:31:30,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060287307 with entries=85, filesize=62.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060290071
2014-07-10 23:31:33,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:33,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060290071 with entries=84, filesize=61.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060293254
2014-07-10 23:31:38,276 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=169, memsize=259.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/7b260b5536434f02adb1fc25f90a3c65
2014-07-10 23:31:38,286 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/7b260b5536434f02adb1fc25f90a3c65 as hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/7b260b5536434f02adb1fc25f90a3c65
2014-07-10 23:31:38,296 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/7b260b5536434f02adb1fc25f90a3c65, entries=944560, sequenceid=169, filesize=67.3m
2014-07-10 23:31:38,296 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.4m/272025680, currentsize=51.7m/54179040 for region usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. in 9420ms, sequenceid=169, compaction requested=false
2014-07-10 23:31:38,298 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., current region memstore size 310.7m
2014-07-10 23:31:38,475 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:31:38,619 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=168, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/4fff64d5374743ba9194a42bdd1d3134
2014-07-10 23:31:38,630 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/4fff64d5374743ba9194a42bdd1d3134 as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/4fff64d5374743ba9194a42bdd1d3134
2014-07-10 23:31:38,638 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/4fff64d5374743ba9194a42bdd1d3134, entries=938100, sequenceid=168, filesize=66.9m
2014-07-10 23:31:38,639 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270166000, currentsize=52.8m/55392560 for region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. in 9836ms, sequenceid=168, compaction requested=false
2014-07-10 23:31:38,639 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405060169521.e472980be441986b612f83054b0dc330., current region memstore size 310.6m
2014-07-10 23:31:38,804 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:31:47,675 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=202, memsize=310.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/d380c19503e1496d9eaa08fe7243f3df
2014-07-10 23:31:47,686 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/d380c19503e1496d9eaa08fe7243f3df as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/d380c19503e1496d9eaa08fe7243f3df
2014-07-10 23:31:47,695 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/d380c19503e1496d9eaa08fe7243f3df, entries=1131250, sequenceid=202, filesize=80.6m
2014-07-10 23:31:47,696 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~310.7m/325790720, currentsize=0.0/0 for region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. in 9397ms, sequenceid=202, compaction requested=false
2014-07-10 23:31:47,873 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=202, memsize=310.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/ff0ec5a75dda4e7588f47aca56d68936
2014-07-10 23:31:47,884 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/ff0ec5a75dda4e7588f47aca56d68936 as hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/ff0ec5a75dda4e7588f47aca56d68936
2014-07-10 23:31:47,894 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/ff0ec5a75dda4e7588f47aca56d68936, entries=1130900, sequenceid=202, filesize=80.6m
2014-07-10 23:31:47,894 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~310.6m/325693280, currentsize=0.0/0 for region usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. in 9255ms, sequenceid=202, compaction requested=false
2014-07-10 23:31:58,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:31:58,391 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1046 synced till here 1044
2014-07-10 23:31:58,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060293254 with entries=85, filesize=63.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060318373
2014-07-10 23:32:00,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:00,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060318373 with entries=86, filesize=63.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060320822
2014-07-10 23:32:03,236 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:03,588 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060320822 with entries=91, filesize=68.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060323237
2014-07-10 23:32:05,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:05,271 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1312 synced till here 1309
2014-07-10 23:32:05,319 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060323237 with entries=89, filesize=64.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060325184
2014-07-10 23:32:07,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:07,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060325184 with entries=85, filesize=61.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060327240
2014-07-10 23:32:26,196 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:26,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060327240 with entries=84, filesize=61.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060346196
2014-07-10 23:32:28,490 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:28,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060346196 with entries=82, filesize=60.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060348490
2014-07-10 23:32:37,341 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:32:37,343 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., current region memstore size 256.5m
2014-07-10 23:32:37,539 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:37,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1649 synced till here 1647
2014-07-10 23:32:37,635 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060348490 with entries=86, filesize=64.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060357539
2014-07-10 23:32:37,702 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:32:37,703 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., current region memstore size 256.8m
2014-07-10 23:32:37,835 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:32:38,100 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:32:39,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:39,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1737 synced till here 1733
2014-07-10 23:32:39,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060357539 with entries=88, filesize=65.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060359280
2014-07-10 23:32:41,329 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:41,414 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:32:41,439 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060359280 with entries=86, filesize=63.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060361330
2014-07-10 23:32:41,611 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:32:43,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:32:43,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060361330 with entries=85, filesize=61.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060363733
2014-07-10 23:32:48,303 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=335, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/9b208fbbab3c4568a7ec1ff2fc2a7bd3
2014-07-10 23:32:48,314 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/9b208fbbab3c4568a7ec1ff2fc2a7bd3 as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/9b208fbbab3c4568a7ec1ff2fc2a7bd3
2014-07-10 23:32:48,326 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/9b208fbbab3c4568a7ec1ff2fc2a7bd3, entries=939580, sequenceid=335, filesize=66.9m
2014-07-10 23:32:48,327 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.1m/270593040, currentsize=98.3m/103031600 for region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. in 10985ms, sequenceid=335, compaction requested=false
2014-07-10 23:32:48,327 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., current region memstore size 302.6m
2014-07-10 23:32:48,412 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=336, memsize=258.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/05c283e1e22c4f5bacf209ed38664686
2014-07-10 23:32:48,422 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/05c283e1e22c4f5bacf209ed38664686 as hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/05c283e1e22c4f5bacf209ed38664686
2014-07-10 23:32:48,431 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/05c283e1e22c4f5bacf209ed38664686, entries=940770, sequenceid=336, filesize=67.0m
2014-07-10 23:32:48,431 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.4m/270933200, currentsize=96.0m/100623600 for region usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. in 10728ms, sequenceid=336, compaction requested=false
2014-07-10 23:32:48,431 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405060169521.e472980be441986b612f83054b0dc330., current region memstore size 303.3m
2014-07-10 23:32:48,504 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:32:48,620 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:32:57,285 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=398, memsize=302.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/8af8d41e4c5a436e98bf4c661fa4e217
2014-07-10 23:32:57,296 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/8af8d41e4c5a436e98bf4c661fa4e217 as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/8af8d41e4c5a436e98bf4c661fa4e217
2014-07-10 23:32:57,305 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/8af8d41e4c5a436e98bf4c661fa4e217, entries=1101940, sequenceid=398, filesize=78.4m
2014-07-10 23:32:57,306 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~302.6m/317350960, currentsize=0.0/0 for region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. in 8979ms, sequenceid=398, compaction requested=false
2014-07-10 23:32:57,344 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=398, memsize=303.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/ed75eecf8e144fd6b96bbdc787e0c32a
2014-07-10 23:32:57,353 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/ed75eecf8e144fd6b96bbdc787e0c32a as hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/ed75eecf8e144fd6b96bbdc787e0c32a
2014-07-10 23:32:57,362 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/ed75eecf8e144fd6b96bbdc787e0c32a, entries=1104150, sequenceid=398, filesize=78.6m
2014-07-10 23:32:57,362 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~303.3m/317987360, currentsize=0.0/0 for region usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. in 8931ms, sequenceid=398, compaction requested=false
2014-07-10 23:33:12,897 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=1037, hits=1032, hitRatio=99.51%, , cachingAccesses=1034, cachingHits=1029, cachingHitsRatio=99.51%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 23:33:16,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:16,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060363733 with entries=84, filesize=61.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060396885
2014-07-10 23:33:20,811 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:20,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2077 synced till here 2075
2014-07-10 23:33:20,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060396885 with entries=85, filesize=63.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060400812
2014-07-10 23:33:23,507 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:23,522 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2162 synced till here 2161
2014-07-10 23:33:23,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060400812 with entries=85, filesize=62.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060403508
2014-07-10 23:33:25,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:26,626 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060403508 with entries=155, filesize=113.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060405169
2014-07-10 23:33:28,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:28,590 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060405169 with entries=83, filesize=62.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060408565
2014-07-10 23:33:30,122 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:33:30,122 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., current region memstore size 256.5m
2014-07-10 23:33:30,443 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:33:30,443 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., current region memstore size 256.3m
2014-07-10 23:33:30,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:30,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2487 synced till here 2486
2014-07-10 23:33:30,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060408565 with entries=87, filesize=64.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060410444
2014-07-10 23:33:30,615 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:33:30,924 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:33:32,713 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:32,752 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2576 synced till here 2573
2014-07-10 23:33:32,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060410444 with entries=89, filesize=65.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060412713
2014-07-10 23:33:34,247 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:34,670 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2681 synced till here 2679
2014-07-10 23:33:34,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060412713 with entries=105, filesize=76.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060414248
2014-07-10 23:33:36,848 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:33:36,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:37,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2797 synced till here 2791
2014-07-10 23:33:37,662 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:33:38,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060414248 with entries=116, filesize=87.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060416998
2014-07-10 23:33:38,486 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:33:39,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:39,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2885 synced till here 2884
2014-07-10 23:33:39,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060416998 with entries=88, filesize=63.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060419779
2014-07-10 23:33:41,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:42,107 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060419779 with entries=86, filesize=63.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060421974
2014-07-10 23:33:42,108 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:33:42,871 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=502, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/3f7f6f07a6224bd6a97f2dc9e063961e
2014-07-10 23:33:42,884 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/3f7f6f07a6224bd6a97f2dc9e063961e as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/3f7f6f07a6224bd6a97f2dc9e063961e
2014-07-10 23:33:42,894 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/3f7f6f07a6224bd6a97f2dc9e063961e, entries=939710, sequenceid=502, filesize=67.0m
2014-07-10 23:33:42,894 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.1m/270628320, currentsize=167.2m/175282800 for region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. in 12772ms, sequenceid=502, compaction requested=true
2014-07-10 23:33:42,895 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-10 23:33:42,895 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 23:33:42,895 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c., current region memstore size 281.7m
2014-07-10 23:33:42,896 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 210520442 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-10 23:33:42,896 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: 2f0a37e0c2bb48c75813e7844f62e799 - family: Initiating major compaction
2014-07-10 23:33:42,896 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:33:42,896 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp, totalSize=200.8m
2014-07-10 23:33:42,897 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/4fff64d5374743ba9194a42bdd1d3134, keycount=93810, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=168, earliestPutTs=1405060185164
2014-07-10 23:33:42,897 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/9b208fbbab3c4568a7ec1ff2fc2a7bd3, keycount=93958, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=335, earliestPutTs=1405060288819
2014-07-10 23:33:42,897 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/3f7f6f07a6224bd6a97f2dc9e063961e, keycount=93971, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=502, earliestPutTs=1405060357351
2014-07-10 23:33:43,013 DEBUG [regionserver60020-smallCompactions-1405059830600] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:33:43,349 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:33:43,353 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-10 23:33:43,354 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-10 23:33:43,678 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:43,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3060 synced till here 3056
2014-07-10 23:33:43,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060421974 with entries=89, filesize=66.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060423679
2014-07-10 23:33:43,852 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=504, memsize=259.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/c5acba37922249c388d9d26958f50601
2014-07-10 23:33:43,863 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/c5acba37922249c388d9d26958f50601 as hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/c5acba37922249c388d9d26958f50601
2014-07-10 23:33:43,936 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/c5acba37922249c388d9d26958f50601, entries=944620, sequenceid=504, filesize=67.3m
2014-07-10 23:33:43,937 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.4m/272043520, currentsize=177.4m/185999840 for region usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. in 13494ms, sequenceid=504, compaction requested=true
2014-07-10 23:33:43,938 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-10 23:33:43,938 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., current region memstore size 338.8m
2014-07-10 23:33:44,432 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:33:45,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:45,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060423679 with entries=84, filesize=61.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060425924
2014-07-10 23:33:47,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:47,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3235 synced till here 3226
2014-07-10 23:33:48,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060425924 with entries=91, filesize=68.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060427942
2014-07-10 23:33:49,295 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:33:49,869 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:33:49,910 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:50,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060427942 with entries=130, filesize=93.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060429910
2014-07-10 23:33:53,238 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:53,258 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3456 synced till here 3444
2014-07-10 23:33:53,552 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060429910 with entries=91, filesize=71.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060433239
2014-07-10 23:33:55,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:55,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3565 synced till here 3562
2014-07-10 23:33:55,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060433239 with entries=109, filesize=79.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060435179
2014-07-10 23:33:57,653 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:33:57,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060435179 with entries=88, filesize=61.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060437653
2014-07-10 23:33:59,227 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=604, memsize=281.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/.tmp/7560d7758a3744f08a454a4de9d05344
2014-07-10 23:33:59,238 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/.tmp/7560d7758a3744f08a454a4de9d05344 as hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/family/7560d7758a3744f08a454a4de9d05344
2014-07-10 23:33:59,246 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/family/7560d7758a3744f08a454a4de9d05344, entries=1025670, sequenceid=604, filesize=73.0m
2014-07-10 23:33:59,247 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~281.7m/295365360, currentsize=66.4m/69652560 for region usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c. in 16352ms, sequenceid=604, compaction requested=false
2014-07-10 23:33:59,247 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405060169521.e472980be441986b612f83054b0dc330., current region memstore size 541.4m
2014-07-10 23:33:59,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:00,200 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:34:00,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3766 synced till here 3755
2014-07-10 23:34:00,620 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060437653 with entries=113, filesize=86.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060439557
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405059825344
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060187865
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060190536
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060223989
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060226278
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060230545
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060263541
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060266085
2014-07-10 23:34:00,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060284386
2014-07-10 23:34:00,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060287307
2014-07-10 23:34:00,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060290071
2014-07-10 23:34:00,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060293254
2014-07-10 23:34:00,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060318373
2014-07-10 23:34:00,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060320822
2014-07-10 23:34:00,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060323237
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060325184
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060327240
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060346196
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060348490
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060357539
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060359280
2014-07-10 23:34:00,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060361330
2014-07-10 23:34:02,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:02,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3860 synced till here 3846
2014-07-10 23:34:02,601 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060439557 with entries=94, filesize=70.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060442072
2014-07-10 23:34:04,062 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:04,072 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=618, memsize=340.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/67bece0549ac4654921a327d51be22c4
2014-07-10 23:34:04,098 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/67bece0549ac4654921a327d51be22c4 as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/67bece0549ac4654921a327d51be22c4
2014-07-10 23:34:04,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3956 synced till here 3941
2014-07-10 23:34:04,210 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/67bece0549ac4654921a327d51be22c4, entries=1239390, sequenceid=618, filesize=88.3m
2014-07-10 23:34:04,210 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~340.4m/356933200, currentsize=270.6m/283733600 for region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. in 20272ms, sequenceid=618, compaction requested=true
2014-07-10 23:34:04,211 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-10 23:34:04,211 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., current region memstore size 467.4m
2014-07-10 23:34:04,236 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060442072 with entries=96, filesize=69.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060444062
2014-07-10 23:34:04,343 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:34:04,621 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:34:06,261 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:06,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4050 synced till here 4043
2014-07-10 23:34:06,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060444062 with entries=94, filesize=68.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060446261
2014-07-10 23:34:08,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:08,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4147 synced till here 4134
2014-07-10 23:34:08,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060446261 with entries=97, filesize=73.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060448435
2014-07-10 23:34:12,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:13,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4262 synced till here 4237
2014-07-10 23:34:13,572 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060448435 with entries=115, filesize=87.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060452861
2014-07-10 23:34:16,083 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:16,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4365 synced till here 4343
2014-07-10 23:34:16,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060452861 with entries=103, filesize=77.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060456083
2014-07-10 23:34:19,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:19,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4463 synced till here 4451
2014-07-10 23:34:19,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060456083 with entries=98, filesize=67.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060459266
2014-07-10 23:34:21,713 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:21,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060459266 with entries=88, filesize=61.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060461713
2014-07-10 23:34:24,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:24,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4654 synced till here 4630
2014-07-10 23:34:25,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060461713 with entries=103, filesize=80.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060464035
2014-07-10 23:34:26,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:26,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4747 synced till here 4732
2014-07-10 23:34:26,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060464035 with entries=93, filesize=70.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060466650
2014-07-10 23:34:28,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:29,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4853 synced till here 4833
2014-07-10 23:34:29,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060466650 with entries=106, filesize=76.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060468740
2014-07-10 23:34:30,662 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:30,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4945 synced till here 4943
2014-07-10 23:34:30,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060468740 with entries=92, filesize=64.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060470662
2014-07-10 23:34:33,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:33,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5030 synced till here 5029
2014-07-10 23:34:33,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060470662 with entries=85, filesize=62.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060473040
2014-07-10 23:34:34,995 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:35,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5115 synced till here 5110
2014-07-10 23:34:35,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060473040 with entries=85, filesize=63.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060474995
2014-07-10 23:34:36,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:36,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5199 synced till here 5198
2014-07-10 23:34:36,724 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060474995 with entries=84, filesize=61.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060476684
2014-07-10 23:34:38,558 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:38,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5292 synced till here 5284
2014-07-10 23:34:38,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060476684 with entries=93, filesize=69.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060478560
2014-07-10 23:34:40,038 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=749, memsize=542.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/1552ea18df694f62a1d501681e93b883
2014-07-10 23:34:40,050 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/1552ea18df694f62a1d501681e93b883 as hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/1552ea18df694f62a1d501681e93b883
2014-07-10 23:34:40,104 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/1552ea18df694f62a1d501681e93b883, entries=1976750, sequenceid=749, filesize=140.7m
2014-07-10 23:34:40,105 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~542.9m/569284800, currentsize=505.4m/529923600 for region usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. in 40858ms, sequenceid=749, compaction requested=true
2014-07-10 23:34:40,105 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 23:34:40,105 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., current region memstore size 885.2m
2014-07-10 23:34:40,117 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=804, memsize=467.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/869734f6047b4f2eb9af188c936b12bf
2014-07-10 23:34:40,126 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/869734f6047b4f2eb9af188c936b12bf as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/869734f6047b4f2eb9af188c936b12bf
2014-07-10 23:34:40,137 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/869734f6047b4f2eb9af188c936b12bf, entries=1701960, sequenceid=804, filesize=121.2m
2014-07-10 23:34:40,137 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~467.4m/490150240, currentsize=421.0m/441476240 for region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. in 35926ms, sequenceid=804, compaction requested=false
2014-07-10 23:34:40,138 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., current region memstore size 709.1m
2014-07-10 23:34:40,156 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:34:41,450 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:34:41,807 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:41,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5381 synced till here 5378
2014-07-10 23:34:41,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060478560 with entries=89, filesize=65.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060481807
2014-07-10 23:34:41,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060363733
2014-07-10 23:34:41,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060396885
2014-07-10 23:34:41,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060400812
2014-07-10 23:34:41,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060403508
2014-07-10 23:34:41,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060405169
2014-07-10 23:34:41,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060408565
2014-07-10 23:34:42,601 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:34:43,168 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:34:45,102 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:45,264 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5493 synced till here 5469
2014-07-10 23:34:46,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060481807 with entries=112, filesize=86.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060485103
2014-07-10 23:34:49,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:49,343 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5588 synced till here 5575
2014-07-10 23:34:50,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060485103 with entries=95, filesize=71.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060489212
2014-07-10 23:34:52,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:52,605 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5691 synced till here 5680
2014-07-10 23:34:52,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060489212 with entries=103, filesize=71.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060492495
2014-07-10 23:34:53,167 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/c9d130e538f14db0a3ee321805d75256 as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/c9d130e538f14db0a3ee321805d75256
2014-07-10 23:34:53,464 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Removing store files after compaction...
2014-07-10 23:34:53,481 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/4fff64d5374743ba9194a42bdd1d3134, to hdfs://master:54310/hbase/archive/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/4fff64d5374743ba9194a42bdd1d3134
2014-07-10 23:34:53,484 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/9b208fbbab3c4568a7ec1ff2fc2a7bd3, to hdfs://master:54310/hbase/archive/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/9b208fbbab3c4568a7ec1ff2fc2a7bd3
2014-07-10 23:34:53,486 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/3f7f6f07a6224bd6a97f2dc9e063961e, to hdfs://master:54310/hbase/archive/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/3f7f6f07a6224bd6a97f2dc9e063961e
2014-07-10 23:34:53,486 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. into c9d130e538f14db0a3ee321805d75256(size=200.7m), total size for store is 321.9m. This selection was in queue for 0sec, and took 1mins, 10sec to execute.
2014-07-10 23:34:53,486 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., storeName=family, fileCount=3, fileSize=200.8m, priority=17, time=14339287202780; duration=1mins, 10sec
2014-07-10 23:34:53,487 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 23:34:53,487 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-10 23:34:53,487 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 211430406 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-10 23:34:53,487 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: 5efb4c8cc936a019263d5b128583c6c6 - family: Initiating major compaction
2014-07-10 23:34:53,488 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:34:53,488 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp, totalSize=201.6m
2014-07-10 23:34:53,488 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/7b260b5536434f02adb1fc25f90a3c65, keycount=94456, bloomtype=ROW, size=67.3m, encoding=NONE, seqNum=169, earliestPutTs=1405060186033
2014-07-10 23:34:53,488 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/05c283e1e22c4f5bacf209ed38664686, keycount=94077, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=336, earliestPutTs=1405060289049
2014-07-10 23:34:53,488 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/c5acba37922249c388d9d26958f50601, keycount=94462, bloomtype=ROW, size=67.3m, encoding=NONE, seqNum=504, earliestPutTs=1405060357705
2014-07-10 23:34:53,733 DEBUG [regionserver60020-smallCompactions-1405059830600] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:34:54,796 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:34:54,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:54,926 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060492495 with entries=90, filesize=62.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060494896
2014-07-10 23:34:58,628 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:34:58,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5869 synced till here 5861
2014-07-10 23:34:58,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060494896 with entries=88, filesize=68.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060498628
2014-07-10 23:35:37,950 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 42326ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 23:35:37,950 WARN  [regionserver60020] util.Sleeper: We slept 37207ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 23:35:37,950 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 42323ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-10 23:35:38,072 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:35:38,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5962 synced till here 5955
2014-07-10 23:35:38,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060498628 with entries=93, filesize=70.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060538072
2014-07-10 23:35:38,341 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 36157ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=36585ms
2014-07-10 23:35:38,585 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39146,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499317,"queuetimems":5,"class":"HRegionServer","responsesize":16987,"method":"Multi"}
2014-07-10 23:35:38,587 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499141,"queuetimems":0,"class":"HRegionServer","responsesize":17042,"method":"Multi"}
2014-07-10 23:35:38,589 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060498797,"queuetimems":1,"class":"HRegionServer","responsesize":17149,"method":"Multi"}
2014-07-10 23:35:38,592 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39461,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060498619,"queuetimems":3,"class":"HRegionServer","responsesize":17049,"method":"Multi"}
2014-07-10 23:35:38,592 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39461,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060498983,"queuetimems":0,"class":"HRegionServer","responsesize":16946,"method":"Multi"}
2014-07-10 23:35:38,596 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39132,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060498948,"queuetimems":3,"class":"HRegionServer","responsesize":17247,"method":"Multi"}
2014-07-10 23:35:38,600 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39354,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499090,"queuetimems":0,"class":"HRegionServer","responsesize":16685,"method":"Multi"}
2014-07-10 23:35:38,618 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39074,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499543,"queuetimems":1,"class":"HRegionServer","responsesize":17003,"method":"Multi"}
2014-07-10 23:35:39,070 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39489,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499580,"queuetimems":0,"class":"HRegionServer","responsesize":16648,"method":"Multi"}
2014-07-10 23:35:39,070 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39268,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499801,"queuetimems":4,"class":"HRegionServer","responsesize":17161,"method":"Multi"}
2014-07-10 23:35:39,070 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39224,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060499845,"queuetimems":1,"class":"HRegionServer","responsesize":17019,"method":"Multi"}
2014-07-10 23:35:39,121 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39018,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060500102,"queuetimems":0,"class":"HRegionServer","responsesize":16625,"method":"Multi"}
2014-07-10 23:35:39,122 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060500920,"queuetimems":0,"class":"HRegionServer","responsesize":16903,"method":"Multi"}
2014-07-10 23:35:39,123 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38656,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060500467,"queuetimems":1,"class":"HRegionServer","responsesize":16418,"method":"Multi"}
2014-07-10 23:35:39,125 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38381,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060500743,"queuetimems":1,"class":"HRegionServer","responsesize":17220,"method":"Multi"}
2014-07-10 23:35:39,125 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":38335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060500784,"queuetimems":0,"class":"HRegionServer","responsesize":17232,"method":"Multi"}
2014-07-10 23:35:39,149 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":39056,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060500070,"queuetimems":0,"class":"HRegionServer","responsesize":17175,"method":"Multi"}
2014-07-10 23:35:39,149 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":37996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060501129,"queuetimems":0,"class":"HRegionServer","responsesize":16596,"method":"Multi"}
2014-07-10 23:35:43,633 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2790ms
GC pool 'ParNew' had collection(s): count=1 time=3152ms
2014-07-10 23:35:43,664 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:35:43,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6061 synced till here 6048
2014-07-10 23:35:43,756 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42435,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060501320,"queuetimems":0,"class":"HRegionServer","responsesize":16958,"method":"Multi"}
2014-07-10 23:35:43,758 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":42590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060501165,"queuetimems":1,"class":"HRegionServer","responsesize":17003,"method":"Multi"}
2014-07-10 23:35:43,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060538072 with entries=99, filesize=74.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060543665
2014-07-10 23:35:48,413 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2278ms
GC pool 'ParNew' had collection(s): count=1 time=2767ms
2014-07-10 23:35:48,524 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:35:48,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6175 synced till here 6153
2014-07-10 23:35:48,893 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060543665 with entries=114, filesize=84.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060548524
2014-07-10 23:35:52,478 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2564ms
GC pool 'ParNew' had collection(s): count=1 time=2972ms
2014-07-10 23:35:52,754 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:35:52,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6283 synced till here 6264
2014-07-10 23:35:52,910 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060548524 with entries=108, filesize=78.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060552754
2014-07-10 23:35:53,483 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,484 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,504 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,504 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,504 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,504 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,505 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,505 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,505 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,505 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,506 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,506 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,514 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,537 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,540 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,540 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,540 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:53,540 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:54,143 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:54,215 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:55,974 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1494ms
GC pool 'ParNew' had collection(s): count=1 time=1687ms
2014-07-10 23:35:55,976 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:55,987 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,004 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,036 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,068 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,104 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,134 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,166 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,198 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,230 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,262 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,292 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,323 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:56,354 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:35:58,484 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:35:58,504 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5021ms
2014-07-10 23:35:58,505 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5021ms
2014-07-10 23:35:58,505 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5022ms
2014-07-10 23:35:58,505 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-10 23:35:58,505 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:35:58,506 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5022ms
2014-07-10 23:35:58,506 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5022ms
2014-07-10 23:35:58,506 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5023ms
2014-07-10 23:35:58,506 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5022ms
2014-07-10 23:35:58,506 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:35:58,506 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:35:58,514 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:35:58,538 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:35:58,540 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:35:58,540 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:35:58,540 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:35:58,541 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:35:59,144 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:35:59,215 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:00,976 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:00,988 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,004 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,036 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,069 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:01,105 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:01,134 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,166 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:01,198 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,231 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,262 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:01,293 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,324 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:01,355 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:03,485 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:03,504 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10021ms
2014-07-10 23:36:03,505 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10022ms
2014-07-10 23:36:03,505 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:03,506 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:03,506 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10023ms
2014-07-10 23:36:03,507 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10022ms
2014-07-10 23:36:03,507 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:03,507 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10024ms
2014-07-10 23:36:03,507 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10023ms
2014-07-10 23:36:03,507 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10024ms
2014-07-10 23:36:03,508 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:03,515 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:36:03,538 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:03,541 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:03,541 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:03,542 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:03,542 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:04,144 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:04,216 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:05,976 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:05,988 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,005 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,037 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,069 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,106 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:06,135 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,166 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,199 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,231 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,262 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,293 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,324 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:06,355 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:08,485 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:08,505 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15022ms
2014-07-10 23:36:08,506 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15023ms
2014-07-10 23:36:08,506 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:08,506 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-10 23:36:08,507 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15024ms
2014-07-10 23:36:08,507 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15023ms
2014-07-10 23:36:08,507 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:08,507 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15024ms
2014-07-10 23:36:08,508 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15024ms
2014-07-10 23:36:08,508 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15025ms
2014-07-10 23:36:08,508 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:08,516 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:08,538 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:08,541 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:08,541 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:08,542 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:08,543 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:09,145 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:09,216 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:10,977 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:10,988 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,006 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:11,037 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,069 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,106 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:11,135 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,166 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,199 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,231 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,263 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:11,293 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,324 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:36:11,356 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:36:12,555 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1075, memsize=709.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/648aea90055248b8ab08acdc4be78df0
2014-07-10 23:36:12,566 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/648aea90055248b8ab08acdc4be78df0 as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/648aea90055248b8ab08acdc4be78df0
2014-07-10 23:36:12,607 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/648aea90055248b8ab08acdc4be78df0, entries=2581800, sequenceid=1075, filesize=183.7m
2014-07-10 23:36:12,608 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~709.1m/743537920, currentsize=313.3m/328550720 for region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. in 92470ms, sequenceid=1075, compaction requested=true
2014-07-10 23:36:12,612 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 23:36:12,612 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16258ms
2014-07-10 23:36:12,612 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., current region memstore size 742.7m
2014-07-10 23:36:12,612 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,612 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16289ms
2014-07-10 23:36:12,612 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,613 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16321ms
2014-07-10 23:36:12,613 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,613 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16352ms
2014-07-10 23:36:12,613 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,615 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16385ms
2014-07-10 23:36:12,615 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,622 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16424ms
2014-07-10 23:36:12,622 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,622 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16457ms
2014-07-10 23:36:12,622 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,622 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16488ms
2014-07-10 23:36:12,622 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,623 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16519ms
2014-07-10 23:36:12,623 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,624 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16556ms
2014-07-10 23:36:12,624 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,624 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16588ms
2014-07-10 23:36:12,624 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,624 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16620ms
2014-07-10 23:36:12,624 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,625 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16638ms
2014-07-10 23:36:12,625 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,625 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16650ms
2014-07-10 23:36:12,625 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,628 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18412ms
2014-07-10 23:36:12,628 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,628 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18485ms
2014-07-10 23:36:12,628 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,628 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19088ms
2014-07-10 23:36:12,628 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,633 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19093ms
2014-07-10 23:36:12,633 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,633 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19093ms
2014-07-10 23:36:12,633 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,640 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19101ms
2014-07-10 23:36:12,641 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,641 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19104ms
2014-07-10 23:36:12,641 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,641 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19127ms
2014-07-10 23:36:12,641 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,645 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19139ms
2014-07-10 23:36:12,645 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,645 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19162ms
2014-07-10 23:36:12,645 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,646 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19161ms
2014-07-10 23:36:12,646 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,646 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19163ms
2014-07-10 23:36:12,646 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,646 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19140ms
2014-07-10 23:36:12,647 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,652 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19168ms
2014-07-10 23:36:12,652 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,652 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19169ms
2014-07-10 23:36:12,652 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,653 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19149ms
2014-07-10 23:36:12,653 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,660 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19156ms
2014-07-10 23:36:12,660 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,660 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19177ms
2014-07-10 23:36:12,660 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,664 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060549450,"queuetimems":0,"class":"HRegionServer","responsesize":16998,"method":"Multi"}
2014-07-10 23:36:12,665 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19182ms
2014-07-10 23:36:12,665 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,673 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19190ms
2014-07-10 23:36:12,673 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:12,741 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20178,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552545,"queuetimems":1,"class":"HRegionServer","responsesize":17135,"method":"Multi"}
2014-07-10 23:36:12,750 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:36:13,035 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:13,604 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552810,"queuetimems":0,"class":"HRegionServer","responsesize":16879,"method":"Multi"}
2014-07-10 23:36:13,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6396 synced till here 6389
2014-07-10 23:36:13,686 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21205,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552481,"queuetimems":1,"class":"HRegionServer","responsesize":16913,"method":"Multi"}
2014-07-10 23:36:13,687 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20985,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552702,"queuetimems":1,"class":"HRegionServer","responsesize":17005,"method":"Multi"}
2014-07-10 23:36:13,687 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552639,"queuetimems":1,"class":"HRegionServer","responsesize":17115,"method":"Multi"}
2014-07-10 23:36:13,688 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20955,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552732,"queuetimems":0,"class":"HRegionServer","responsesize":16826,"method":"Multi"}
2014-07-10 23:36:13,689 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20826,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552862,"queuetimems":1,"class":"HRegionServer","responsesize":17020,"method":"Multi"}
2014-07-10 23:36:13,690 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060553074,"queuetimems":1,"class":"HRegionServer","responsesize":16445,"method":"Multi"}
2014-07-10 23:36:13,690 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21114,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552576,"queuetimems":1,"class":"HRegionServer","responsesize":16853,"method":"Multi"}
2014-07-10 23:36:13,689 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21195,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552494,"queuetimems":0,"class":"HRegionServer","responsesize":16966,"method":"Multi"}
2014-07-10 23:36:13,691 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21082,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552607,"queuetimems":0,"class":"HRegionServer","responsesize":17104,"method":"Multi"}
2014-07-10 23:36:13,698 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21178,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552511,"queuetimems":0,"class":"HRegionServer","responsesize":17021,"method":"Multi"}
2014-07-10 23:36:13,698 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21016,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552670,"queuetimems":1,"class":"HRegionServer","responsesize":16902,"method":"Multi"}
2014-07-10 23:36:13,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060552754 with entries=113, filesize=81.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060573036
2014-07-10 23:36:13,862 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:36:13,990 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20971,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060553019,"queuetimems":1,"class":"HRegionServer","responsesize":16881,"method":"Multi"}
2014-07-10 23:36:13,990 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21036,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060552954,"queuetimems":0,"class":"HRegionServer","responsesize":17001,"method":"Multi"}
2014-07-10 23:36:14,276 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060553205,"queuetimems":1,"class":"HRegionServer","responsesize":16600,"method":"Multi"}
2014-07-10 23:36:14,278 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21150,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060553127,"queuetimems":1,"class":"HRegionServer","responsesize":17467,"method":"Multi"}
2014-07-10 23:36:14,305 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17952,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556353,"queuetimems":0,"class":"HRegionServer","responsesize":16962,"method":"Multi"}
2014-07-10 23:36:14,306 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18304,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556002,"queuetimems":0,"class":"HRegionServer","responsesize":16964,"method":"Multi"}
2014-07-10 23:36:14,364 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556290,"queuetimems":0,"class":"HRegionServer","responsesize":16978,"method":"Multi"}
2014-07-10 23:36:14,402 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556132,"queuetimems":1,"class":"HRegionServer","responsesize":16857,"method":"Multi"}
2014-07-10 23:36:14,402 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556322,"queuetimems":1,"class":"HRegionServer","responsesize":16996,"method":"Multi"}
2014-07-10 23:36:14,402 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556101,"queuetimems":1,"class":"HRegionServer","responsesize":17007,"method":"Multi"}
2014-07-10 23:36:14,466 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:14,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6498 synced till here 6481
2014-07-10 23:36:14,543 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18378,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556164,"queuetimems":1,"class":"HRegionServer","responsesize":17032,"method":"Multi"}
2014-07-10 23:36:17,798 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3234ms
GC pool 'ParNew' had collection(s): count=1 time=3241ms
2014-07-10 23:36:17,828 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21568,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556259,"queuetimems":0,"class":"HRegionServer","responsesize":16867,"method":"Multi"}
2014-07-10 23:36:17,828 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556196,"queuetimems":0,"class":"HRegionServer","responsesize":16991,"method":"Multi"}
2014-07-10 23:36:17,828 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23687,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060554140,"queuetimems":1,"class":"HRegionServer","responsesize":16951,"method":"Multi"}
2014-07-10 23:36:17,828 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21760,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556067,"queuetimems":1,"class":"HRegionServer","responsesize":17009,"method":"Multi"}
2014-07-10 23:36:17,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060573036 with entries=102, filesize=77.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060574466
2014-07-10 23:36:17,931 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556228,"queuetimems":0,"class":"HRegionServer","responsesize":17188,"method":"Multi"}
2014-07-10 23:36:17,931 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060554276,"queuetimems":0,"class":"HRegionServer","responsesize":16956,"method":"Multi"}
2014-07-10 23:36:18,036 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22001,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060556034,"queuetimems":0,"class":"HRegionServer","responsesize":17610,"method":"Multi"}
2014-07-10 23:36:18,036 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22050,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060555985,"queuetimems":0,"class":"HRegionServer","responsesize":17275,"method":"Multi"}
2014-07-10 23:36:18,036 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060554212,"queuetimems":0,"class":"HRegionServer","responsesize":17064,"method":"Multi"}
2014-07-10 23:36:18,696 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:18,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060574466 with entries=90, filesize=62.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060578697
2014-07-10 23:36:20,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:21,003 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6680 synced till here 6673
2014-07-10 23:36:21,051 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060578697 with entries=92, filesize=68.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060580942
2014-07-10 23:36:22,821 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1175ms
GC pool 'ParNew' had collection(s): count=1 time=1634ms
2014-07-10 23:36:23,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:23,490 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6766 synced till here 6765
2014-07-10 23:36:23,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060580942 with entries=86, filesize=63.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060583447
2014-07-10 23:36:24,511 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/f48a665d55234a8f837cc9c617bd038c as hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/f48a665d55234a8f837cc9c617bd038c
2014-07-10 23:36:24,532 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Removing store files after compaction...
2014-07-10 23:36:24,537 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/7b260b5536434f02adb1fc25f90a3c65, to hdfs://master:54310/hbase/archive/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/7b260b5536434f02adb1fc25f90a3c65
2014-07-10 23:36:24,540 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/05c283e1e22c4f5bacf209ed38664686, to hdfs://master:54310/hbase/archive/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/05c283e1e22c4f5bacf209ed38664686
2014-07-10 23:36:25,638 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/c5acba37922249c388d9d26958f50601, to hdfs://master:54310/hbase/archive/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/c5acba37922249c388d9d26958f50601
2014-07-10 23:36:25,639 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. into f48a665d55234a8f837cc9c617bd038c(size=201.5m), total size for store is 201.5m. This selection was in queue for 0sec, and took 1mins, 32sec to execute.
2014-07-10 23:36:25,640 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., storeName=family, fileCount=3, fileSize=201.6m, priority=17, time=14409878656894; duration=1mins, 32sec
2014-07-10 23:36:25,640 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 23:36:25,640 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 23:36:25,640 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 451946207 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-10 23:36:25,641 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: a17619b4327f9b5610de972e6da3dce2 - family: Initiating major compaction
2014-07-10 23:36:25,641 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:36:25,641 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp, totalSize=431.0m
2014-07-10 23:36:25,641 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/d380c19503e1496d9eaa08fe7243f3df, keycount=113125, bloomtype=ROW, size=80.6m, encoding=NONE, seqNum=202, earliestPutTs=1405060186788
2014-07-10 23:36:25,641 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/8af8d41e4c5a436e98bf4c661fa4e217, keycount=110194, bloomtype=ROW, size=78.4m, encoding=NONE, seqNum=398, earliestPutTs=1405060317313
2014-07-10 23:36:25,642 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/67bece0549ac4654921a327d51be22c4, keycount=123939, bloomtype=ROW, size=88.3m, encoding=NONE, seqNum=618, earliestPutTs=1405060396331
2014-07-10 23:36:25,642 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/648aea90055248b8ab08acdc4be78df0, keycount=258180, bloomtype=ROW, size=183.7m, encoding=NONE, seqNum=1075, earliestPutTs=1405060423941
2014-07-10 23:36:25,797 DEBUG [regionserver60020-smallCompactions-1405059830600] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:36:26,101 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1075, memsize=885.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/87e1fce1d58f4e39b027b2a31c4e0c0f
2014-07-10 23:36:26,154 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/87e1fce1d58f4e39b027b2a31c4e0c0f as hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/87e1fce1d58f4e39b027b2a31c4e0c0f
2014-07-10 23:36:26,183 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/87e1fce1d58f4e39b027b2a31c4e0c0f, entries=3222980, sequenceid=1075, filesize=229.3m
2014-07-10 23:36:26,184 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~885.2m/928192000, currentsize=464.7m/487299520 for region usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. in 106079ms, sequenceid=1075, compaction requested=false
2014-07-10 23:36:26,184 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405060169521.e472980be441986b612f83054b0dc330., current region memstore size 964.1m
2014-07-10 23:36:26,187 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:36:26,258 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:26,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6857 synced till here 6849
2014-07-10 23:36:26,351 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060583447 with entries=91, filesize=68.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060586258
2014-07-10 23:36:26,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060410444
2014-07-10 23:36:26,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060412713
2014-07-10 23:36:26,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060414248
2014-07-10 23:36:26,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060416998
2014-07-10 23:36:26,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060419779
2014-07-10 23:36:26,440 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:28,225 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:36:28,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:28,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6960 synced till here 6959
2014-07-10 23:36:28,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060586258 with entries=103, filesize=73.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060588296
2014-07-10 23:36:28,827 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:30,738 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1439ms
GC pool 'ParNew' had collection(s): count=1 time=1778ms
2014-07-10 23:36:31,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:31,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7050 synced till here 7037
2014-07-10 23:36:31,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060588296 with entries=90, filesize=67.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060591272
2014-07-10 23:36:31,338 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:32,891 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:32,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7140 synced till here 7136
2014-07-10 23:36:32,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060591272 with entries=90, filesize=66.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060592891
2014-07-10 23:36:32,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:34,756 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:34,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7227 synced till here 7224
2014-07-10 23:36:34,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060592891 with entries=87, filesize=63.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060594757
2014-07-10 23:36:34,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:36,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:36,994 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060594757 with entries=86, filesize=61.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060596970
2014-07-10 23:36:36,995 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:38,852 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:39,127 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7424 synced till here 7422
2014-07-10 23:36:39,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060596970 with entries=111, filesize=83.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060598853
2014-07-10 23:36:39,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:40,639 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:40,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7523 synced till here 7519
2014-07-10 23:36:40,923 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060598853 with entries=99, filesize=73.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060600640
2014-07-10 23:36:40,924 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): 2f8b7bbfe3f11e72550880324064a38c
2014-07-10 23:36:40,988 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:40,989 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:40,990 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:40,990 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:40,990 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:40,990 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:40,991 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,021 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,021 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,022 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,022 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,023 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,041 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,063 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,119 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,170 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,247 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,299 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:41,355 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:42,619 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:42,761 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:42,821 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:42,869 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:42,915 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:42,955 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:43,010 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:43,069 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:43,102 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:44,160 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:44,274 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:44,321 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:44,505 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:36:45,989 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:45,990 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-10 23:36:45,990 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:45,990 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:45,991 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:45,991 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:45,992 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,021 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,021 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,022 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:46,022 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,024 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:46,042 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,063 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,120 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:46,170 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,247 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:46,300 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:46,356 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:47,716 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5097ms
2014-07-10 23:36:47,762 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:47,821 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:47,869 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:47,915 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:47,956 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:48,011 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:48,069 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:48,102 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:49,160 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:36:49,274 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:49,321 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:49,506 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:36:50,990 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:50,990 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:50,990 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:36:50,991 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:50,991 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:50,992 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:50,992 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,021 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:36:51,022 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,022 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,023 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:36:51,024 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,042 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,064 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,120 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:36:51,171 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,247 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:36:51,300 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:51,356 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:52,717 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10098ms
2014-07-10 23:36:52,762 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:52,822 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:36:52,870 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:52,915 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:52,956 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:52,959 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1284, memsize=742.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/1fe578a0e1674ea8a7928be1d18857e1
2014-07-10 23:36:52,970 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/1fe578a0e1674ea8a7928be1d18857e1 as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/1fe578a0e1674ea8a7928be1d18857e1
2014-07-10 23:36:52,992 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/1fe578a0e1674ea8a7928be1d18857e1, entries=2704070, sequenceid=1284, filesize=192.4m
2014-07-10 23:36:52,992 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~742.7m/778752000, currentsize=366.2m/384022160 for region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. in 40380ms, sequenceid=1284, compaction requested=true
2014-07-10 23:36:52,993 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-10 23:36:52,993 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10038ms
2014-07-10 23:36:52,993 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:52,993 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10079ms
2014-07-10 23:36:52,993 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:52,993 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c., current region memstore size 420.9m
2014-07-10 23:36:52,993 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10124ms
2014-07-10 23:36:52,993 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:52,994 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10173ms
2014-07-10 23:36:52,994 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:52,994 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10233ms
2014-07-10 23:36:52,994 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,002 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10383ms
2014-07-10 23:36:53,002 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,002 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11647ms
2014-07-10 23:36:53,002 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,003 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11703ms
2014-07-10 23:36:53,003 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,003 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11756ms
2014-07-10 23:36:53,003 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,003 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11833ms
2014-07-10 23:36:53,003 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,003 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11885ms
2014-07-10 23:36:53,003 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,005 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11942ms
2014-07-10 23:36:53,005 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,011 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:36:53,011 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,013 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11972ms
2014-07-10 23:36:53,013 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,016 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11992ms
2014-07-10 23:36:53,016 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,016 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11994ms
2014-07-10 23:36:53,016 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,016 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11995ms
2014-07-10 23:36:53,016 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,017 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11996ms
2014-07-10 23:36:53,017 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,021 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12000ms
2014-07-10 23:36:53,021 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,033 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12042ms
2014-07-10 23:36:53,033 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,037 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12047ms
2014-07-10 23:36:53,037 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,037 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12047ms
2014-07-10 23:36:53,037 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,037 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12047ms
2014-07-10 23:36:53,037 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,038 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12048ms
2014-07-10 23:36:53,039 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,039 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12051ms
2014-07-10 23:36:53,039 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,039 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12051ms
2014-07-10 23:36:53,039 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,040 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8535ms
2014-07-10 23:36:53,040 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,042 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8721ms
2014-07-10 23:36:53,042 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,043 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8768ms
2014-07-10 23:36:53,043 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,053 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8893ms
2014-07-10 23:36:53,053 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,053 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9951ms
2014-07-10 23:36:53,053 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,056 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9987ms
2014-07-10 23:36:53,056 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:36:53,063 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12558,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600503,"queuetimems":1,"class":"HRegionServer","responsesize":17127,"method":"Multi"}
2014-07-10 23:36:53,063 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600470,"queuetimems":0,"class":"HRegionServer","responsesize":16781,"method":"Multi"}
2014-07-10 23:36:53,451 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799.
2014-07-10 23:36:53,505 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12930,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600575,"queuetimems":1,"class":"HRegionServer","responsesize":17191,"method":"Multi"}
2014-07-10 23:36:53,507 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12969,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600537,"queuetimems":0,"class":"HRegionServer","responsesize":16990,"method":"Multi"}
2014-07-10 23:36:53,764 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:36:53,794 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13181,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600612,"queuetimems":1,"class":"HRegionServer","responsesize":16878,"method":"Multi"}
2014-07-10 23:36:53,794 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13133,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600660,"queuetimems":0,"class":"HRegionServer","responsesize":17008,"method":"Multi"}
2014-07-10 23:36:53,795 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600710,"queuetimems":0,"class":"HRegionServer","responsesize":16766,"method":"Multi"}
2014-07-10 23:36:54,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:54,123 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7621 synced till here 7608
2014-07-10 23:36:54,218 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13277,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600940,"queuetimems":1,"class":"HRegionServer","responsesize":16794,"method":"Multi"}
2014-07-10 23:36:54,218 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13334,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600884,"queuetimems":0,"class":"HRegionServer","responsesize":17386,"method":"Multi"}
2014-07-10 23:36:54,220 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13391,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600826,"queuetimems":0,"class":"HRegionServer","responsesize":17104,"method":"Multi"}
2014-07-10 23:36:54,225 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13452,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600772,"queuetimems":0,"class":"HRegionServer","responsesize":16689,"method":"Multi"}
2014-07-10 23:36:54,225 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11271,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060602953,"queuetimems":0,"class":"HRegionServer","responsesize":16902,"method":"Multi"}
2014-07-10 23:36:54,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060600640 with entries=98, filesize=74.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060614084
2014-07-10 23:36:55,735 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12821,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060602913,"queuetimems":1,"class":"HRegionServer","responsesize":17152,"method":"Multi"}
2014-07-10 23:36:55,774 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13014,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060602759,"queuetimems":0,"class":"HRegionServer","responsesize":16688,"method":"Multi"}
2014-07-10 23:36:56,181 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:56,182 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601062,"queuetimems":0,"class":"HRegionServer","responsesize":8051,"method":"Multi"}
2014-07-10 23:36:56,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7731 synced till here 7700
2014-07-10 23:36:56,312 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15016,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601296,"queuetimems":0,"class":"HRegionServer","responsesize":17022,"method":"Multi"}
2014-07-10 23:36:56,313 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14961,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601352,"queuetimems":1,"class":"HRegionServer","responsesize":17157,"method":"Multi"}
2014-07-10 23:36:56,313 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601168,"queuetimems":1,"class":"HRegionServer","responsesize":16944,"method":"Multi"}
2014-07-10 23:36:56,314 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13447,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060602867,"queuetimems":0,"class":"HRegionServer","responsesize":16930,"method":"Multi"}
2014-07-10 23:36:56,315 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060602819,"queuetimems":1,"class":"HRegionServer","responsesize":16971,"method":"Multi"}
2014-07-10 23:36:56,315 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060600989,"queuetimems":0,"class":"HRegionServer","responsesize":17184,"method":"Multi"}
2014-07-10 23:36:56,316 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15200,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601116,"queuetimems":0,"class":"HRegionServer","responsesize":16932,"method":"Multi"}
2014-07-10 23:36:56,317 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060604502,"queuetimems":1,"class":"HRegionServer","responsesize":17011,"method":"Multi"}
2014-07-10 23:36:56,317 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15278,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601039,"queuetimems":0,"class":"HRegionServer","responsesize":16858,"method":"Multi"}
2014-07-10 23:36:56,317 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13217,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060603100,"queuetimems":0,"class":"HRegionServer","responsesize":17278,"method":"Multi"}
2014-07-10 23:36:56,318 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13309,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060603008,"queuetimems":0,"class":"HRegionServer","responsesize":17183,"method":"Multi"}
2014-07-10 23:36:56,317 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060604156,"queuetimems":0,"class":"HRegionServer","responsesize":16699,"method":"Multi"}
2014-07-10 23:36:56,318 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12000,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060604317,"queuetimems":0,"class":"HRegionServer","responsesize":17172,"method":"Multi"}
2014-07-10 23:36:56,378 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15132,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060601245,"queuetimems":1,"class":"HRegionServer","responsesize":16681,"method":"Multi"}
2014-07-10 23:36:56,378 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13761,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060602616,"queuetimems":1,"class":"HRegionServer","responsesize":17198,"method":"Multi"}
2014-07-10 23:36:56,380 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060603067,"queuetimems":0,"class":"HRegionServer","responsesize":17085,"method":"Multi"}
2014-07-10 23:36:56,382 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060604269,"queuetimems":1,"class":"HRegionServer","responsesize":17250,"method":"Multi"}
2014-07-10 23:36:56,467 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060614084 with entries=110, filesize=78.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060616181
2014-07-10 23:36:58,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:36:58,571 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7821 synced till here 7820
2014-07-10 23:36:58,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060616181 with entries=90, filesize=62.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060618544
2014-07-10 23:37:00,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:00,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7908 synced till here 7905
2014-07-10 23:37:00,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060618544 with entries=87, filesize=65.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060620373
2014-07-10 23:37:02,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:02,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7994 synced till here 7993
2014-07-10 23:37:02,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060620373 with entries=86, filesize=63.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060622423
2014-07-10 23:37:04,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:04,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8082 synced till here 8080
2014-07-10 23:37:04,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060622423 with entries=88, filesize=64.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060624292
2014-07-10 23:37:04,464 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,465 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,465 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,467 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,467 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,468 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,476 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,490 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,502 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,539 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,577 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,626 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,676 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,709 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,746 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,800 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,835 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,870 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,907 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,946 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:04,978 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,012 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,073 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,123 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,165 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,197 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,233 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,268 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,301 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,336 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,366 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,399 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,432 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,465 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,495 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,555 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:05,597 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:09,464 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,465 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,466 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,467 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,467 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,469 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,476 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,491 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,502 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,539 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,577 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,626 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,676 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,709 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,746 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,801 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,835 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,870 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:09,908 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,947 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:09,978 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,013 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,073 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:10,123 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,165 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,197 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,233 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,268 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,301 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,337 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:10,366 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,399 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,432 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,465 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:10,496 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:10,556 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:10,597 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:13,429 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1372, memsize=967.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/c79b51b4b7ba44a98f7b245cb235e717
2014-07-10 23:37:13,441 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/c79b51b4b7ba44a98f7b245cb235e717 as hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/c79b51b4b7ba44a98f7b245cb235e717
2014-07-10 23:37:13,461 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/c79b51b4b7ba44a98f7b245cb235e717, entries=3521840, sequenceid=1372, filesize=250.6m
2014-07-10 23:37:13,462 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~967.3m/1014265280, currentsize=383.7m/402328240 for region usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. in 47278ms, sequenceid=1372, compaction requested=true
2014-07-10 23:37:13,462 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-10 23:37:13,462 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7865ms
2014-07-10 23:37:13,462 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,462 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., current region memstore size 850.3m
2014-07-10 23:37:13,462 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7907ms
2014-07-10 23:37:13,462 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,463 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7968ms
2014-07-10 23:37:13,463 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,464 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7998ms
2014-07-10 23:37:13,465 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,465 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8033ms
2014-07-10 23:37:13,465 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,467 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8068ms
2014-07-10 23:37:13,467 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,468 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8102ms
2014-07-10 23:37:13,468 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,468 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8132ms
2014-07-10 23:37:13,468 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,468 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8167ms
2014-07-10 23:37:13,468 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,469 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8201ms
2014-07-10 23:37:13,469 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,473 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8240ms
2014-07-10 23:37:13,473 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,475 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8278ms
2014-07-10 23:37:13,475 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,475 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8310ms
2014-07-10 23:37:13,476 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,476 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8353ms
2014-07-10 23:37:13,476 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,480 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8408ms
2014-07-10 23:37:13,480 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,482 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8470ms
2014-07-10 23:37:13,482 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,483 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8505ms
2014-07-10 23:37:13,484 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,484 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8538ms
2014-07-10 23:37:13,484 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,484 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8577ms
2014-07-10 23:37:13,484 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,484 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8614ms
2014-07-10 23:37:13,484 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,488 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8652ms
2014-07-10 23:37:13,488 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,488 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8688ms
2014-07-10 23:37:13,488 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,490 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8743ms
2014-07-10 23:37:13,490 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,491 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8781ms
2014-07-10 23:37:13,491 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,491 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8815ms
2014-07-10 23:37:13,491 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,491 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8865ms
2014-07-10 23:37:13,491 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,493 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8916ms
2014-07-10 23:37:13,494 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,496 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8956ms
2014-07-10 23:37:13,496 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,496 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8994ms
2014-07-10 23:37:13,496 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,497 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9007ms
2014-07-10 23:37:13,497 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,497 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9021ms
2014-07-10 23:37:13,497 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,501 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9033ms
2014-07-10 23:37:13,501 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,504 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9037ms
2014-07-10 23:37:13,504 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,505 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9037ms
2014-07-10 23:37:13,505 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,505 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9040ms
2014-07-10 23:37:13,505 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,507 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9042ms
2014-07-10 23:37:13,507 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,509 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9046ms
2014-07-10 23:37:13,509 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:13,540 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10509,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060623031,"queuetimems":0,"class":"HRegionServer","responsesize":16995,"method":"Multi"}
2014-07-10 23:37:13,597 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1505, memsize=420.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/.tmp/eea914acc3644323be1018308b2932ff
2014-07-10 23:37:13,607 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/.tmp/eea914acc3644323be1018308b2932ff as hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/family/eea914acc3644323be1018308b2932ff
2014-07-10 23:37:13,630 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:37:13,637 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f8b7bbfe3f11e72550880324064a38c/family/eea914acc3644323be1018308b2932ff, entries=1532740, sequenceid=1505, filesize=109.0m
2014-07-10 23:37:13,638 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~420.9m/441388320, currentsize=52.5m/55049520 for region usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c. in 20645ms, sequenceid=1505, compaction requested=false
2014-07-10 23:37:13,638 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., current region memstore size 857.1m
2014-07-10 23:37:13,717 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060623110,"queuetimems":0,"class":"HRegionServer","responsesize":17393,"method":"Multi"}
2014-07-10 23:37:13,722 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10649,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060623072,"queuetimems":1,"class":"HRegionServer","responsesize":16642,"method":"Multi"}
2014-07-10 23:37:14,144 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:37:14,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:14,267 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8174 synced till here 8160
2014-07-10 23:37:14,417 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:37:14,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060624292 with entries=92, filesize=73.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060634252
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060421974
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060423679
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060425924
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060427942
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060429910
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060433239
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060435179
2014-07-10 23:37:14,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060437653
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060439557
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060442072
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060444062
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060446261
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060448435
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060452861
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060456083
2014-07-10 23:37:14,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060459266
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060461713
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060464035
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060466650
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060468740
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060470662
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060473040
2014-07-10 23:37:14,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060474995
2014-07-10 23:37:14,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060476684
2014-07-10 23:37:16,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:16,144 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10748,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625396,"queuetimems":0,"class":"HRegionServer","responsesize":17136,"method":"Multi"}
2014-07-10 23:37:16,154 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11667,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624486,"queuetimems":0,"class":"HRegionServer","responsesize":17091,"method":"Multi"}
2014-07-10 23:37:16,154 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11085,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625068,"queuetimems":1,"class":"HRegionServer","responsesize":16888,"method":"Multi"}
2014-07-10 23:37:16,154 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624623,"queuetimems":1,"class":"HRegionServer","responsesize":17032,"method":"Multi"}
2014-07-10 23:37:16,154 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10888,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625266,"queuetimems":1,"class":"HRegionServer","responsesize":17125,"method":"Multi"}
2014-07-10 23:37:16,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8272 synced till here 8261
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11367,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624833,"queuetimems":1,"class":"HRegionServer","responsesize":17142,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624744,"queuetimems":1,"class":"HRegionServer","responsesize":17051,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10867,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625333,"queuetimems":1,"class":"HRegionServer","responsesize":17005,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11257,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624944,"queuetimems":0,"class":"HRegionServer","responsesize":16909,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11038,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625162,"queuetimems":0,"class":"HRegionServer","responsesize":17233,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11193,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625009,"queuetimems":1,"class":"HRegionServer","responsesize":16915,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10737,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625463,"queuetimems":1,"class":"HRegionServer","responsesize":17578,"method":"Multi"}
2014-07-10 23:37:16,203 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11083,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625119,"queuetimems":0,"class":"HRegionServer","responsesize":16444,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625364,"queuetimems":0,"class":"HRegionServer","responsesize":16776,"method":"Multi"}
2014-07-10 23:37:16,203 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11335,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624868,"queuetimems":1,"class":"HRegionServer","responsesize":17005,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624976,"queuetimems":0,"class":"HRegionServer","responsesize":16923,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11665,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624536,"queuetimems":1,"class":"HRegionServer","responsesize":17192,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10903,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625299,"queuetimems":0,"class":"HRegionServer","responsesize":16746,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10708,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625494,"queuetimems":1,"class":"HRegionServer","responsesize":16658,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624573,"queuetimems":0,"class":"HRegionServer","responsesize":17065,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11296,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624905,"queuetimems":1,"class":"HRegionServer","responsesize":17065,"method":"Multi"}
2014-07-10 23:37:16,202 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10973,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625228,"queuetimems":1,"class":"HRegionServer","responsesize":16451,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10771,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625430,"queuetimems":1,"class":"HRegionServer","responsesize":17341,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11403,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624798,"queuetimems":0,"class":"HRegionServer","responsesize":16983,"method":"Multi"}
2014-07-10 23:37:16,201 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11534,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624667,"queuetimems":0,"class":"HRegionServer","responsesize":16940,"method":"Multi"}
2014-07-10 23:37:16,204 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10656,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625547,"queuetimems":0,"class":"HRegionServer","responsesize":16945,"method":"Multi"}
2014-07-10 23:37:16,203 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060625194,"queuetimems":0,"class":"HRegionServer","responsesize":16907,"method":"Multi"}
2014-07-10 23:37:16,203 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060624704,"queuetimems":1,"class":"HRegionServer","responsesize":17116,"method":"Multi"}
2014-07-10 23:37:16,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060634252 with entries=98, filesize=65.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060636140
2014-07-10 23:37:17,943 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:17,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8360 synced till here 8353
2014-07-10 23:37:18,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060636140 with entries=88, filesize=67.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060637943
2014-07-10 23:37:19,175 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:19,252 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060637943 with entries=90, filesize=62.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060639176
2014-07-10 23:37:21,499 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:21,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8551 synced till here 8546
2014-07-10 23:37:21,792 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060639176 with entries=101, filesize=76.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060641500
2014-07-10 23:37:23,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:23,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8640 synced till here 8631
2014-07-10 23:37:23,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060641500 with entries=89, filesize=66.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060643327
2014-07-10 23:37:24,912 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:25,239 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060643327 with entries=110, filesize=79.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060644912
2014-07-10 23:37:26,846 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:27,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8854 synced till here 8847
2014-07-10 23:37:27,172 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060644912 with entries=104, filesize=78.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060646846
2014-07-10 23:37:28,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:28,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8945 synced till here 8939
2014-07-10 23:37:28,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060646846 with entries=91, filesize=67.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060648518
2014-07-10 23:37:29,863 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:29,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9036 synced till here 9028
2014-07-10 23:37:29,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060648518 with entries=91, filesize=67.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060649863
2014-07-10 23:37:31,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:31,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9127 synced till here 9126
2014-07-10 23:37:31,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060649863 with entries=91, filesize=61.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060651437
2014-07-10 23:37:31,594 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,606 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,619 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,635 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,644 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,651 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,657 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,697 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,754 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,799 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,882 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:31,942 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,015 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,090 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,147 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,213 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,270 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,339 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,405 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,488 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,550 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,616 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,676 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,724 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,762 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,822 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,868 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,921 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:32,962 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:33,012 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:34,559 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1457ms
GC pool 'ParNew' had collection(s): count=1 time=1514ms
2014-07-10 23:37:34,573 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:34,585 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:34,601 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:34,633 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:34,665 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:34,697 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:37:36,595 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:36,606 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,619 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,635 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,645 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:36,651 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,657 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,697 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,755 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:36,800 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:36,882 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:36,942 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,016 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,090 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,148 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,214 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,271 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,339 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,405 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,488 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,550 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,616 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,676 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,724 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,762 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,822 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:37,869 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,921 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:37,962 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:38,013 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:39,575 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:39,585 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:37:39,601 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:39,633 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:39,665 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:39,697 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:37:41,596 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:41,607 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:41,619 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:41,636 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:41,645 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:41,652 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:41,657 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:41,697 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:41,755 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:41,800 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:41,883 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:41,942 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:42,016 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,090 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,148 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,214 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,271 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,340 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,406 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,489 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:37:42,551 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,616 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,677 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,725 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,763 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,823 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,869 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,922 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:42,963 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:43,013 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:44,576 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-10 23:37:44,586 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:44,601 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:44,634 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:44,666 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:37:44,698 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:37:46,596 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:46,607 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,620 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,636 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,646 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,652 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,658 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,698 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,755 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,801 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:46,883 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:46,943 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,016 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,091 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:47,148 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,214 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,271 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,340 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,406 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,489 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:47,551 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,617 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:47,677 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:47,725 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,763 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,823 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,869 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:47,922 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:47,963 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:48,014 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:48,922 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/b31a4cd24ddb48a8b0e67d3b1d944f93 as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/b31a4cd24ddb48a8b0e67d3b1d944f93
2014-07-10 23:37:48,935 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Removing store files after compaction...
2014-07-10 23:37:48,943 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/d380c19503e1496d9eaa08fe7243f3df, to hdfs://master:54310/hbase/archive/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/d380c19503e1496d9eaa08fe7243f3df
2014-07-10 23:37:48,946 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/8af8d41e4c5a436e98bf4c661fa4e217, to hdfs://master:54310/hbase/archive/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/8af8d41e4c5a436e98bf4c661fa4e217
2014-07-10 23:37:48,948 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/67bece0549ac4654921a327d51be22c4, to hdfs://master:54310/hbase/archive/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/67bece0549ac4654921a327d51be22c4
2014-07-10 23:37:48,950 DEBUG [regionserver60020-smallCompactions-1405059830600] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/648aea90055248b8ab08acdc4be78df0, to hdfs://master:54310/hbase/archive/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/648aea90055248b8ab08acdc4be78df0
2014-07-10 23:37:48,950 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. into b31a4cd24ddb48a8b0e67d3b1d944f93(size=430.8m), total size for store is 430.8m. This selection was in queue for 0sec, and took 1mins, 23sec to execute.
2014-07-10 23:37:48,951 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., storeName=family, fileCount=4, fileSize=431.0m, priority=16, time=14502031959071; duration=1mins, 23sec
2014-07-10 23:37:48,951 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-10 23:37:48,951 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-10 23:37:48,951 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 577187023 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-10 23:37:48,951 DEBUG [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: e472980be441986b612f83054b0dc330 - family: Initiating major compaction
2014-07-10 23:37:48,952 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:37:48,952 INFO  [regionserver60020-smallCompactions-1405059830600] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp, totalSize=550.4m
2014-07-10 23:37:48,952 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/ff0ec5a75dda4e7588f47aca56d68936, keycount=113090, bloomtype=ROW, size=80.6m, encoding=NONE, seqNum=202, earliestPutTs=1405060187127
2014-07-10 23:37:48,952 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/ed75eecf8e144fd6b96bbdc787e0c32a, keycount=110415, bloomtype=ROW, size=78.6m, encoding=NONE, seqNum=398, earliestPutTs=1405060317345
2014-07-10 23:37:48,952 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/1552ea18df694f62a1d501681e93b883, keycount=197675, bloomtype=ROW, size=140.7m, encoding=NONE, seqNum=749, earliestPutTs=1405060396363
2014-07-10 23:37:48,952 DEBUG [regionserver60020-smallCompactions-1405059830600] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/c79b51b4b7ba44a98f7b245cb235e717, keycount=352184, bloomtype=ROW, size=250.6m, encoding=NONE, seqNum=1372, earliestPutTs=1405060439786
2014-07-10 23:37:49,044 DEBUG [regionserver60020-smallCompactions-1405059830600] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:37:49,576 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-10 23:37:49,586 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-10 23:37:49,602 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:49,634 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:49,666 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:49,698 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-10 23:37:50,028 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1624, memsize=850.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/10f6cc56da0e47588eadb05d4965e2d2
2014-07-10 23:37:50,039 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/10f6cc56da0e47588eadb05d4965e2d2 as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/10f6cc56da0e47588eadb05d4965e2d2
2014-07-10 23:37:50,051 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/10f6cc56da0e47588eadb05d4965e2d2, entries=3095970, sequenceid=1624, filesize=220.3m
2014-07-10 23:37:50,052 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~850.3m/891614400, currentsize=320.8m/336433280 for region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. in 36590ms, sequenceid=1624, compaction requested=false
2014-07-10 23:37:50,052 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15355ms
2014-07-10 23:37:50,052 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,052 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799., current region memstore size 856.2m
2014-07-10 23:37:50,052 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15387ms
2014-07-10 23:37:50,053 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,053 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15420ms
2014-07-10 23:37:50,053 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,053 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15452ms
2014-07-10 23:37:50,053 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,053 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15469ms
2014-07-10 23:37:50,053 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,053 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15480ms
2014-07-10 23:37:50,053 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,054 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17042ms
2014-07-10 23:37:50,054 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,060 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17095ms
2014-07-10 23:37:50,061 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,061 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17141ms
2014-07-10 23:37:50,061 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,061 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17193ms
2014-07-10 23:37:50,061 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,061 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17239ms
2014-07-10 23:37:50,061 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,065 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17303ms
2014-07-10 23:37:50,065 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,065 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17341ms
2014-07-10 23:37:50,065 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,065 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17390ms
2014-07-10 23:37:50,065 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,066 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17451ms
2014-07-10 23:37:50,066 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,069 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17519ms
2014-07-10 23:37:50,069 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,069 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17582ms
2014-07-10 23:37:50,069 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,071 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17666ms
2014-07-10 23:37:50,071 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,073 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17734ms
2014-07-10 23:37:50,073 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,075 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17805ms
2014-07-10 23:37:50,075 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,076 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17863ms
2014-07-10 23:37:50,076 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,079 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17932ms
2014-07-10 23:37:50,079 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,079 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17990ms
2014-07-10 23:37:50,079 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,080 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18065ms
2014-07-10 23:37:50,080 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,080 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18138ms
2014-07-10 23:37:50,080 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,080 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18198ms
2014-07-10 23:37:50,080 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,081 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18282ms
2014-07-10 23:37:50,081 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,085 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18331ms
2014-07-10 23:37:50,085 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,085 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18388ms
2014-07-10 23:37:50,085 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,085 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18428ms
2014-07-10 23:37:50,085 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,088 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18437ms
2014-07-10 23:37:50,088 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,088 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18444ms
2014-07-10 23:37:50,088 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,096 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18461ms
2014-07-10 23:37:50,096 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,097 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18477ms
2014-07-10 23:37:50,097 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,097 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18491ms
2014-07-10 23:37:50,097 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,097 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18503ms
2014-07-10 23:37:50,097 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:37:50,242 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2.
2014-07-10 23:37:50,261 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1629, memsize=857.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/e499a988730f4aef9303096a4ee91086
2014-07-10 23:37:50,272 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/.tmp/e499a988730f4aef9303096a4ee91086 as hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/e499a988730f4aef9303096a4ee91086
2014-07-10 23:37:50,287 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5efb4c8cc936a019263d5b128583c6c6/family/e499a988730f4aef9303096a4ee91086, entries=3120660, sequenceid=1629, filesize=222.0m
2014-07-10 23:37:50,288 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~857.1m/898725280, currentsize=320.7m/336260960 for region usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6. in 36650ms, sequenceid=1629, compaction requested=true
2014-07-10 23:37:50,288 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-10 23:37:50,288 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405060169521.e472980be441986b612f83054b0dc330., current region memstore size 709.8m
2014-07-10 23:37:50,460 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651388,"queuetimems":0,"class":"HRegionServer","responsesize":16847,"method":"Multi"}
2014-07-10 23:37:50,561 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6.
2014-07-10 23:37:50,567 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651487,"queuetimems":0,"class":"HRegionServer","responsesize":17221,"method":"Multi"}
2014-07-10 23:37:51,167 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19734,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651433,"queuetimems":1,"class":"HRegionServer","responsesize":16955,"method":"Multi"}
2014-07-10 23:37:51,269 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19704,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651565,"queuetimems":1,"class":"HRegionServer","responsesize":16821,"method":"Multi"}
2014-07-10 23:37:51,270 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19743,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651526,"queuetimems":0,"class":"HRegionServer","responsesize":17303,"method":"Multi"}
2014-07-10 23:37:51,355 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:37:51,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:51,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9230 synced till here 9211
2014-07-10 23:37:51,556 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:37:51,649 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060651437 with entries=103, filesize=84.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060671379
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060478560
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060481807
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060485103
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060489212
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060492495
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060494896
2014-07-10 23:37:51,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060498628
2014-07-10 23:37:51,650 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060538072
2014-07-10 23:37:51,650 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060543665
2014-07-10 23:37:51,650 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060548524
2014-07-10 23:37:51,746 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17051,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060654695,"queuetimems":0,"class":"HRegionServer","responsesize":16991,"method":"Multi"}
2014-07-10 23:37:51,747 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17083,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060654663,"queuetimems":1,"class":"HRegionServer","responsesize":16804,"method":"Multi"}
2014-07-10 23:37:51,747 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18736,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060653010,"queuetimems":0,"class":"HRegionServer","responsesize":16680,"method":"Multi"}
2014-07-10 23:37:51,801 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17202,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060654599,"queuetimems":0,"class":"HRegionServer","responsesize":16788,"method":"Multi"}
2014-07-10 23:37:51,860 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17228,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060654631,"queuetimems":1,"class":"HRegionServer","responsesize":16926,"method":"Multi"}
2014-07-10 23:37:51,970 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17398,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060654571,"queuetimems":0,"class":"HRegionServer","responsesize":17097,"method":"Multi"}
2014-07-10 23:37:51,970 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17386,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060654583,"queuetimems":0,"class":"HRegionServer","responsesize":16902,"method":"Multi"}
2014-07-10 23:37:51,973 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19057,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652916,"queuetimems":1,"class":"HRegionServer","responsesize":17319,"method":"Multi"}
2014-07-10 23:37:51,974 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652866,"queuetimems":0,"class":"HRegionServer","responsesize":17198,"method":"Multi"}
2014-07-10 23:37:51,975 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652722,"queuetimems":0,"class":"HRegionServer","responsesize":17043,"method":"Multi"}
2014-07-10 23:37:52,183 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19697,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652485,"queuetimems":1,"class":"HRegionServer","responsesize":16718,"method":"Multi"}
2014-07-10 23:37:52,184 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19784,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652399,"queuetimems":1,"class":"HRegionServer","responsesize":16730,"method":"Multi"}
2014-07-10 23:37:52,343 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19583,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652760,"queuetimems":0,"class":"HRegionServer","responsesize":16894,"method":"Multi"}
2014-07-10 23:37:52,344 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652267,"queuetimems":1,"class":"HRegionServer","responsesize":16855,"method":"Multi"}
2014-07-10 23:37:52,379 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20628,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651750,"queuetimems":1,"class":"HRegionServer","responsesize":16898,"method":"Multi"}
2014-07-10 23:37:53,071 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:53,094 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9331 synced till here 9318
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20943,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652209,"queuetimems":0,"class":"HRegionServer","responsesize":16703,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21215,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651937,"queuetimems":0,"class":"HRegionServer","responsesize":16809,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652009,"queuetimems":1,"class":"HRegionServer","responsesize":17119,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21460,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651693,"queuetimems":0,"class":"HRegionServer","responsesize":16760,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20541,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652612,"queuetimems":1,"class":"HRegionServer","responsesize":16903,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651604,"queuetimems":0,"class":"HRegionServer","responsesize":17026,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21358,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651795,"queuetimems":1,"class":"HRegionServer","responsesize":16897,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21013,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652140,"queuetimems":0,"class":"HRegionServer","responsesize":16848,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20333,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652820,"queuetimems":1,"class":"HRegionServer","responsesize":17188,"method":"Multi"}
2014-07-10 23:37:53,153 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21068,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652085,"queuetimems":1,"class":"HRegionServer","responsesize":16900,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20484,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652668,"queuetimems":2,"class":"HRegionServer","responsesize":16958,"method":"Multi"}
2014-07-10 23:37:53,156 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21501,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651654,"queuetimems":1,"class":"HRegionServer","responsesize":17288,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20606,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652547,"queuetimems":1,"class":"HRegionServer","responsesize":16993,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21276,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060651877,"queuetimems":1,"class":"HRegionServer","responsesize":16835,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652959,"queuetimems":0,"class":"HRegionServer","responsesize":17127,"method":"Multi"}
2014-07-10 23:37:53,154 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20817,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060652336,"queuetimems":2,"class":"HRegionServer","responsesize":16966,"method":"Multi"}
2014-07-10 23:37:53,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060671379 with entries=101, filesize=66.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060673071
2014-07-10 23:37:53,993 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:54,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9419 synced till here 9414
2014-07-10 23:37:54,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060673071 with entries=88, filesize=63.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060673993
2014-07-10 23:37:55,382 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:56,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9527 synced till here 9526
2014-07-10 23:37:56,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060673993 with entries=108, filesize=76.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060675382
2014-07-10 23:37:57,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:37:58,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9615 synced till here 9612
2014-07-10 23:37:58,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060675382 with entries=88, filesize=65.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060677421
2014-07-10 23:37:59,121 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:00,615 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9715 synced till here 9702
2014-07-10 23:38:00,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060677421 with entries=100, filesize=74.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060679121
2014-07-10 23:38:01,244 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:01,265 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9805 synced till here 9800
2014-07-10 23:38:01,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060679121 with entries=90, filesize=64.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060681244
2014-07-10 23:38:02,782 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1191ms
GC pool 'ParNew' had collection(s): count=1 time=1393ms
2014-07-10 23:38:03,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:05,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060681244 with entries=119, filesize=82.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060683516
2014-07-10 23:38:07,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:07,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10013 synced till here 10006
2014-07-10 23:38:07,486 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060683516 with entries=89, filesize=66.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060687381
2014-07-10 23:38:08,250 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:08,270 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10104 synced till here 10102
2014-07-10 23:38:08,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060687381 with entries=91, filesize=64.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060688251
2014-07-10 23:38:09,701 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1333ms
GC pool 'ParNew' had collection(s): count=1 time=1332ms
2014-07-10 23:38:10,618 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:10,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10202 synced till here 10201
2014-07-10 23:38:10,828 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060688251 with entries=98, filesize=73.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060690619
2014-07-10 23:38:12,897 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.17 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=31996, hits=1142, hitRatio=3.56%, , cachingAccesses=1144, cachingHits=1139, cachingHitsRatio=99.56%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-10 23:38:12,933 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:13,071 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c.
2014-07-10 23:38:13,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10306 synced till here 10304
2014-07-10 23:38:13,874 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060690619 with entries=104, filesize=76.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060692933
2014-07-10 23:38:14,703 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:15,258 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10405 synced till here 10404
2014-07-10 23:38:15,273 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060692933 with entries=99, filesize=72.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060694703
2014-07-10 23:38:15,483 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,500 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,505 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,534 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,534 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,537 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,537 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,563 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,564 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,569 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,572 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,574 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,624 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:15,642 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,064 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,219 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,262 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,373 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,744 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,758 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:16,782 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1405059792813: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-10 23:38:20,484 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:20,500 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,506 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,534 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,535 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:20,537 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,537 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,563 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,564 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,569 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,572 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,575 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:20,625 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:20,642 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:21,065 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:21,219 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:21,262 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:21,373 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:21,745 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:21,759 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-10 23:38:21,783 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-10 23:38:25,485 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,501 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,506 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,535 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,535 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,537 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:38:25,538 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,564 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,564 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:38:25,569 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:38:25,572 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:38:25,575 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,625 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:25,642 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:38:26,065 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:26,220 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:38:26,262 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-10 23:38:26,373 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:26,746 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-10 23:38:26,759 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:26,783 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-10 23:38:26,975 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1833, memsize=711.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/9b101071a7bd4e4c87d26cd23d16d597
2014-07-10 23:38:26,986 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/.tmp/9b101071a7bd4e4c87d26cd23d16d597 as hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/9b101071a7bd4e4c87d26cd23d16d597
2014-07-10 23:38:27,050 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/e472980be441986b612f83054b0dc330/family/9b101071a7bd4e4c87d26cd23d16d597, entries=2589900, sequenceid=1833, filesize=184.3m
2014-07-10 23:38:27,051 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~711.3m/745868640, currentsize=392.6m/411678880 for region usertable,user7,1405060169521.e472980be441986b612f83054b0dc330. in 36762ms, sequenceid=1833, compaction requested=false
2014-07-10 23:38:27,051 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10269ms
2014-07-10 23:38:27,051 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,051 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2., current region memstore size 721.7m
2014-07-10 23:38:27,051 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10293ms
2014-07-10 23:38:27,051 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,051 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10307ms
2014-07-10 23:38:27,051 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,052 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10679ms
2014-07-10 23:38:27,052 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,052 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10790ms
2014-07-10 23:38:27,052 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,052 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10834ms
2014-07-10 23:38:27,052 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,052 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10988ms
2014-07-10 23:38:27,052 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,065 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11423ms
2014-07-10 23:38:27,065 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,065 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11441ms
2014-07-10 23:38:27,065 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,067 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11493ms
2014-07-10 23:38:27,067 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,067 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11495ms
2014-07-10 23:38:27,067 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,068 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11499ms
2014-07-10 23:38:27,068 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,074 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11510ms
2014-07-10 23:38:27,074 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,075 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11511ms
2014-07-10 23:38:27,075 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,076 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11538ms
2014-07-10 23:38:27,076 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,076 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11539ms
2014-07-10 23:38:27,076 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,077 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11543ms
2014-07-10 23:38:27,078 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,078 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11544ms
2014-07-10 23:38:27,078 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,083 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11578ms
2014-07-10 23:38:27,083 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,083 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11583ms
2014-07-10 23:38:27,083 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,084 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11601ms
2014-07-10 23:38:27,084 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1405059792813
2014-07-10 23:38:27,117 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12363,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060694754,"queuetimems":2,"class":"HRegionServer","responsesize":16721,"method":"Multi"}
2014-07-10 23:38:27,202 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405060169521.e472980be441986b612f83054b0dc330.
2014-07-10 23:38:27,202 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060694706,"queuetimems":0,"class":"HRegionServer","responsesize":17206,"method":"Multi"}
2014-07-10 23:38:27,202 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12540,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060694662,"queuetimems":1,"class":"HRegionServer","responsesize":16868,"method":"Multi"}
2014-07-10 23:38:27,345 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695286,"queuetimems":0,"class":"HRegionServer","responsesize":16919,"method":"Multi"}
2014-07-10 23:38:27,345 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695241,"queuetimems":0,"class":"HRegionServer","responsesize":16886,"method":"Multi"}
2014-07-10 23:38:27,346 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12547,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060694799,"queuetimems":1,"class":"HRegionServer","responsesize":17058,"method":"Multi"}
2014-07-10 23:38:27,346 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12091,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695255,"queuetimems":0,"class":"HRegionServer","responsesize":17013,"method":"Multi"}
2014-07-10 23:38:27,347 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11933,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695414,"queuetimems":1,"class":"HRegionServer","responsesize":8052,"method":"Multi"}
2014-07-10 23:38:27,365 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11979,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695385,"queuetimems":0,"class":"HRegionServer","responsesize":16988,"method":"Multi"}
2014-07-10 23:38:27,449 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695328,"queuetimems":0,"class":"HRegionServer","responsesize":16908,"method":"Multi"}
2014-07-10 23:38:27,490 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10710,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696779,"queuetimems":0,"class":"HRegionServer","responsesize":7956,"method":"Multi"}
2014-07-10 23:38:27,490 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10732,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696757,"queuetimems":0,"class":"HRegionServer","responsesize":8004,"method":"Multi"}
2014-07-10 23:38:27,506 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11865,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695640,"queuetimems":0,"class":"HRegionServer","responsesize":8205,"method":"Multi"}
2014-07-10 23:38:27,635 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:38:27,655 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:27,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10501 synced till here 10495
2014-07-10 23:38:27,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060694703 with entries=96, filesize=66.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060707655
2014-07-10 23:38:27,798 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12231,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695566,"queuetimems":0,"class":"HRegionServer","responsesize":16876,"method":"Multi"}
2014-07-10 23:38:28,050 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12427,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695622,"queuetimems":1,"class":"HRegionServer","responsesize":16957,"method":"Multi"}
2014-07-10 23:38:28,050 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11838,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696211,"queuetimems":1,"class":"HRegionServer","responsesize":17180,"method":"Multi"}
2014-07-10 23:38:28,050 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11307,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696742,"queuetimems":0,"class":"HRegionServer","responsesize":16945,"method":"Multi"}
2014-07-10 23:38:28,050 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12553,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060695496,"queuetimems":1,"class":"HRegionServer","responsesize":16917,"method":"Multi"}
2014-07-10 23:38:28,062 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696053,"queuetimems":0,"class":"HRegionServer","responsesize":16945,"method":"Multi"}
2014-07-10 23:38:28,063 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11693,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696370,"queuetimems":1,"class":"HRegionServer","responsesize":16984,"method":"Multi"}
2014-07-10 23:38:28,072 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11812,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:56596","starttimems":1405060696260,"queuetimems":1,"class":"HRegionServer","responsesize":17086,"method":"Multi"}
2014-07-10 23:38:29,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:29,135 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10597 synced till here 10595
2014-07-10 23:38:29,148 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060707655 with entries=96, filesize=63.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060709111
2014-07-10 23:38:31,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-10 23:38:31,982 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060709111 with entries=92, filesize=61.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1405059792813/sceplus-vm48.almaden.ibm.com%2C60020%2C1405059792813.1405060711953
2014-07-10 23:38:34,359 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1838, memsize=856.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/351a61f54722469b8b97a3d424c4d2c0
2014-07-10 23:38:34,370 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/.tmp/351a61f54722469b8b97a3d424c4d2c0 as hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/351a61f54722469b8b97a3d424c4d2c0
2014-07-10 23:38:34,378 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2f0a37e0c2bb48c75813e7844f62e799/family/351a61f54722469b8b97a3d424c4d2c0, entries=3117440, sequenceid=1838, filesize=221.8m
2014-07-10 23:38:34,379 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~856.2m/897798160, currentsize=468.6m/491314960 for region usertable,user1,1405060169521.2f0a37e0c2bb48c75813e7844f62e799. in 44327ms, sequenceid=1838, compaction requested=true
2014-07-10 23:38:34,379 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-10 23:38:34,379 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405060169521.5efb4c8cc936a019263d5b128583c6c6., current region memstore size 789.2m
2014-07-10 23:38:34,917 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-10 23:38:50,696 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2095, memsize=721.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/debbafc0548a458a9b752cdd0c884472
2014-07-10 23:38:50,706 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/.tmp/debbafc0548a458a9b752cdd0c884472 as hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/debbafc0548a458a9b752cdd0c884472
2014-07-10 23:38:50,872 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/a17619b4327f9b5610de972e6da3dce2/family/debbafc0548a458a9b752cdd0c884472, entries=2627570, sequenceid=2095, filesize=187.0m
2014-07-10 23:38:50,872 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~721.7m/756719360, currentsize=74.0m/77542320 for region usertable,user5,1405060169521.a17619b4327f9b5610de972e6da3dce2. in 23821ms, sequenceid=2095, compaction requested=true
2014-07-10 23:38:50,872 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-10 23:38:50,873 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1405060169521.2f8b7bbfe3f11e72550880324064a38c., current region memstore size 293.4m
2014-07-10 23:38:51,141 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
