Mon Jul 14 02:40:05 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-14 02:40:05,923 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-14 02:40:05,924 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-14 02:40:05,924 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-14 02:40:06,157 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-14 02:40:06,157 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 33148 22
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-14 02:40:06,158 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 33148 9.1.143.59 22
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-14 02:40:06,159 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-14 02:40:06,160 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-14 02:40:06,162 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=969
2014-07-14 02:40:06,163 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-14 02:40:06,163 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-14 02:40:06,163 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-14 02:40:06,163 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-14 02:40:06,163 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-14 02:40:06,165 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-14 02:40:06,165 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-14 02:40:06,396 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-14 02:40:06,865 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-14 02:40:06,967 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-14 02:40:06,980 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-14 02:40:07,043 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-14 02:40:07,044 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-14 02:40:07,044 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-14 02:40:07,049 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-14 02:40:07,054 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-14 02:40:07,142 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-14 02:40:07,142 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-14 02:40:07,147 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-14 02:40:07,149 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-14 02:40:07,228 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-14 02:40:07,284 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-14 02:40:07,294 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-14 02:40:07,296 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-14 02:40:07,296 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-14 02:40:07,296 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-14 02:40:07,609 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-14 02:40:07,650 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-14 02:40:07,650 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-14 02:40:07,650 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-14 02:40:07,650 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-14 02:40:07,651 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-14 02:40:07,653 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-14 02:40:07,657 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-14 02:40:07,678 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-14 02:40:07,681 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-14 02:40:07,685 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-14 02:40:07,701 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147343e59c80000, negotiated timeout = 90000
2014-07-14 02:40:40,300 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x195e5600, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-14 02:40:40,302 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x195e5600 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-14 02:40:40,302 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-14 02:40:40,303 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-14 02:40:40,311 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147343e59c80001, negotiated timeout = 90000
2014-07-14 02:40:40,585 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7e0892c5
2014-07-14 02:40:40,591 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-14 02:40:40,597 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-14 02:40:40,613 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-14 02:40:40,650 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-14 02:40:40,656 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-14 02:40:40,661 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-14 02:40:40,682 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405330805365 with port=60020, startcode=1405330807068
2014-07-14 02:40:41,023 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-14 02:40:41,023 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-14 02:40:41,023 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-14 02:40:41,053 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-14 02:40:41,062 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068
2014-07-14 02:40:41,104 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-14 02:40:41,115 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-14 02:40:41,212 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405330841123
2014-07-14 02:40:41,229 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-14 02:40:41,237 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-14 02:40:41,242 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-14 02:40:41,249 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-14 02:40:41,253 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-14 02:40:41,254 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-14 02:40:41,254 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-14 02:40:41,254 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-14 02:40:41,254 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-14 02:40:41,265 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [sceplus-vm48.almaden.ibm.com,60020,1405330807223, slave1,60020,1405330807068] other RSs: [sceplus-vm48.almaden.ibm.com,60020,1405330807223, slave1,60020,1405330807068]
2014-07-14 02:40:41,304 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-14 02:40:41,306 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x68275748, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-14 02:40:41,307 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x68275748 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-14 02:40:41,308 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-14 02:40:41,309 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-14 02:40:41,312 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x147343e59c80002, negotiated timeout = 90000
2014-07-14 02:40:41,318 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-14 02:40:41,318 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-14 02:40:41,372 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405330807068, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x147343e59c80000
2014-07-14 02:40:41,372 INFO  [SplitLogWorker-slave1,60020,1405330807068] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405330807068 starting
2014-07-14 02:40:41,373 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-14 02:40:41,373 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405330807068
2014-07-14 02:40:41,373 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405330807068'
2014-07-14 02:40:41,373 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-14 02:40:41,375 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-14 02:40:41,377 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-14 02:40:45,981 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:40:46,122 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 018fa362abf2ec7a02c06683da5e76f5 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,123 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:40:46,123 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:40:46,124 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f7644f9dbefce312f180da53011ffa5c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,125 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 02:40:46,125 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4d29ddafd3242e2ff279396a5cf1682c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,134 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:40:46,135 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:40:46,151 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 018fa362abf2ec7a02c06683da5e76f5 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,152 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f7644f9dbefce312f180da53011ffa5c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,152 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4d29ddafd3242e2ff279396a5cf1682c from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,170 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 4d29ddafd3242e2ff279396a5cf1682c, NAME => 'usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-14 02:40:46,170 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 018fa362abf2ec7a02c06683da5e76f5, NAME => 'usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-14 02:40:46,170 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => f7644f9dbefce312f180da53011ffa5c, NAME => 'usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-14 02:40:46,198 INFO  [RS_OPEN_REGION-slave1:60020-2] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-14 02:40:46,199 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:40:46,199 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 018fa362abf2ec7a02c06683da5e76f5
2014-07-14 02:40:46,199 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:40:46,199 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:40:46,199 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:40:46,199 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:40:46,208 INFO  [RS_OPEN_REGION-slave1:60020-2] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-14 02:40:46,210 INFO  [RS_OPEN_REGION-slave1:60020-2] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-14 02:40:46,213 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-14 02:40:46,213 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-14 02:40:46,213 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-14 02:40:46,296 INFO  [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 02:40:46,297 INFO  [StoreOpener-018fa362abf2ec7a02c06683da5e76f5-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 02:40:46,304 INFO  [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 02:40:46,332 INFO  [StoreOpener-018fa362abf2ec7a02c06683da5e76f5-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-14 02:40:46,344 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/018fa362abf2ec7a02c06683da5e76f5
2014-07-14 02:40:46,349 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 018fa362abf2ec7a02c06683da5e76f5; next sequenceid=1
2014-07-14 02:40:46,349 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 018fa362abf2ec7a02c06683da5e76f5
2014-07-14 02:40:46,353 INFO  [PostOpenDeployTasks:018fa362abf2ec7a02c06683da5e76f5] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:40:46,424 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-14 02:40:46,430 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-14 02:40:46,447 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/0f7d46abe6f748d1821c0900b9a53cbc, isReference=false, isBulkLoadResult=false, seqid=20282, majorCompaction=false
2014-07-14 02:40:46,447 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/00c7b2b5dd9b433385379df2eb3c49f3, isReference=false, isBulkLoadResult=false, seqid=20183, majorCompaction=false
2014-07-14 02:40:46,463 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/038bf8bec53c4d6db2d15332ab7447a2, isReference=false, isBulkLoadResult=false, seqid=21948, majorCompaction=false
2014-07-14 02:40:46,465 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/125e1a35b00b40ef97e74ed13ec5c568, isReference=false, isBulkLoadResult=false, seqid=21818, majorCompaction=false
2014-07-14 02:40:46,512 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/03f01ec3ba9645e9973850c6131f836a, isReference=false, isBulkLoadResult=false, seqid=3209, majorCompaction=true
2014-07-14 02:40:46,539 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/06f53cacdd574b399cf369b44cd912fa, isReference=false, isBulkLoadResult=false, seqid=20690, majorCompaction=false
2014-07-14 02:40:46,539 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/17a576ac7ffd4ac3acf5efb366d5516b, isReference=false, isBulkLoadResult=false, seqid=8162, majorCompaction=false
2014-07-14 02:40:46,577 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/27608c4b79f945d7bf4e35c02a1a5e8c, isReference=false, isBulkLoadResult=false, seqid=18767, majorCompaction=false
2014-07-14 02:40:46,581 INFO  [PostOpenDeployTasks:018fa362abf2ec7a02c06683da5e76f5] catalog.MetaEditor: Updated row usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5. with server=slave1,60020,1405330807068
2014-07-14 02:40:46,582 INFO  [PostOpenDeployTasks:018fa362abf2ec7a02c06683da5e76f5] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:40:46,582 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 018fa362abf2ec7a02c06683da5e76f5 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:46,584 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/2139d8d45daa42098f2c36c1e5f88079, isReference=false, isBulkLoadResult=false, seqid=21943, majorCompaction=false
2014-07-14 02:40:46,587 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 018fa362abf2ec7a02c06683da5e76f5 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:46,587 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 018fa362abf2ec7a02c06683da5e76f5 to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:40:46,587 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5. on slave1,60020,1405330807068
2014-07-14 02:40:46,587 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,591 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,592 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-14 02:40:46,592 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-14 02:40:46,593 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 02:40:46,594 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/2e6fff9c982647a9ab52ac896684f91e, isReference=false, isBulkLoadResult=false, seqid=11284, majorCompaction=false
2014-07-14 02:40:46,599 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 02:40:46,609 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/218bf59287d940669932bcd5a8399fb6, isReference=false, isBulkLoadResult=false, seqid=13456, majorCompaction=false
2014-07-14 02:40:46,624 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-14 02:40:46,629 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-14 02:40:46,635 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-14 02:40:46,636 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-14 02:40:46,637 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/3880b5634922490aad507617fecd1265, isReference=false, isBulkLoadResult=false, seqid=17745, majorCompaction=false
2014-07-14 02:40:46,639 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 02:40:46,644 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/2660f1a703ca4633ae04f1e6c0738edb, isReference=false, isBulkLoadResult=false, seqid=2397, majorCompaction=true
2014-07-14 02:40:46,652 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405330807068
2014-07-14 02:40:46,652 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-14 02:40:46,652 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:46,662 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:46,662 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:40:46,662 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405330807068
2014-07-14 02:40:46,662 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3ed99555c5854aec8a0656312deed2cf, isReference=false, isBulkLoadResult=false, seqid=13952, majorCompaction=false
2014-07-14 02:40:46,663 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3990157c1b6a259f95c53a0f0007d7bc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,665 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/4e4b0d442bc44db5975e70e49c78649c, isReference=false, isBulkLoadResult=false, seqid=12398, majorCompaction=false
2014-07-14 02:40:46,673 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3990157c1b6a259f95c53a0f0007d7bc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:46,674 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 3990157c1b6a259f95c53a0f0007d7bc, NAME => 'usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-14 02:40:46,675 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:40:46,675 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:40:46,684 INFO  [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 02:40:46,686 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/4a434c7dd72946edb994ccb017acf8ab, isReference=false, isBulkLoadResult=false, seqid=13036, majorCompaction=false
2014-07-14 02:40:46,712 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/530de20f1e5042e7bf62d3f0760f52ea, isReference=false, isBulkLoadResult=false, seqid=11733, majorCompaction=false
2014-07-14 02:40:46,719 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/01b1d41e3bbf4f1da9d1821657737897, isReference=false, isBulkLoadResult=false, seqid=17186, majorCompaction=false
2014-07-14 02:40:46,724 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/5ba4342c7a5640438ac3196dec5e3b2a, isReference=false, isBulkLoadResult=false, seqid=8749, majorCompaction=false
2014-07-14 02:40:46,740 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/0d2bdeb807914855bfc4f10b1c92c3b2, isReference=false, isBulkLoadResult=false, seqid=18140, majorCompaction=false
2014-07-14 02:40:46,741 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/69286036448e41c3949cacb0cad5350f, isReference=false, isBulkLoadResult=false, seqid=17189, majorCompaction=false
2014-07-14 02:40:46,744 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/64151486dbfe4c3cae67e88b8c8f5af4, isReference=false, isBulkLoadResult=false, seqid=18144, majorCompaction=false
2014-07-14 02:40:46,770 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/649c642706d846abbcc80191ee5fd4eb, isReference=false, isBulkLoadResult=false, seqid=18825, majorCompaction=false
2014-07-14 02:40:46,772 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/6a7a695dd27d4bb58cb61d84a34ce19e, isReference=false, isBulkLoadResult=false, seqid=3650, majorCompaction=false
2014-07-14 02:40:46,781 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/1063b48f64274ab698f7eb1eeef87e58, isReference=false, isBulkLoadResult=false, seqid=8013, majorCompaction=false
2014-07-14 02:40:46,806 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/739223e5c99d45f58cec822b2c37da2f, isReference=false, isBulkLoadResult=false, seqid=13337, majorCompaction=false
2014-07-14 02:40:46,815 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/126df90076864347baaf622d2e39ffc3, isReference=false, isBulkLoadResult=false, seqid=7439, majorCompaction=false
2014-07-14 02:40:46,817 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/75d35efcd71642ab91fbbe74d212e59c, isReference=false, isBulkLoadResult=false, seqid=14949, majorCompaction=false
2014-07-14 02:40:46,820 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/885919622070466790802a2da30c0358, isReference=false, isBulkLoadResult=false, seqid=21688, majorCompaction=false
2014-07-14 02:40:46,831 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/77bf31c07654435e9149b697af072f46, isReference=false, isBulkLoadResult=false, seqid=21332, majorCompaction=false
2014-07-14 02:40:46,833 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/127fd3c9deff4a908dbcb05d88735c01, isReference=false, isBulkLoadResult=false, seqid=21344, majorCompaction=false
2014-07-14 02:40:46,846 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/8fef34548ab64301b4e2c091e00ac407, isReference=false, isBulkLoadResult=false, seqid=19580, majorCompaction=false
2014-07-14 02:40:46,850 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/158f9bc8af9b49ef9afd5df26f27bdca, isReference=false, isBulkLoadResult=false, seqid=19600, majorCompaction=false
2014-07-14 02:40:46,860 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/98106d908d2b428a9a37b4c8763a023b, isReference=false, isBulkLoadResult=false, seqid=7020, majorCompaction=false
2014-07-14 02:40:46,876 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/17f35316da484cf4959d379ecc9868f8, isReference=false, isBulkLoadResult=false, seqid=10247, majorCompaction=false
2014-07-14 02:40:46,880 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/915bbbeb2cc248ff93804d8f54227832, isReference=false, isBulkLoadResult=false, seqid=10407, majorCompaction=false
2014-07-14 02:40:46,894 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/a8a4bc0d17ba428e886ff1909b2cab2d, isReference=false, isBulkLoadResult=false, seqid=9216, majorCompaction=false
2014-07-14 02:40:46,899 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a06716b3bcc048e48f5029761ff7da5b, isReference=false, isBulkLoadResult=false, seqid=14601, majorCompaction=false
2014-07-14 02:40:46,907 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/22682bcc6b6145f0b1eaf84294cfbb78, isReference=false, isBulkLoadResult=false, seqid=13611, majorCompaction=false
2014-07-14 02:40:46,922 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/aa82df1846b3494f8efb0642053aba22, isReference=false, isBulkLoadResult=false, seqid=7583, majorCompaction=false
2014-07-14 02:40:46,931 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a38f7bc6ffde47519c390ccedea9d579, isReference=false, isBulkLoadResult=false, seqid=16437, majorCompaction=false
2014-07-14 02:40:46,934 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/2e72b3d834cf40c79b422b1169d61146, isReference=false, isBulkLoadResult=false, seqid=16459, majorCompaction=false
2014-07-14 02:40:46,950 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/48508c638a864cfbbf0b2fabbe71a77a, isReference=false, isBulkLoadResult=false, seqid=11694, majorCompaction=false
2014-07-14 02:40:46,954 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/bf2813c99aac4e9f9e422102cb25c6e8, isReference=false, isBulkLoadResult=false, seqid=16225, majorCompaction=false
2014-07-14 02:40:46,959 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/a68e4f3654d845ecaafbbba0c6d5931e, isReference=false, isBulkLoadResult=false, seqid=5211, majorCompaction=false
2014-07-14 02:40:46,978 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/c55a7dfa5db149bf8e5c2796d9971b6e, isReference=false, isBulkLoadResult=false, seqid=15385, majorCompaction=false
2014-07-14 02:40:46,983 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/b4bf44c0d1914e4faffdce0b5dab6532, isReference=false, isBulkLoadResult=false, seqid=14032, majorCompaction=false
2014-07-14 02:40:46,986 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/4f501be8f3654e7d9a7969ff53484294, isReference=false, isBulkLoadResult=false, seqid=8569, majorCompaction=false
2014-07-14 02:40:47,008 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/d533394788c040daa3ce4af201f1e8a1, isReference=false, isBulkLoadResult=false, seqid=11119, majorCompaction=false
2014-07-14 02:40:47,013 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/6c7eb087f31441ebbda90db74f6dc942, isReference=false, isBulkLoadResult=false, seqid=4424, majorCompaction=true
2014-07-14 02:40:47,014 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/c37e016b64e34a69bbdda3d282d625ea, isReference=false, isBulkLoadResult=false, seqid=5679, majorCompaction=false
2014-07-14 02:40:47,024 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/df495c966e794018b158f457d8c61e35, isReference=false, isBulkLoadResult=false, seqid=14354, majorCompaction=false
2014-07-14 02:40:47,041 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/cb32be1fb19349d699274c5ef12d377c, isReference=false, isBulkLoadResult=false, seqid=4598, majorCompaction=false
2014-07-14 02:40:47,045 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/80d9a77cf1c44168afc42f814df616db, isReference=false, isBulkLoadResult=false, seqid=6967, majorCompaction=false
2014-07-14 02:40:47,058 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/e82659f12ae241cc858db1ae8c520e5b, isReference=false, isBulkLoadResult=false, seqid=19824, majorCompaction=false
2014-07-14 02:40:47,067 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/ec8ffafe7c7e4c00850cdb98e22cfb30, isReference=false, isBulkLoadResult=false, seqid=20972, majorCompaction=false
2014-07-14 02:40:47,079 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/8a0183a500e94e07864b4c7482dfe157, isReference=false, isBulkLoadResult=false, seqid=15231, majorCompaction=false
2014-07-14 02:40:47,088 DEBUG [StoreOpener-4d29ddafd3242e2ff279396a5cf1682c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/f09479c2197e42a7a74bb81543ef4bc8, isReference=false, isBulkLoadResult=false, seqid=10318, majorCompaction=false
2014-07-14 02:40:47,091 DEBUG [StoreOpener-f7644f9dbefce312f180da53011ffa5c-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c/family/f7498d9850a14a649efc73be1b4fb2ec, isReference=false, isBulkLoadResult=false, seqid=4245, majorCompaction=false
2014-07-14 02:40:47,093 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:40:47,094 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:40:47,097 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 4d29ddafd3242e2ff279396a5cf1682c; next sequenceid=21944
2014-07-14 02:40:47,097 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 4d29ddafd3242e2ff279396a5cf1682c
2014-07-14 02:40:47,098 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined f7644f9dbefce312f180da53011ffa5c; next sequenceid=21949
2014-07-14 02:40:47,098 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node f7644f9dbefce312f180da53011ffa5c
2014-07-14 02:40:47,100 INFO  [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:40:47,100 INFO  [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:40:47,104 DEBUG [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 02:40:47,105 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 02:40:47,105 DEBUG [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 02:40:47,106 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/93950a5ae16c46d6b560ad6a8afcb622, isReference=false, isBulkLoadResult=false, seqid=18506, majorCompaction=false
2014-07-14 02:40:47,113 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 299079523 starting at candidate #10 after considering 132 permutations with 123 in ratio
2014-07-14 02:40:47,115 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 4d29ddafd3242e2ff279396a5cf1682c - family: Initiating minor compaction
2014-07-14 02:40:47,115 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:40:47,115 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/.tmp, totalSize=285.2m
2014-07-14 02:40:47,116 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/3ed99555c5854aec8a0656312deed2cf, keycount=107472, bloomtype=ROW, size=76.5m, encoding=NONE, seqNum=13952
2014-07-14 02:40:47,117 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/df495c966e794018b158f457d8c61e35, keycount=130570, bloomtype=ROW, size=93.0m, encoding=NONE, seqNum=14354
2014-07-14 02:40:47,117 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/4d29ddafd3242e2ff279396a5cf1682c/family/75d35efcd71642ab91fbbe74d212e59c, keycount=162531, bloomtype=ROW, size=115.7m, encoding=NONE, seqNum=14949
2014-07-14 02:40:47,119 INFO  [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] catalog.MetaEditor: Updated row usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. with server=slave1,60020,1405330807068
2014-07-14 02:40:47,119 INFO  [PostOpenDeployTasks:f7644f9dbefce312f180da53011ffa5c] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:40:47,120 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f7644f9dbefce312f180da53011ffa5c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,120 INFO  [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] catalog.MetaEditor: Updated row usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. with server=slave1,60020,1405330807068
2014-07-14 02:40:47,120 INFO  [PostOpenDeployTasks:4d29ddafd3242e2ff279396a5cf1682c] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:40:47,121 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4d29ddafd3242e2ff279396a5cf1682c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,125 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f7644f9dbefce312f180da53011ffa5c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,125 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4d29ddafd3242e2ff279396a5cf1682c from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,125 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned f7644f9dbefce312f180da53011ffa5c to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:40:47,125 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 4d29ddafd3242e2ff279396a5cf1682c to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:40:47,126 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. on slave1,60020,1405330807068
2014-07-14 02:40:47,126 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. on slave1,60020,1405330807068
2014-07-14 02:40:47,126 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8a1d10978c87bbc043a64b1893a75b1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:47,130 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8a1d10978c87bbc043a64b1893a75b1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:40:47,130 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => c8a1d10978c87bbc043a64b1893a75b1, NAME => 'usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-14 02:40:47,131 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:40:47,131 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:40:47,133 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/9f4b67abbc534839890687e071851d70, isReference=false, isBulkLoadResult=false, seqid=13111, majorCompaction=false
2014-07-14 02:40:47,140 INFO  [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-14 02:40:47,144 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:40:47,185 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/a06416db3b28457abfec150e5362d3e2, isReference=false, isBulkLoadResult=false, seqid=20622, majorCompaction=false
2014-07-14 02:40:47,200 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/113618597e08416d94873ddee7cadb74, isReference=false, isBulkLoadResult=false, seqid=18428, majorCompaction=false
2014-07-14 02:40:47,226 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b34cc1ad7def4637b727d3712e97eaa8, isReference=false, isBulkLoadResult=false, seqid=15615, majorCompaction=false
2014-07-14 02:40:47,244 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/13188f0eeece4db2b2bfdffb2974f7ef, isReference=false, isBulkLoadResult=false, seqid=21389, majorCompaction=false
2014-07-14 02:40:47,257 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/b89aea7f89cb400880e8a70c51c1ff53, isReference=false, isBulkLoadResult=false, seqid=21417, majorCompaction=false
2014-07-14 02:40:47,267 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/c3c71155aea94f799cd0089afdbd85b0, isReference=false, isBulkLoadResult=false, seqid=21951, majorCompaction=false
2014-07-14 02:40:47,276 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/142697ca4b6c49bc9283095bcf4c55de, isReference=false, isBulkLoadResult=false, seqid=1779, majorCompaction=true
2014-07-14 02:40:47,298 DEBUG [StoreOpener-3990157c1b6a259f95c53a0f0007d7bc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc/family/f8d7ae7fcfe14c81803e5f0da6a071fa, isReference=false, isBulkLoadResult=false, seqid=4851, majorCompaction=false
2014-07-14 02:40:47,302 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:40:47,304 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 3990157c1b6a259f95c53a0f0007d7bc; next sequenceid=21952
2014-07-14 02:40:47,304 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 3990157c1b6a259f95c53a0f0007d7bc
2014-07-14 02:40:47,306 INFO  [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:40:47,306 DEBUG [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:40:47,314 INFO  [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] catalog.MetaEditor: Updated row usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. with server=slave1,60020,1405330807068
2014-07-14 02:40:47,315 INFO  [PostOpenDeployTasks:3990157c1b6a259f95c53a0f0007d7bc] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:40:47,315 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/26121a0962fc4fcb9e89d6d50b98184f, isReference=false, isBulkLoadResult=false, seqid=14324, majorCompaction=false
2014-07-14 02:40:47,316 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3990157c1b6a259f95c53a0f0007d7bc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,320 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3990157c1b6a259f95c53a0f0007d7bc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,320 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 3990157c1b6a259f95c53a0f0007d7bc to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:40:47,320 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. on slave1,60020,1405330807068
2014-07-14 02:40:47,350 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/27cd9bd0a0654403ade07afe6309e058, isReference=false, isBulkLoadResult=false, seqid=20965, majorCompaction=false
2014-07-14 02:40:47,385 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/36f41bb928ed496b95da9e5721dcbbca, isReference=false, isBulkLoadResult=false, seqid=7134, majorCompaction=false
2014-07-14 02:40:47,409 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/3f9ab447904f4c619ded73efe82dad05, isReference=false, isBulkLoadResult=false, seqid=6171, majorCompaction=false
2014-07-14 02:40:47,428 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/474a661aa08a4b15b219ba60cfc74c58, isReference=false, isBulkLoadResult=false, seqid=20612, majorCompaction=false
2014-07-14 02:40:47,443 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/79703c39e24448a892c0cd3490297877, isReference=false, isBulkLoadResult=false, seqid=21559, majorCompaction=false
2014-07-14 02:40:47,478 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/90b07a2c4f1c4c64a62fc70554fa2489, isReference=false, isBulkLoadResult=false, seqid=14614, majorCompaction=false
2014-07-14 02:40:47,486 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/91f58a2baea147a2baf4ba572e799623, isReference=false, isBulkLoadResult=false, seqid=21946, majorCompaction=false
2014-07-14 02:40:47,521 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/9c7dddb0e19e4ef9826c7c68f4314e3a, isReference=false, isBulkLoadResult=false, seqid=6698, majorCompaction=false
2014-07-14 02:40:47,536 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/a4c11f9bb048411ba514f167323a4abb, isReference=false, isBulkLoadResult=false, seqid=17542, majorCompaction=false
2014-07-14 02:40:47,559 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/b9f5252e887f4eff879f138ac984a536, isReference=false, isBulkLoadResult=false, seqid=7741, majorCompaction=false
2014-07-14 02:40:47,586 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/bbadbdbaf13c4247a779b3e00f7bfe2b, isReference=false, isBulkLoadResult=false, seqid=15308, majorCompaction=false
2014-07-14 02:40:47,606 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/ce0808e0b2a84502ac98109ebbf03f07, isReference=false, isBulkLoadResult=false, seqid=19221, majorCompaction=false
2014-07-14 02:40:47,632 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/d6a55640bb1a4a7facc36c65fbe4c8c9, isReference=false, isBulkLoadResult=false, seqid=16869, majorCompaction=false
2014-07-14 02:40:47,655 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/da763b8100124b8ea6cf6b74af843c83, isReference=false, isBulkLoadResult=false, seqid=15926, majorCompaction=false
2014-07-14 02:40:47,676 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/eb0e768a68f640b5acf6c73937dc89f9, isReference=false, isBulkLoadResult=false, seqid=13264, majorCompaction=false
2014-07-14 02:40:47,700 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f2286dd7c71f420cb684b8468134e246, isReference=false, isBulkLoadResult=false, seqid=5688, majorCompaction=false
2014-07-14 02:40:47,717 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/f45cecbc22104d4dbd33fa31c4b87aaa, isReference=false, isBulkLoadResult=false, seqid=19860, majorCompaction=false
2014-07-14 02:40:47,741 DEBUG [StoreOpener-c8a1d10978c87bbc043a64b1893a75b1-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1/family/fedd2aeb548f4f3f97d72500df542bb2, isReference=false, isBulkLoadResult=false, seqid=13724, majorCompaction=false
2014-07-14 02:40:47,745 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:40:47,747 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined c8a1d10978c87bbc043a64b1893a75b1; next sequenceid=21947
2014-07-14 02:40:47,747 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node c8a1d10978c87bbc043a64b1893a75b1
2014-07-14 02:40:47,749 INFO  [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:40:47,749 DEBUG [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-14 02:40:47,757 INFO  [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] catalog.MetaEditor: Updated row usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. with server=slave1,60020,1405330807068
2014-07-14 02:40:47,757 INFO  [PostOpenDeployTasks:c8a1d10978c87bbc043a64b1893a75b1] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:40:47,758 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8a1d10978c87bbc043a64b1893a75b1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,762 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8a1d10978c87bbc043a64b1893a75b1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:40:47,762 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned c8a1d10978c87bbc043a64b1893a75b1 to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:40:47,762 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. on slave1,60020,1405330807068
2014-07-14 02:40:51,259 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:40:51,259 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-14 02:40:51,260 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-14 02:40:51,260 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-14 02:41:13,973 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close 4d29ddafd3242e2ff279396a5cf1682c, via zk=yes, znode version=0, on null
2014-07-14 02:41:13,973 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close 3990157c1b6a259f95c53a0f0007d7bc, via zk=yes, znode version=0, on null
2014-07-14 02:41:13,973 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close c8a1d10978c87bbc043a64b1893a75b1, via zk=yes, znode version=0, on null
2014-07-14 02:41:13,973 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close f7644f9dbefce312f180da53011ffa5c, via zk=yes, znode version=0, on null
2014-07-14 02:41:13,973 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 018fa362abf2ec7a02c06683da5e76f5, via zk=yes, znode version=0, on null
2014-07-14 02:41:13,977 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:41:13,977 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:41:13,978 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:41:13,981 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.: disabling compactions & flushes
2014-07-14 02:41:13,981 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.: disabling compactions & flushes
2014-07-14 02:41:13,981 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: waiting for 1 compactions to complete for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:41:13,982 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.: disabling compactions & flushes
2014-07-14 02:41:13,982 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:41:13,982 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:41:14,031 INFO  [StoreCloserThread-usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.-1] regionserver.HStore: Closed family
2014-07-14 02:41:14,032 INFO  [StoreCloserThread-usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.-1] regionserver.HStore: Closed family
2014-07-14 02:41:14,034 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:41:14,034 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:41:14,034 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8a1d10978c87bbc043a64b1893a75b1 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,034 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 3990157c1b6a259f95c53a0f0007d7bc from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,038 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8a1d10978c87bbc043a64b1893a75b1 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,038 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. on slave1,60020,1405330807068
2014-07-14 02:41:14,038 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1.
2014-07-14 02:41:14,038 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:41:14,039 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 3990157c1b6a259f95c53a0f0007d7bc from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,039 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. on slave1,60020,1405330807068
2014-07-14 02:41:14,039 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc.
2014-07-14 02:41:14,040 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:41:14,040 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.: disabling compactions & flushes
2014-07-14 02:41:14,040 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:41:14,041 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.: disabling compactions & flushes
2014-07-14 02:41:14,041 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:41:14,042 INFO  [StoreCloserThread-usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.-1] regionserver.HStore: Closed family
2014-07-14 02:41:14,042 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:41:14,043 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 018fa362abf2ec7a02c06683da5e76f5 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,045 INFO  [StoreCloserThread-usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.-1] regionserver.HStore: Closed family
2014-07-14 02:41:14,046 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:41:14,046 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 018fa362abf2ec7a02c06683da5e76f5 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,046 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f7644f9dbefce312f180da53011ffa5c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,046 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5. on slave1,60020,1405330807068
2014-07-14 02:41:14,047 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,,1405328249400.018fa362abf2ec7a02c06683da5e76f5.
2014-07-14 02:41:14,050 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f7644f9dbefce312f180da53011ffa5c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,051 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. on slave1,60020,1405330807068
2014-07-14 02:41:14,051 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c.
2014-07-14 02:41:14,654 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: compaction interrupted
java.io.InterruptedIOException: Aborting compaction of store family in region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. because it was interrupted.
	at org.apache.hadoop.hbase.regionserver.compactions.DefaultCompactor.compact(DefaultCompactor.java:81)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreEngine$DefaultCompactionContext.compact(DefaultStoreEngine.java:109)
	at org.apache.hadoop.hbase.regionserver.HStore.compact(HStore.java:1086)
	at org.apache.hadoop.hbase.regionserver.HRegion.compact(HRegion.java:1481)
	at org.apache.hadoop.hbase.regionserver.CompactSplitThread$CompactionRunner.run(CompactSplitThread.java:475)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-14 02:41:14,655 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:41:14,659 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Aborted compaction: Request = regionName=usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c., storeName=family, fileCount=3, fileSize=285.2m (93.0m, 115.7m), priority=-2, time=284754541812671; duration=27sec
2014-07-14 02:41:14,659 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-14 02:41:14,660 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. because compaction request was cancelled
2014-07-14 02:41:14,660 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user3,1405328249400.3990157c1b6a259f95c53a0f0007d7bc. because compaction request was cancelled
2014-07-14 02:41:14,660 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. because compaction request was cancelled
2014-07-14 02:41:14,660 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. because compaction request was cancelled
2014-07-14 02:41:14,660 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user7,1405328249400.f7644f9dbefce312f180da53011ffa5c. because compaction request was cancelled
2014-07-14 02:41:14,661 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. because compaction request was cancelled
2014-07-14 02:41:14,661 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Not compacting usertable,user4,1405328249400.c8a1d10978c87bbc043a64b1893a75b1. because compaction request was cancelled
2014-07-14 02:41:14,663 INFO  [StoreCloserThread-usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.-1] regionserver.HStore: Closed family
2014-07-14 02:41:14,664 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:41:14,664 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 4d29ddafd3242e2ff279396a5cf1682c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,668 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 4d29ddafd3242e2ff279396a5cf1682c from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-14 02:41:14,668 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c. on slave1,60020,1405330807068
2014-07-14 02:41:14,668 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user6,1405328249400.4d29ddafd3242e2ff279396a5cf1682c.
2014-07-14 02:45:07,159 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=11619, hits=4328, hitRatio=37.24%, , cachingAccesses=4332, cachingHits=4327, cachingHitsRatio=99.88%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-14 02:46:25,436 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:46:25,449 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:46:25,449 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5cdea4a8c4f1b79cac96dfb3d518efe1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,449 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:46:25,450 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:46:25,450 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f874ab9cace3c84c3e27af574e5b4d27 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,450 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fd2af1df8ba9259ec0c538eeceae443e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,450 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b.
2014-07-14 02:46:25,482 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5cdea4a8c4f1b79cac96dfb3d518efe1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,483 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 5cdea4a8c4f1b79cac96dfb3d518efe1, NAME => 'usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-14 02:46:25,483 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f874ab9cace3c84c3e27af574e5b4d27 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,484 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fd2af1df8ba9259ec0c538eeceae443e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,484 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => f874ab9cace3c84c3e27af574e5b4d27, NAME => 'usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-14 02:46:25,484 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 02:46:25,484 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => fd2af1df8ba9259ec0c538eeceae443e, NAME => 'usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-14 02:46:25,485 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:46:25,485 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 02:46:25,485 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 02:46:25,485 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:46:25,486 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:46:25,498 INFO  [StoreOpener-f874ab9cace3c84c3e27af574e5b4d27-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 02:46:25,499 INFO  [StoreOpener-5cdea4a8c4f1b79cac96dfb3d518efe1-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 02:46:25,501 INFO  [StoreOpener-fd2af1df8ba9259ec0c538eeceae443e-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 02:46:25,504 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 02:46:25,505 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 02:46:25,506 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 02:46:25,507 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined f874ab9cace3c84c3e27af574e5b4d27; next sequenceid=1
2014-07-14 02:46:25,507 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 02:46:25,508 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 5cdea4a8c4f1b79cac96dfb3d518efe1; next sequenceid=1
2014-07-14 02:46:25,508 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 02:46:25,509 INFO  [PostOpenDeployTasks:5cdea4a8c4f1b79cac96dfb3d518efe1] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:46:25,509 INFO  [PostOpenDeployTasks:f874ab9cace3c84c3e27af574e5b4d27] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:46:25,519 INFO  [PostOpenDeployTasks:f874ab9cace3c84c3e27af574e5b4d27] catalog.MetaEditor: Updated row usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. with server=slave1,60020,1405330807068
2014-07-14 02:46:25,519 INFO  [PostOpenDeployTasks:f874ab9cace3c84c3e27af574e5b4d27] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:46:25,519 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning f874ab9cace3c84c3e27af574e5b4d27 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,520 INFO  [PostOpenDeployTasks:5cdea4a8c4f1b79cac96dfb3d518efe1] catalog.MetaEditor: Updated row usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. with server=slave1,60020,1405330807068
2014-07-14 02:46:25,520 INFO  [PostOpenDeployTasks:5cdea4a8c4f1b79cac96dfb3d518efe1] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:46:25,520 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5cdea4a8c4f1b79cac96dfb3d518efe1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,523 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node f874ab9cace3c84c3e27af574e5b4d27 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,523 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned f874ab9cace3c84c3e27af574e5b4d27 to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:46:25,523 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. on slave1,60020,1405330807068
2014-07-14 02:46:25,523 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 7f4e87d2eea7a637326e2204c730bf5a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,523 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5cdea4a8c4f1b79cac96dfb3d518efe1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,524 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 5cdea4a8c4f1b79cac96dfb3d518efe1 to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:46:25,524 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. on slave1,60020,1405330807068
2014-07-14 02:46:25,524 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e09ff48a9fe69e3f6c8e6a97470cf37b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,528 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 7f4e87d2eea7a637326e2204c730bf5a from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,528 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e09ff48a9fe69e3f6c8e6a97470cf37b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-14 02:46:25,528 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 7f4e87d2eea7a637326e2204c730bf5a, NAME => 'usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-14 02:46:25,528 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => e09ff48a9fe69e3f6c8e6a97470cf37b, NAME => 'usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-14 02:46:25,529 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 02:46:25,529 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:46:25,529 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable e09ff48a9fe69e3f6c8e6a97470cf37b
2014-07-14 02:46:25,529 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b.
2014-07-14 02:46:25,531 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined fd2af1df8ba9259ec0c538eeceae443e; next sequenceid=1
2014-07-14 02:46:25,531 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 02:46:25,532 INFO  [PostOpenDeployTasks:fd2af1df8ba9259ec0c538eeceae443e] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:46:25,539 INFO  [PostOpenDeployTasks:fd2af1df8ba9259ec0c538eeceae443e] catalog.MetaEditor: Updated row usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. with server=slave1,60020,1405330807068
2014-07-14 02:46:25,539 INFO  [PostOpenDeployTasks:fd2af1df8ba9259ec0c538eeceae443e] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:46:25,540 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fd2af1df8ba9259ec0c538eeceae443e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,540 INFO  [StoreOpener-e09ff48a9fe69e3f6c8e6a97470cf37b-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 02:46:25,543 INFO  [StoreOpener-7f4e87d2eea7a637326e2204c730bf5a-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-14 02:46:25,545 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fd2af1df8ba9259ec0c538eeceae443e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,545 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned fd2af1df8ba9259ec0c538eeceae443e to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:46:25,545 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. on slave1,60020,1405330807068
2014-07-14 02:46:25,548 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/e09ff48a9fe69e3f6c8e6a97470cf37b
2014-07-14 02:46:25,549 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 02:46:25,550 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined e09ff48a9fe69e3f6c8e6a97470cf37b; next sequenceid=1
2014-07-14 02:46:25,550 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e09ff48a9fe69e3f6c8e6a97470cf37b
2014-07-14 02:46:25,552 INFO  [PostOpenDeployTasks:e09ff48a9fe69e3f6c8e6a97470cf37b] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b.
2014-07-14 02:46:25,558 INFO  [PostOpenDeployTasks:e09ff48a9fe69e3f6c8e6a97470cf37b] catalog.MetaEditor: Updated row usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b. with server=slave1,60020,1405330807068
2014-07-14 02:46:25,558 INFO  [PostOpenDeployTasks:e09ff48a9fe69e3f6c8e6a97470cf37b] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b.
2014-07-14 02:46:25,558 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e09ff48a9fe69e3f6c8e6a97470cf37b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,580 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e09ff48a9fe69e3f6c8e6a97470cf37b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,580 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned e09ff48a9fe69e3f6c8e6a97470cf37b to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:46:25,581 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,,1405331185400.e09ff48a9fe69e3f6c8e6a97470cf37b. on slave1,60020,1405330807068
2014-07-14 02:46:25,589 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 7f4e87d2eea7a637326e2204c730bf5a; next sequenceid=1
2014-07-14 02:46:25,589 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 02:46:25,592 INFO  [PostOpenDeployTasks:7f4e87d2eea7a637326e2204c730bf5a] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:46:25,601 INFO  [PostOpenDeployTasks:7f4e87d2eea7a637326e2204c730bf5a] catalog.MetaEditor: Updated row usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. with server=slave1,60020,1405330807068
2014-07-14 02:46:25,601 INFO  [PostOpenDeployTasks:7f4e87d2eea7a637326e2204c730bf5a] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:46:25,602 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 7f4e87d2eea7a637326e2204c730bf5a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,609 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x147343e59c80000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 7f4e87d2eea7a637326e2204c730bf5a from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-14 02:46:25,609 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 7f4e87d2eea7a637326e2204c730bf5a to OPENED in zk on slave1,60020,1405330807068
2014-07-14 02:46:25,609 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. on slave1,60020,1405330807068
2014-07-14 02:46:44,228 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:44,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80 synced till here 73
2014-07-14 02:46:44,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405330841123 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331204229
2014-07-14 02:46:46,114 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:46,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 164 synced till here 151
2014-07-14 02:46:46,576 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331204229 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331206114
2014-07-14 02:46:48,040 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:48,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 242 synced till here 238
2014-07-14 02:46:48,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331206114 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331208040
2014-07-14 02:46:50,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:50,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 335 synced till here 322
2014-07-14 02:46:50,812 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331208040 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331210461
2014-07-14 02:46:53,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:53,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 448 synced till here 416
2014-07-14 02:46:54,349 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331210461 with entries=113, filesize=97.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331213218
2014-07-14 02:46:56,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:56,463 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 553 synced till here 539
2014-07-14 02:46:56,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331213218 with entries=105, filesize=89.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331216189
2014-07-14 02:46:57,910 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:46:57,996 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 265.5m
2014-07-14 02:46:58,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:46:58,501 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:46:58,502 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 259.6m
2014-07-14 02:46:58,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 664 synced till here 644
2014-07-14 02:46:59,029 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331216189 with entries=111, filesize=95.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331218482
2014-07-14 02:46:59,210 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:00,151 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:47:01,005 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:01,011 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-14 02:47:01,412 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:01,441 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:47:01,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 777 synced till here 768
2014-07-14 02:47:01,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331218482 with entries=113, filesize=97.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331221413
2014-07-14 02:47:03,076 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:03,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 871 synced till here 856
2014-07-14 02:47:03,663 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331221413 with entries=94, filesize=80.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331223076
2014-07-14 02:47:05,388 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:05,417 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331223076 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331225388
2014-07-14 02:47:06,952 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=183, memsize=74.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1a32e30fe19f45a791426e4911167793
2014-07-14 02:47:06,966 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1a32e30fe19f45a791426e4911167793 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1a32e30fe19f45a791426e4911167793
2014-07-14 02:47:06,991 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1a32e30fe19f45a791426e4911167793, entries=271820, sequenceid=183, filesize=19.4m
2014-07-14 02:47:06,991 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~281.0m/294628480, currentsize=115.1m/120726080 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 8995ms, sequenceid=183, compaction requested=false
2014-07-14 02:47:06,996 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 388.5m
2014-07-14 02:47:07,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:07,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1022 synced till here 1016
2014-07-14 02:47:07,416 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331225388 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331227265
2014-07-14 02:47:07,923 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:07,952 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=182, memsize=74.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/7fe7bcc4d80e420bbd478376e6d3b46a
2014-07-14 02:47:07,976 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/7fe7bcc4d80e420bbd478376e6d3b46a as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/7fe7bcc4d80e420bbd478376e6d3b46a
2014-07-14 02:47:08,108 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/7fe7bcc4d80e420bbd478376e6d3b46a, entries=271890, sequenceid=182, filesize=19.4m
2014-07-14 02:47:08,109 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~278.2m/291764800, currentsize=130.2m/136554400 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9607ms, sequenceid=182, compaction requested=false
2014-07-14 02:47:08,111 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 405.0m
2014-07-14 02:47:09,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:09,162 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:10,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1148 synced till here 1139
2014-07-14 02:47:11,023 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331227265 with entries=126, filesize=107.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331229139
2014-07-14 02:47:12,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:12,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1226 synced till here 1220
2014-07-14 02:47:12,935 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331229139 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331232623
2014-07-14 02:47:14,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:14,999 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1325 synced till here 1307
2014-07-14 02:47:15,631 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331232623 with entries=99, filesize=84.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331234810
2014-07-14 02:47:16,235 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:47:17,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:17,561 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:47:17,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1431 synced till here 1414
2014-07-14 02:47:18,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331234810 with entries=106, filesize=89.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331237560
2014-07-14 02:47:18,684 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=252, memsize=90.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/648e953868834daf96b624fe29e9c657
2014-07-14 02:47:18,701 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/648e953868834daf96b624fe29e9c657 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/648e953868834daf96b624fe29e9c657
2014-07-14 02:47:18,716 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/648e953868834daf96b624fe29e9c657, entries=328710, sequenceid=252, filesize=23.4m
2014-07-14 02:47:18,717 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~390.0m/408907360, currentsize=146.4m/153505840 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 11721ms, sequenceid=252, compaction requested=false
2014-07-14 02:47:18,717 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 303.3m
2014-07-14 02:47:20,158 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:20,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:20,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1530 synced till here 1510
2014-07-14 02:47:21,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331237560 with entries=99, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331240454
2014-07-14 02:47:23,122 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=263, memsize=98.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8bc99d5c88a04f3fa7b5b2e7c8564f54
2014-07-14 02:47:23,147 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8bc99d5c88a04f3fa7b5b2e7c8564f54 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8bc99d5c88a04f3fa7b5b2e7c8564f54
2014-07-14 02:47:23,166 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8bc99d5c88a04f3fa7b5b2e7c8564f54, entries=356960, sequenceid=263, filesize=25.4m
2014-07-14 02:47:23,167 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~405.0m/424714240, currentsize=181.3m/190086320 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 15057ms, sequenceid=263, compaction requested=false
2014-07-14 02:47:23,168 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 334.7m
2014-07-14 02:47:23,783 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:24,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1650 synced till here 1637
2014-07-14 02:47:24,672 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331240454 with entries=120, filesize=102.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331243783
2014-07-14 02:47:24,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405330841123
2014-07-14 02:47:24,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331204229
2014-07-14 02:47:24,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331206114
2014-07-14 02:47:24,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331208040
2014-07-14 02:47:24,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331210461
2014-07-14 02:47:24,673 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331213218
2014-07-14 02:47:25,083 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:25,777 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:47:26,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:26,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1764 synced till here 1731
2014-07-14 02:47:27,269 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:47:27,274 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331243783 with entries=114, filesize=97.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331246598
2014-07-14 02:47:28,836 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:28,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1871 synced till here 1847
2014-07-14 02:47:30,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331246598 with entries=107, filesize=90.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331248837
2014-07-14 02:47:32,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:33,020 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1977 synced till here 1976
2014-07-14 02:47:33,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331248837 with entries=106, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331252812
2014-07-14 02:47:34,184 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=390, memsize=143.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/e2b2a83498384244a45f7601b8c4103e
2014-07-14 02:47:34,278 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/e2b2a83498384244a45f7601b8c4103e as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e2b2a83498384244a45f7601b8c4103e
2014-07-14 02:47:34,346 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e2b2a83498384244a45f7601b8c4103e, entries=523950, sequenceid=390, filesize=37.3m
2014-07-14 02:47:34,346 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~318.6m/334055440, currentsize=222.3m/233096160 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 15629ms, sequenceid=390, compaction requested=false
2014-07-14 02:47:34,346 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 388.6m
2014-07-14 02:47:35,319 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:36,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:36,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2099 synced till here 2092
2014-07-14 02:47:36,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331252812 with entries=122, filesize=104.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331256074
2014-07-14 02:47:36,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331216189
2014-07-14 02:47:37,666 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=419, memsize=144.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/bef32264e9dc470c90cd04e798dcde9c
2014-07-14 02:47:37,769 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/bef32264e9dc470c90cd04e798dcde9c as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/bef32264e9dc470c90cd04e798dcde9c
2014-07-14 02:47:37,886 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/bef32264e9dc470c90cd04e798dcde9c, entries=526000, sequenceid=419, filesize=37.5m
2014-07-14 02:47:37,886 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~365.5m/383279840, currentsize=183.9m/192813120 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 14719ms, sequenceid=419, compaction requested=false
2014-07-14 02:47:37,887 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 373.7m
2014-07-14 02:47:39,261 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:39,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:39,274 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:47:39,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2241 synced till here 2239
2014-07-14 02:47:40,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331256074 with entries=142, filesize=121.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331259274
2014-07-14 02:47:40,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331218482
2014-07-14 02:47:40,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331221413
2014-07-14 02:47:40,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331223076
2014-07-14 02:47:41,733 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=507, memsize=90.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/b30c1f35718b487080e1fa380ad62cfe
2014-07-14 02:47:41,746 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/b30c1f35718b487080e1fa380ad62cfe as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b30c1f35718b487080e1fa380ad62cfe
2014-07-14 02:47:41,757 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b30c1f35718b487080e1fa380ad62cfe, entries=328710, sequenceid=507, filesize=23.4m
2014-07-14 02:47:41,757 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~391.7m/410676560, currentsize=89.2m/93548320 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 7411ms, sequenceid=507, compaction requested=false
2014-07-14 02:47:41,758 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 261.9m
2014-07-14 02:47:41,990 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:43,525 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=514, memsize=77.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/5ca23f83027a4ccfb98498c143b9b897
2014-07-14 02:47:43,538 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/5ca23f83027a4ccfb98498c143b9b897 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5ca23f83027a4ccfb98498c143b9b897
2014-07-14 02:47:43,547 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5ca23f83027a4ccfb98498c143b9b897, entries=282380, sequenceid=514, filesize=20.1m
2014-07-14 02:47:43,548 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~384.6m/403321680, currentsize=80.7m/84592160 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 5661ms, sequenceid=514, compaction requested=false
2014-07-14 02:47:44,805 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=563, memsize=55.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/6e84730f3d1b441ea7cb38b89aafbb81
2014-07-14 02:47:44,825 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/6e84730f3d1b441ea7cb38b89aafbb81 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6e84730f3d1b441ea7cb38b89aafbb81
2014-07-14 02:47:44,842 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6e84730f3d1b441ea7cb38b89aafbb81, entries=201160, sequenceid=563, filesize=14.3m
2014-07-14 02:47:44,842 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.9m/274595360, currentsize=21.7m/22748480 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 3084ms, sequenceid=563, compaction requested=true
2014-07-14 02:47:44,843 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-14 02:47:44,843 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 02:47:44,843 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 74458779 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 02:47:44,843 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating major compaction
2014-07-14 02:47:44,844 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:47:44,844 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=71.0m
2014-07-14 02:47:44,844 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1a32e30fe19f45a791426e4911167793, keycount=27182, bloomtype=ROW, size=19.4m, encoding=NONE, seqNum=183, earliestPutTs=1405331203944
2014-07-14 02:47:44,844 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e2b2a83498384244a45f7601b8c4103e, keycount=52395, bloomtype=ROW, size=37.3m, encoding=NONE, seqNum=390, earliestPutTs=1405331222479
2014-07-14 02:47:44,844 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6e84730f3d1b441ea7cb38b89aafbb81, keycount=20116, bloomtype=ROW, size=14.3m, encoding=NONE, seqNum=563, earliestPutTs=1405331252995
2014-07-14 02:47:44,859 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:45,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:45,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2314 synced till here 2312
2014-07-14 02:47:45,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331259274 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331265343
2014-07-14 02:47:45,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331225388
2014-07-14 02:47:45,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331227265
2014-07-14 02:47:45,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331229139
2014-07-14 02:47:45,459 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331232623
2014-07-14 02:47:45,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331234810
2014-07-14 02:47:45,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331237560
2014-07-14 02:47:45,612 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:47:45,613 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 257.2m
2014-07-14 02:47:45,966 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:47,075 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:47,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2387 synced till here 2385
2014-07-14 02:47:47,121 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331265343 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331267075
2014-07-14 02:47:49,217 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:49,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2464 synced till here 2460
2014-07-14 02:47:49,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331267075 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331269217
2014-07-14 02:47:50,948 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:51,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2542 synced till here 2535
2014-07-14 02:47:51,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331269217 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331270949
2014-07-14 02:47:52,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:52,814 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=586, memsize=74.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f232aca1a3bb47f09dc4dbfb150d0861
2014-07-14 02:47:52,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2621 synced till here 2613
2014-07-14 02:47:52,923 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f232aca1a3bb47f09dc4dbfb150d0861 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f232aca1a3bb47f09dc4dbfb150d0861
2014-07-14 02:47:52,957 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f232aca1a3bb47f09dc4dbfb150d0861, entries=272440, sequenceid=586, filesize=19.4m
2014-07-14 02:47:52,958 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.7m/271272960, currentsize=114.5m/120092240 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 7345ms, sequenceid=586, compaction requested=true
2014-07-14 02:47:52,959 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 02:47:53,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331270949 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331272801
2014-07-14 02:47:53,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331240454
2014-07-14 02:47:53,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331243783
2014-07-14 02:47:53,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331246598
2014-07-14 02:47:53,121 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331248837
2014-07-14 02:47:54,086 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:47:54,094 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.1m
2014-07-14 02:47:54,419 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:54,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2696 synced till here 2695
2014-07-14 02:47:54,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331272801 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331274419
2014-07-14 02:47:54,739 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:55,216 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:47:55,221 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 258.2m
2014-07-14 02:47:55,806 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:47:55,946 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-14 02:47:55,946 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-14 02:47:56,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:56,267 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2774 synced till here 2770
2014-07-14 02:47:56,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331274419 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331276239
2014-07-14 02:47:58,192 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:47:58,719 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:48:01,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2964 synced till here 2953
2014-07-14 02:48:01,296 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331276239 with entries=190, filesize=162.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331278192
2014-07-14 02:48:01,613 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:48:02,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:03,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3051 synced till here 3042
2014-07-14 02:48:03,223 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331278192 with entries=87, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331282880
2014-07-14 02:48:03,457 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1dae241a1e124bad962841fd6ff124c4 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1dae241a1e124bad962841fd6ff124c4
2014-07-14 02:48:03,605 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:48:03,700 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1a32e30fe19f45a791426e4911167793, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1a32e30fe19f45a791426e4911167793
2014-07-14 02:48:03,704 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e2b2a83498384244a45f7601b8c4103e, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e2b2a83498384244a45f7601b8c4103e
2014-07-14 02:48:03,709 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6e84730f3d1b441ea7cb38b89aafbb81, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6e84730f3d1b441ea7cb38b89aafbb81
2014-07-14 02:48:03,709 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 1dae241a1e124bad962841fd6ff124c4(size=44.7m), total size for store is 44.7m. This selection was in queue for 0sec, and took 18sec to execute.
2014-07-14 02:48:03,710 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=3, fileSize=71.0m, priority=17, time=285172270771784; duration=18sec
2014-07-14 02:48:03,710 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 02:48:03,710 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 02:48:03,711 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 79946921 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 02:48:03,711 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating major compaction
2014-07-14 02:48:03,711 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:48:03,712 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=76.2m
2014-07-14 02:48:03,712 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/7fe7bcc4d80e420bbd478376e6d3b46a, keycount=27189, bloomtype=ROW, size=19.4m, encoding=NONE, seqNum=182, earliestPutTs=1405331204376
2014-07-14 02:48:03,712 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/bef32264e9dc470c90cd04e798dcde9c, keycount=52600, bloomtype=ROW, size=37.5m, encoding=NONE, seqNum=419, earliestPutTs=1405331223216
2014-07-14 02:48:03,712 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f232aca1a3bb47f09dc4dbfb150d0861, keycount=27244, bloomtype=ROW, size=19.4m, encoding=NONE, seqNum=586, earliestPutTs=1405331256082
2014-07-14 02:48:03,730 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:48:04,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:04,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3126 synced till here 3124
2014-07-14 02:48:04,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331282880 with entries=75, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331284707
2014-07-14 02:48:06,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:06,925 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3201 synced till here 3199
2014-07-14 02:48:06,968 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331284707 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331286809
2014-07-14 02:48:07,883 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=678, memsize=160.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/17f290ffcb2449ea8b05165858025c28
2014-07-14 02:48:07,905 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/17f290ffcb2449ea8b05165858025c28 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/17f290ffcb2449ea8b05165858025c28
2014-07-14 02:48:07,919 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/17f290ffcb2449ea8b05165858025c28, entries=584410, sequenceid=678, filesize=41.7m
2014-07-14 02:48:07,920 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.1m/277976160, currentsize=207.4m/217509520 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 13826ms, sequenceid=678, compaction requested=true
2014-07-14 02:48:07,920 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-14 02:48:07,921 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 391.2m
2014-07-14 02:48:08,687 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:08,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3280 synced till here 3270
2014-07-14 02:48:08,865 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:48:09,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331286809 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331288688
2014-07-14 02:48:09,030 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331252812
2014-07-14 02:48:09,059 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=683, memsize=160.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/037eaec61bd84683b65a304964101bf7
2014-07-14 02:48:09,169 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/037eaec61bd84683b65a304964101bf7 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/037eaec61bd84683b65a304964101bf7
2014-07-14 02:48:09,185 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/037eaec61bd84683b65a304964101bf7, entries=585310, sequenceid=683, filesize=41.7m
2014-07-14 02:48:09,185 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.6m/272257200, currentsize=209.2m/219388880 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 13964ms, sequenceid=683, compaction requested=true
2014-07-14 02:48:09,186 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:48:09,186 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 374.4m
2014-07-14 02:48:10,291 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:48:10,585 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:10,616 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:48:10,623 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3358 synced till here 3354
2014-07-14 02:48:10,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331288688 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331290585
2014-07-14 02:48:10,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331256074
2014-07-14 02:48:11,540 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:48:12,657 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:12,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3447 synced till here 3432
2014-07-14 02:48:13,205 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331290585 with entries=89, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331292794
2014-07-14 02:48:15,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:15,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3542 synced till here 3521
2014-07-14 02:48:15,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331292794 with entries=95, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331295375
2014-07-14 02:48:17,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:18,082 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3656 synced till here 3624
2014-07-14 02:48:20,268 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331295375 with entries=114, filesize=97.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331297809
2014-07-14 02:48:21,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:21,698 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3744 synced till here 3728
2014-07-14 02:48:22,210 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331297809 with entries=88, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331301571
2014-07-14 02:48:23,324 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/d626dd1b76104a24abb0748dee66cd9c as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d626dd1b76104a24abb0748dee66cd9c
2014-07-14 02:48:23,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:23,503 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3827 synced till here 3816
2014-07-14 02:48:23,697 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:48:23,709 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/7fe7bcc4d80e420bbd478376e6d3b46a, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/7fe7bcc4d80e420bbd478376e6d3b46a
2014-07-14 02:48:23,711 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331301571 with entries=83, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331303485
2014-07-14 02:48:23,714 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/bef32264e9dc470c90cd04e798dcde9c, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/bef32264e9dc470c90cd04e798dcde9c
2014-07-14 02:48:23,716 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f232aca1a3bb47f09dc4dbfb150d0861, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f232aca1a3bb47f09dc4dbfb150d0861
2014-07-14 02:48:23,717 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into d626dd1b76104a24abb0748dee66cd9c(size=49.7m), total size for store is 49.7m. This selection was in queue for 0sec, and took 20sec to execute.
2014-07-14 02:48:23,717 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=3, fileSize=76.2m, priority=17, time=285191138166200; duration=20sec
2014-07-14 02:48:23,717 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:48:23,717 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 02:48:23,718 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 92861084 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 02:48:23,718 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating major compaction
2014-07-14 02:48:23,718 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:48:23,718 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=88.6m
2014-07-14 02:48:23,720 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/648e953868834daf96b624fe29e9c657, keycount=32871, bloomtype=ROW, size=23.4m, encoding=NONE, seqNum=252, earliestPutTs=1405331204584
2014-07-14 02:48:23,721 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b30c1f35718b487080e1fa380ad62cfe, keycount=32871, bloomtype=ROW, size=23.4m, encoding=NONE, seqNum=507, earliestPutTs=1405331227103
2014-07-14 02:48:23,721 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/17f290ffcb2449ea8b05165858025c28, keycount=58441, bloomtype=ROW, size=41.7m, encoding=NONE, seqNum=678, earliestPutTs=1405331259716
2014-07-14 02:48:23,844 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:48:25,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:25,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3908 synced till here 3901
2014-07-14 02:48:25,678 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331303485 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331305290
2014-07-14 02:48:26,980 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=830, memsize=210.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f8de731a992241b1bbb82cad9638052b
2014-07-14 02:48:27,003 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f8de731a992241b1bbb82cad9638052b as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f8de731a992241b1bbb82cad9638052b
2014-07-14 02:48:27,042 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f8de731a992241b1bbb82cad9638052b, entries=765950, sequenceid=830, filesize=54.6m
2014-07-14 02:48:27,043 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~379.0m/397412400, currentsize=255.7m/268103280 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 17857ms, sequenceid=830, compaction requested=false
2014-07-14 02:48:27,043 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 486.8m
2014-07-14 02:48:27,360 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:48:27,990 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:28,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4001 synced till here 3986
2014-07-14 02:48:28,320 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=821, memsize=236.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/2e2461d2993e43ad8da095e02136a5fd
2014-07-14 02:48:28,336 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/2e2461d2993e43ad8da095e02136a5fd as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/2e2461d2993e43ad8da095e02136a5fd
2014-07-14 02:48:28,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331305290 with entries=93, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331307991
2014-07-14 02:48:28,501 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/2e2461d2993e43ad8da095e02136a5fd, entries=860550, sequenceid=821, filesize=61.3m
2014-07-14 02:48:28,502 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~397.6m/416911360, currentsize=301.0m/315581760 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 20581ms, sequenceid=821, compaction requested=false
2014-07-14 02:48:28,502 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 485.7m
2014-07-14 02:48:29,019 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:48:29,033 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:48:30,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:30,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4092 synced till here 4073
2014-07-14 02:48:30,453 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:48:30,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331307991 with entries=91, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331310132
2014-07-14 02:48:30,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331259274
2014-07-14 02:48:30,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331265343
2014-07-14 02:48:30,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331267075
2014-07-14 02:48:30,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331269217
2014-07-14 02:48:30,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331270949
2014-07-14 02:48:30,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331272801
2014-07-14 02:48:32,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:32,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4190 synced till here 4175
2014-07-14 02:48:32,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331310132 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331312588
2014-07-14 02:48:34,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:34,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4278 synced till here 4268
2014-07-14 02:48:34,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331312588 with entries=88, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331314653
2014-07-14 02:48:36,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:36,616 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4363 synced till here 4350
2014-07-14 02:48:37,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331314653 with entries=85, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331316587
2014-07-14 02:48:39,376 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:39,581 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4474 synced till here 4445
2014-07-14 02:48:40,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331316587 with entries=111, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331319376
2014-07-14 02:48:42,558 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:42,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4584 synced till here 4548
2014-07-14 02:48:43,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331319376 with entries=110, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331322558
2014-07-14 02:48:45,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:47,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4737 synced till here 4711
2014-07-14 02:48:47,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331322558 with entries=153, filesize=131.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331325538
2014-07-14 02:48:50,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:50,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4834 synced till here 4816
2014-07-14 02:48:50,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331325538 with entries=97, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331330243
2014-07-14 02:48:52,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:48:52,464 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4936 synced till here 4913
2014-07-14 02:48:52,797 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331330243 with entries=102, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331332435
2014-07-14 02:49:08,075 WARN  [regionserver60020] util.Sleeper: We slept 15241ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-14 02:49:08,112 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13708ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=14099ms
2014-07-14 02:49:08,157 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=996, memsize=189.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/b0b4c39d38a1483aa27b9f069c27a514
2014-07-14 02:49:08,174 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/b0b4c39d38a1483aa27b9f069c27a514 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b0b4c39d38a1483aa27b9f069c27a514
2014-07-14 02:49:08,189 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b0b4c39d38a1483aa27b9f069c27a514, entries=688300, sequenceid=996, filesize=49.1m
2014-07-14 02:49:08,189 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~491.5m/515411440, currentsize=392.5m/411545440 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 41146ms, sequenceid=996, compaction requested=false
2014-07-14 02:49:08,190 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 648.9m
2014-07-14 02:49:08,336 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16645,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331331646,"queuetimems":91,"class":"HRegionServer","responsesize":15651,"method":"Multi"}
2014-07-14 02:49:08,336 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16536,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331331672,"queuetimems":0,"class":"HRegionServer","responsesize":15607,"method":"Multi"}
2014-07-14 02:49:08,336 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16768,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331331524,"queuetimems":0,"class":"HRegionServer","responsesize":15700,"method":"Multi"}
2014-07-14 02:49:08,336 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16799,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331331494,"queuetimems":0,"class":"HRegionServer","responsesize":15864,"method":"Multi"}
2014-07-14 02:49:08,337 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1888 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,338 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,338 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1889 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,339 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,339 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1890 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,339 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,339 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1887 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,339 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,430 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:08,430 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:49:08,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5019 synced till here 5009
2014-07-14 02:49:08,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331332435 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331348430
2014-07-14 02:49:08,775 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1005, memsize=194.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/b6fe1a212b9c4bd3a76bbf04946f76f2
2014-07-14 02:49:08,781 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15942,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331332838,"queuetimems":0,"class":"HRegionServer","responsesize":15867,"method":"Multi"}
2014-07-14 02:49:08,781 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1893 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,781 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,801 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/b6fe1a212b9c4bd3a76bbf04946f76f2 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b6fe1a212b9c4bd3a76bbf04946f76f2
2014-07-14 02:49:08,871 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15842,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333029,"queuetimems":0,"class":"HRegionServer","responsesize":15729,"method":"Multi"}
2014-07-14 02:49:08,871 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15522,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333349,"queuetimems":0,"class":"HRegionServer","responsesize":15968,"method":"Multi"}
2014-07-14 02:49:08,872 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1902 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,872 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,872 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1899 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,872 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:08,873 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15988,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331332885,"queuetimems":0,"class":"HRegionServer","responsesize":15503,"method":"Multi"}
2014-07-14 02:49:08,874 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1903 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:08,874 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,118 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:09,328 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b6fe1a212b9c4bd3a76bbf04946f76f2, entries=708460, sequenceid=1005, filesize=50.5m
2014-07-14 02:49:09,329 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~499.5m/523745920, currentsize=384.1m/402728400 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 40827ms, sequenceid=1005, compaction requested=true
2014-07-14 02:49:09,330 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:49:09,330 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 694.3m
2014-07-14 02:49:09,345 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:49:09,346 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15852,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333493,"queuetimems":2,"class":"HRegionServer","responsesize":15695,"method":"Multi"}
2014-07-14 02:49:09,346 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16105,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333240,"queuetimems":1,"class":"HRegionServer","responsesize":15844,"method":"Multi"}
2014-07-14 02:49:09,346 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1897 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,346 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,346 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16173,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333172,"queuetimems":1,"class":"HRegionServer","responsesize":16078,"method":"Multi"}
2014-07-14 02:49:09,346 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1900 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,347 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,347 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1901 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,347 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15919,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333522,"queuetimems":0,"class":"HRegionServer","responsesize":15479,"method":"Multi"}
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333942,"queuetimems":0,"class":"HRegionServer","responsesize":15507,"method":"Multi"}
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333874,"queuetimems":0,"class":"HRegionServer","responsesize":15673,"method":"Multi"}
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1919 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1896 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,442 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,443 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1907 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,443 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,443 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1905 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,443 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,443 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16058,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333384,"queuetimems":1,"class":"HRegionServer","responsesize":15879,"method":"Multi"}
2014-07-14 02:49:09,443 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1898 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,444 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,444 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15755,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333687,"queuetimems":0,"class":"HRegionServer","responsesize":16012,"method":"Multi"}
2014-07-14 02:49:09,444 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1894 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,444 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,445 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15882,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333563,"queuetimems":1,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15546,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333899,"queuetimems":1,"class":"HRegionServer","responsesize":16303,"method":"Multi"}
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1911 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1895 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1904 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,446 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,447 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15723,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47234","starttimems":1405331333723,"queuetimems":0,"class":"HRegionServer","responsesize":15520,"method":"Multi"}
2014-07-14 02:49:09,447 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1908 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,447 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: RpcServer.handler=39,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,448 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 1906 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.53:47234: output error
2014-07-14 02:49:09,448 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-14 02:49:09,937 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/c912ff6c1d9248189821a904f4541705 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c912ff6c1d9248189821a904f4541705
2014-07-14 02:49:09,949 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:49:09,955 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/648e953868834daf96b624fe29e9c657, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/648e953868834daf96b624fe29e9c657
2014-07-14 02:49:09,957 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b30c1f35718b487080e1fa380ad62cfe, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b30c1f35718b487080e1fa380ad62cfe
2014-07-14 02:49:09,959 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/17f290ffcb2449ea8b05165858025c28, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/17f290ffcb2449ea8b05165858025c28
2014-07-14 02:49:09,960 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into c912ff6c1d9248189821a904f4541705(size=71.9m), total size for store is 121.0m. This selection was in queue for 0sec, and took 46sec to execute.
2014-07-14 02:49:09,960 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=3, fileSize=88.6m, priority=17, time=285211144984396; duration=46sec
2014-07-14 02:49:09,960 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:49:09,960 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-14 02:49:09,960 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 144527935 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-14 02:49:09,961 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating major compaction
2014-07-14 02:49:09,961 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:49:09,961 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=137.8m
2014-07-14 02:49:09,961 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8bc99d5c88a04f3fa7b5b2e7c8564f54, keycount=35696, bloomtype=ROW, size=25.4m, encoding=NONE, seqNum=263, earliestPutTs=1405331205093
2014-07-14 02:49:09,962 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5ca23f83027a4ccfb98498c143b9b897, keycount=28238, bloomtype=ROW, size=20.1m, encoding=NONE, seqNum=514, earliestPutTs=1405331228610
2014-07-14 02:49:09,962 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/037eaec61bd84683b65a304964101bf7, keycount=58531, bloomtype=ROW, size=41.7m, encoding=NONE, seqNum=683, earliestPutTs=1405331259839
2014-07-14 02:49:09,962 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b6fe1a212b9c4bd3a76bbf04946f76f2, keycount=70846, bloomtype=ROW, size=50.5m, encoding=NONE, seqNum=1005, earliestPutTs=1405331275329
2014-07-14 02:49:10,007 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:10,170 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:12,121 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:12,154 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5097 synced till here 5094
2014-07-14 02:49:12,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331348430 with entries=78, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331352122
2014-07-14 02:49:12,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331274419
2014-07-14 02:49:12,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331276239
2014-07-14 02:49:12,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331278192
2014-07-14 02:49:12,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331282880
2014-07-14 02:49:12,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331284707
2014-07-14 02:49:13,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:13,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5173 synced till here 5169
2014-07-14 02:49:13,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331352122 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331353674
2014-07-14 02:49:15,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:15,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5248 synced till here 5246
2014-07-14 02:49:15,856 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331353674 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331355798
2014-07-14 02:49:17,415 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:17,436 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5324 synced till here 5320
2014-07-14 02:49:17,494 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331355798 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331357415
2014-07-14 02:49:19,152 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1258, memsize=135.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/e4eeffcb63aa46b4848d13f8460f6476
2014-07-14 02:49:19,170 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/e4eeffcb63aa46b4848d13f8460f6476 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/e4eeffcb63aa46b4848d13f8460f6476
2014-07-14 02:49:19,193 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/e4eeffcb63aa46b4848d13f8460f6476, entries=491940, sequenceid=1258, filesize=35.1m
2014-07-14 02:49:19,193 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~661.2m/693362240, currentsize=145.6m/152632720 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 11003ms, sequenceid=1258, compaction requested=true
2014-07-14 02:49:19,194 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-14 02:49:19,194 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 549.3m
2014-07-14 02:49:19,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:19,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5413 synced till here 5399
2014-07-14 02:49:19,429 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331357415 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331359273
2014-07-14 02:49:20,800 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:20,902 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:21,437 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1269, memsize=138.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/6dcdd3fe78c0443b8f2eecb6ddf64cb9
2014-07-14 02:49:21,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5527 synced till here 5519
2014-07-14 02:49:21,508 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/6dcdd3fe78c0443b8f2eecb6ddf64cb9 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6dcdd3fe78c0443b8f2eecb6ddf64cb9
2014-07-14 02:49:21,525 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331359273 with entries=114, filesize=97.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331360902
2014-07-14 02:49:21,525 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6dcdd3fe78c0443b8f2eecb6ddf64cb9, entries=504120, sequenceid=1269, filesize=35.9m
2014-07-14 02:49:21,526 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~695.9m/729678160, currentsize=192.5m/201886880 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 12196ms, sequenceid=1269, compaction requested=true
2014-07-14 02:49:21,526 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-14 02:49:21,527 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 581.1m
2014-07-14 02:49:23,033 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:23,234 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:23,272 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5628 synced till here 5608
2014-07-14 02:49:23,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331360902 with entries=101, filesize=86.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331363235
2014-07-14 02:49:23,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331286809
2014-07-14 02:49:23,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331288688
2014-07-14 02:49:23,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331290585
2014-07-14 02:49:23,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331292794
2014-07-14 02:49:23,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331295375
2014-07-14 02:49:23,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331297809
2014-07-14 02:49:23,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331301571
2014-07-14 02:49:23,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331303485
2014-07-14 02:49:24,565 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:49:24,716 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:49:26,404 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:27,008 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5791 synced till here 5752
2014-07-14 02:49:28,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331363235 with entries=163, filesize=139.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331366405
2014-07-14 02:49:29,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:30,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5893 synced till here 5870
2014-07-14 02:49:30,474 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331366405 with entries=102, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331369240
2014-07-14 02:49:32,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:32,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6000 synced till here 5975
2014-07-14 02:49:32,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331369240 with entries=107, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331372439
2014-07-14 02:49:34,834 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1353, memsize=130.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/430c8ee5eef64daeabe819e312420d47
2014-07-14 02:49:34,848 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/430c8ee5eef64daeabe819e312420d47 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/430c8ee5eef64daeabe819e312420d47
2014-07-14 02:49:34,859 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/430c8ee5eef64daeabe819e312420d47, entries=474990, sequenceid=1353, filesize=33.8m
2014-07-14 02:49:34,860 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~551.0m/577722800, currentsize=233.4m/244708800 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 15665ms, sequenceid=1353, compaction requested=true
2014-07-14 02:49:34,860 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:49:34,860 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 422.8m
2014-07-14 02:49:34,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:35,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6109 synced till here 6073
2014-07-14 02:49:35,257 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:49:35,326 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:35,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331372439 with entries=109, filesize=93.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331374929
2014-07-14 02:49:35,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331305290
2014-07-14 02:49:36,577 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1002ms
GC pool 'ParNew' had collection(s): count=1 time=1051ms
2014-07-14 02:49:37,280 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:37,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6220 synced till here 6186
2014-07-14 02:49:37,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331374929 with entries=111, filesize=94.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331377281
2014-07-14 02:49:40,583 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:40,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6325 synced till here 6299
2014-07-14 02:49:40,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331377281 with entries=105, filesize=89.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331380584
2014-07-14 02:49:42,790 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1387, memsize=167.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/0f65c65b64f640e892b5bb8d45d632c6
2014-07-14 02:49:42,805 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/0f65c65b64f640e892b5bb8d45d632c6 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0f65c65b64f640e892b5bb8d45d632c6
2014-07-14 02:49:42,874 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0f65c65b64f640e892b5bb8d45d632c6, entries=611020, sequenceid=1387, filesize=43.6m
2014-07-14 02:49:42,875 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~590.4m/619122960, currentsize=326.2m/342043840 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 21348ms, sequenceid=1387, compaction requested=false
2014-07-14 02:49:42,875 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 532.9m
2014-07-14 02:49:43,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:43,220 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:49:44,791 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:45,661 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6580 synced till here 6547
2014-07-14 02:49:46,589 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331380584 with entries=255, filesize=218.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331383219
2014-07-14 02:49:46,589 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331307991
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331310132
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331312588
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331314653
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331316587
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331319376
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331322558
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331325538
2014-07-14 02:49:46,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331330243
2014-07-14 02:49:47,223 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/5276c4b77b8f4900a09c186785a5a9f8 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5276c4b77b8f4900a09c186785a5a9f8
2014-07-14 02:49:47,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:47,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6679 synced till here 6660
2014-07-14 02:49:47,642 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:49:47,652 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8bc99d5c88a04f3fa7b5b2e7c8564f54, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8bc99d5c88a04f3fa7b5b2e7c8564f54
2014-07-14 02:49:47,659 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5ca23f83027a4ccfb98498c143b9b897, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5ca23f83027a4ccfb98498c143b9b897
2014-07-14 02:49:47,676 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331383219 with entries=99, filesize=80.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331387503
2014-07-14 02:49:47,682 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/037eaec61bd84683b65a304964101bf7, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/037eaec61bd84683b65a304964101bf7
2014-07-14 02:49:47,685 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b6fe1a212b9c4bd3a76bbf04946f76f2, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b6fe1a212b9c4bd3a76bbf04946f76f2
2014-07-14 02:49:47,685 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into 5276c4b77b8f4900a09c186785a5a9f8(size=113.2m), total size for store is 156.7m. This selection was in queue for 0sec, and took 37sec to execute.
2014-07-14 02:49:47,685 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=4, fileSize=137.8m, priority=16, time=285257387931727; duration=37sec
2014-07-14 02:49:47,686 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:49:47,686 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-14 02:49:47,686 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 162320822 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-14 02:49:47,686 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating major compaction
2014-07-14 02:49:47,686 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:49:47,687 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=154.8m
2014-07-14 02:49:47,687 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c912ff6c1d9248189821a904f4541705, keycount=100855, bloomtype=ROW, size=71.9m, encoding=NONE, seqNum=678, earliestPutTs=1405331204584
2014-07-14 02:49:47,687 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b0b4c39d38a1483aa27b9f069c27a514, keycount=68830, bloomtype=ROW, size=49.1m, encoding=NONE, seqNum=996, earliestPutTs=1405331274762
2014-07-14 02:49:47,687 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/430c8ee5eef64daeabe819e312420d47, keycount=47499, bloomtype=ROW, size=33.8m, encoding=NONE, seqNum=1353, earliestPutTs=1405331348737
2014-07-14 02:49:47,730 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:48,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:48,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6758 synced till here 6753
2014-07-14 02:49:49,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331387503 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331388950
2014-07-14 02:49:50,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:50,886 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1542, memsize=213.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/046eada7e7704b0fa35ec39861fecb86
2014-07-14 02:49:50,913 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/046eada7e7704b0fa35ec39861fecb86 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/046eada7e7704b0fa35ec39861fecb86
2014-07-14 02:49:50,926 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331388950 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331390884
2014-07-14 02:49:50,938 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/046eada7e7704b0fa35ec39861fecb86, entries=777890, sequenceid=1542, filesize=55.4m
2014-07-14 02:49:50,938 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~438.4m/459669360, currentsize=266.9m/279861520 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 16078ms, sequenceid=1542, compaction requested=true
2014-07-14 02:49:50,939 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-14 02:49:50,939 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 557.4m
2014-07-14 02:49:51,059 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:49:51,375 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:52,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:52,487 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331390884 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331392386
2014-07-14 02:49:52,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331332435
2014-07-14 02:49:54,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:54,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6975 synced till here 6974
2014-07-14 02:49:54,082 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331392386 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331394050
2014-07-14 02:49:55,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:55,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7054 synced till here 7047
2014-07-14 02:49:55,868 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331394050 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331395787
2014-07-14 02:49:56,801 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1647, memsize=211.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/279dedd8c48e43e1927dd330c83280e1
2014-07-14 02:49:56,821 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/279dedd8c48e43e1927dd330c83280e1 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/279dedd8c48e43e1927dd330c83280e1
2014-07-14 02:49:56,848 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/279dedd8c48e43e1927dd330c83280e1, entries=768750, sequenceid=1647, filesize=54.8m
2014-07-14 02:49:56,848 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~585.7m/614175440, currentsize=213.0m/223311760 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 13973ms, sequenceid=1647, compaction requested=true
2014-07-14 02:49:56,848 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-14 02:49:56,849 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 607.4m
2014-07-14 02:49:57,015 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:57,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7128 synced till here 7127
2014-07-14 02:49:57,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331395787 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331397015
2014-07-14 02:49:57,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331348430
2014-07-14 02:49:57,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331352122
2014-07-14 02:49:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331353674
2014-07-14 02:49:57,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331355798
2014-07-14 02:49:57,107 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1715, memsize=105.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/927bfab3c6c940cd904a823c799a0b24
2014-07-14 02:49:57,123 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/927bfab3c6c940cd904a823c799a0b24 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/927bfab3c6c940cd904a823c799a0b24
2014-07-14 02:49:57,137 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/927bfab3c6c940cd904a823c799a0b24, entries=383240, sequenceid=1715, filesize=27.3m
2014-07-14 02:49:57,138 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~558.7m/585855200, currentsize=114.8m/120371040 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 6199ms, sequenceid=1715, compaction requested=false
2014-07-14 02:49:57,138 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 383.8m
2014-07-14 02:49:57,403 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:57,526 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:49:58,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:58,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7202 synced till here 7200
2014-07-14 02:49:58,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331397015 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331398315
2014-07-14 02:49:58,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331357415
2014-07-14 02:49:58,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331359273
2014-07-14 02:49:58,528 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:49:59,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:49:59,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7284 synced till here 7279
2014-07-14 02:49:59,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331398315 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331399165
2014-07-14 02:50:00,969 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:02,518 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331399165 with entries=139, filesize=119.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331400970
2014-07-14 02:50:03,689 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:03,710 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7496 synced till here 7494
2014-07-14 02:50:03,717 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:50:03,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331400970 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331403690
2014-07-14 02:50:05,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:05,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7569 synced till here 7567
2014-07-14 02:50:05,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331403690 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331405183
2014-07-14 02:50:05,475 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1793, memsize=169.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/81bcc2255545412eb43ff6f69569635c
2014-07-14 02:50:05,505 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/81bcc2255545412eb43ff6f69569635c as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/81bcc2255545412eb43ff6f69569635c
2014-07-14 02:50:05,529 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/81bcc2255545412eb43ff6f69569635c, entries=616380, sequenceid=1793, filesize=43.9m
2014-07-14 02:50:05,530 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~388.4m/407223680, currentsize=166.2m/174299680 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8392ms, sequenceid=1793, compaction requested=true
2014-07-14 02:50:05,531 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-14 02:50:05,531 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 390.1m
2014-07-14 02:50:05,787 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:06,583 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1787, memsize=170.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/819c0d36510c44218e7691b24c1872f6
2014-07-14 02:50:06,598 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/819c0d36510c44218e7691b24c1872f6 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/819c0d36510c44218e7691b24c1872f6
2014-07-14 02:50:06,611 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/819c0d36510c44218e7691b24c1872f6, entries=621960, sequenceid=1787, filesize=44.3m
2014-07-14 02:50:06,611 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~612.0m/641682160, currentsize=186.6m/195704480 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 9762ms, sequenceid=1787, compaction requested=true
2014-07-14 02:50:06,611 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-14 02:50:06,612 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 294.2m
2014-07-14 02:50:06,822 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:07,157 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.28 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=29509, hits=6042, hitRatio=20.47%, , cachingAccesses=6047, cachingHits=6041, cachingHitsRatio=99.90%, evictions=0, evicted=3, evictedPerRun=Infinity
2014-07-14 02:50:08,741 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:09,271 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7649 synced till here 7648
2014-07-14 02:50:09,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331405183 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331408742
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331360902
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331363235
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331366405
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331369240
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331372439
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331374929
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331377281
2014-07-14 02:50:09,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331387503
2014-07-14 02:50:10,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:10,377 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7723 synced till here 7721
2014-07-14 02:50:10,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331408742 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331410343
2014-07-14 02:50:11,814 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:50:12,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:12,096 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:50:12,649 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331410343 with entries=80, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331412029
2014-07-14 02:50:13,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:14,751 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7895 synced till here 7893
2014-07-14 02:50:14,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331412029 with entries=92, filesize=78.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331413505
2014-07-14 02:50:14,918 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/539ce5842b84413783eff39c30e0e1a4 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/539ce5842b84413783eff39c30e0e1a4
2014-07-14 02:50:14,996 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:50:15,015 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c912ff6c1d9248189821a904f4541705, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c912ff6c1d9248189821a904f4541705
2014-07-14 02:50:15,021 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b0b4c39d38a1483aa27b9f069c27a514, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b0b4c39d38a1483aa27b9f069c27a514
2014-07-14 02:50:15,025 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/430c8ee5eef64daeabe819e312420d47, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/430c8ee5eef64daeabe819e312420d47
2014-07-14 02:50:15,025 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into 539ce5842b84413783eff39c30e0e1a4(size=142.3m), total size for store is 169.6m. This selection was in queue for 0sec, and took 27sec to execute.
2014-07-14 02:50:15,026 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=3, fileSize=154.8m, priority=17, time=285295113411346; duration=27sec
2014-07-14 02:50:15,026 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-14 02:50:15,026 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-14 02:50:15,026 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 250265705 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-14 02:50:15,027 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating major compaction
2014-07-14 02:50:15,027 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:50:15,027 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=238.7m
2014-07-14 02:50:15,027 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d626dd1b76104a24abb0748dee66cd9c, keycount=69643, bloomtype=ROW, size=49.7m, encoding=NONE, seqNum=586, earliestPutTs=1405331204376
2014-07-14 02:50:15,027 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f8de731a992241b1bbb82cad9638052b, keycount=76595, bloomtype=ROW, size=54.6m, encoding=NONE, seqNum=830, earliestPutTs=1405331265615
2014-07-14 02:50:15,027 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/e4eeffcb63aa46b4848d13f8460f6476, keycount=49194, bloomtype=ROW, size=35.1m, encoding=NONE, seqNum=1258, earliestPutTs=1405331289577
2014-07-14 02:50:15,028 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/046eada7e7704b0fa35ec39861fecb86, keycount=77789, bloomtype=ROW, size=55.4m, encoding=NONE, seqNum=1542, earliestPutTs=1405331348496
2014-07-14 02:50:15,028 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/81bcc2255545412eb43ff6f69569635c, keycount=61638, bloomtype=ROW, size=43.9m, encoding=NONE, seqNum=1793, earliestPutTs=1405331383260
2014-07-14 02:50:15,142 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:16,988 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:17,021 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331413505 with entries=74, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331416988
2014-07-14 02:50:17,469 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1906, memsize=295.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/fd259302b6a14b26aa59bc41d24d3f2f
2014-07-14 02:50:17,514 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/fd259302b6a14b26aa59bc41d24d3f2f as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fd259302b6a14b26aa59bc41d24d3f2f
2014-07-14 02:50:17,537 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fd259302b6a14b26aa59bc41d24d3f2f, entries=1076960, sequenceid=1906, filesize=76.7m
2014-07-14 02:50:17,537 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~295.8m/310154880, currentsize=155.3m/162810800 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 10926ms, sequenceid=1906, compaction requested=true
2014-07-14 02:50:17,538 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-14 02:50:17,538 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 338.6m
2014-07-14 02:50:17,958 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1899, memsize=320.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/9a398fbda9a3412fa45f1e22abf86f6f
2014-07-14 02:50:17,973 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/9a398fbda9a3412fa45f1e22abf86f6f as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a398fbda9a3412fa45f1e22abf86f6f
2014-07-14 02:50:17,987 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a398fbda9a3412fa45f1e22abf86f6f, entries=1166110, sequenceid=1899, filesize=83.0m
2014-07-14 02:50:17,987 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~390.1m/409084560, currentsize=174.2m/182707600 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 12456ms, sequenceid=1899, compaction requested=true
2014-07-14 02:50:17,988 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-14 02:50:17,988 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 338.0m
2014-07-14 02:50:18,053 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:18,531 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:18,675 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:18,698 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8044 synced till here 8041
2014-07-14 02:50:18,745 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331416988 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331418676
2014-07-14 02:50:18,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331380584
2014-07-14 02:50:18,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331383219
2014-07-14 02:50:18,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331388950
2014-07-14 02:50:18,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331390884
2014-07-14 02:50:18,746 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331392386
2014-07-14 02:50:18,746 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331394050
2014-07-14 02:50:20,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:20,751 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331418676 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331420718
2014-07-14 02:50:26,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:26,459 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331420718 with entries=72, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331426407
2014-07-14 02:50:28,865 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:50:29,259 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:50:29,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:29,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8263 synced till here 8260
2014-07-14 02:50:29,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331426407 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331429633
2014-07-14 02:50:30,196 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2010, memsize=341.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ff755fe80c864930a49a53bca83c3280
2014-07-14 02:50:30,212 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ff755fe80c864930a49a53bca83c3280 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ff755fe80c864930a49a53bca83c3280
2014-07-14 02:50:30,225 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ff755fe80c864930a49a53bca83c3280, entries=1244630, sequenceid=2010, filesize=88.6m
2014-07-14 02:50:30,226 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~344.9m/361667440, currentsize=116.5m/122140480 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 12688ms, sequenceid=2010, compaction requested=true
2014-07-14 02:50:30,226 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-14 02:50:30,227 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 279.7m
2014-07-14 02:50:30,374 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:30,792 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2013, memsize=337.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/73a859e0504946feaa02708b17d1012b
2014-07-14 02:50:30,812 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/73a859e0504946feaa02708b17d1012b as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/73a859e0504946feaa02708b17d1012b
2014-07-14 02:50:30,825 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/73a859e0504946feaa02708b17d1012b, entries=1230270, sequenceid=2013, filesize=87.6m
2014-07-14 02:50:30,826 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~341.0m/357572880, currentsize=105.7m/110792560 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 12837ms, sequenceid=2013, compaction requested=false
2014-07-14 02:50:30,826 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 271.8m
2014-07-14 02:50:30,960 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:32,341 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:32,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8338 synced till here 8335
2014-07-14 02:50:32,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331429633 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331432341
2014-07-14 02:50:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331395787
2014-07-14 02:50:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331397015
2014-07-14 02:50:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331398315
2014-07-14 02:50:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331399165
2014-07-14 02:50:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331400970
2014-07-14 02:50:32,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331403690
2014-07-14 02:50:33,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:33,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8412 synced till here 8411
2014-07-14 02:50:33,638 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331432341 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331433571
2014-07-14 02:50:36,472 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:36,495 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8488 synced till here 8486
2014-07-14 02:50:36,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331433571 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331436472
2014-07-14 02:50:37,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:38,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8592 synced till here 8591
2014-07-14 02:50:38,236 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331436472 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331437834
2014-07-14 02:50:39,727 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:50:39,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:39,925 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8664 synced till here 8663
2014-07-14 02:50:39,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331437834 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331439904
2014-07-14 02:50:39,948 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2080, memsize=279.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/27e19050cf924ef9910c624df072da5b
2014-07-14 02:50:39,963 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/27e19050cf924ef9910c624df072da5b as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/27e19050cf924ef9910c624df072da5b
2014-07-14 02:50:39,979 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/27e19050cf924ef9910c624df072da5b, entries=1018420, sequenceid=2080, filesize=72.5m
2014-07-14 02:50:39,979 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~279.7m/293296720, currentsize=144.1m/151106800 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 9752ms, sequenceid=2080, compaction requested=true
2014-07-14 02:50:39,979 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-14 02:50:39,980 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 259.8m
2014-07-14 02:50:40,117 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:40,180 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2083, memsize=271.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2466f73dcbaf495e9dae5ba238157dc5
2014-07-14 02:50:40,200 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2466f73dcbaf495e9dae5ba238157dc5 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2466f73dcbaf495e9dae5ba238157dc5
2014-07-14 02:50:40,270 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2466f73dcbaf495e9dae5ba238157dc5, entries=989510, sequenceid=2083, filesize=70.5m
2014-07-14 02:50:40,270 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~271.8m/284972080, currentsize=146.5m/153658400 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 9444ms, sequenceid=2083, compaction requested=true
2014-07-14 02:50:40,270 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-14 02:50:40,475 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:50:40,475 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.2m
2014-07-14 02:50:41,124 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:44,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:44,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331439904 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331444972
2014-07-14 02:50:44,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331405183
2014-07-14 02:50:44,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331408742
2014-07-14 02:50:44,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331410343
2014-07-14 02:50:44,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331412029
2014-07-14 02:50:44,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331413505
2014-07-14 02:50:46,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:46,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8811 synced till here 8808
2014-07-14 02:50:46,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331444972 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331446281
2014-07-14 02:50:48,033 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2178, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/d83b04986bc1431ba65ffbc0b56eb91e
2014-07-14 02:50:48,048 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/d83b04986bc1431ba65ffbc0b56eb91e as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d83b04986bc1431ba65ffbc0b56eb91e
2014-07-14 02:50:48,079 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d83b04986bc1431ba65ffbc0b56eb91e, entries=940290, sequenceid=2178, filesize=67.0m
2014-07-14 02:50:48,080 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.8m/272414720, currentsize=76.1m/79765040 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 8100ms, sequenceid=2178, compaction requested=true
2014-07-14 02:50:48,080 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-14 02:50:48,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:49,373 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:50:49,374 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 257.4m
2014-07-14 02:50:49,435 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:50:49,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8958 synced till here 8956
2014-07-14 02:50:49,817 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2179, memsize=254.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/646070c862cf4325a8b2bcc9ac485131
2014-07-14 02:50:49,924 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cc0ce3d7c7754ae785151978b6d5ea12 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cc0ce3d7c7754ae785151978b6d5ea12
2014-07-14 02:50:49,926 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:49,932 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/646070c862cf4325a8b2bcc9ac485131 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/646070c862cf4325a8b2bcc9ac485131
2014-07-14 02:50:50,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331446281 with entries=147, filesize=126.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331448532
2014-07-14 02:50:50,248 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/646070c862cf4325a8b2bcc9ac485131, entries=926830, sequenceid=2179, filesize=66.0m
2014-07-14 02:50:50,248 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268612000, currentsize=108.7m/113955520 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9773ms, sequenceid=2179, compaction requested=false
2014-07-14 02:50:50,248 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.5m
2014-07-14 02:50:50,319 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:50:50,337 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d626dd1b76104a24abb0748dee66cd9c, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d626dd1b76104a24abb0748dee66cd9c
2014-07-14 02:50:50,343 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f8de731a992241b1bbb82cad9638052b, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f8de731a992241b1bbb82cad9638052b
2014-07-14 02:50:50,346 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/e4eeffcb63aa46b4848d13f8460f6476, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/e4eeffcb63aa46b4848d13f8460f6476
2014-07-14 02:50:50,350 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/046eada7e7704b0fa35ec39861fecb86, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/046eada7e7704b0fa35ec39861fecb86
2014-07-14 02:50:50,353 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/81bcc2255545412eb43ff6f69569635c, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/81bcc2255545412eb43ff6f69569635c
2014-07-14 02:50:50,354 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into cc0ce3d7c7754ae785151978b6d5ea12(size=189.3m), total size for store is 342.9m. This selection was in queue for 0sec, and took 35sec to execute.
2014-07-14 02:50:50,354 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=5, fileSize=238.7m, priority=15, time=285322453817449; duration=35sec
2014-07-14 02:50:50,354 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-14 02:50:50,355 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-14 02:50:50,355 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 6 files of size 369398023 starting at candidate #0 after considering 10 permutations with 10 in ratio
2014-07-14 02:50:50,355 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating major compaction
2014-07-14 02:50:50,355 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:50:50,356 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 6 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=352.3m
2014-07-14 02:50:50,356 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1dae241a1e124bad962841fd6ff124c4, keycount=62625, bloomtype=ROW, size=44.7m, encoding=NONE, seqNum=563, earliestPutTs=1405331203944
2014-07-14 02:50:50,356 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/2e2461d2993e43ad8da095e02136a5fd, keycount=86055, bloomtype=ROW, size=61.3m, encoding=NONE, seqNum=821, earliestPutTs=1405331262882
2014-07-14 02:50:50,356 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6dcdd3fe78c0443b8f2eecb6ddf64cb9, keycount=50412, bloomtype=ROW, size=35.9m, encoding=NONE, seqNum=1269, earliestPutTs=1405331288062
2014-07-14 02:50:50,356 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/279dedd8c48e43e1927dd330c83280e1, keycount=76875, bloomtype=ROW, size=54.8m, encoding=NONE, seqNum=1647, earliestPutTs=1405331350897
2014-07-14 02:50:50,356 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a398fbda9a3412fa45f1e22abf86f6f, keycount=116611, bloomtype=ROW, size=83.0m, encoding=NONE, seqNum=1899, earliestPutTs=1405331387347
2014-07-14 02:50:50,356 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/27e19050cf924ef9910c624df072da5b, keycount=101842, bloomtype=ROW, size=72.5m, encoding=NONE, seqNum=2080, earliestPutTs=1405331405918
2014-07-14 02:50:50,421 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:50,470 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:50:51,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:51,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9033 synced till here 9031
2014-07-14 02:50:52,102 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331448532 with entries=75, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331451789
2014-07-14 02:50:52,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331416988
2014-07-14 02:50:52,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331418676
2014-07-14 02:50:52,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331420718
2014-07-14 02:50:52,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331426407
2014-07-14 02:50:53,049 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:53,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9115 synced till here 9114
2014-07-14 02:50:53,400 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331451789 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331453050
2014-07-14 02:50:55,720 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:55,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331453050 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331455720
2014-07-14 02:50:58,383 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2248, memsize=257.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/915013d897ce4a6d888db886ff6c3e68
2014-07-14 02:50:58,400 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/915013d897ce4a6d888db886ff6c3e68 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/915013d897ce4a6d888db886ff6c3e68
2014-07-14 02:50:58,411 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/915013d897ce4a6d888db886ff6c3e68, entries=937540, sequenceid=2248, filesize=66.8m
2014-07-14 02:50:58,412 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.0m/271604720, currentsize=113.3m/118787920 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 9038ms, sequenceid=2248, compaction requested=false
2014-07-14 02:50:58,524 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:50:58,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9262 synced till here 9261
2014-07-14 02:50:59,297 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2251, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/fe84170fd17240e18c3985e57ec81685
2014-07-14 02:50:59,337 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331455720 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331458524
2014-07-14 02:50:59,377 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/fe84170fd17240e18c3985e57ec81685 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fe84170fd17240e18c3985e57ec81685
2014-07-14 02:50:59,395 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fe84170fd17240e18c3985e57ec81685, entries=939520, sequenceid=2251, filesize=66.9m
2014-07-14 02:50:59,396 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.6m/272218480, currentsize=116.8m/122433440 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 9148ms, sequenceid=2251, compaction requested=true
2014-07-14 02:50:59,396 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-14 02:51:17,881 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:51:17,883 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 256.0m
2014-07-14 02:51:18,040 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:18,250 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:18,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331458524 with entries=71, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331478251
2014-07-14 02:51:18,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331429633
2014-07-14 02:51:18,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331432341
2014-07-14 02:51:18,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331433571
2014-07-14 02:51:18,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331436472
2014-07-14 02:51:18,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331437834
2014-07-14 02:51:19,886 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:51:19,886 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.5m
2014-07-14 02:51:20,295 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:21,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:21,162 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331478251 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331481132
2014-07-14 02:51:23,405 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:23,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331481132 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331483406
2014-07-14 02:51:26,316 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2344, memsize=254.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/0e4b945dd629404bbc2014a10689f889
2014-07-14 02:51:26,331 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/0e4b945dd629404bbc2014a10689f889 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0e4b945dd629404bbc2014a10689f889
2014-07-14 02:51:26,342 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0e4b945dd629404bbc2014a10689f889, entries=926400, sequenceid=2344, filesize=65.9m
2014-07-14 02:51:26,343 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.0m/268466640, currentsize=85.2m/89358960 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 8461ms, sequenceid=2344, compaction requested=true
2014-07-14 02:51:26,343 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-14 02:51:26,631 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:26,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9549 synced till here 9548
2014-07-14 02:51:26,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331483406 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331486631
2014-07-14 02:51:28,494 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:51:28,495 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.4m
2014-07-14 02:51:28,919 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2346, memsize=255.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/549b7a89523c46dda025f4da7c54b529
2014-07-14 02:51:28,955 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/549b7a89523c46dda025f4da7c54b529 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/549b7a89523c46dda025f4da7c54b529
2014-07-14 02:51:28,969 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:28,970 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/549b7a89523c46dda025f4da7c54b529, entries=928310, sequenceid=2346, filesize=66.0m
2014-07-14 02:51:28,970 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.5m/268960640, currentsize=112.4m/117813840 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9084ms, sequenceid=2346, compaction requested=true
2014-07-14 02:51:28,971 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-14 02:51:28,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9623 synced till here 9622
2014-07-14 02:51:28,991 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:51:28,991 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.7m
2014-07-14 02:51:29,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331486631 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331488969
2014-07-14 02:51:29,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331439904
2014-07-14 02:51:29,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331444972
2014-07-14 02:51:29,067 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:29,253 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:30,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:31,005 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9702 synced till here 9697
2014-07-14 02:51:31,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331488969 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331490968
2014-07-14 02:51:32,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:33,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331490968 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331492697
2014-07-14 02:51:35,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:35,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9866 synced till here 9865
2014-07-14 02:51:35,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331492697 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331495154
2014-07-14 02:51:37,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:37,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9945 synced till here 9937
2014-07-14 02:51:37,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331495154 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331497026
2014-07-14 02:51:37,972 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/52c857a38a484232bbdb434da2b6c601 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/52c857a38a484232bbdb434da2b6c601
2014-07-14 02:51:37,989 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:51:38,003 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1dae241a1e124bad962841fd6ff124c4, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1dae241a1e124bad962841fd6ff124c4
2014-07-14 02:51:38,007 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/2e2461d2993e43ad8da095e02136a5fd, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/2e2461d2993e43ad8da095e02136a5fd
2014-07-14 02:51:38,011 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6dcdd3fe78c0443b8f2eecb6ddf64cb9, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/6dcdd3fe78c0443b8f2eecb6ddf64cb9
2014-07-14 02:51:38,014 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/279dedd8c48e43e1927dd330c83280e1, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/279dedd8c48e43e1927dd330c83280e1
2014-07-14 02:51:38,018 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a398fbda9a3412fa45f1e22abf86f6f, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a398fbda9a3412fa45f1e22abf86f6f
2014-07-14 02:51:38,021 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/27e19050cf924ef9910c624df072da5b, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/27e19050cf924ef9910c624df072da5b
2014-07-14 02:51:38,021 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 6 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 52c857a38a484232bbdb434da2b6c601(size=300.2m), total size for store is 367.0m. This selection was in queue for 0sec, and took 47sec to execute.
2014-07-14 02:51:38,021 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=6, fileSize=352.3m, priority=14, time=285357782353601; duration=47sec
2014-07-14 02:51:38,021 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-14 02:51:38,022 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-14 02:51:38,022 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 6 files of size 443095377 starting at candidate #0 after considering 10 permutations with 10 in ratio
2014-07-14 02:51:38,022 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating major compaction
2014-07-14 02:51:38,022 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:51:38,022 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 6 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=422.6m
2014-07-14 02:51:38,023 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5276c4b77b8f4900a09c186785a5a9f8, keycount=158816, bloomtype=ROW, size=113.2m, encoding=NONE, seqNum=1005, earliestPutTs=1405331205093
2014-07-14 02:51:38,023 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0f65c65b64f640e892b5bb8d45d632c6, keycount=61102, bloomtype=ROW, size=43.6m, encoding=NONE, seqNum=1387, earliestPutTs=1405331349446
2014-07-14 02:51:38,023 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/819c0d36510c44218e7691b24c1872f6, keycount=62196, bloomtype=ROW, size=44.3m, encoding=NONE, seqNum=1787, earliestPutTs=1405331361738
2014-07-14 02:51:38,023 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ff755fe80c864930a49a53bca83c3280, keycount=124463, bloomtype=ROW, size=88.6m, encoding=NONE, seqNum=2010, earliestPutTs=1405331396869
2014-07-14 02:51:38,023 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d83b04986bc1431ba65ffbc0b56eb91e, keycount=94029, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=2178, earliestPutTs=1405331417857
2014-07-14 02:51:38,023 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0e4b945dd629404bbc2014a10689f889, keycount=92640, bloomtype=ROW, size=65.9m, encoding=NONE, seqNum=2344, earliestPutTs=1405331439995
2014-07-14 02:51:38,106 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:38,322 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2415, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ca69b55992994d9c8fc20213a8ab8d73
2014-07-14 02:51:38,336 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ca69b55992994d9c8fc20213a8ab8d73 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ca69b55992994d9c8fc20213a8ab8d73
2014-07-14 02:51:38,358 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ca69b55992994d9c8fc20213a8ab8d73, entries=939590, sequenceid=2415, filesize=66.9m
2014-07-14 02:51:38,358 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270594480, currentsize=134.9m/141475680 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 9863ms, sequenceid=2415, compaction requested=true
2014-07-14 02:51:38,358 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-14 02:51:38,415 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2419, memsize=259.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2db3a1f6da744db697dfab4262f61955
2014-07-14 02:51:38,426 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2db3a1f6da744db697dfab4262f61955 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2db3a1f6da744db697dfab4262f61955
2014-07-14 02:51:38,450 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2db3a1f6da744db697dfab4262f61955, entries=945600, sequenceid=2419, filesize=67.3m
2014-07-14 02:51:38,450 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.7m/272325040, currentsize=133.5m/140007360 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 9459ms, sequenceid=2419, compaction requested=true
2014-07-14 02:51:38,451 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-14 02:51:39,074 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 257.2m
2014-07-14 02:51:39,075 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:51:39,092 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:51:39,093 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 256.5m
2014-07-14 02:51:39,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:39,330 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:39,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10025 synced till here 10019
2014-07-14 02:51:39,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331497026 with entries=80, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331499322
2014-07-14 02:51:39,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331446281
2014-07-14 02:51:39,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331448532
2014-07-14 02:51:39,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331451789
2014-07-14 02:51:39,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331453050
2014-07-14 02:51:39,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331455720
2014-07-14 02:51:39,430 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:41,755 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:41,786 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10099 synced till here 10098
2014-07-14 02:51:41,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331499322 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331501755
2014-07-14 02:51:47,667 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:47,722 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10174 synced till here 10172
2014-07-14 02:51:47,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331501755 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331507667
2014-07-14 02:51:48,342 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2514, memsize=246.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/077fbc20860940d08442f227f1be7380
2014-07-14 02:51:48,356 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/077fbc20860940d08442f227f1be7380 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/077fbc20860940d08442f227f1be7380
2014-07-14 02:51:48,391 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2512, memsize=253.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/1ac925dbf3e44680a9a82dcdeb8659e1
2014-07-14 02:51:48,414 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/1ac925dbf3e44680a9a82dcdeb8659e1 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1ac925dbf3e44680a9a82dcdeb8659e1
2014-07-14 02:51:48,424 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/077fbc20860940d08442f227f1be7380, entries=896730, sequenceid=2514, filesize=63.9m
2014-07-14 02:51:48,424 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.3m/272903520, currentsize=78.7m/82543440 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9350ms, sequenceid=2514, compaction requested=true
2014-07-14 02:51:48,424 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:16), split_queue=0, merge_queue=0
2014-07-14 02:51:48,466 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1ac925dbf3e44680a9a82dcdeb8659e1, entries=922100, sequenceid=2512, filesize=65.7m
2014-07-14 02:51:48,467 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.5m/272154240, currentsize=87.2m/91408720 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 9374ms, sequenceid=2512, compaction requested=false
2014-07-14 02:51:49,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:49,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10255 synced till here 10254
2014-07-14 02:51:49,223 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331507667 with entries=81, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331509086
2014-07-14 02:51:49,223 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331458524
2014-07-14 02:51:49,223 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331478251
2014-07-14 02:51:49,223 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331481132
2014-07-14 02:51:49,223 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331483406
2014-07-14 02:51:49,752 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:51:49,753 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.3m
2014-07-14 02:51:49,915 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:50,336 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:51:50,337 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.3m
2014-07-14 02:51:50,994 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:51:51,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:51,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10334 synced till here 10329
2014-07-14 02:51:51,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331509086 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331511026
2014-07-14 02:51:52,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:52,570 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10416 synced till here 10406
2014-07-14 02:51:52,678 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331511026 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331512545
2014-07-14 02:51:54,643 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:54,679 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10493 synced till here 10487
2014-07-14 02:51:54,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331512545 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331514644
2014-07-14 02:51:56,224 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:56,258 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331514644 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331516225
2014-07-14 02:51:58,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:51:58,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10640 synced till here 10638
2014-07-14 02:51:58,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331516225 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331518344
2014-07-14 02:51:58,652 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:51:59,722 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2582, memsize=239.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/155d4b55d2084b478003a9d349dec761
2014-07-14 02:51:59,739 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/155d4b55d2084b478003a9d349dec761 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/155d4b55d2084b478003a9d349dec761
2014-07-14 02:51:59,751 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/155d4b55d2084b478003a9d349dec761, entries=870920, sequenceid=2582, filesize=62.1m
2014-07-14 02:51:59,751 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268762960, currentsize=149.0m/156185440 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 9999ms, sequenceid=2582, compaction requested=true
2014-07-14 02:51:59,752 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:17), split_queue=0, merge_queue=0
2014-07-14 02:51:59,752 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 264.3m
2014-07-14 02:51:59,912 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:00,464 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2589, memsize=245.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/55abccbf946b4e168dc9d496dba74be5
2014-07-14 02:52:00,481 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/55abccbf946b4e168dc9d496dba74be5 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/55abccbf946b4e168dc9d496dba74be5
2014-07-14 02:52:00,500 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/55abccbf946b4e168dc9d496dba74be5, entries=893440, sequenceid=2589, filesize=63.7m
2014-07-14 02:52:00,501 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.5m/275237920, currentsize=142.2m/149102320 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 10165ms, sequenceid=2589, compaction requested=true
2014-07-14 02:52:00,501 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-14 02:52:00,558 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:52:00,559 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.9m
2014-07-14 02:52:00,747 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:01,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:01,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10716 synced till here 10714
2014-07-14 02:52:01,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331518344 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331521358
2014-07-14 02:52:01,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331486631
2014-07-14 02:52:01,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331488969
2014-07-14 02:52:01,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331490968
2014-07-14 02:52:01,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331492697
2014-07-14 02:52:01,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331495154
2014-07-14 02:52:02,841 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:02,869 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10792 synced till here 10790
2014-07-14 02:52:02,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331521358 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331522842
2014-07-14 02:52:05,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:05,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10868 synced till here 10866
2014-07-14 02:52:05,410 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331522842 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331525311
2014-07-14 02:52:07,303 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:07,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331525311 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331527304
2014-07-14 02:52:07,922 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2683, memsize=225.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e657209a6c524e119a0a068d049ef82f
2014-07-14 02:52:07,940 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e657209a6c524e119a0a068d049ef82f as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e657209a6c524e119a0a068d049ef82f
2014-07-14 02:52:07,954 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e657209a6c524e119a0a068d049ef82f, entries=821260, sequenceid=2683, filesize=58.5m
2014-07-14 02:52:07,955 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.3m/277119600, currentsize=104.3m/109407760 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 8203ms, sequenceid=2683, compaction requested=false
2014-07-14 02:52:09,016 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2682, memsize=219.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ec50252e6d4b4bbdb565230e044616cb
2014-07-14 02:52:09,046 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ec50252e6d4b4bbdb565230e044616cb as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ec50252e6d4b4bbdb565230e044616cb
2014-07-14 02:52:09,072 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ec50252e6d4b4bbdb565230e044616cb, entries=799380, sequenceid=2682, filesize=56.9m
2014-07-14 02:52:09,072 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.4m/270944880, currentsize=101.0m/105909360 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8513ms, sequenceid=2682, compaction requested=true
2014-07-14 02:52:09,072 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-14 02:52:24,825 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:52:24,826 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.5m
2014-07-14 02:52:25,226 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:25,702 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:52:25,702 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.9m
2014-07-14 02:52:25,923 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:26,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:26,552 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11015 synced till here 11013
2014-07-14 02:52:26,613 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331527304 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331546516
2014-07-14 02:52:26,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331497026
2014-07-14 02:52:26,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331499322
2014-07-14 02:52:26,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331501755
2014-07-14 02:52:26,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331507667
2014-07-14 02:52:27,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:27,924 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331546516 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331547897
2014-07-14 02:52:29,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:29,118 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11163 synced till here 11161
2014-07-14 02:52:29,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331547897 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331549085
2014-07-14 02:52:30,306 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:30,744 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331549085 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331550306
2014-07-14 02:52:32,683 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:32,713 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11317 synced till here 11316
2014-07-14 02:52:32,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331550306 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331552684
2014-07-14 02:52:32,990 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:52:33,048 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:52:33,628 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2749, memsize=226.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/7adaf7b9e63240b4ac3b7dee9d2dda9e
2014-07-14 02:52:33,642 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/7adaf7b9e63240b4ac3b7dee9d2dda9e as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/7adaf7b9e63240b4ac3b7dee9d2dda9e
2014-07-14 02:52:33,673 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/7adaf7b9e63240b4ac3b7dee9d2dda9e, entries=825820, sequenceid=2749, filesize=58.8m
2014-07-14 02:52:33,674 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.0m/270535600, currentsize=161.6m/169454720 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 8848ms, sequenceid=2749, compaction requested=true
2014-07-14 02:52:33,674 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:20), split_queue=0, merge_queue=0
2014-07-14 02:52:33,674 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 267.6m
2014-07-14 02:52:33,862 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:34,082 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:34,200 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2757, memsize=235.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/b492cf38bcec4818b8996e9e6974b172
2014-07-14 02:52:34,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331552684 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331554082
2014-07-14 02:52:34,268 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/b492cf38bcec4818b8996e9e6974b172 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b492cf38bcec4818b8996e9e6974b172
2014-07-14 02:52:34,287 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b492cf38bcec4818b8996e9e6974b172, entries=855600, sequenceid=2757, filesize=60.9m
2014-07-14 02:52:34,287 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.1m/272724960, currentsize=164.2m/172195920 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 8585ms, sequenceid=2757, compaction requested=true
2014-07-14 02:52:34,288 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-14 02:52:34,288 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 281.8m
2014-07-14 02:52:34,450 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:35,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:36,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11479 synced till here 11478
2014-07-14 02:52:36,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331554082 with entries=83, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331555809
2014-07-14 02:52:36,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331509086
2014-07-14 02:52:36,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331511026
2014-07-14 02:52:36,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331512545
2014-07-14 02:52:36,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331514644
2014-07-14 02:52:36,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331516225
2014-07-14 02:52:37,550 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:38,479 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11560 synced till here 11554
2014-07-14 02:52:38,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331555809 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331557550
2014-07-14 02:52:39,841 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:52:41,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:41,316 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:52:41,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331557550 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331561230
2014-07-14 02:52:42,873 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2857, memsize=269.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/53dadd8e152e4f30a415f397166157ef
2014-07-14 02:52:42,887 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/53dadd8e152e4f30a415f397166157ef as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/53dadd8e152e4f30a415f397166157ef
2014-07-14 02:52:42,904 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/53dadd8e152e4f30a415f397166157ef, entries=979850, sequenceid=2857, filesize=69.8m
2014-07-14 02:52:42,904 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~269.1m/282186720, currentsize=120.8m/126638720 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 9230ms, sequenceid=2857, compaction requested=true
2014-07-14 02:52:42,904 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-14 02:52:42,904 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 284.7m
2014-07-14 02:52:43,076 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:43,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:43,967 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331561230 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331563567
2014-07-14 02:52:44,160 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ad11889ca28a48cdb276b117afa89896 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ad11889ca28a48cdb276b117afa89896
2014-07-14 02:52:44,192 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:52:44,205 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5276c4b77b8f4900a09c186785a5a9f8, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5276c4b77b8f4900a09c186785a5a9f8
2014-07-14 02:52:44,209 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0f65c65b64f640e892b5bb8d45d632c6, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0f65c65b64f640e892b5bb8d45d632c6
2014-07-14 02:52:44,213 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/819c0d36510c44218e7691b24c1872f6, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/819c0d36510c44218e7691b24c1872f6
2014-07-14 02:52:44,220 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ff755fe80c864930a49a53bca83c3280, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ff755fe80c864930a49a53bca83c3280
2014-07-14 02:52:44,229 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d83b04986bc1431ba65ffbc0b56eb91e, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d83b04986bc1431ba65ffbc0b56eb91e
2014-07-14 02:52:44,232 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0e4b945dd629404bbc2014a10689f889, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0e4b945dd629404bbc2014a10689f889
2014-07-14 02:52:44,232 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 6 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into ad11889ca28a48cdb276b117afa89896(size=402.6m), total size for store is 596.6m. This selection was in queue for 0sec, and took 1mins, 6sec to execute.
2014-07-14 02:52:44,232 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=6, fileSize=422.6m, priority=14, time=285405449311859; duration=1mins, 6sec
2014-07-14 02:52:44,233 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-14 02:52:44,233 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-14 02:52:44,233 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 8 files of size 603573041 starting at candidate #0 after considering 21 permutations with 21 in ratio
2014-07-14 02:52:44,234 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating major compaction
2014-07-14 02:52:44,234 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:52:44,234 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 8 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=575.6m
2014-07-14 02:52:44,234 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/539ce5842b84413783eff39c30e0e1a4, keycount=199718, bloomtype=ROW, size=142.3m, encoding=NONE, seqNum=1353, earliestPutTs=1405331204584
2014-07-14 02:52:44,234 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/927bfab3c6c940cd904a823c799a0b24, keycount=38324, bloomtype=ROW, size=27.3m, encoding=NONE, seqNum=1715, earliestPutTs=1405331359388
2014-07-14 02:52:44,235 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fd259302b6a14b26aa59bc41d24d3f2f, keycount=107696, bloomtype=ROW, size=76.7m, encoding=NONE, seqNum=1906, earliestPutTs=1405331391063
2014-07-14 02:52:44,235 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2466f73dcbaf495e9dae5ba238157dc5, keycount=98951, bloomtype=ROW, size=70.5m, encoding=NONE, seqNum=2083, earliestPutTs=1405331406615
2014-07-14 02:52:44,235 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fe84170fd17240e18c3985e57ec81685, keycount=93952, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=2251, earliestPutTs=1405331431444
2014-07-14 02:52:44,235 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2db3a1f6da744db697dfab4262f61955, keycount=94560, bloomtype=ROW, size=67.3m, encoding=NONE, seqNum=2419, earliestPutTs=1405331450319
2014-07-14 02:52:44,235 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/55abccbf946b4e168dc9d496dba74be5, keycount=89344, bloomtype=ROW, size=63.7m, encoding=NONE, seqNum=2589, earliestPutTs=1405331489450
2014-07-14 02:52:44,235 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b492cf38bcec4818b8996e9e6974b172, keycount=85560, bloomtype=ROW, size=60.9m, encoding=NONE, seqNum=2757, earliestPutTs=1405331510346
2014-07-14 02:52:44,369 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:44,421 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2864, memsize=281.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/685cc1a55a2645e2aa134a5a5c6b75f9
2014-07-14 02:52:44,447 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/685cc1a55a2645e2aa134a5a5c6b75f9 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/685cc1a55a2645e2aa134a5a5c6b75f9
2014-07-14 02:52:44,466 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/685cc1a55a2645e2aa134a5a5c6b75f9, entries=1026050, sequenceid=2864, filesize=73.1m
2014-07-14 02:52:44,466 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~281.8m/295496480, currentsize=121.1m/127030560 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 10178ms, sequenceid=2864, compaction requested=true
2014-07-14 02:52:44,466 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-14 02:52:44,466 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 287.5m
2014-07-14 02:52:44,623 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:45,936 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:45,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11795 synced till here 11792
2014-07-14 02:52:46,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331563567 with entries=79, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331565936
2014-07-14 02:52:46,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331518344
2014-07-14 02:52:46,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331521358
2014-07-14 02:52:46,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331522842
2014-07-14 02:52:46,034 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331525311
2014-07-14 02:52:47,215 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:47,238 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11868 synced till here 11866
2014-07-14 02:52:47,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331565936 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331567216
2014-07-14 02:52:48,432 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:49,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331567216 with entries=110, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331568433
2014-07-14 02:52:50,078 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:52:50,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:50,608 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:52:51,238 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12083 synced till here 12076
2014-07-14 02:52:51,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331568433 with entries=105, filesize=89.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331570359
2014-07-14 02:52:52,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:52:52,308 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331570359 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331572282
2014-07-14 02:52:53,160 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2933, memsize=284.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/4fdba0afc71f45d4a0f5328c3651033d
2014-07-14 02:52:53,217 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/4fdba0afc71f45d4a0f5328c3651033d as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4fdba0afc71f45d4a0f5328c3651033d
2014-07-14 02:52:53,340 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4fdba0afc71f45d4a0f5328c3651033d, entries=1036430, sequenceid=2933, filesize=73.8m
2014-07-14 02:52:53,341 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~284.7m/298484000, currentsize=183.2m/192053680 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 10437ms, sequenceid=2933, compaction requested=true
2014-07-14 02:52:53,341 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:23), split_queue=0, merge_queue=0
2014-07-14 02:52:53,342 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 307.2m
2014-07-14 02:52:53,500 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:52:54,281 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2943, memsize=287.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/3636ba02ff5f4b04a71388acc2ba40d5
2014-07-14 02:52:54,312 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/3636ba02ff5f4b04a71388acc2ba40d5 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3636ba02ff5f4b04a71388acc2ba40d5
2014-07-14 02:52:54,321 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3636ba02ff5f4b04a71388acc2ba40d5, entries=1046650, sequenceid=2943, filesize=74.5m
2014-07-14 02:52:54,322 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~287.5m/301426320, currentsize=170.6m/178863120 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 9856ms, sequenceid=2943, compaction requested=false
2014-07-14 02:52:54,322 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 292.1m
2014-07-14 02:52:54,493 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:02,435 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3057, memsize=307.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/2f18d3375e86420e875f970f6d55a1dd
2014-07-14 02:53:02,497 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/2f18d3375e86420e875f970f6d55a1dd as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2f18d3375e86420e875f970f6d55a1dd
2014-07-14 02:53:02,511 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2f18d3375e86420e875f970f6d55a1dd, entries=1118530, sequenceid=3057, filesize=79.7m
2014-07-14 02:53:02,512 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~307.2m/322127840, currentsize=0.0/0 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 9170ms, sequenceid=3057, compaction requested=true
2014-07-14 02:53:02,512 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:24), split_queue=0, merge_queue=0
2014-07-14 02:53:02,599 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3053, memsize=292.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cce31156d8344b339345ee43a7b6c9a7
2014-07-14 02:53:02,614 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cce31156d8344b339345ee43a7b6c9a7 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cce31156d8344b339345ee43a7b6c9a7
2014-07-14 02:53:02,644 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cce31156d8344b339345ee43a7b6c9a7, entries=1063660, sequenceid=3053, filesize=75.8m
2014-07-14 02:53:02,644 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~292.1m/306326160, currentsize=0.0/0 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8322ms, sequenceid=3053, compaction requested=true
2014-07-14 02:53:02,644 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:25), split_queue=0, merge_queue=0
2014-07-14 02:53:07,250 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:07,850 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12240 synced till here 12238
2014-07-14 02:53:07,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331572282 with entries=86, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331587250
2014-07-14 02:53:07,867 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331527304
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331546516
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331547897
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331549085
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331550306
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331552684
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331554082
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331555809
2014-07-14 02:53:07,868 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331557550
2014-07-14 02:53:08,869 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:08,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12314 synced till here 12313
2014-07-14 02:53:08,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331587250 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331588869
2014-07-14 02:53:09,535 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:53:09,535 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.3m
2014-07-14 02:53:09,695 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:10,252 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:53:10,252 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 257.4m
2014-07-14 02:53:10,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:10,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12390 synced till here 12387
2014-07-14 02:53:10,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331588869 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331590263
2014-07-14 02:53:10,434 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:11,824 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:12,130 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331590263 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331591824
2014-07-14 02:53:15,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:15,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331591824 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331595519
2014-07-14 02:53:17,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:17,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12621 synced till here 12618
2014-07-14 02:53:17,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331595519 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331597110
2014-07-14 02:53:18,206 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3100, memsize=257.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/8618c0feca69454f82d692c3434689f4
2014-07-14 02:53:18,229 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/8618c0feca69454f82d692c3434689f4 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8618c0feca69454f82d692c3434689f4
2014-07-14 02:53:18,255 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8618c0feca69454f82d692c3434689f4, entries=938620, sequenceid=3100, filesize=66.9m
2014-07-14 02:53:18,256 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.8m/270315200, currentsize=114.8m/120325440 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 8721ms, sequenceid=3100, compaction requested=true
2014-07-14 02:53:18,256 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-14 02:53:18,702 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3111, memsize=259.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/a572f3f58e4440d180fec70e488039d7
2014-07-14 02:53:18,715 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/a572f3f58e4440d180fec70e488039d7 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/a572f3f58e4440d180fec70e488039d7
2014-07-14 02:53:18,724 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/a572f3f58e4440d180fec70e488039d7, entries=943360, sequenceid=3111, filesize=67.2m
2014-07-14 02:53:18,724 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.1m/271680160, currentsize=113.5m/119044720 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 8472ms, sequenceid=3111, compaction requested=false
2014-07-14 02:53:19,111 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:20,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331597110 with entries=110, filesize=94.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331599111
2014-07-14 02:53:20,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331561230
2014-07-14 02:53:20,072 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331563567
2014-07-14 02:53:20,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331565936
2014-07-14 02:53:20,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331567216
2014-07-14 02:53:20,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331568433
2014-07-14 02:53:20,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331570359
2014-07-14 02:53:21,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:21,863 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331599111 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331601684
2014-07-14 02:53:22,072 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:53:22,072 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 257.1m
2014-07-14 02:53:22,101 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:53:22,101 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 257.0m
2014-07-14 02:53:22,245 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:22,269 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:23,169 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:23,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12884 synced till here 12879
2014-07-14 02:53:23,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331601684 with entries=76, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331603169
2014-07-14 02:53:24,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:24,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12961 synced till here 12957
2014-07-14 02:53:24,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331603169 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331604546
2014-07-14 02:53:25,063 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:53:25,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:25,889 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:53:25,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13049 synced till here 13048
2014-07-14 02:53:26,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331604546 with entries=88, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331605649
2014-07-14 02:53:27,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:27,242 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331605649 with entries=80, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331607108
2014-07-14 02:53:30,824 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3223, memsize=253.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e7cd8ba87b3c4b6b9960df077eb2988e
2014-07-14 02:53:30,840 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e7cd8ba87b3c4b6b9960df077eb2988e as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e7cd8ba87b3c4b6b9960df077eb2988e
2014-07-14 02:53:30,855 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e7cd8ba87b3c4b6b9960df077eb2988e, entries=924250, sequenceid=3223, filesize=65.8m
2014-07-14 02:53:30,855 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.0m/269462560, currentsize=131.4m/137810880 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 8754ms, sequenceid=3223, compaction requested=true
2014-07-14 02:53:30,855 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-14 02:53:30,856 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 313.3m
2014-07-14 02:53:30,912 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3221, memsize=255.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/27ad04701916424186ded7ee75b3d264
2014-07-14 02:53:30,929 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/27ad04701916424186ded7ee75b3d264 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/27ad04701916424186ded7ee75b3d264
2014-07-14 02:53:30,940 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/27ad04701916424186ded7ee75b3d264, entries=930680, sequenceid=3221, filesize=66.3m
2014-07-14 02:53:30,940 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.6m/271205600, currentsize=129.5m/135816640 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8868ms, sequenceid=3221, compaction requested=true
2014-07-14 02:53:30,940 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:28), split_queue=0, merge_queue=0
2014-07-14 02:53:30,940 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 300.1m
2014-07-14 02:53:31,020 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:31,084 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:36,721 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:36,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13202 synced till here 13201
2014-07-14 02:53:36,749 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331607108 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331616721
2014-07-14 02:53:36,749 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331572282
2014-07-14 02:53:36,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331587250
2014-07-14 02:53:38,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:38,088 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331616721 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331618058
2014-07-14 02:53:39,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:39,249 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13348 synced till here 13347
2014-07-14 02:53:39,264 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331618058 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331619223
2014-07-14 02:53:40,567 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3305, memsize=284.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/6c574588a5a04f098cc3e4697553a2f7
2014-07-14 02:53:40,582 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/6c574588a5a04f098cc3e4697553a2f7 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6c574588a5a04f098cc3e4697553a2f7
2014-07-14 02:53:40,596 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6c574588a5a04f098cc3e4697553a2f7, entries=1035930, sequenceid=3305, filesize=73.8m
2014-07-14 02:53:40,596 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~300.1m/314692720, currentsize=97.7m/102470000 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 9656ms, sequenceid=3305, compaction requested=true
2014-07-14 02:53:40,597 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:29), split_queue=0, merge_queue=0
2014-07-14 02:53:40,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:40,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13423 synced till here 13422
2014-07-14 02:53:40,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331619223 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331620705
2014-07-14 02:53:40,804 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3303, memsize=297.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/4aa07b72c415472fa644922e1f4c9bd7
2014-07-14 02:53:40,823 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/4aa07b72c415472fa644922e1f4c9bd7 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4aa07b72c415472fa644922e1f4c9bd7
2014-07-14 02:53:40,839 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4aa07b72c415472fa644922e1f4c9bd7, entries=1084440, sequenceid=3303, filesize=77.2m
2014-07-14 02:53:40,839 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~313.3m/328473360, currentsize=109.0m/114286320 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 9983ms, sequenceid=3303, compaction requested=true
2014-07-14 02:53:40,839 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-14 02:53:43,045 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:53:43,046 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 257.1m
2014-07-14 02:53:43,182 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:43,232 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:53:43,232 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 257.1m
2014-07-14 02:53:43,365 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:45,104 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:45,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331620705 with entries=71, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331625104
2014-07-14 02:53:45,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331588869
2014-07-14 02:53:45,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331590263
2014-07-14 02:53:45,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331591824
2014-07-14 02:53:45,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331595519
2014-07-14 02:53:45,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331597110
2014-07-14 02:53:45,139 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331599111
2014-07-14 02:53:46,479 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:46,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13570 synced till here 13567
2014-07-14 02:53:46,546 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331625104 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331626480
2014-07-14 02:53:47,620 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:47,795 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13652 synced till here 13651
2014-07-14 02:53:47,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331626480 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331627621
2014-07-14 02:53:49,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:49,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13732 synced till here 13726
2014-07-14 02:53:49,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331627621 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331629814
2014-07-14 02:53:51,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:51,173 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:53:51,186 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13808 synced till here 13806
2014-07-14 02:53:51,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331629814 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331631140
2014-07-14 02:53:51,336 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:53:52,004 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3387, memsize=243.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/924befbaf4fc47c0900e275c255b1146
2014-07-14 02:53:52,017 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/924befbaf4fc47c0900e275c255b1146 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/924befbaf4fc47c0900e275c255b1146
2014-07-14 02:53:52,030 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/924befbaf4fc47c0900e275c255b1146, entries=884860, sequenceid=3387, filesize=63.0m
2014-07-14 02:53:52,031 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.1m/269608400, currentsize=136.7m/143322240 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8798ms, sequenceid=3387, compaction requested=true
2014-07-14 02:53:52,031 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:31), split_queue=0, merge_queue=0
2014-07-14 02:53:52,031 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 265.9m
2014-07-14 02:53:52,041 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3390, memsize=243.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8e2bc380dc154e208dac6baa47a9ce60
2014-07-14 02:53:52,054 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8e2bc380dc154e208dac6baa47a9ce60 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8e2bc380dc154e208dac6baa47a9ce60
2014-07-14 02:53:52,070 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8e2bc380dc154e208dac6baa47a9ce60, entries=886200, sequenceid=3390, filesize=63.1m
2014-07-14 02:53:52,070 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.1m/269613760, currentsize=135.3m/141883200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 9024ms, sequenceid=3390, compaction requested=true
2014-07-14 02:53:52,071 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:32), split_queue=0, merge_queue=0
2014-07-14 02:53:52,071 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 262.4m
2014-07-14 02:53:52,237 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:52,279 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:53:52,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:53:52,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13886 synced till here 13882
2014-07-14 02:53:52,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331631140 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331632473
2014-07-14 02:53:52,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331601684
2014-07-14 02:53:52,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331603169
2014-07-14 02:53:52,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331604546
2014-07-14 02:53:52,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331605649
2014-07-14 02:53:59,771 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3477, memsize=251.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/cd3639b2a40341fbb88f513bfa3fa556
2014-07-14 02:53:59,791 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/cd3639b2a40341fbb88f513bfa3fa556 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/cd3639b2a40341fbb88f513bfa3fa556
2014-07-14 02:53:59,803 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/cd3639b2a40341fbb88f513bfa3fa556, entries=917240, sequenceid=3477, filesize=65.3m
2014-07-14 02:53:59,803 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~268.9m/281912640, currentsize=40.5m/42449360 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 7772ms, sequenceid=3477, compaction requested=true
2014-07-14 02:53:59,803 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:33), split_queue=0, merge_queue=0
2014-07-14 02:53:59,912 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3476, memsize=246.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/9a4d1f08029f4b039e87e5f746709f3a
2014-07-14 02:53:59,931 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/9a4d1f08029f4b039e87e5f746709f3a as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/9a4d1f08029f4b039e87e5f746709f3a
2014-07-14 02:53:59,947 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/9a4d1f08029f4b039e87e5f746709f3a, entries=898910, sequenceid=3476, filesize=64.0m
2014-07-14 02:53:59,948 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.0m/276828720, currentsize=45.2m/47441040 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 7877ms, sequenceid=3476, compaction requested=true
2014-07-14 02:53:59,948 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-14 02:54:10,012 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e509b05a45ba4c7288b8d83244e56573 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e509b05a45ba4c7288b8d83244e56573
2014-07-14 02:54:10,031 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:54:10,045 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/539ce5842b84413783eff39c30e0e1a4, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/539ce5842b84413783eff39c30e0e1a4
2014-07-14 02:54:10,051 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/927bfab3c6c940cd904a823c799a0b24, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/927bfab3c6c940cd904a823c799a0b24
2014-07-14 02:54:10,056 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fd259302b6a14b26aa59bc41d24d3f2f, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fd259302b6a14b26aa59bc41d24d3f2f
2014-07-14 02:54:10,060 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2466f73dcbaf495e9dae5ba238157dc5, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2466f73dcbaf495e9dae5ba238157dc5
2014-07-14 02:54:10,063 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fe84170fd17240e18c3985e57ec81685, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/fe84170fd17240e18c3985e57ec81685
2014-07-14 02:54:10,070 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2db3a1f6da744db697dfab4262f61955, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2db3a1f6da744db697dfab4262f61955
2014-07-14 02:54:10,074 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/55abccbf946b4e168dc9d496dba74be5, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/55abccbf946b4e168dc9d496dba74be5
2014-07-14 02:54:10,077 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b492cf38bcec4818b8996e9e6974b172, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/b492cf38bcec4818b8996e9e6974b172
2014-07-14 02:54:10,077 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 8 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into e509b05a45ba4c7288b8d83244e56573(size=554.2m), total size for store is 833.8m. This selection was in queue for 0sec, and took 1mins, 25sec to execute.
2014-07-14 02:54:10,077 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=8, fileSize=575.6m, priority=12, time=285471660903330; duration=1mins, 25sec
2014-07-14 02:54:10,078 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-14 02:54:10,078 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 10 store files, 0 compacting, 10 eligible, 20 blocking
2014-07-14 02:54:10,079 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 847171117 starting at candidate #0 after considering 36 permutations with 35 in ratio
2014-07-14 02:54:10,079 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating major compaction
2014-07-14 02:54:10,079 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:54:10,079 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=807.9m
2014-07-14 02:54:10,079 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cc0ce3d7c7754ae785151978b6d5ea12, keycount=265739, bloomtype=ROW, size=189.3m, encoding=NONE, seqNum=1793, earliestPutTs=1405331204376
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/73a859e0504946feaa02708b17d1012b, keycount=123027, bloomtype=ROW, size=87.6m, encoding=NONE, seqNum=2013, earliestPutTs=1405331397178
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/646070c862cf4325a8b2bcc9ac485131, keycount=92683, bloomtype=ROW, size=66.0m, encoding=NONE, seqNum=2179, earliestPutTs=1405331418181
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/549b7a89523c46dda025f4da7c54b529, keycount=92831, bloomtype=ROW, size=66.0m, encoding=NONE, seqNum=2346, earliestPutTs=1405331440496
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/077fbc20860940d08442f227f1be7380, keycount=89673, bloomtype=ROW, size=63.9m, encoding=NONE, seqNum=2514, earliestPutTs=1405331479919
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ec50252e6d4b4bbdb565230e044616cb, keycount=79938, bloomtype=ROW, size=56.9m, encoding=NONE, seqNum=2682, earliestPutTs=1405331499095
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/685cc1a55a2645e2aa134a5a5c6b75f9, keycount=102605, bloomtype=ROW, size=73.1m, encoding=NONE, seqNum=2864, earliestPutTs=1405331520728
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cce31156d8344b339345ee43a7b6c9a7, keycount=106366, bloomtype=ROW, size=75.8m, encoding=NONE, seqNum=3053, earliestPutTs=1405331554337
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/27ad04701916424186ded7ee75b3d264, keycount=93068, bloomtype=ROW, size=66.3m, encoding=NONE, seqNum=3221, earliestPutTs=1405331584554
2014-07-14 02:54:10,080 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/924befbaf4fc47c0900e275c255b1146, keycount=88486, bloomtype=ROW, size=63.0m, encoding=NONE, seqNum=3387, earliestPutTs=1405331602116
2014-07-14 02:54:10,205 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:12,575 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:12,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331632473 with entries=75, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331652575
2014-07-14 02:54:12,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331607108
2014-07-14 02:54:12,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331616721
2014-07-14 02:54:12,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331618058
2014-07-14 02:54:12,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331619223
2014-07-14 02:54:16,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:16,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14035 synced till here 14033
2014-07-14 02:54:16,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331652575 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331656473
2014-07-14 02:54:17,962 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:18,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14115 synced till here 14113
2014-07-14 02:54:18,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331656473 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331657963
2014-07-14 02:54:18,565 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:54:18,565 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.1m
2014-07-14 02:54:18,656 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:54:18,657 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 256.6m
2014-07-14 02:54:18,801 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:19,261 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:19,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:19,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14230 synced till here 14223
2014-07-14 02:54:20,013 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331657963 with entries=115, filesize=99.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331659587
2014-07-14 02:54:21,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:22,029 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14325 synced till here 14320
2014-07-14 02:54:22,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331659587 with entries=95, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331661289
2014-07-14 02:54:23,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:24,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14414 synced till here 14412
2014-07-14 02:54:24,161 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331661289 with entries=89, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331663979
2014-07-14 02:54:25,544 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:25,695 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:54:25,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331663979 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331665544
2014-07-14 02:54:25,879 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:54:27,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:27,184 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14572 synced till here 14570
2014-07-14 02:54:27,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331665544 with entries=75, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331667169
2014-07-14 02:54:28,456 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:28,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14647 synced till here 14645
2014-07-14 02:54:28,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331667169 with entries=75, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331668456
2014-07-14 02:54:29,085 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3557, memsize=242.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/51a652194db8439499f7cc708dec7822
2014-07-14 02:54:29,091 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3554, memsize=242.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/622c243dba10405caadc972d113be024
2014-07-14 02:54:29,101 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/51a652194db8439499f7cc708dec7822 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/51a652194db8439499f7cc708dec7822
2014-07-14 02:54:29,105 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/622c243dba10405caadc972d113be024 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/622c243dba10405caadc972d113be024
2014-07-14 02:54:29,114 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/51a652194db8439499f7cc708dec7822, entries=883500, sequenceid=3557, filesize=63.0m
2014-07-14 02:54:29,114 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.1m/270608880, currentsize=209.5m/219659280 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 10457ms, sequenceid=3557, compaction requested=true
2014-07-14 02:54:29,114 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-14 02:54:29,115 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 330.2m
2014-07-14 02:54:29,117 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/622c243dba10405caadc972d113be024, entries=881140, sequenceid=3554, filesize=62.8m
2014-07-14 02:54:29,117 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.7m/270194000, currentsize=210.9m/221190160 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 10552ms, sequenceid=3554, compaction requested=false
2014-07-14 02:54:29,118 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 330.8m
2014-07-14 02:54:29,354 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:29,397 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:29,407 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:29,852 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14725 synced till here 14720
2014-07-14 02:54:29,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331668456 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331669407
2014-07-14 02:54:29,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331620705
2014-07-14 02:54:29,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331625104
2014-07-14 02:54:29,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331626480
2014-07-14 02:54:29,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331627621
2014-07-14 02:54:29,914 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331629814
2014-07-14 02:54:30,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:30,859 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14799 synced till here 14798
2014-07-14 02:54:30,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331669407 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331670833
2014-07-14 02:54:31,294 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:54:31,445 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:54:31,868 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:32,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14884 synced till here 14883
2014-07-14 02:54:32,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331670833 with entries=85, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331671868
2014-07-14 02:54:34,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:34,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14974 synced till here 14964
2014-07-14 02:54:34,549 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331671868 with entries=90, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331674218
2014-07-14 02:54:36,377 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:36,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15071 synced till here 15047
2014-07-14 02:54:36,606 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331674218 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331676378
2014-07-14 02:54:38,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:38,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15170 synced till here 15152
2014-07-14 02:54:38,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331676378 with entries=99, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331678118
2014-07-14 02:54:40,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:40,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15283 synced till here 15271
2014-07-14 02:54:40,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331678118 with entries=113, filesize=96.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331680436
2014-07-14 02:54:42,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:42,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15359 synced till here 15356
2014-07-14 02:54:42,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331680436 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331682063
2014-07-14 02:54:43,452 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:43,472 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15434 synced till here 15431
2014-07-14 02:54:43,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331682063 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331683452
2014-07-14 02:54:44,889 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3691, memsize=292.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/4e78a78cf4b84717a172322a59568d5a
2014-07-14 02:54:45,025 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/4e78a78cf4b84717a172322a59568d5a as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4e78a78cf4b84717a172322a59568d5a
2014-07-14 02:54:45,036 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4e78a78cf4b84717a172322a59568d5a, entries=1063970, sequenceid=3691, filesize=75.8m
2014-07-14 02:54:45,036 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~331.6m/347744640, currentsize=315.1m/330382400 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 15921ms, sequenceid=3691, compaction requested=true
2014-07-14 02:54:45,037 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:35), split_queue=0, merge_queue=0
2014-07-14 02:54:45,037 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 522.6m
2014-07-14 02:54:45,117 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:54:45,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:45,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15520 synced till here 15506
2014-07-14 02:54:45,240 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3692, memsize=296.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/38ea92f9e37a4c879ae98b544b012c42
2014-07-14 02:54:45,254 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/38ea92f9e37a4c879ae98b544b012c42 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/38ea92f9e37a4c879ae98b544b012c42
2014-07-14 02:54:45,264 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/38ea92f9e37a4c879ae98b544b012c42, entries=1080520, sequenceid=3692, filesize=77.0m
2014-07-14 02:54:45,264 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~332.2m/348304560, currentsize=311.7m/326832480 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 16146ms, sequenceid=3692, compaction requested=true
2014-07-14 02:54:45,264 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:36), split_queue=0, merge_queue=0
2014-07-14 02:54:45,264 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 514.5m
2014-07-14 02:54:45,301 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:54:45,323 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331683452 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331685148
2014-07-14 02:54:45,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331631140
2014-07-14 02:54:45,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331632473
2014-07-14 02:54:45,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331652575
2014-07-14 02:54:45,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331656473
2014-07-14 02:54:45,508 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:46,548 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:54:46,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:46,988 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15599 synced till here 15596
2014-07-14 02:54:47,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331685148 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331686847
2014-07-14 02:54:48,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:48,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15674 synced till here 15673
2014-07-14 02:54:48,373 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331686847 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331688321
2014-07-14 02:54:49,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:49,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15766 synced till here 15763
2014-07-14 02:54:49,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331688321 with entries=92, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331689567
2014-07-14 02:54:50,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:51,234 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15871 synced till here 15868
2014-07-14 02:54:51,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331689567 with entries=105, filesize=89.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331690842
2014-07-14 02:54:52,726 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:52,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15944 synced till here 15942
2014-07-14 02:54:52,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331690842 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331692727
2014-07-14 02:54:54,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:54,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16030 synced till here 16026
2014-07-14 02:54:54,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331692727 with entries=86, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331694013
2014-07-14 02:54:55,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:55,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16108 synced till here 16102
2014-07-14 02:54:55,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331694013 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331695396
2014-07-14 02:54:56,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:57,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16214 synced till here 16211
2014-07-14 02:54:57,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331695396 with entries=106, filesize=90.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331696785
2014-07-14 02:54:58,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:54:58,541 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16289 synced till here 16287
2014-07-14 02:54:58,580 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331696785 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331698513
2014-07-14 02:54:59,938 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3894, memsize=303.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/aabc1e48d7454c2a96ba3903ffa7eeb2
2014-07-14 02:54:59,957 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/aabc1e48d7454c2a96ba3903ffa7eeb2 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/aabc1e48d7454c2a96ba3903ffa7eeb2
2014-07-14 02:54:59,979 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/aabc1e48d7454c2a96ba3903ffa7eeb2, entries=1106280, sequenceid=3894, filesize=78.8m
2014-07-14 02:54:59,980 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~525.5m/550993760, currentsize=322.3m/337936800 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 14943ms, sequenceid=3894, compaction requested=false
2014-07-14 02:54:59,980 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 637.0m
2014-07-14 02:55:00,166 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:55:00,249 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3896, memsize=303.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/1c9c12a789394f8da144bff3d4ba927d
2014-07-14 02:55:00,264 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/1c9c12a789394f8da144bff3d4ba927d as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1c9c12a789394f8da144bff3d4ba927d
2014-07-14 02:55:00,277 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1c9c12a789394f8da144bff3d4ba927d, entries=1103190, sequenceid=3896, filesize=78.6m
2014-07-14 02:55:00,278 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~523.7m/549146640, currentsize=324.6m/340330080 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 15014ms, sequenceid=3896, compaction requested=true
2014-07-14 02:55:00,278 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:37), split_queue=0, merge_queue=0
2014-07-14 02:55:00,278 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 637.9m
2014-07-14 02:55:00,305 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:55:00,413 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:55:00,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:00,571 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16364 synced till here 16362
2014-07-14 02:55:00,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331698513 with entries=75, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331700537
2014-07-14 02:55:00,623 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331657963
2014-07-14 02:55:00,623 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331659587
2014-07-14 02:55:00,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331661289
2014-07-14 02:55:00,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331663979
2014-07-14 02:55:00,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331665544
2014-07-14 02:55:00,624 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331667169
2014-07-14 02:55:01,125 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:55:01,728 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:01,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16438 synced till here 16437
2014-07-14 02:55:01,779 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331700537 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331701728
2014-07-14 02:55:02,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:02,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16512 synced till here 16510
2014-07-14 02:55:02,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331701728 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331702812
2014-07-14 02:55:03,877 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:04,408 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16605 synced till here 16592
2014-07-14 02:55:04,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331702812 with entries=93, filesize=79.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331703878
2014-07-14 02:55:06,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:07,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16707 synced till here 16703
2014-07-14 02:55:07,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331703878 with entries=102, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331706242
2014-07-14 02:55:07,157 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.41 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=104910, hits=17361, hitRatio=16.54%, , cachingAccesses=17373, cachingHits=17351, cachingHitsRatio=99.87%, evictions=0, evicted=18, evictedPerRun=Infinity
2014-07-14 02:55:08,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:08,605 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16799 synced till here 16787
2014-07-14 02:55:08,708 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331706242 with entries=92, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331708563
2014-07-14 02:55:10,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:10,596 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16896 synced till here 16894
2014-07-14 02:55:10,670 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331708563 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331710441
2014-07-14 02:55:12,176 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:12,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16973 synced till here 16970
2014-07-14 02:55:12,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331710441 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331712177
2014-07-14 02:55:12,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:13,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17052 synced till here 17046
2014-07-14 02:55:13,546 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331712177 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331712963
2014-07-14 02:55:14,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:14,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17126 synced till here 17124
2014-07-14 02:55:14,804 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331712963 with entries=74, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331714572
2014-07-14 02:55:16,032 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:16,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17211 synced till here 17206
2014-07-14 02:55:16,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331714572 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331716033
2014-07-14 02:55:17,715 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:18,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17295 synced till here 17290
2014-07-14 02:55:18,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331716033 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331717716
2014-07-14 02:55:20,072 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:20,096 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17381 synced till here 17369
2014-07-14 02:55:20,199 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331717716 with entries=86, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331720072
2014-07-14 02:55:20,937 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:21,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17464 synced till here 17454
2014-07-14 02:55:21,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331720072 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331720938
2014-07-14 02:55:22,780 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:23,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17550 synced till here 17535
2014-07-14 02:55:23,834 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331720938 with entries=86, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331722780
2014-07-14 02:55:25,439 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4100, memsize=402.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/9a4ec92042204b1b97fe8304e52e3fdf
2014-07-14 02:55:25,469 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/9a4ec92042204b1b97fe8304e52e3fdf as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a4ec92042204b1b97fe8304e52e3fdf
2014-07-14 02:55:25,490 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a4ec92042204b1b97fe8304e52e3fdf, entries=1466160, sequenceid=4100, filesize=104.4m
2014-07-14 02:55:25,491 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~637.0m/667962160, currentsize=517.0m/542126960 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 25511ms, sequenceid=4100, compaction requested=true
2014-07-14 02:55:25,491 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:38), split_queue=0, merge_queue=0
2014-07-14 02:55:25,491 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 824.6m
2014-07-14 02:55:25,666 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:25,667 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:55:25,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17655 synced till here 17629
2014-07-14 02:55:26,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331722780 with entries=105, filesize=90.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331725666
2014-07-14 02:55:26,453 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4106, memsize=407.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e2a81427f41b4664a4007d094cc2ba88
2014-07-14 02:55:26,469 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e2a81427f41b4664a4007d094cc2ba88 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e2a81427f41b4664a4007d094cc2ba88
2014-07-14 02:55:26,495 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e2a81427f41b4664a4007d094cc2ba88, entries=1481970, sequenceid=4106, filesize=105.5m
2014-07-14 02:55:26,496 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~641.0m/672120160, currentsize=507.7m/532349040 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 26218ms, sequenceid=4106, compaction requested=true
2014-07-14 02:55:26,496 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-14 02:55:26,496 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 824.1m
2014-07-14 02:55:26,504 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:55:27,487 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:55:27,664 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:27,694 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17760 synced till here 17742
2014-07-14 02:55:27,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331725666 with entries=105, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331727664
2014-07-14 02:55:27,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331668456
2014-07-14 02:55:27,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331669407
2014-07-14 02:55:27,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331670833
2014-07-14 02:55:27,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331671868
2014-07-14 02:55:27,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331674218
2014-07-14 02:55:27,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331676378
2014-07-14 02:55:27,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331678118
2014-07-14 02:55:27,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331680436
2014-07-14 02:55:27,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331682063
2014-07-14 02:55:28,092 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:55:29,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:29,375 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17848 synced till here 17831
2014-07-14 02:55:29,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331727664 with entries=88, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331729327
2014-07-14 02:55:31,285 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:31,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17955 synced till here 17932
2014-07-14 02:55:31,571 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331729327 with entries=107, filesize=91.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331731285
2014-07-14 02:55:33,377 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:33,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18055 synced till here 18029
2014-07-14 02:55:34,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331731285 with entries=100, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331733378
2014-07-14 02:55:36,489 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:36,553 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18176 synced till here 18143
2014-07-14 02:55:36,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331733378 with entries=121, filesize=103.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331736489
2014-07-14 02:55:38,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:38,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18265 synced till here 18254
2014-07-14 02:55:38,495 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331736489 with entries=89, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331738317
2014-07-14 02:55:39,565 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:39,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18347 synced till here 18346
2014-07-14 02:55:39,846 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331738317 with entries=82, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331739565
2014-07-14 02:55:41,589 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:41,686 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18426 synced till here 18422
2014-07-14 02:55:41,723 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331739565 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331741589
2014-07-14 02:55:42,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:42,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18503 synced till here 18500
2014-07-14 02:55:42,901 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331741589 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331742814
2014-07-14 02:55:43,176 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,185 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,208 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,209 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,217 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,223 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,229 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,250 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,250 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,256 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,270 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:43,987 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,023 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,079 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,119 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,160 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,211 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,243 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,295 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,337 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,376 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,435 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:44,466 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,157 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,172 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,184 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,213 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,244 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,273 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,308 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,362 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,406 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,458 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,491 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,527 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,564 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,603 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:45,682 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,099 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,129 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,160 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,210 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,253 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,295 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,332 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,375 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,416 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,460 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,492 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:46,535 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:55:48,177 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:48,187 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 02:55:48,209 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:48,209 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:48,217 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:48,223 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:48,230 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:48,251 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:48,251 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:48,256 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:48,271 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,158 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5039ms
2014-07-14 02:55:49,159 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5136ms
2014-07-14 02:55:49,159 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-14 02:55:49,160 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5172ms
2014-07-14 02:55:49,160 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,212 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,243 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,295 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,337 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,376 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,435 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:49,466 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,158 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:50,172 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,184 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,213 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,244 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,273 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:50,308 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,363 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:50,406 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,458 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,492 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:50,527 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,564 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:50,603 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:50,682 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,100 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:51,129 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,160 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,210 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,253 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,296 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:51,333 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:51,376 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,416 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,460 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 02:55:51,493 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:51,535 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 02:55:52,767 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4436, memsize=502.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/b57b130742d7455caeda14f8e4b295d0
2014-07-14 02:55:52,782 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/b57b130742d7455caeda14f8e4b295d0 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/b57b130742d7455caeda14f8e4b295d0
2014-07-14 02:55:52,793 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/b57b130742d7455caeda14f8e4b295d0, entries=1827950, sequenceid=4436, filesize=130.2m
2014-07-14 02:55:52,793 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~841.8m/882673360, currentsize=340.1m/356599600 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 27302ms, sequenceid=4436, compaction requested=true
2014-07-14 02:55:52,793 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:40), split_queue=0, merge_queue=0
2014-07-14 02:55:52,793 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6259ms
2014-07-14 02:55:52,794 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,794 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 856.9m
2014-07-14 02:55:52,794 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6302ms
2014-07-14 02:55:52,794 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,794 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6334ms
2014-07-14 02:55:52,794 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,794 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6378ms
2014-07-14 02:55:52,794 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,794 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6419ms
2014-07-14 02:55:52,794 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,795 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6462ms
2014-07-14 02:55:52,795 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,795 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6500ms
2014-07-14 02:55:52,795 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,796 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6543ms
2014-07-14 02:55:52,796 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,797 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6587ms
2014-07-14 02:55:52,797 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,797 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6637ms
2014-07-14 02:55:52,801 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,801 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6672ms
2014-07-14 02:55:52,801 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,801 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6702ms
2014-07-14 02:55:52,801 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,802 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7119ms
2014-07-14 02:55:52,802 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,802 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7200ms
2014-07-14 02:55:52,802 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,803 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7239ms
2014-07-14 02:55:52,803 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,804 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7277ms
2014-07-14 02:55:52,804 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,805 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7314ms
2014-07-14 02:55:52,805 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,805 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7347ms
2014-07-14 02:55:52,805 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,806 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7399ms
2014-07-14 02:55:52,806 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,807 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7445ms
2014-07-14 02:55:52,807 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,808 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7499ms
2014-07-14 02:55:52,808 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,811 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7538ms
2014-07-14 02:55:52,811 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,812 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7567ms
2014-07-14 02:55:52,812 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,813 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7599ms
2014-07-14 02:55:52,813 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,813 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7629ms
2014-07-14 02:55:52,813 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,814 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7641ms
2014-07-14 02:55:52,814 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,815 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7658ms
2014-07-14 02:55:52,815 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,815 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8349ms
2014-07-14 02:55:52,815 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,815 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8380ms
2014-07-14 02:55:52,816 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,816 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8440ms
2014-07-14 02:55:52,816 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,816 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8479ms
2014-07-14 02:55:52,816 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,822 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8526ms
2014-07-14 02:55:52,822 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,823 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8579ms
2014-07-14 02:55:52,823 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,823 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8612ms
2014-07-14 02:55:52,823 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,823 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8663ms
2014-07-14 02:55:52,823 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,824 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8837ms
2014-07-14 02:55:52,824 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,825 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8745ms
2014-07-14 02:55:52,825 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,825 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8802ms
2014-07-14 02:55:52,825 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,826 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8706ms
2014-07-14 02:55:52,826 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,827 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9556ms
2014-07-14 02:55:52,827 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,828 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9571ms
2014-07-14 02:55:52,828 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,829 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9579ms
2014-07-14 02:55:52,829 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,833 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9583ms
2014-07-14 02:55:52,833 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,834 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9605ms
2014-07-14 02:55:52,834 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,835 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9611ms
2014-07-14 02:55:52,835 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,835 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9618ms
2014-07-14 02:55:52,835 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,841 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9633ms
2014-07-14 02:55:52,842 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,842 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9634ms
2014-07-14 02:55:52,842 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:52,845 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9660ms
2014-07-14 02:55:52,845 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:53,417 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9669ms
2014-07-14 02:55:53,417 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:55:53,610 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:55:53,612 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10723,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331742888,"queuetimems":0,"class":"HRegionServer","responsesize":16066,"method":"Multi"}
2014-07-14 02:55:53,622 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10777,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331742844,"queuetimems":0,"class":"HRegionServer","responsesize":16008,"method":"Multi"}
2014-07-14 02:55:53,623 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10700,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331742918,"queuetimems":1,"class":"HRegionServer","responsesize":15848,"method":"Multi"}
2014-07-14 02:55:53,624 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10821,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331742800,"queuetimems":0,"class":"HRegionServer","responsesize":15701,"method":"Multi"}
2014-07-14 02:55:54,048 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:54,049 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11099,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331742949,"queuetimems":0,"class":"HRegionServer","responsesize":15945,"method":"Multi"}
2014-07-14 02:55:54,049 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331742978,"queuetimems":0,"class":"HRegionServer","responsesize":15962,"method":"Multi"}
2014-07-14 02:55:54,160 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:55:54,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18601 synced till here 18599
2014-07-14 02:55:54,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331742814 with entries=98, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331754048
2014-07-14 02:55:54,208 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331683452
2014-07-14 02:55:54,407 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4435, memsize=502.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ca59963ec855454d94d8ec8fb7605a3e
2014-07-14 02:55:54,416 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331743084,"queuetimems":0,"class":"HRegionServer","responsesize":15637,"method":"Multi"}
2014-07-14 02:55:54,416 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11286,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331743130,"queuetimems":0,"class":"HRegionServer","responsesize":15575,"method":"Multi"}
2014-07-14 02:55:54,416 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11379,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331743037,"queuetimems":0,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 02:55:54,422 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ca59963ec855454d94d8ec8fb7605a3e as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ca59963ec855454d94d8ec8fb7605a3e
2014-07-14 02:55:54,450 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ca59963ec855454d94d8ec8fb7605a3e, entries=1827970, sequenceid=4435, filesize=130.2m
2014-07-14 02:55:54,451 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~836.7m/877386560, currentsize=353.7m/370893360 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 27955ms, sequenceid=4435, compaction requested=true
2014-07-14 02:55:54,451 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-14 02:55:54,451 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 865.1m
2014-07-14 02:55:55,330 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:55:55,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:55,690 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18714 synced till here 18675
2014-07-14 02:55:55,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331754048 with entries=113, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331755508
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331685148
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331686847
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331688321
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331689567
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331690842
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331692727
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331694013
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331695396
2014-07-14 02:55:55,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331696785
2014-07-14 02:55:55,928 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:55:56,068 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745679,"queuetimems":0,"class":"HRegionServer","responsesize":15769,"method":"Multi"}
2014-07-14 02:55:56,723 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10474,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746248,"queuetimems":0,"class":"HRegionServer","responsesize":15328,"method":"Multi"}
2014-07-14 02:55:56,723 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11234,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745488,"queuetimems":0,"class":"HRegionServer","responsesize":16282,"method":"Multi"}
2014-07-14 02:55:56,723 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746097,"queuetimems":0,"class":"HRegionServer","responsesize":15673,"method":"Multi"}
2014-07-14 02:55:56,724 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11365,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745359,"queuetimems":1,"class":"HRegionServer","responsesize":16008,"method":"Multi"}
2014-07-14 02:55:56,723 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13501,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331743221,"queuetimems":1,"class":"HRegionServer","responsesize":15955,"method":"Multi"}
2014-07-14 02:55:56,724 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10314,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746410,"queuetimems":0,"class":"HRegionServer","responsesize":15624,"method":"Multi"}
2014-07-14 02:55:56,723 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10351,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746371,"queuetimems":0,"class":"HRegionServer","responsesize":16175,"method":"Multi"}
2014-07-14 02:55:56,725 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11201,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745523,"queuetimems":0,"class":"HRegionServer","responsesize":15701,"method":"Multi"}
2014-07-14 02:55:56,724 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11321,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745402,"queuetimems":1,"class":"HRegionServer","responsesize":15894,"method":"Multi"}
2014-07-14 02:55:56,878 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745211,"queuetimems":1,"class":"HRegionServer","responsesize":15531,"method":"Multi"}
2014-07-14 02:55:56,879 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11696,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745182,"queuetimems":0,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-14 02:55:56,879 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12416,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744463,"queuetimems":0,"class":"HRegionServer","responsesize":15890,"method":"Multi"}
2014-07-14 02:55:56,879 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744158,"queuetimems":0,"class":"HRegionServer","responsesize":15638,"method":"Multi"}
2014-07-14 02:55:57,074 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13088,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331743985,"queuetimems":0,"class":"HRegionServer","responsesize":15978,"method":"Multi"}
2014-07-14 02:55:57,074 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745448,"queuetimems":1,"class":"HRegionServer","responsesize":15846,"method":"Multi"}
2014-07-14 02:55:57,075 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12865,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744209,"queuetimems":0,"class":"HRegionServer","responsesize":15624,"method":"Multi"}
2014-07-14 02:55:57,074 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12699,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744374,"queuetimems":0,"class":"HRegionServer","responsesize":15712,"method":"Multi"}
2014-07-14 02:55:57,082 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744077,"queuetimems":0,"class":"HRegionServer","responsesize":15328,"method":"Multi"}
2014-07-14 02:55:57,085 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331743174,"queuetimems":1,"class":"HRegionServer","responsesize":15661,"method":"Multi"}
2014-07-14 02:55:57,074 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745560,"queuetimems":0,"class":"HRegionServer","responsesize":16066,"method":"Multi"}
2014-07-14 02:55:57,074 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745242,"queuetimems":1,"class":"HRegionServer","responsesize":15926,"method":"Multi"}
2014-07-14 02:55:57,089 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10799,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746290,"queuetimems":1,"class":"HRegionServer","responsesize":15816,"method":"Multi"}
2014-07-14 02:55:57,093 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12976,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744117,"queuetimems":0,"class":"HRegionServer","responsesize":15821,"method":"Multi"}
2014-07-14 02:55:57,097 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744241,"queuetimems":0,"class":"HRegionServer","responsesize":16175,"method":"Multi"}
2014-07-14 02:55:57,074 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10746,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746327,"queuetimems":0,"class":"HRegionServer","responsesize":15821,"method":"Multi"}
2014-07-14 02:55:57,098 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12804,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744293,"queuetimems":0,"class":"HRegionServer","responsesize":15816,"method":"Multi"}
2014-07-14 02:55:57,098 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744335,"queuetimems":0,"class":"HRegionServer","responsesize":15786,"method":"Multi"}
2014-07-14 02:55:57,082 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745170,"queuetimems":0,"class":"HRegionServer","responsesize":15673,"method":"Multi"}
2014-07-14 02:55:57,082 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746206,"queuetimems":0,"class":"HRegionServer","responsesize":15626,"method":"Multi"}
2014-07-14 02:55:57,100 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10942,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746158,"queuetimems":0,"class":"HRegionServer","responsesize":15638,"method":"Multi"}
2014-07-14 02:55:57,106 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11834,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745271,"queuetimems":0,"class":"HRegionServer","responsesize":15490,"method":"Multi"}
2014-07-14 02:55:57,113 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745305,"queuetimems":1,"class":"HRegionServer","responsesize":15739,"method":"Multi"}
2014-07-14 02:55:57,099 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12667,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744432,"queuetimems":0,"class":"HRegionServer","responsesize":15626,"method":"Multi"}
2014-07-14 02:55:57,098 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10971,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331746127,"queuetimems":0,"class":"HRegionServer","responsesize":15712,"method":"Multi"}
2014-07-14 02:55:57,098 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744021,"queuetimems":1,"class":"HRegionServer","responsesize":15487,"method":"Multi"}
2014-07-14 02:55:57,098 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331745598,"queuetimems":0,"class":"HRegionServer","responsesize":15143,"method":"Multi"}
2014-07-14 02:55:57,221 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:57,294 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18817 synced till here 18789
2014-07-14 02:55:57,373 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405331744517,"queuetimems":0,"class":"HRegionServer","responsesize":15937,"method":"Multi"}
2014-07-14 02:55:57,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331755508 with entries=103, filesize=86.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331757222
2014-07-14 02:55:59,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:55:59,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18902 synced till here 18892
2014-07-14 02:55:59,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331757222 with entries=85, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331759188
2014-07-14 02:56:00,805 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:01,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19036 synced till here 19016
2014-07-14 02:56:02,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331759188 with entries=134, filesize=112.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331760806
2014-07-14 02:56:03,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:03,256 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19144 synced till here 19112
2014-07-14 02:56:04,090 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331760806 with entries=108, filesize=92.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331763058
2014-07-14 02:56:04,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:05,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19227 synced till here 19219
2014-07-14 02:56:05,120 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331763058 with entries=83, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331764959
2014-07-14 02:56:06,459 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:06,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19320 synced till here 19312
2014-07-14 02:56:06,725 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331764959 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331766459
2014-07-14 02:56:08,367 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:08,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19398 synced till here 19394
2014-07-14 02:56:08,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331766459 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331768368
2014-07-14 02:56:09,736 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:09,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19474 synced till here 19471
2014-07-14 02:56:09,816 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331768368 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331769736
2014-07-14 02:56:11,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:11,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19547 synced till here 19546
2014-07-14 02:56:11,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331769736 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331771161
2014-07-14 02:56:12,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:12,512 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19622 synced till here 19620
2014-07-14 02:56:12,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331771161 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331772488
2014-07-14 02:56:12,616 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,618 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,618 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,625 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,642 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,642 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,643 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,662 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,663 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,695 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,730 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,766 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,798 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,830 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,879 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,935 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:12,992 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:13,054 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:13,107 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:13,164 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:56:13,317 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4656, memsize=301.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f9e5d0a41e804851a517aced6ec685ff
2014-07-14 02:56:13,335 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f9e5d0a41e804851a517aced6ec685ff as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f9e5d0a41e804851a517aced6ec685ff
2014-07-14 02:56:13,349 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f9e5d0a41e804851a517aced6ec685ff, entries=1096380, sequenceid=4656, filesize=78.0m
2014-07-14 02:56:13,349 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~856.9m/898544720, currentsize=419.6m/439998880 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 20555ms, sequenceid=4656, compaction requested=true
2014-07-14 02:56:13,350 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:42), split_queue=0, merge_queue=0
2014-07-14 02:56:13,350 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 186ms
2014-07-14 02:56:13,350 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,350 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 758.9m
2014-07-14 02:56:13,350 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 243ms
2014-07-14 02:56:13,350 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,350 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 296ms
2014-07-14 02:56:13,350 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,350 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 358ms
2014-07-14 02:56:13,351 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,351 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 416ms
2014-07-14 02:56:13,351 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,351 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 472ms
2014-07-14 02:56:13,351 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,351 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 521ms
2014-07-14 02:56:13,351 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,352 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 553ms
2014-07-14 02:56:13,352 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,353 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 587ms
2014-07-14 02:56:13,353 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,369 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 639ms
2014-07-14 02:56:13,369 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,369 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 674ms
2014-07-14 02:56:13,369 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,369 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 706ms
2014-07-14 02:56:13,369 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,374 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 711ms
2014-07-14 02:56:13,374 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,374 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 731ms
2014-07-14 02:56:13,374 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,374 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 732ms
2014-07-14 02:56:13,374 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,375 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 733ms
2014-07-14 02:56:13,375 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,376 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 750ms
2014-07-14 02:56:13,376 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,377 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 758ms
2014-07-14 02:56:13,377 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,378 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 759ms
2014-07-14 02:56:13,378 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:13,378 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 762ms
2014-07-14 02:56:13,378 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:56:14,127 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:56:14,701 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:56:14,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:14,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19718 synced till here 19700
2014-07-14 02:56:15,005 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331772488 with entries=96, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331774787
2014-07-14 02:56:15,965 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4662, memsize=304.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/343f0b3993d54f8e84e593c725960411
2014-07-14 02:56:15,984 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/343f0b3993d54f8e84e593c725960411 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/343f0b3993d54f8e84e593c725960411
2014-07-14 02:56:16,003 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/343f0b3993d54f8e84e593c725960411, entries=1109520, sequenceid=4662, filesize=79.0m
2014-07-14 02:56:16,004 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~866.7m/908776880, currentsize=454.2m/476263440 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 21553ms, sequenceid=4662, compaction requested=true
2014-07-14 02:56:16,004 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-14 02:56:16,005 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 797.5m
2014-07-14 02:56:16,167 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:56:16,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:16,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19815 synced till here 19797
2014-07-14 02:56:16,603 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331774787 with entries=97, filesize=83.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331776460
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331698513
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331700537
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331701728
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331702812
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331703878
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331706242
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331708563
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331710441
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331712177
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331712963
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331714572
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331716033
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331717716
2014-07-14 02:56:16,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331720072
2014-07-14 02:56:16,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331720938
2014-07-14 02:56:17,441 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:56:18,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:18,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19906 synced till here 19891
2014-07-14 02:56:18,857 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331776460 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331778039
2014-07-14 02:56:19,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:20,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20004 synced till here 19980
2014-07-14 02:56:20,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331778039 with entries=98, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331779563
2014-07-14 02:56:21,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:22,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20108 synced till here 20088
2014-07-14 02:56:22,379 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331779563 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331781964
2014-07-14 02:56:24,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:24,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20211 synced till here 20210
2014-07-14 02:56:24,392 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331781964 with entries=103, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331784154
2014-07-14 02:56:26,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:26,523 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20310 synced till here 20295
2014-07-14 02:56:26,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331784154 with entries=99, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331786441
2014-07-14 02:56:28,232 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:28,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20405 synced till here 20385
2014-07-14 02:56:28,514 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331786441 with entries=95, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331788232
2014-07-14 02:56:30,255 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:30,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20507 synced till here 20484
2014-07-14 02:56:31,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331788232 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331790256
2014-07-14 02:56:32,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:33,192 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20609 synced till here 20585
2014-07-14 02:56:33,398 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331790256 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331792363
2014-07-14 02:56:34,178 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:34,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20697 synced till here 20688
2014-07-14 02:56:34,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331792363 with entries=88, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331794179
2014-07-14 02:56:34,931 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4928, memsize=230.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/512e8366de0749049f98ad3c0ec9b13f
2014-07-14 02:56:34,947 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/512e8366de0749049f98ad3c0ec9b13f as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/512e8366de0749049f98ad3c0ec9b13f
2014-07-14 02:56:34,995 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/512e8366de0749049f98ad3c0ec9b13f, entries=837840, sequenceid=4928, filesize=59.7m
2014-07-14 02:56:34,996 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~758.9m/795746800, currentsize=421.3m/441772480 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 21645ms, sequenceid=4928, compaction requested=true
2014-07-14 02:56:34,996 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:44), split_queue=0, merge_queue=0
2014-07-14 02:56:34,996 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 834.1m
2014-07-14 02:56:35,176 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:56:35,551 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:56:36,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:36,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20775 synced till here 20771
2014-07-14 02:56:36,733 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331794179 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331796174
2014-07-14 02:56:36,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331722780
2014-07-14 02:56:37,667 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:37,686 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20849 synced till here 20845
2014-07-14 02:56:37,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331796174 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331797668
2014-07-14 02:56:38,436 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4962, memsize=276.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/6fbfd4d1de084d33a90e6a30944ecaa8
2014-07-14 02:56:38,450 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/6fbfd4d1de084d33a90e6a30944ecaa8 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/6fbfd4d1de084d33a90e6a30944ecaa8
2014-07-14 02:56:38,507 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/6fbfd4d1de084d33a90e6a30944ecaa8, entries=1007440, sequenceid=4962, filesize=71.8m
2014-07-14 02:56:38,507 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~811.4m/850782480, currentsize=436.6m/457854080 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 22502ms, sequenceid=4962, compaction requested=true
2014-07-14 02:56:38,508 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-14 02:56:38,508 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 890.6m
2014-07-14 02:56:38,699 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:56:38,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:38,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20923 synced till here 20922
2014-07-14 02:56:38,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331797668 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331798896
2014-07-14 02:56:38,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331725666
2014-07-14 02:56:38,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331727664
2014-07-14 02:56:38,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331729327
2014-07-14 02:56:38,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331731285
2014-07-14 02:56:38,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331733378
2014-07-14 02:56:38,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331736489
2014-07-14 02:56:38,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331738317
2014-07-14 02:56:38,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331739565
2014-07-14 02:56:38,960 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331741589
2014-07-14 02:56:39,781 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:56:40,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:40,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21009 synced till here 21008
2014-07-14 02:56:40,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331798896 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331800082
2014-07-14 02:56:41,782 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:41,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21087 synced till here 21082
2014-07-14 02:56:41,915 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331800082 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331801782
2014-07-14 02:56:43,635 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:43,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21171 synced till here 21170
2014-07-14 02:56:43,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331801782 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331803636
2014-07-14 02:56:45,102 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:45,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21253 synced till here 21245
2014-07-14 02:56:45,386 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331803636 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331805269
2014-07-14 02:56:46,572 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:47,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21363 synced till here 21357
2014-07-14 02:56:47,536 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331805269 with entries=110, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331806573
2014-07-14 02:56:48,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:49,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21450 synced till here 21437
2014-07-14 02:56:49,252 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331806573 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331808293
2014-07-14 02:56:49,938 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5200, memsize=211.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f252e93f334d487399e18cf156dc50ee
2014-07-14 02:56:49,956 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f252e93f334d487399e18cf156dc50ee as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f252e93f334d487399e18cf156dc50ee
2014-07-14 02:56:49,976 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f252e93f334d487399e18cf156dc50ee, entries=770080, sequenceid=5200, filesize=54.9m
2014-07-14 02:56:49,977 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~834.1m/874657680, currentsize=313.2m/328440480 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 14980ms, sequenceid=5200, compaction requested=true
2014-07-14 02:56:49,977 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-14 02:56:49,977 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 726.7m
2014-07-14 02:56:49,989 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:56:50,194 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:50,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21537 synced till here 21528
2014-07-14 02:56:50,993 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331808293 with entries=87, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331810194
2014-07-14 02:56:50,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331742814
2014-07-14 02:56:51,331 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:56:52,553 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:52,605 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21631 synced till here 21619
2014-07-14 02:56:52,836 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331810194 with entries=94, filesize=80.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331812554
2014-07-14 02:56:54,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:54,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21724 synced till here 21709
2014-07-14 02:56:54,751 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331812554 with entries=93, filesize=80.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331814437
2014-07-14 02:56:55,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:55,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21798 synced till here 21795
2014-07-14 02:56:55,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331814437 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331815517
2014-07-14 02:56:56,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:56,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21873 synced till here 21869
2014-07-14 02:56:56,867 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5243, memsize=245.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/99038c7fc14c492f8b8e5126baffa108
2014-07-14 02:56:56,887 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/99038c7fc14c492f8b8e5126baffa108 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/99038c7fc14c492f8b8e5126baffa108
2014-07-14 02:56:56,906 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/99038c7fc14c492f8b8e5126baffa108, entries=893790, sequenceid=5243, filesize=63.7m
2014-07-14 02:56:56,906 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~898.8m/942417600, currentsize=378.4m/396778640 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 18398ms, sequenceid=5243, compaction requested=true
2014-07-14 02:56:56,906 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-14 02:56:56,906 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 816.7m
2014-07-14 02:56:56,910 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331815517 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331816806
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331754048
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331755508
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331757222
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331759188
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331760806
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331763058
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331764959
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331766459
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331768368
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331769736
2014-07-14 02:56:56,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331771161
2014-07-14 02:56:56,941 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:56:58,160 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:56:58,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:58,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21950 synced till here 21947
2014-07-14 02:56:58,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331816806 with entries=77, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331818248
2014-07-14 02:56:59,781 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:56:59,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22028 synced till here 22021
2014-07-14 02:56:59,946 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331818248 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331819782
2014-07-14 02:57:02,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:02,566 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22133 synced till here 22112
2014-07-14 02:57:02,748 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331819782 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331822498
2014-07-14 02:57:04,341 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:04,375 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22231 synced till here 22211
2014-07-14 02:57:04,592 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331822498 with entries=98, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331824341
2014-07-14 02:57:06,219 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:06,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22328 synced till here 22304
2014-07-14 02:57:06,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331824341 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331826220
2014-07-14 02:57:08,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:08,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22420 synced till here 22404
2014-07-14 02:57:08,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331826220 with entries=92, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331828352
2014-07-14 02:57:08,918 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/a6e687c088e2486eb3aed019945ea232 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/a6e687c088e2486eb3aed019945ea232
2014-07-14 02:57:10,297 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 02:57:10,318 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cc0ce3d7c7754ae785151978b6d5ea12, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cc0ce3d7c7754ae785151978b6d5ea12
2014-07-14 02:57:10,321 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/73a859e0504946feaa02708b17d1012b, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/73a859e0504946feaa02708b17d1012b
2014-07-14 02:57:10,323 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/646070c862cf4325a8b2bcc9ac485131, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/646070c862cf4325a8b2bcc9ac485131
2014-07-14 02:57:10,327 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/549b7a89523c46dda025f4da7c54b529, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/549b7a89523c46dda025f4da7c54b529
2014-07-14 02:57:10,330 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/077fbc20860940d08442f227f1be7380, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/077fbc20860940d08442f227f1be7380
2014-07-14 02:57:10,341 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ec50252e6d4b4bbdb565230e044616cb, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ec50252e6d4b4bbdb565230e044616cb
2014-07-14 02:57:10,346 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/685cc1a55a2645e2aa134a5a5c6b75f9, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/685cc1a55a2645e2aa134a5a5c6b75f9
2014-07-14 02:57:10,351 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cce31156d8344b339345ee43a7b6c9a7, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cce31156d8344b339345ee43a7b6c9a7
2014-07-14 02:57:10,358 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/27ad04701916424186ded7ee75b3d264, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/27ad04701916424186ded7ee75b3d264
2014-07-14 02:57:10,361 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/924befbaf4fc47c0900e275c255b1146, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/924befbaf4fc47c0900e275c255b1146
2014-07-14 02:57:10,361 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed major compaction of 10 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into a6e687c088e2486eb3aed019945ea232(size=802.3m), total size for store is 1.1g. This selection was in queue for 0sec, and took 3mins, 0sec to execute.
2014-07-14 02:57:10,362 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=10, fileSize=807.9m, priority=10, time=285557506120727; duration=3mins, 0sec
2014-07-14 02:57:10,362 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-14 02:57:10,362 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-14 02:57:10,364 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 752021569 starting at candidate #3 after considering 60 permutations with 58 in ratio
2014-07-14 02:57:10,364 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating minor compaction
2014-07-14 02:57:10,364 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:57:10,365 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=717.2m
2014-07-14 02:57:10,365 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/155d4b55d2084b478003a9d349dec761, keycount=87092, bloomtype=ROW, size=62.1m, encoding=NONE, seqNum=2582
2014-07-14 02:57:10,365 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/7adaf7b9e63240b4ac3b7dee9d2dda9e, keycount=82582, bloomtype=ROW, size=58.8m, encoding=NONE, seqNum=2749
2014-07-14 02:57:10,365 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4fdba0afc71f45d4a0f5328c3651033d, keycount=103643, bloomtype=ROW, size=73.8m, encoding=NONE, seqNum=2933
2014-07-14 02:57:10,365 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8618c0feca69454f82d692c3434689f4, keycount=93862, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=3100
2014-07-14 02:57:10,366 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4aa07b72c415472fa644922e1f4c9bd7, keycount=108444, bloomtype=ROW, size=77.2m, encoding=NONE, seqNum=3303
2014-07-14 02:57:10,366 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/cd3639b2a40341fbb88f513bfa3fa556, keycount=91724, bloomtype=ROW, size=65.3m, encoding=NONE, seqNum=3477
2014-07-14 02:57:10,366 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4e78a78cf4b84717a172322a59568d5a, keycount=106397, bloomtype=ROW, size=75.8m, encoding=NONE, seqNum=3691
2014-07-14 02:57:10,366 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a4ec92042204b1b97fe8304e52e3fdf, keycount=146616, bloomtype=ROW, size=104.4m, encoding=NONE, seqNum=4100
2014-07-14 02:57:10,366 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f9e5d0a41e804851a517aced6ec685ff, keycount=109638, bloomtype=ROW, size=78.0m, encoding=NONE, seqNum=4656
2014-07-14 02:57:10,366 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f252e93f334d487399e18cf156dc50ee, keycount=77008, bloomtype=ROW, size=54.9m, encoding=NONE, seqNum=5200
2014-07-14 02:57:10,610 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5402, memsize=269.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cdea6eebefa74bffad5a8efedfff6f8d
2014-07-14 02:57:10,631 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cdea6eebefa74bffad5a8efedfff6f8d as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cdea6eebefa74bffad5a8efedfff6f8d
2014-07-14 02:57:10,649 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cdea6eebefa74bffad5a8efedfff6f8d, entries=979820, sequenceid=5402, filesize=69.8m
2014-07-14 02:57:10,650 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~736.0m/771738400, currentsize=367.1m/384957040 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 20672ms, sequenceid=5402, compaction requested=true
2014-07-14 02:57:10,650 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-14 02:57:10,651 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 714.9m
2014-07-14 02:57:10,671 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:57:10,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:10,818 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:57:10,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22517 synced till here 22509
2014-07-14 02:57:10,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331828352 with entries=97, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331830818
2014-07-14 02:57:10,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331772488
2014-07-14 02:57:12,373 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:57:12,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:12,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22625 synced till here 22608
2014-07-14 02:57:12,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331830818 with entries=108, filesize=92.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331832776
2014-07-14 02:57:14,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:14,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22714 synced till here 22698
2014-07-14 02:57:14,809 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331832776 with entries=89, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331834601
2014-07-14 02:57:16,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:16,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22786 synced till here 22785
2014-07-14 02:57:16,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331834601 with entries=72, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331836253
2014-07-14 02:57:17,761 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:18,156 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5492, memsize=292.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/63c27f55635045f3b502b39c2602ad7f
2014-07-14 02:57:18,220 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/63c27f55635045f3b502b39c2602ad7f as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/63c27f55635045f3b502b39c2602ad7f
2014-07-14 02:57:18,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331836253 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331837762
2014-07-14 02:57:18,310 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/63c27f55635045f3b502b39c2602ad7f, entries=1063570, sequenceid=5492, filesize=75.7m
2014-07-14 02:57:18,311 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~821.4m/861298240, currentsize=388.6m/407494080 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 21405ms, sequenceid=5492, compaction requested=true
2014-07-14 02:57:18,311 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:48), split_queue=0, merge_queue=0
2014-07-14 02:57:18,312 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 769.0m
2014-07-14 02:57:18,635 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:57:19,240 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:57:19,770 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:20,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22962 synced till here 22961
2014-07-14 02:57:20,084 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331837762 with entries=92, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331839771
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331774787
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331776460
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331778039
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331779563
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331781964
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331784154
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331786441
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331788232
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331790256
2014-07-14 02:57:20,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331792363
2014-07-14 02:57:21,270 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:21,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23040 synced till here 23033
2014-07-14 02:57:21,379 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331839771 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331841270
2014-07-14 02:57:22,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:23,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23138 synced till here 23132
2014-07-14 02:57:23,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331841270 with entries=98, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331842697
2014-07-14 02:57:24,479 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:24,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331842697 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331844479
2014-07-14 02:57:25,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:25,836 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23285 synced till here 23284
2014-07-14 02:57:25,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331844479 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331845812
2014-07-14 02:57:27,116 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:27,134 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23360 synced till here 23356
2014-07-14 02:57:27,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331845812 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331847116
2014-07-14 02:57:28,546 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:28,701 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23445 synced till here 23443
2014-07-14 02:57:28,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331847116 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331848547
2014-07-14 02:57:30,031 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:30,282 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23542 synced till here 23537
2014-07-14 02:57:30,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331848547 with entries=97, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331850033
2014-07-14 02:57:31,505 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5664, memsize=369.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/237c9d8bc7bd49a589a920c64a0cf6cb
2014-07-14 02:57:31,523 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/237c9d8bc7bd49a589a920c64a0cf6cb as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/237c9d8bc7bd49a589a920c64a0cf6cb
2014-07-14 02:57:31,536 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/237c9d8bc7bd49a589a920c64a0cf6cb, entries=1344170, sequenceid=5664, filesize=95.7m
2014-07-14 02:57:31,536 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~717.8m/752709120, currentsize=406.9m/426636400 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 20885ms, sequenceid=5664, compaction requested=true
2014-07-14 02:57:31,537 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-14 02:57:31,537 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 810.8m
2014-07-14 02:57:31,607 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:57:31,621 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:31,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23630 synced till here 23629
2014-07-14 02:57:31,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331850033 with entries=88, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331851621
2014-07-14 02:57:31,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331794179
2014-07-14 02:57:31,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331796174
2014-07-14 02:57:32,624 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:57:33,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:33,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23706 synced till here 23701
2014-07-14 02:57:33,710 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331851621 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331853271
2014-07-14 02:57:35,170 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:36,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23808 synced till here 23804
2014-07-14 02:57:36,300 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5737, memsize=320.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/96fe258015bc42cc9e1dca11eb762ea1
2014-07-14 02:57:36,311 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331853271 with entries=102, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331855170
2014-07-14 02:57:36,359 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/96fe258015bc42cc9e1dca11eb762ea1 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/96fe258015bc42cc9e1dca11eb762ea1
2014-07-14 02:57:36,424 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/96fe258015bc42cc9e1dca11eb762ea1, entries=1166990, sequenceid=5737, filesize=83.2m
2014-07-14 02:57:36,424 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~769.0m/806347520, currentsize=363.2m/380810080 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 18112ms, sequenceid=5737, compaction requested=true
2014-07-14 02:57:36,425 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:50), split_queue=0, merge_queue=0
2014-07-14 02:57:36,425 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 744.4m
2014-07-14 02:57:36,464 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:57:37,952 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:37,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23903 synced till here 23886
2014-07-14 02:57:37,989 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:57:38,140 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331855170 with entries=95, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331857952
2014-07-14 02:57:38,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331797668
2014-07-14 02:57:38,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331798896
2014-07-14 02:57:38,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331800082
2014-07-14 02:57:38,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331801782
2014-07-14 02:57:38,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331803636
2014-07-14 02:57:38,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331805269
2014-07-14 02:57:38,141 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331806573
2014-07-14 02:57:39,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:40,154 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24006 synced till here 23975
2014-07-14 02:57:40,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331857952 with entries=103, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331859874
2014-07-14 02:57:42,246 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:42,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24104 synced till here 24086
2014-07-14 02:57:42,461 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331859874 with entries=98, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331862247
2014-07-14 02:57:44,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:44,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24199 synced till here 24194
2014-07-14 02:57:45,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331862247 with entries=95, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331864289
2014-07-14 02:57:46,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:46,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24300 synced till here 24273
2014-07-14 02:57:47,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331864289 with entries=101, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331866414
2014-07-14 02:57:49,631 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:49,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24411 synced till here 24385
2014-07-14 02:57:50,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331866414 with entries=111, filesize=94.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331869631
2014-07-14 02:57:51,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:52,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24517 synced till here 24481
2014-07-14 02:57:52,271 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331869631 with entries=106, filesize=91.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331871907
2014-07-14 02:57:53,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:54,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24623 synced till here 24596
2014-07-14 02:57:55,370 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331871907 with entries=106, filesize=88.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331873978
2014-07-14 02:57:56,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:57,366 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24736 synced till here 24702
2014-07-14 02:57:57,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331873978 with entries=113, filesize=96.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331876416
2014-07-14 02:57:59,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:57:59,701 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24857 synced till here 24807
2014-07-14 02:57:59,752 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,753 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,757 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,760 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,760 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,760 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,761 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,761 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,761 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,762 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,763 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,763 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,764 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,765 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,765 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,765 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,765 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,766 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,766 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,768 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,931 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,931 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,931 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,932 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,933 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,934 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,937 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,937 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,938 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,939 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,939 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:57:59,939 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,519 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,520 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,521 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,521 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,521 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,522 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,522 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,523 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,523 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331876416 with entries=121, filesize=103.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331879394
2014-07-14 02:58:00,600 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,600 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,601 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,602 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,603 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,604 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,613 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,613 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:00,616 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:03,196 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5927, memsize=402.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/45f731b667e1494888d97dd00b4f4124
2014-07-14 02:58:03,213 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/45f731b667e1494888d97dd00b4f4124 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/45f731b667e1494888d97dd00b4f4124
2014-07-14 02:58:03,224 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/45f731b667e1494888d97dd00b4f4124, entries=1465000, sequenceid=5927, filesize=104.3m
2014-07-14 02:58:03,224 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~813.9m/853417120, currentsize=497.8m/522029600 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 31687ms, sequenceid=5927, compaction requested=true
2014-07-14 02:58:03,225 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:51), split_queue=0, merge_queue=0
2014-07-14 02:58:03,225 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2609ms
2014-07-14 02:58:03,225 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 925.0m
2014-07-14 02:58:03,225 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,225 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2612ms
2014-07-14 02:58:03,225 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,225 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2613ms
2014-07-14 02:58:03,226 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,226 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2622ms
2014-07-14 02:58:03,226 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,237 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2634ms
2014-07-14 02:58:03,237 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,237 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2635ms
2014-07-14 02:58:03,237 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,237 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2636ms
2014-07-14 02:58:03,237 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,237 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2637ms
2014-07-14 02:58:03,237 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,237 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2637ms
2014-07-14 02:58:03,238 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,241 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3298ms
2014-07-14 02:58:03,241 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,241 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2719ms
2014-07-14 02:58:03,241 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,241 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2719ms
2014-07-14 02:58:03,241 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,257 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2735ms
2014-07-14 02:58:03,257 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,257 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2736ms
2014-07-14 02:58:03,257 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,257 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2736ms
2014-07-14 02:58:03,257 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,257 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2736ms
2014-07-14 02:58:03,257 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,265 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2745ms
2014-07-14 02:58:03,265 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,265 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2746ms
2014-07-14 02:58:03,265 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,265 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3326ms
2014-07-14 02:58:03,265 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,265 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3326ms
2014-07-14 02:58:03,265 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,266 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3327ms
2014-07-14 02:58:03,266 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,266 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3328ms
2014-07-14 02:58:03,266 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,266 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-14 02:58:03,266 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,275 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3338ms
2014-07-14 02:58:03,275 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,275 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3341ms
2014-07-14 02:58:03,275 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,276 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3343ms
2014-07-14 02:58:03,276 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,277 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3344ms
2014-07-14 02:58:03,277 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,277 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3346ms
2014-07-14 02:58:03,277 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,282 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3351ms
2014-07-14 02:58:03,282 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,283 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3352ms
2014-07-14 02:58:03,283 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,283 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3515ms
2014-07-14 02:58:03,283 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,283 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3518ms
2014-07-14 02:58:03,283 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,284 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3519ms
2014-07-14 02:58:03,284 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,285 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3520ms
2014-07-14 02:58:03,285 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,285 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3523ms
2014-07-14 02:58:03,285 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,285 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3524ms
2014-07-14 02:58:03,285 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,289 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3524ms
2014-07-14 02:58:03,289 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,292 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3528ms
2014-07-14 02:58:03,292 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,292 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3529ms
2014-07-14 02:58:03,292 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,292 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3529ms
2014-07-14 02:58:03,292 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,292 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3530ms
2014-07-14 02:58:03,292 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,292 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3531ms
2014-07-14 02:58:03,292 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,293 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3532ms
2014-07-14 02:58:03,293 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,293 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3533ms
2014-07-14 02:58:03,293 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,295 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3535ms
2014-07-14 02:58:03,296 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,296 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3536ms
2014-07-14 02:58:03,296 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,296 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3536ms
2014-07-14 02:58:03,296 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,296 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3539ms
2014-07-14 02:58:03,296 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,301 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3548ms
2014-07-14 02:58:03,301 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,301 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3549ms
2014-07-14 02:58:03,301 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:03,600 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:58:03,963 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:05,251 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24935 synced till here 24934
2014-07-14 02:58:05,315 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331879394 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331883963
2014-07-14 02:58:05,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331808293
2014-07-14 02:58:05,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331810194
2014-07-14 02:58:05,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331812554
2014-07-14 02:58:05,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331814437
2014-07-14 02:58:05,315 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331815517
2014-07-14 02:58:05,617 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:58:06,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:06,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25049 synced till here 25048
2014-07-14 02:58:06,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331883963 with entries=114, filesize=97.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331886275
2014-07-14 02:58:07,914 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:07,985 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25140 synced till here 25130
2014-07-14 02:58:08,113 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331886275 with entries=91, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331887915
2014-07-14 02:58:09,368 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5977, memsize=394.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/a4fc0db2c67344c09a7b7cc4071e753e
2014-07-14 02:58:09,383 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/a4fc0db2c67344c09a7b7cc4071e753e as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/a4fc0db2c67344c09a7b7cc4071e753e
2014-07-14 02:58:09,413 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/a4fc0db2c67344c09a7b7cc4071e753e, entries=1436390, sequenceid=5977, filesize=102.2m
2014-07-14 02:58:09,413 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~752.3m/788808080, currentsize=531.1m/556885200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 32988ms, sequenceid=5977, compaction requested=true
2014-07-14 02:58:09,413 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:52), split_queue=0, merge_queue=0
2014-07-14 02:58:09,414 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 892.9m
2014-07-14 02:58:09,575 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:58:10,161 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:58:10,216 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:10,242 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331887915 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331890217
2014-07-14 02:58:10,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331816806
2014-07-14 02:58:10,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331818248
2014-07-14 02:58:10,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331819782
2014-07-14 02:58:10,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331822498
2014-07-14 02:58:10,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331824341
2014-07-14 02:58:10,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331826220
2014-07-14 02:58:12,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:12,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331890217 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331892302
2014-07-14 02:58:13,995 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:14,013 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25358 synced till here 25356
2014-07-14 02:58:14,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331892302 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331893996
2014-07-14 02:58:15,185 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:15,551 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25444 synced till here 25432
2014-07-14 02:58:15,658 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331893996 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331895185
2014-07-14 02:58:17,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25524 synced till here 25518
2014-07-14 02:58:17,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331895185 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331897011
2014-07-14 02:58:18,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:18,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25603 synced till here 25596
2014-07-14 02:58:18,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331897011 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331898561
2014-07-14 02:58:19,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:20,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25689 synced till here 25688
2014-07-14 02:58:20,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331898561 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331899896
2014-07-14 02:58:21,358 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:21,515 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25774 synced till here 25772
2014-07-14 02:58:21,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331899896 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331901358
2014-07-14 02:58:22,642 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,643 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,643 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,645 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,649 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,667 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,670 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,680 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,710 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,755 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,794 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,836 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,880 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,925 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,958 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:22,995 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,193 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,240 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,283 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,324 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,368 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,406 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,452 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,506 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,545 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,585 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,645 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,695 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:23,725 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:24,965 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:24,987 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:25,010 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:25,060 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:25,119 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:25,524 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6261, memsize=390.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/25647c0be23c4b7788c835645397ef1c
2014-07-14 02:58:25,538 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/25647c0be23c4b7788c835645397ef1c as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25647c0be23c4b7788c835645397ef1c
2014-07-14 02:58:25,550 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25647c0be23c4b7788c835645397ef1c, entries=1421680, sequenceid=6261, filesize=101.2m
2014-07-14 02:58:25,551 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~925.0m/969978720, currentsize=347.9m/364835440 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 22326ms, sequenceid=6261, compaction requested=true
2014-07-14 02:58:25,551 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-14 02:58:25,551 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 432ms
2014-07-14 02:58:25,551 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,551 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 863.4m
2014-07-14 02:58:25,552 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 492ms
2014-07-14 02:58:25,552 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,552 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 542ms
2014-07-14 02:58:25,552 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,552 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 565ms
2014-07-14 02:58:25,552 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,553 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 588ms
2014-07-14 02:58:25,553 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,553 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1828ms
2014-07-14 02:58:25,553 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,553 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1858ms
2014-07-14 02:58:25,553 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,553 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1908ms
2014-07-14 02:58:25,554 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,554 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1969ms
2014-07-14 02:58:25,554 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,554 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2009ms
2014-07-14 02:58:25,554 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,554 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2048ms
2014-07-14 02:58:25,554 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,554 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2102ms
2014-07-14 02:58:25,555 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,562 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2156ms
2014-07-14 02:58:25,562 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,562 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2194ms
2014-07-14 02:58:25,562 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,562 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2238ms
2014-07-14 02:58:25,562 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,562 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2279ms
2014-07-14 02:58:25,563 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,563 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2323ms
2014-07-14 02:58:25,563 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,563 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2370ms
2014-07-14 02:58:25,563 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,563 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2568ms
2014-07-14 02:58:25,563 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,567 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2608ms
2014-07-14 02:58:25,567 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,569 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2643ms
2014-07-14 02:58:25,569 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,569 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2689ms
2014-07-14 02:58:25,569 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,570 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2734ms
2014-07-14 02:58:25,570 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,573 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2779ms
2014-07-14 02:58:25,573 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,574 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2818ms
2014-07-14 02:58:25,574 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,576 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2867ms
2014-07-14 02:58:25,576 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,576 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2896ms
2014-07-14 02:58:25,576 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,577 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2907ms
2014-07-14 02:58:25,577 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,577 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2910ms
2014-07-14 02:58:25,577 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,585 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2936ms
2014-07-14 02:58:25,585 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,586 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2940ms
2014-07-14 02:58:25,586 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,586 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2944ms
2014-07-14 02:58:25,586 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,588 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2945ms
2014-07-14 02:58:25,588 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,588 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2946ms
2014-07-14 02:58:25,601 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:25,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:25,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25864 synced till here 25846
2014-07-14 02:58:25,919 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:58:25,939 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331901358 with entries=90, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331905746
2014-07-14 02:58:25,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331828352
2014-07-14 02:58:25,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331830818
2014-07-14 02:58:25,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331832776
2014-07-14 02:58:25,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331834601
2014-07-14 02:58:25,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331836253
2014-07-14 02:58:26,321 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:58:27,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:27,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25967 synced till here 25940
2014-07-14 02:58:27,656 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331905746 with entries=103, filesize=88.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331907391
2014-07-14 02:58:27,872 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6315, memsize=327.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f5d15748d5bd4be780a1b5bfccdcc72c
2014-07-14 02:58:27,899 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f5d15748d5bd4be780a1b5bfccdcc72c as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f5d15748d5bd4be780a1b5bfccdcc72c
2014-07-14 02:58:27,922 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f5d15748d5bd4be780a1b5bfccdcc72c, entries=1191300, sequenceid=6315, filesize=84.8m
2014-07-14 02:58:27,923 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~892.9m/936284160, currentsize=309.3m/324311040 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 18509ms, sequenceid=6315, compaction requested=true
2014-07-14 02:58:27,923 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:54), split_queue=0, merge_queue=0
2014-07-14 02:58:27,923 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 834.5m
2014-07-14 02:58:29,003 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:58:29,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:29,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26081 synced till here 26071
2014-07-14 02:58:29,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331907391 with entries=114, filesize=97.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331909498
2014-07-14 02:58:29,747 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331837762
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331839771
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331841270
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331842697
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331844479
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331845812
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331847116
2014-07-14 02:58:29,748 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331848547
2014-07-14 02:58:29,881 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:58:31,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:31,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26170 synced till here 26157
2014-07-14 02:58:32,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331909498 with entries=89, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331911861
2014-07-14 02:58:33,484 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1265ms
GC pool 'ParNew' had collection(s): count=1 time=1363ms
2014-07-14 02:58:34,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:34,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26284 synced till here 26264
2014-07-14 02:58:35,652 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331911861 with entries=114, filesize=98.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331914266
2014-07-14 02:58:37,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:37,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26383 synced till here 26365
2014-07-14 02:58:37,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331914266 with entries=99, filesize=85.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331917397
2014-07-14 02:58:39,476 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:39,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26488 synced till here 26469
2014-07-14 02:58:39,815 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331917397 with entries=105, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331919477
2014-07-14 02:58:41,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:41,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26609 synced till here 26589
2014-07-14 02:58:42,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331919477 with entries=121, filesize=103.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331921569
2014-07-14 02:58:43,615 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:43,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26700 synced till here 26681
2014-07-14 02:58:44,853 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331921569 with entries=91, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331923615
2014-07-14 02:58:45,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:46,871 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26802 synced till here 26783
2014-07-14 02:58:47,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331923615 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331925818
2014-07-14 02:58:48,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:48,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26900 synced till here 26876
2014-07-14 02:58:49,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331925818 with entries=98, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331928826
2014-07-14 02:58:50,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:51,149 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27024 synced till here 26974
2014-07-14 02:58:51,221 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,221 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,222 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,226 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,227 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,230 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,232 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,235 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,236 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,236 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,237 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,237 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,238 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,239 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,409 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,410 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,410 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,412 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,412 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,413 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,415 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,415 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,418 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,418 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,419 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,419 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,419 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,420 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,420 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,420 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,421 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,422 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,422 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,422 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,422 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,423 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,425 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,425 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,430 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331928826 with entries=124, filesize=106.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331930883
2014-07-14 02:58:51,520 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,520 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,520 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,520 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,520 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,521 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,524 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,525 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,530 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,530 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,531 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:51,532 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 02:58:54,625 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6483, memsize=300.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/8411fb05fa494445a7270baa6d5916de
2014-07-14 02:58:54,654 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/8411fb05fa494445a7270baa6d5916de as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/8411fb05fa494445a7270baa6d5916de
2014-07-14 02:58:54,670 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/8411fb05fa494445a7270baa6d5916de, entries=1093660, sequenceid=6483, filesize=77.9m
2014-07-14 02:58:54,671 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~863.4m/905374800, currentsize=483.1m/506600560 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 29120ms, sequenceid=6483, compaction requested=true
2014-07-14 02:58:54,671 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:55), split_queue=0, merge_queue=0
2014-07-14 02:58:54,672 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3140ms
2014-07-14 02:58:54,672 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 834.2m
2014-07-14 02:58:54,672 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,672 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3142ms
2014-07-14 02:58:54,672 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,672 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3142ms
2014-07-14 02:58:54,672 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,672 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3143ms
2014-07-14 02:58:54,673 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,673 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3148ms
2014-07-14 02:58:54,673 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,673 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3149ms
2014-07-14 02:58:54,673 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,673 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3152ms
2014-07-14 02:58:54,673 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,674 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3153ms
2014-07-14 02:58:54,674 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,675 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3155ms
2014-07-14 02:58:54,675 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,681 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3161ms
2014-07-14 02:58:54,681 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,681 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3161ms
2014-07-14 02:58:54,681 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,682 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3162ms
2014-07-14 02:58:54,682 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,682 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3259ms
2014-07-14 02:58:54,683 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,683 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3260ms
2014-07-14 02:58:54,683 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,683 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3260ms
2014-07-14 02:58:54,683 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,683 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3261ms
2014-07-14 02:58:54,683 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,683 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3261ms
2014-07-14 02:58:54,683 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,687 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3266ms
2014-07-14 02:58:54,709 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,709 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3288ms
2014-07-14 02:58:54,710 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,710 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3289ms
2014-07-14 02:58:54,710 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,712 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3293ms
2014-07-14 02:58:54,712 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,717 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3297ms
2014-07-14 02:58:54,717 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,717 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3297ms
2014-07-14 02:58:54,717 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,717 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3299ms
2014-07-14 02:58:54,717 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,729 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3311ms
2014-07-14 02:58:54,730 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,730 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3312ms
2014-07-14 02:58:54,730 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,730 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3312ms
2014-07-14 02:58:54,730 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,733 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3315ms
2014-07-14 02:58:54,733 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,735 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3320ms
2014-07-14 02:58:54,735 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,736 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3320ms
2014-07-14 02:58:54,736 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,741 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-14 02:58:54,741 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,741 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-14 02:58:54,741 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,742 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-14 02:58:54,742 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,746 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3337ms
2014-07-14 02:58:54,746 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,746 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3337ms
2014-07-14 02:58:54,746 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,747 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3338ms
2014-07-14 02:58:54,747 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,753 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3515ms
2014-07-14 02:58:54,753 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,753 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3515ms
2014-07-14 02:58:54,753 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,755 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3518ms
2014-07-14 02:58:54,755 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,755 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3518ms
2014-07-14 02:58:54,756 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,756 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3520ms
2014-07-14 02:58:54,757 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,758 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3522ms
2014-07-14 02:58:54,758 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,758 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3523ms
2014-07-14 02:58:54,758 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,759 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3527ms
2014-07-14 02:58:54,759 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,760 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3530ms
2014-07-14 02:58:54,760 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,766 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3538ms
2014-07-14 02:58:54,766 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,766 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3540ms
2014-07-14 02:58:54,766 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,766 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3544ms
2014-07-14 02:58:54,766 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,768 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3547ms
2014-07-14 02:58:54,768 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,773 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3552ms
2014-07-14 02:58:54,773 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 02:58:54,993 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:58:56,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:56,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27112 synced till here 27098
2014-07-14 02:58:56,779 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331930883 with entries=88, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331936480
2014-07-14 02:58:56,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331850033
2014-07-14 02:58:56,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331851621
2014-07-14 02:58:56,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331853271
2014-07-14 02:58:57,011 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:58:58,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:58:58,539 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27224 synced till here 27206
2014-07-14 02:58:58,806 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331936480 with entries=112, filesize=96.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331938397
2014-07-14 02:58:58,875 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6522, memsize=315.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/63be9a876d9b4eaabcdc9ea6100496b7
2014-07-14 02:58:58,892 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/63be9a876d9b4eaabcdc9ea6100496b7 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/63be9a876d9b4eaabcdc9ea6100496b7
2014-07-14 02:58:58,904 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/63be9a876d9b4eaabcdc9ea6100496b7, entries=1148850, sequenceid=6522, filesize=81.8m
2014-07-14 02:58:58,904 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~840.6m/881425440, currentsize=456.1m/478246960 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 30981ms, sequenceid=6522, compaction requested=true
2014-07-14 02:58:58,904 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:56), split_queue=0, merge_queue=0
2014-07-14 02:58:58,905 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 785.7m
2014-07-14 02:58:59,093 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:59:00,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:00,257 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27326 synced till here 27317
2014-07-14 02:59:00,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331938397 with entries=102, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331940147
2014-07-14 02:59:00,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331855170
2014-07-14 02:59:00,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331857952
2014-07-14 02:59:00,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331859874
2014-07-14 02:59:00,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331862247
2014-07-14 02:59:00,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331864289
2014-07-14 02:59:00,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331866414
2014-07-14 02:59:00,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331869631
2014-07-14 02:59:00,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331871907
2014-07-14 02:59:00,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331873978
2014-07-14 02:59:00,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331876416
2014-07-14 02:59:00,668 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:59:01,051 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:01,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331940147 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331941051
2014-07-14 02:59:03,977 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:04,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27474 synced till here 27472
2014-07-14 02:59:04,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331941051 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331943978
2014-07-14 02:59:04,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:05,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27558 synced till here 27556
2014-07-14 02:59:05,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331943978 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331944988
2014-07-14 02:59:06,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:06,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27650 synced till here 27649
2014-07-14 02:59:06,910 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331944988 with entries=92, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331946370
2014-07-14 02:59:08,122 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:08,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27728 synced till here 27724
2014-07-14 02:59:08,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331946370 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331948123
2014-07-14 02:59:09,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:09,231 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27802 synced till here 27801
2014-07-14 02:59:09,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331948123 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331949208
2014-07-14 02:59:10,443 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:10,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331949208 with entries=85, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331950444
2014-07-14 02:59:11,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:12,212 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331950444 with entries=81, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331951796
2014-07-14 02:59:13,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:13,480 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28042 synced till here 28041
2014-07-14 02:59:13,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331951796 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331953453
2014-07-14 02:59:14,204 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6800, memsize=330.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/d3944f55c0314e95a8a6b5c1562f3ac0
2014-07-14 02:59:14,216 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/d3944f55c0314e95a8a6b5c1562f3ac0 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/d3944f55c0314e95a8a6b5c1562f3ac0
2014-07-14 02:59:14,229 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/d3944f55c0314e95a8a6b5c1562f3ac0, entries=1203920, sequenceid=6800, filesize=85.8m
2014-07-14 02:59:14,230 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~834.2m/874700880, currentsize=376.8m/395133120 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 19557ms, sequenceid=6800, compaction requested=true
2014-07-14 02:59:14,230 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-14 02:59:14,230 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 874.6m
2014-07-14 02:59:14,232 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 02:59:14,735 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:14,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28117 synced till here 28116
2014-07-14 02:59:14,814 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331953453 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331954736
2014-07-14 02:59:14,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331879394
2014-07-14 02:59:14,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331883963
2014-07-14 02:59:14,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331886275
2014-07-14 02:59:14,918 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:59:15,534 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6828, memsize=324.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/cc7f13d8a66a472499329d3cd46a668a
2014-07-14 02:59:15,546 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/cc7f13d8a66a472499329d3cd46a668a as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cc7f13d8a66a472499329d3cd46a668a
2014-07-14 02:59:15,556 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cc7f13d8a66a472499329d3cd46a668a, entries=1182090, sequenceid=6828, filesize=84.2m
2014-07-14 02:59:15,556 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~796.5m/835227840, currentsize=359.1m/376588480 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 16651ms, sequenceid=6828, compaction requested=true
2014-07-14 02:59:15,556 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-14 02:59:15,556 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 846.1m
2014-07-14 02:59:15,576 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 02:59:16,166 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:59:16,700 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:16,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28191 synced till here 28188
2014-07-14 02:59:16,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331954736 with entries=74, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331956701
2014-07-14 02:59:16,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331887915
2014-07-14 02:59:16,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331890217
2014-07-14 02:59:16,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331892302
2014-07-14 02:59:16,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331893996
2014-07-14 02:59:16,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331895185
2014-07-14 02:59:16,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331897011
2014-07-14 02:59:16,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331898561
2014-07-14 02:59:16,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331899896
2014-07-14 02:59:18,038 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:18,127 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28271 synced till here 28268
2014-07-14 02:59:18,196 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331956701 with entries=80, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331958038
2014-07-14 02:59:19,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:20,020 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28374 synced till here 28366
2014-07-14 02:59:20,095 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331958038 with entries=103, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331959200
2014-07-14 02:59:20,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:20,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28450 synced till here 28446
2014-07-14 02:59:21,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331959200 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331960789
2014-07-14 02:59:22,312 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:23,561 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1103ms
GC pool 'ParNew' had collection(s): count=1 time=1148ms
2014-07-14 02:59:23,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28545 synced till here 28522
2014-07-14 02:59:23,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331960789 with entries=95, filesize=81.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331962312
2014-07-14 02:59:26,208 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1146ms
GC pool 'ParNew' had collection(s): count=1 time=1613ms
2014-07-14 02:59:26,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:26,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28651 synced till here 28629
2014-07-14 02:59:27,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331962312 with entries=106, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331966787
2014-07-14 02:59:28,856 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:28,900 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28753 synced till here 28737
2014-07-14 02:59:29,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331966787 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331968856
2014-07-14 02:59:30,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:31,012 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28868 synced till here 28840
2014-07-14 02:59:32,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331968856 with entries=115, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331970882
2014-07-14 02:59:33,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:33,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28961 synced till here 28945
2014-07-14 02:59:34,198 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331970882 with entries=93, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331973153
2014-07-14 02:59:34,889 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:34,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29049 synced till here 29033
2014-07-14 02:59:35,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331973153 with entries=88, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331974889
2014-07-14 02:59:36,037 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7044, memsize=263.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/df124f1db16b4722bd1a28e72550a91c
2014-07-14 02:59:36,061 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/df124f1db16b4722bd1a28e72550a91c as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/df124f1db16b4722bd1a28e72550a91c
2014-07-14 02:59:36,095 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/df124f1db16b4722bd1a28e72550a91c, entries=957420, sequenceid=7044, filesize=68.2m
2014-07-14 02:59:36,101 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~876.1m/918698800, currentsize=389.1m/408041520 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 21870ms, sequenceid=7044, compaction requested=true
2014-07-14 02:59:36,101 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-14 02:59:36,101 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 775.3m
2014-07-14 02:59:36,215 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 02:59:36,562 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:36,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331974889 with entries=73, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331976562
2014-07-14 02:59:36,609 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331901358
2014-07-14 02:59:36,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331905746
2014-07-14 02:59:36,963 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:59:38,089 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:38,218 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7067, memsize=289.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/d382c38aff004178bbc81e32bfc10884
2014-07-14 02:59:38,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29205 synced till here 29203
2014-07-14 02:59:38,257 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/d382c38aff004178bbc81e32bfc10884 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d382c38aff004178bbc81e32bfc10884
2014-07-14 02:59:38,258 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331976562 with entries=83, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331978090
2014-07-14 02:59:38,323 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/d382c38aff004178bbc81e32bfc10884, entries=1053970, sequenceid=7067, filesize=75.1m
2014-07-14 02:59:38,324 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~849.2m/890492720, currentsize=404.7m/424339360 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 22768ms, sequenceid=7067, compaction requested=true
2014-07-14 02:59:38,324 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-14 02:59:38,324 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 769.3m
2014-07-14 02:59:38,398 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 02:59:39,448 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 02:59:39,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:39,545 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29281 synced till here 29277
2014-07-14 02:59:39,605 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331978090 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331979528
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331907391
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331909498
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331911861
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331914266
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331917397
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331919477
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331921569
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331923615
2014-07-14 02:59:39,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331925818
2014-07-14 02:59:39,608 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331928826
2014-07-14 02:59:40,661 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:40,681 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29356 synced till here 29354
2014-07-14 02:59:40,896 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331979528 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331980661
2014-07-14 02:59:42,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:42,210 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29432 synced till here 29429
2014-07-14 02:59:42,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331980661 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331982183
2014-07-14 02:59:43,660 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:43,711 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29510 synced till here 29506
2014-07-14 02:59:43,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331982183 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331983660
2014-07-14 02:59:44,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:44,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29586 synced till here 29583
2014-07-14 02:59:45,116 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331983660 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331984886
2014-07-14 02:59:46,725 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:46,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29683 synced till here 29663
2014-07-14 02:59:47,080 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331984886 with entries=97, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331986725
2014-07-14 02:59:48,891 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:49,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29785 synced till here 29779
2014-07-14 02:59:49,210 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331986725 with entries=102, filesize=87.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331988892
2014-07-14 02:59:50,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:50,916 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29876 synced till here 29856
2014-07-14 02:59:52,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331988892 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331990895
2014-07-14 02:59:53,088 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:53,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29978 synced till here 29956
2014-07-14 02:59:54,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331990895 with entries=102, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331993088
2014-07-14 02:59:54,972 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:56,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30070 synced till here 30049
2014-07-14 02:59:56,283 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331993088 with entries=92, filesize=79.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331994973
2014-07-14 02:59:58,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 02:59:58,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30171 synced till here 30142
2014-07-14 02:59:58,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331994973 with entries=101, filesize=86.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331998223
2014-07-14 03:00:00,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:00,445 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,446 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,447 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,447 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,448 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,449 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,450 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,451 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,452 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,453 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30269 synced till here 30254
2014-07-14 03:00:00,498 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,553 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,554 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,555 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,557 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,570 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,578 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,612 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331998223 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332000421
2014-07-14 03:00:00,653 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,654 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,695 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,726 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,726 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,727 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,728 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,744 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,786 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:00,843 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:01,228 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:01,273 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:01,319 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:02,195 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7302, memsize=380.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ec2060d272084041a58e0a640d89ae50
2014-07-14 03:00:02,213 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ec2060d272084041a58e0a640d89ae50 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec2060d272084041a58e0a640d89ae50
2014-07-14 03:00:02,225 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec2060d272084041a58e0a640d89ae50, entries=1385460, sequenceid=7302, filesize=98.7m
2014-07-14 03:00:02,225 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~781.6m/819525200, currentsize=473.8m/496804080 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 26124ms, sequenceid=7302, compaction requested=true
2014-07-14 03:00:02,226 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-14 03:00:02,226 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 907ms
2014-07-14 03:00:02,226 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,226 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 855.6m
2014-07-14 03:00:02,226 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 953ms
2014-07-14 03:00:02,226 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,226 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 998ms
2014-07-14 03:00:02,226 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,229 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1386ms
2014-07-14 03:00:02,229 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,229 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1443ms
2014-07-14 03:00:02,229 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,229 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1485ms
2014-07-14 03:00:02,229 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,241 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1513ms
2014-07-14 03:00:02,241 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,241 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1515ms
2014-07-14 03:00:02,241 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,242 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1516ms
2014-07-14 03:00:02,242 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,242 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1517ms
2014-07-14 03:00:02,242 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,245 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1550ms
2014-07-14 03:00:02,245 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,245 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1591ms
2014-07-14 03:00:02,245 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,248 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1595ms
2014-07-14 03:00:02,248 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,250 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1638ms
2014-07-14 03:00:02,250 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,256 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1678ms
2014-07-14 03:00:02,256 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,256 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1687ms
2014-07-14 03:00:02,256 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,256 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1699ms
2014-07-14 03:00:02,256 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,256 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1701ms
2014-07-14 03:00:02,257 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,257 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1703ms
2014-07-14 03:00:02,257 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,257 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1705ms
2014-07-14 03:00:02,257 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,257 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1759ms
2014-07-14 03:00:02,257 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,259 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1806ms
2014-07-14 03:00:02,259 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,260 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1809ms
2014-07-14 03:00:02,260 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,260 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1809ms
2014-07-14 03:00:02,260 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,305 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1856ms
2014-07-14 03:00:02,305 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,305 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1856ms
2014-07-14 03:00:02,305 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,305 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1857ms
2014-07-14 03:00:02,305 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,305 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1859ms
2014-07-14 03:00:02,305 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,311 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1865ms
2014-07-14 03:00:02,311 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,311 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1865ms
2014-07-14 03:00:02,311 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:02,312 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1867ms
2014-07-14 03:00:02,312 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:03,429 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:00:04,005 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:04,018 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:04,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30370 synced till here 30353
2014-07-14 03:00:04,184 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332000421 with entries=101, filesize=86.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332004006
2014-07-14 03:00:04,184 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331930883
2014-07-14 03:00:04,185 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331936480
2014-07-14 03:00:05,608 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/16c81cb79f3b47ceb65f7af1f6ffa379 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/16c81cb79f3b47ceb65f7af1f6ffa379
2014-07-14 03:00:05,653 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:00:05,667 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/155d4b55d2084b478003a9d349dec761, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/155d4b55d2084b478003a9d349dec761
2014-07-14 03:00:05,670 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/7adaf7b9e63240b4ac3b7dee9d2dda9e, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/7adaf7b9e63240b4ac3b7dee9d2dda9e
2014-07-14 03:00:05,673 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4fdba0afc71f45d4a0f5328c3651033d, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4fdba0afc71f45d4a0f5328c3651033d
2014-07-14 03:00:05,675 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8618c0feca69454f82d692c3434689f4, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8618c0feca69454f82d692c3434689f4
2014-07-14 03:00:05,678 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4aa07b72c415472fa644922e1f4c9bd7, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4aa07b72c415472fa644922e1f4c9bd7
2014-07-14 03:00:05,682 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/cd3639b2a40341fbb88f513bfa3fa556, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/cd3639b2a40341fbb88f513bfa3fa556
2014-07-14 03:00:05,684 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4e78a78cf4b84717a172322a59568d5a, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/4e78a78cf4b84717a172322a59568d5a
2014-07-14 03:00:05,689 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a4ec92042204b1b97fe8304e52e3fdf, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9a4ec92042204b1b97fe8304e52e3fdf
2014-07-14 03:00:05,693 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f9e5d0a41e804851a517aced6ec685ff, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f9e5d0a41e804851a517aced6ec685ff
2014-07-14 03:00:05,697 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f252e93f334d487399e18cf156dc50ee, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f252e93f334d487399e18cf156dc50ee
2014-07-14 03:00:05,697 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 16c81cb79f3b47ceb65f7af1f6ffa379(size=700.3m), total size for store is 1.5g. This selection was in queue for 0sec, and took 2mins, 55sec to execute.
2014-07-14 03:00:05,697 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=10, fileSize=717.2m, priority=7, time=285737791421442; duration=2mins, 55sec
2014-07-14 03:00:05,697 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-14 03:00:05,698 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 15 store files, 0 compacting, 15 eligible, 20 blocking
2014-07-14 03:00:05,700 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 782351983 starting at candidate #1 after considering 76 permutations with 73 in ratio
2014-07-14 03:00:05,700 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating minor compaction
2014-07-14 03:00:05,700 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:00:05,700 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=746.1m
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1ac925dbf3e44680a9a82dcdeb8659e1, keycount=92210, bloomtype=ROW, size=65.7m, encoding=NONE, seqNum=2512
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e657209a6c524e119a0a068d049ef82f, keycount=82126, bloomtype=ROW, size=58.5m, encoding=NONE, seqNum=2683
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/53dadd8e152e4f30a415f397166157ef, keycount=97985, bloomtype=ROW, size=69.8m, encoding=NONE, seqNum=2857
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2f18d3375e86420e875f970f6d55a1dd, keycount=111853, bloomtype=ROW, size=79.7m, encoding=NONE, seqNum=3057
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e7cd8ba87b3c4b6b9960df077eb2988e, keycount=92425, bloomtype=ROW, size=65.8m, encoding=NONE, seqNum=3223
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8e2bc380dc154e208dac6baa47a9ce60, keycount=88620, bloomtype=ROW, size=63.1m, encoding=NONE, seqNum=3390
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/51a652194db8439499f7cc708dec7822, keycount=88350, bloomtype=ROW, size=63.0m, encoding=NONE, seqNum=3557
2014-07-14 03:00:05,701 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1c9c12a789394f8da144bff3d4ba927d, keycount=110319, bloomtype=ROW, size=78.6m, encoding=NONE, seqNum=3896
2014-07-14 03:00:05,702 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ca59963ec855454d94d8ec8fb7605a3e, keycount=182797, bloomtype=ROW, size=130.2m, encoding=NONE, seqNum=4435
2014-07-14 03:00:05,702 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/6fbfd4d1de084d33a90e6a30944ecaa8, keycount=100744, bloomtype=ROW, size=71.8m, encoding=NONE, seqNum=4962
2014-07-14 03:00:05,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:05,781 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332004006 with entries=74, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332005747
2014-07-14 03:00:05,943 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:06,064 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7325, memsize=411.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/425dd42150a748faa7415e0a8996267c
2014-07-14 03:00:06,082 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/425dd42150a748faa7415e0a8996267c as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/425dd42150a748faa7415e0a8996267c
2014-07-14 03:00:06,093 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/425dd42150a748faa7415e0a8996267c, entries=1498770, sequenceid=7325, filesize=106.7m
2014-07-14 03:00:06,093 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~770.8m/808252160, currentsize=482.6m/506075360 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 27769ms, sequenceid=7325, compaction requested=true
2014-07-14 03:00:06,094 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-14 03:00:06,094 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 887.6m
2014-07-14 03:00:06,101 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:00:07,104 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:07,157 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.53 MB, free=3.95 GB, max=3.96 GB, blocks=5, accesses=156383, hits=27507, hitRatio=17.58%, , cachingAccesses=27525, cachingHits=27493, cachingHitsRatio=99.88%, evictions=0, evicted=27, evictedPerRun=Infinity
2014-07-14 03:00:07,522 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:07,562 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30522 synced till here 30517
2014-07-14 03:00:07,609 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332005747 with entries=78, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332007523
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331938397
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331940147
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331941051
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331943978
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331944988
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331946370
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331948123
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331949208
2014-07-14 03:00:07,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331950444
2014-07-14 03:00:07,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331951796
2014-07-14 03:00:09,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:09,030 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30597 synced till here 30595
2014-07-14 03:00:09,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332007523 with entries=75, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332009004
2014-07-14 03:00:10,455 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:10,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332009004 with entries=73, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332010455
2014-07-14 03:00:11,749 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:11,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30749 synced till here 30744
2014-07-14 03:00:12,166 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332010455 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332011749
2014-07-14 03:00:13,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:13,988 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30846 synced till here 30831
2014-07-14 03:00:14,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332011749 with entries=97, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332013914
2014-07-14 03:00:15,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:16,185 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30954 synced till here 30930
2014-07-14 03:00:16,347 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332013914 with entries=108, filesize=92.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332015968
2014-07-14 03:00:18,187 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:18,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31047 synced till here 31036
2014-07-14 03:00:19,317 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332015968 with entries=93, filesize=80.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332018187
2014-07-14 03:00:20,156 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:20,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31135 synced till here 31125
2014-07-14 03:00:21,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332018187 with entries=88, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332020157
2014-07-14 03:00:21,993 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:22,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31232 synced till here 31209
2014-07-14 03:00:23,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332020157 with entries=97, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332021993
2014-07-14 03:00:23,713 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,713 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,715 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,718 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,718 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,719 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,720 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,724 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,725 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,728 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,728 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,728 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,729 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,729 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,729 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,729 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,732 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,732 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,735 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,736 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,739 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,739 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,739 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,739 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,739 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,740 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,742 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,743 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,780 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,806 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,806 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,824 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,831 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,844 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,844 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,844 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,852 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,864 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:23,893 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,000 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,184 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,213 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,248 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,282 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,320 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,349 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:24,387 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:25,489 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:25,500 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:25,519 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:25,617 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7597, memsize=300.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/6dad2e20f5d245208ed6c708b00398f0
2014-07-14 03:00:25,629 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/6dad2e20f5d245208ed6c708b00398f0 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6dad2e20f5d245208ed6c708b00398f0
2014-07-14 03:00:25,642 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6dad2e20f5d245208ed6c708b00398f0, entries=1092240, sequenceid=7597, filesize=77.8m
2014-07-14 03:00:25,643 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~855.6m/897111840, currentsize=391.3m/410281920 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 23417ms, sequenceid=7597, compaction requested=true
2014-07-14 03:00:25,643 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:62), split_queue=0, merge_queue=0
2014-07-14 03:00:25,643 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 124ms
2014-07-14 03:00:25,643 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,643 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 144ms
2014-07-14 03:00:25,643 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 876.4m
2014-07-14 03:00:25,643 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,645 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 156ms
2014-07-14 03:00:25,645 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,645 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1258ms
2014-07-14 03:00:25,645 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,645 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1296ms
2014-07-14 03:00:25,645 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,645 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1325ms
2014-07-14 03:00:25,645 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,645 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1364ms
2014-07-14 03:00:25,645 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,655 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1407ms
2014-07-14 03:00:25,655 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,656 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1443ms
2014-07-14 03:00:25,656 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,656 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1472ms
2014-07-14 03:00:25,656 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,656 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1656ms
2014-07-14 03:00:25,656 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,656 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1763ms
2014-07-14 03:00:25,656 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,656 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1792ms
2014-07-14 03:00:25,656 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,657 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1805ms
2014-07-14 03:00:25,657 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,657 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1813ms
2014-07-14 03:00:25,657 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,657 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1813ms
2014-07-14 03:00:25,658 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,658 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1814ms
2014-07-14 03:00:25,658 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,659 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1828ms
2014-07-14 03:00:25,659 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,659 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1836ms
2014-07-14 03:00:25,659 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,659 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1853ms
2014-07-14 03:00:25,659 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,673 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1867ms
2014-07-14 03:00:25,673 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,673 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1893ms
2014-07-14 03:00:25,673 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,673 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1930ms
2014-07-14 03:00:25,673 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,673 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1931ms
2014-07-14 03:00:25,673 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,685 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1949ms
2014-07-14 03:00:25,685 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,685 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1949ms
2014-07-14 03:00:25,685 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,685 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1946ms
2014-07-14 03:00:25,685 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,685 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1957ms
2014-07-14 03:00:25,685 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,685 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1957ms
2014-07-14 03:00:25,686 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,689 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1950ms
2014-07-14 03:00:25,689 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,689 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1953ms
2014-07-14 03:00:25,689 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,690 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1955ms
2014-07-14 03:00:25,690 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,690 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1958ms
2014-07-14 03:00:25,690 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,697 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1966ms
2014-07-14 03:00:25,697 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,697 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1968ms
2014-07-14 03:00:25,697 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,699 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1970ms
2014-07-14 03:00:25,699 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,700 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1981ms
2014-07-14 03:00:25,700 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,700 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1971ms
2014-07-14 03:00:25,700 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,705 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1977ms
2014-07-14 03:00:25,705 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,713 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1985ms
2014-07-14 03:00:25,713 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,713 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1985ms
2014-07-14 03:00:25,713 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,713 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1988ms
2014-07-14 03:00:25,713 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,713 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1989ms
2014-07-14 03:00:25,713 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,715 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1996ms
2014-07-14 03:00:25,715 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,721 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2002ms
2014-07-14 03:00:25,721 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,725 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2007ms
2014-07-14 03:00:25,725 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,729 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2011ms
2014-07-14 03:00:25,729 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,729 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2014ms
2014-07-14 03:00:25,729 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,729 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2016ms
2014-07-14 03:00:25,729 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,729 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2016ms
2014-07-14 03:00:25,729 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:25,998 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:26,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31342 synced till here 31307
2014-07-14 03:00:26,134 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:00:26,339 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332021993 with entries=110, filesize=92.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332025998
2014-07-14 03:00:26,339 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331953453
2014-07-14 03:00:26,700 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:28,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:28,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31464 synced till here 31445
2014-07-14 03:00:28,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332025998 with entries=122, filesize=104.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332028225
2014-07-14 03:00:29,833 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7643, memsize=282.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/55017e76254b453ab438e14dcf1edc82
2014-07-14 03:00:29,847 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/55017e76254b453ab438e14dcf1edc82 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/55017e76254b453ab438e14dcf1edc82
2014-07-14 03:00:29,863 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/55017e76254b453ab438e14dcf1edc82, entries=1027000, sequenceid=7643, filesize=73.1m
2014-07-14 03:00:29,864 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~887.6m/930724480, currentsize=372.1m/390197280 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 23770ms, sequenceid=7643, compaction requested=true
2014-07-14 03:00:29,864 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:63), split_queue=0, merge_queue=0
2014-07-14 03:00:29,864 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 868.5m
2014-07-14 03:00:29,918 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:00:30,382 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:30,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31555 synced till here 31540
2014-07-14 03:00:30,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332028225 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332030383
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331954736
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331956701
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331958038
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331959200
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331960789
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331962312
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331966787
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331968856
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331970882
2014-07-14 03:00:30,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331973153
2014-07-14 03:00:30,784 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:32,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:32,233 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332030383 with entries=71, filesize=61.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332032203
2014-07-14 03:00:33,506 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:33,545 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31704 synced till here 31699
2014-07-14 03:00:33,602 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332032203 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332033506
2014-07-14 03:00:34,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:34,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332033506 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332034790
2014-07-14 03:00:36,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:36,713 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31887 synced till here 31885
2014-07-14 03:00:36,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332034790 with entries=109, filesize=93.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332036151
2014-07-14 03:00:38,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:38,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31959 synced till here 31958
2014-07-14 03:00:38,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332036151 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332038027
2014-07-14 03:00:39,355 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:39,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32061 synced till here 32059
2014-07-14 03:00:39,884 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332038027 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332039355
2014-07-14 03:00:41,147 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:41,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32137 synced till here 32135
2014-07-14 03:00:41,207 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332039355 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332041147
2014-07-14 03:00:42,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:42,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32218 synced till here 32215
2014-07-14 03:00:42,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332041147 with entries=81, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332042469
2014-07-14 03:00:44,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:44,453 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32308 synced till here 32295
2014-07-14 03:00:44,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332042469 with entries=90, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332044403
2014-07-14 03:00:45,787 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,800 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,800 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,806 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,816 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,843 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:45,846 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,847 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,849 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,858 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,864 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,886 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,928 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:45,958 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,010 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,062 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,099 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,129 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,159 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,167 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,188 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,219 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,225 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332044403 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332045843
2014-07-14 03:00:46,249 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,279 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,315 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:46,346 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:47,137 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:47,147 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:47,159 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:47,177 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7866, memsize=339.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1fffb2fc3fe34f3eb0fc575e4eb76ac8
2014-07-14 03:00:47,187 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:00:47,193 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1fffb2fc3fe34f3eb0fc575e4eb76ac8 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1fffb2fc3fe34f3eb0fc575e4eb76ac8
2014-07-14 03:00:47,205 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1fffb2fc3fe34f3eb0fc575e4eb76ac8, entries=1234320, sequenceid=7866, filesize=87.8m
2014-07-14 03:00:47,206 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~876.4m/918984320, currentsize=400.3m/419696160 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 21562ms, sequenceid=7866, compaction requested=true
2014-07-14 03:00:47,206 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:64), split_queue=0, merge_queue=0
2014-07-14 03:00:47,206 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19ms
2014-07-14 03:00:47,206 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,206 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 47ms
2014-07-14 03:00:47,206 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 820.0m
2014-07-14 03:00:47,207 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,207 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 60ms
2014-07-14 03:00:47,207 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,207 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 70ms
2014-07-14 03:00:47,207 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,208 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 861ms
2014-07-14 03:00:47,208 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,208 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 893ms
2014-07-14 03:00:47,208 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,208 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 929ms
2014-07-14 03:00:47,208 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,213 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 964ms
2014-07-14 03:00:47,213 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,213 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 994ms
2014-07-14 03:00:47,213 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,213 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1025ms
2014-07-14 03:00:47,213 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,214 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1047ms
2014-07-14 03:00:47,214 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,214 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1055ms
2014-07-14 03:00:47,214 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,214 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1085ms
2014-07-14 03:00:47,214 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,219 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1120ms
2014-07-14 03:00:47,219 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,220 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1157ms
2014-07-14 03:00:47,220 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,220 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1210ms
2014-07-14 03:00:47,220 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,220 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1262ms
2014-07-14 03:00:47,220 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,222 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1293ms
2014-07-14 03:00:47,222 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,224 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1338ms
2014-07-14 03:00:47,224 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,225 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1360ms
2014-07-14 03:00:47,226 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,226 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1368ms
2014-07-14 03:00:47,226 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,226 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1377ms
2014-07-14 03:00:47,226 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,233 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1386ms
2014-07-14 03:00:47,234 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,234 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1388ms
2014-07-14 03:00:47,234 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,234 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1418ms
2014-07-14 03:00:47,234 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,235 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1428ms
2014-07-14 03:00:47,235 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,235 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1435ms
2014-07-14 03:00:47,235 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,235 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1435ms
2014-07-14 03:00:47,236 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,236 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1449ms
2014-07-14 03:00:47,237 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:00:47,515 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:00:47,765 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7889, memsize=299.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f9e8f2e6b2bd4987be3c04fddef5e787
2014-07-14 03:00:47,779 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f9e8f2e6b2bd4987be3c04fddef5e787 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9e8f2e6b2bd4987be3c04fddef5e787
2014-07-14 03:00:47,793 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9e8f2e6b2bd4987be3c04fddef5e787, entries=1091810, sequenceid=7889, filesize=77.7m
2014-07-14 03:00:47,795 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~876.1m/918647840, currentsize=364.1m/381824800 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 17931ms, sequenceid=7889, compaction requested=true
2014-07-14 03:00:47,795 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:65), split_queue=0, merge_queue=0
2014-07-14 03:00:47,795 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 754.1m
2014-07-14 03:00:47,961 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:00:48,015 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:48,115 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:48,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32474 synced till here 32456
2014-07-14 03:00:48,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332045843 with entries=91, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332048115
2014-07-14 03:00:48,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331974889
2014-07-14 03:00:48,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331976562
2014-07-14 03:00:48,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331978090
2014-07-14 03:00:48,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331979528
2014-07-14 03:00:48,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331980661
2014-07-14 03:00:48,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331982183
2014-07-14 03:00:48,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331983660
2014-07-14 03:00:48,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331984886
2014-07-14 03:00:48,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331986725
2014-07-14 03:00:48,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331988892
2014-07-14 03:00:48,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331990895
2014-07-14 03:00:48,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331993088
2014-07-14 03:00:48,289 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331994973
2014-07-14 03:00:48,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405331998223
2014-07-14 03:00:49,347 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:00:49,735 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:49,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32565 synced till here 32552
2014-07-14 03:00:49,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332048115 with entries=91, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332049736
2014-07-14 03:00:51,111 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:51,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32655 synced till here 32650
2014-07-14 03:00:51,506 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332049736 with entries=90, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332051112
2014-07-14 03:00:52,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:52,765 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32731 synced till here 32726
2014-07-14 03:00:52,823 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332051112 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332052751
2014-07-14 03:00:53,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:54,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32818 synced till here 32809
2014-07-14 03:00:54,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332052751 with entries=87, filesize=74.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332053965
2014-07-14 03:00:55,476 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:56,010 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332053965 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332055478
2014-07-14 03:00:57,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:58,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32993 synced till here 32982
2014-07-14 03:00:58,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332055478 with entries=103, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332057543
2014-07-14 03:00:59,940 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:00:59,989 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33076 synced till here 33065
2014-07-14 03:01:00,131 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332057543 with entries=83, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332059941
2014-07-14 03:01:01,972 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:01,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33172 synced till here 33152
2014-07-14 03:01:02,314 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332059941 with entries=96, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332061973
2014-07-14 03:01:04,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:04,057 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33264 synced till here 33247
2014-07-14 03:01:04,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332061973 with entries=92, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332064022
2014-07-14 03:01:06,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:06,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33391 synced till here 33354
2014-07-14 03:01:07,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332064022 with entries=127, filesize=109.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332066356
2014-07-14 03:01:09,537 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:09,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33500 synced till here 33468
2014-07-14 03:01:09,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332066356 with entries=109, filesize=92.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332069537
2014-07-14 03:01:10,030 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,035 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,035 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,041 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,131 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,249 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,249 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,250 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,397 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,398 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,398 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,398 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,399 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,403 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,403 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,404 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,405 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,421 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,451 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,476 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,477 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,477 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,487 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,489 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,498 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,498 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,499 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,500 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,500 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,500 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,500 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,500 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,500 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,501 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,501 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,501 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,501 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,501 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,502 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,502 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,502 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,502 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,502 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,503 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,507 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,558 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,596 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,634 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:10,678 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:11,665 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:12,571 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8131, memsize=368.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ee6eb26fe7d94c7394ab48bd7d31bbfe
2014-07-14 03:01:12,586 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/ee6eb26fe7d94c7394ab48bd7d31bbfe as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ee6eb26fe7d94c7394ab48bd7d31bbfe
2014-07-14 03:01:12,604 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ee6eb26fe7d94c7394ab48bd7d31bbfe, entries=1340560, sequenceid=8131, filesize=95.4m
2014-07-14 03:01:12,604 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~758.8m/795660320, currentsize=418.5m/438834720 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 24809ms, sequenceid=8131, compaction requested=true
2014-07-14 03:01:12,604 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:66), split_queue=0, merge_queue=0
2014-07-14 03:01:12,604 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 940ms
2014-07-14 03:01:12,604 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,604 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 874.2m
2014-07-14 03:01:12,605 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1927ms
2014-07-14 03:01:12,605 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,605 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1971ms
2014-07-14 03:01:12,605 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,605 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2009ms
2014-07-14 03:01:12,605 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,605 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2047ms
2014-07-14 03:01:12,605 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,609 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2102ms
2014-07-14 03:01:12,609 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,610 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2107ms
2014-07-14 03:01:12,611 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,611 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2113ms
2014-07-14 03:01:12,611 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,611 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2112ms
2014-07-14 03:01:12,611 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,617 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2118ms
2014-07-14 03:01:12,617 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,617 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2117ms
2014-07-14 03:01:12,617 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,617 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2117ms
2014-07-14 03:01:12,618 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,618 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2118ms
2014-07-14 03:01:12,618 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,618 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2118ms
2014-07-14 03:01:12,618 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,618 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2128ms
2014-07-14 03:01:12,618 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,621 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2130ms
2014-07-14 03:01:12,621 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,625 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2124ms
2014-07-14 03:01:12,625 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,625 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-14 03:01:12,625 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,629 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-14 03:01:12,629 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,629 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-14 03:01:12,629 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,633 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2136ms
2014-07-14 03:01:12,633 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,633 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2135ms
2014-07-14 03:01:12,633 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,633 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2134ms
2014-07-14 03:01:12,633 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,636 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2137ms
2014-07-14 03:01:12,636 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,636 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2138ms
2014-07-14 03:01:12,636 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,637 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2139ms
2014-07-14 03:01:12,637 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,637 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2148ms
2014-07-14 03:01:12,637 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,637 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2150ms
2014-07-14 03:01:12,637 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,643 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2166ms
2014-07-14 03:01:12,643 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,643 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2167ms
2014-07-14 03:01:12,643 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,643 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2167ms
2014-07-14 03:01:12,643 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,645 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2195ms
2014-07-14 03:01:12,645 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,645 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2224ms
2014-07-14 03:01:12,645 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,646 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2241ms
2014-07-14 03:01:12,646 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,646 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2242ms
2014-07-14 03:01:12,646 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,649 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2246ms
2014-07-14 03:01:12,649 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,649 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2246ms
2014-07-14 03:01:12,649 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,649 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2251ms
2014-07-14 03:01:12,649 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,649 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2251ms
2014-07-14 03:01:12,649 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,654 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2256ms
2014-07-14 03:01:12,654 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,657 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2259ms
2014-07-14 03:01:12,657 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,660 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2263ms
2014-07-14 03:01:12,660 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,663 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2413ms
2014-07-14 03:01:12,663 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,664 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2414ms
2014-07-14 03:01:12,664 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,669 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2419ms
2014-07-14 03:01:12,669 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,669 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2538ms
2014-07-14 03:01:12,669 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,669 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2628ms
2014-07-14 03:01:12,669 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,673 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2638ms
2014-07-14 03:01:12,673 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,673 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2638ms
2014-07-14 03:01:12,673 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,677 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2647ms
2014-07-14 03:01:12,677 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:12,721 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:01:12,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:14,250 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1090ms
GC pool 'ParNew' had collection(s): count=1 time=1222ms
2014-07-14 03:01:14,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33605 synced till here 33579
2014-07-14 03:01:14,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332069537 with entries=105, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332072972
2014-07-14 03:01:14,819 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:01:15,003 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8125, memsize=384.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4535ee5b109147b284a70138992fe1b8
2014-07-14 03:01:15,015 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4535ee5b109147b284a70138992fe1b8 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4535ee5b109147b284a70138992fe1b8
2014-07-14 03:01:15,196 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4535ee5b109147b284a70138992fe1b8, entries=1399850, sequenceid=8125, filesize=99.7m
2014-07-14 03:01:15,196 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~820.0m/859871600, currentsize=499.6m/523912000 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 27990ms, sequenceid=8125, compaction requested=true
2014-07-14 03:01:15,196 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-14 03:01:15,197 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 817.2m
2014-07-14 03:01:15,227 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:01:16,753 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:16,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33732 synced till here 33704
2014-07-14 03:01:17,128 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332072972 with entries=127, filesize=108.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332076753
2014-07-14 03:01:17,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332000421
2014-07-14 03:01:17,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332004006
2014-07-14 03:01:17,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332005747
2014-07-14 03:01:17,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332007523
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332009004
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332010455
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332011749
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332013914
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332015968
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332018187
2014-07-14 03:01:17,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332020157
2014-07-14 03:01:17,195 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:01:18,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:18,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33849 synced till here 33808
2014-07-14 03:01:19,236 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332076753 with entries=117, filesize=100.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332078882
2014-07-14 03:01:21,164 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:21,832 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33959 synced till here 33949
2014-07-14 03:01:22,016 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332078882 with entries=110, filesize=94.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332081165
2014-07-14 03:01:23,702 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:23,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34063 synced till here 34038
2014-07-14 03:01:23,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332081165 with entries=104, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332083702
2014-07-14 03:01:24,821 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:25,682 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34139 synced till here 34135
2014-07-14 03:01:25,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332083702 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332084822
2014-07-14 03:01:26,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:26,499 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34228 synced till here 34212
2014-07-14 03:01:27,115 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332084822 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332086470
2014-07-14 03:01:28,841 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:28,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34329 synced till here 34305
2014-07-14 03:01:29,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332086470 with entries=101, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332088842
2014-07-14 03:01:34,890 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:34,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34403 synced till here 34401
2014-07-14 03:01:34,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332088842 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332094891
2014-07-14 03:01:36,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:36,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34485 synced till here 34483
2014-07-14 03:01:36,702 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332094891 with entries=82, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332096481
2014-07-14 03:01:37,280 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,280 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,293 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,307 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,330 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,360 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,433 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,491 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,547 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,619 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,699 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,748 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,801 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,875 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:37,929 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,449 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,465 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,556 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,591 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,622 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,677 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,710 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,893 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,944 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:38,975 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,005 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,038 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,071 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,105 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,134 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,165 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,197 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,229 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,260 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,290 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,323 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,354 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,387 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,420 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,452 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,484 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,548 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,580 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,615 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,647 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,677 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,712 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,742 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,774 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:39,803 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:01:40,357 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8432, memsize=458.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/574b67612cc24c3c85d9013b47a771ad
2014-07-14 03:01:40,371 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/574b67612cc24c3c85d9013b47a771ad as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/574b67612cc24c3c85d9013b47a771ad
2014-07-14 03:01:40,384 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/574b67612cc24c3c85d9013b47a771ad, entries=1670380, sequenceid=8432, filesize=118.9m
2014-07-14 03:01:40,384 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~874.2m/916632080, currentsize=353.1m/370252560 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 27780ms, sequenceid=8432, compaction requested=true
2014-07-14 03:01:40,385 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:68), split_queue=0, merge_queue=0
2014-07-14 03:01:40,385 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 582ms
2014-07-14 03:01:40,385 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,385 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 820.0m
2014-07-14 03:01:40,385 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 612ms
2014-07-14 03:01:40,385 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,385 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 643ms
2014-07-14 03:01:40,385 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,386 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 674ms
2014-07-14 03:01:40,386 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,389 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 712ms
2014-07-14 03:01:40,389 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,389 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 743ms
2014-07-14 03:01:40,389 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,389 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 774ms
2014-07-14 03:01:40,389 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,389 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 809ms
2014-07-14 03:01:40,389 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,389 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 841ms
2014-07-14 03:01:40,389 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,393 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 909ms
2014-07-14 03:01:40,393 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,393 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 941ms
2014-07-14 03:01:40,393 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,405 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 985ms
2014-07-14 03:01:40,405 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,405 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1018ms
2014-07-14 03:01:40,405 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,405 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1051ms
2014-07-14 03:01:40,405 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1085ms
2014-07-14 03:01:40,408 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,408 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1118ms
2014-07-14 03:01:40,408 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,409 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1148ms
2014-07-14 03:01:40,409 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,413 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1185ms
2014-07-14 03:01:40,413 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,413 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1216ms
2014-07-14 03:01:40,413 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,417 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1251ms
2014-07-14 03:01:40,417 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,417 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1283ms
2014-07-14 03:01:40,417 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,417 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1312ms
2014-07-14 03:01:40,417 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,417 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1346ms
2014-07-14 03:01:40,417 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,417 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1380ms
2014-07-14 03:01:40,417 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,417 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1412ms
2014-07-14 03:01:40,417 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,420 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1445ms
2014-07-14 03:01:40,420 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,425 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1482ms
2014-07-14 03:01:40,425 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,425 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1532ms
2014-07-14 03:01:40,425 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,431 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1721ms
2014-07-14 03:01:40,431 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,433 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1756ms
2014-07-14 03:01:40,433 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,433 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1811ms
2014-07-14 03:01:40,433 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,433 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1842ms
2014-07-14 03:01:40,433 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,433 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1877ms
2014-07-14 03:01:40,433 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,433 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1968ms
2014-07-14 03:01:40,433 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,437 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1989ms
2014-07-14 03:01:40,437 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,437 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2508ms
2014-07-14 03:01:40,437 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,438 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2563ms
2014-07-14 03:01:40,438 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,438 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2637ms
2014-07-14 03:01:40,438 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,438 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2690ms
2014-07-14 03:01:40,438 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,442 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2743ms
2014-07-14 03:01:40,442 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,445 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2826ms
2014-07-14 03:01:40,445 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,445 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2898ms
2014-07-14 03:01:40,445 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,445 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2954ms
2014-07-14 03:01:40,445 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,445 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3013ms
2014-07-14 03:01:40,445 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,446 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3086ms
2014-07-14 03:01:40,446 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,448 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3118ms
2014-07-14 03:01:40,448 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,448 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3141ms
2014-07-14 03:01:40,449 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,449 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3156ms
2014-07-14 03:01:40,449 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,450 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3170ms
2014-07-14 03:01:40,450 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:40,450 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3170ms
2014-07-14 03:01:40,450 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:01:41,880 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:41,881 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:01:41,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34581 synced till here 34567
2014-07-14 03:01:42,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332096481 with entries=96, filesize=80.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332101881
2014-07-14 03:01:42,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332021993
2014-07-14 03:01:42,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332025998
2014-07-14 03:01:42,362 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:01:43,915 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:44,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34698 synced till here 34659
2014-07-14 03:01:44,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332101881 with entries=117, filesize=98.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332103915
2014-07-14 03:01:44,293 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8445, memsize=460.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/d6bdce3401484d1185c66bb5e803b5f8
2014-07-14 03:01:44,329 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/d6bdce3401484d1185c66bb5e803b5f8 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/d6bdce3401484d1185c66bb5e803b5f8
2014-07-14 03:01:44,349 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/d6bdce3401484d1185c66bb5e803b5f8, entries=1676130, sequenceid=8445, filesize=119.3m
2014-07-14 03:01:44,350 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~859.6m/901385840, currentsize=403.5m/423065520 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 29153ms, sequenceid=8445, compaction requested=true
2014-07-14 03:01:44,350 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:69), split_queue=0, merge_queue=0
2014-07-14 03:01:44,350 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 907.1m
2014-07-14 03:01:44,393 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:01:45,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:45,803 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34801 synced till here 34770
2014-07-14 03:01:46,018 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:01:46,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332103915 with entries=103, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332105739
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332028225
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332030383
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332032203
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332033506
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332034790
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332036151
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332038027
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332039355
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332041147
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332042469
2014-07-14 03:01:46,170 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332044403
2014-07-14 03:01:47,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:47,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34928 synced till here 34909
2014-07-14 03:01:47,901 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332105739 with entries=127, filesize=108.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332107440
2014-07-14 03:01:49,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:49,871 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35012 synced till here 35007
2014-07-14 03:01:49,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332107440 with entries=84, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332109750
2014-07-14 03:01:50,973 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:51,016 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35088 synced till here 35086
2014-07-14 03:01:51,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332109750 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332110973
2014-07-14 03:01:52,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:52,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35162 synced till here 35160
2014-07-14 03:01:52,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332110973 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332112249
2014-07-14 03:01:53,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:53,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35250 synced till here 35243
2014-07-14 03:01:54,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332112249 with entries=88, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332113543
2014-07-14 03:01:56,100 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:57,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35356 synced till here 35347
2014-07-14 03:01:57,360 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332113543 with entries=106, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332116100
2014-07-14 03:01:59,254 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:01:59,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35445 synced till here 35434
2014-07-14 03:01:59,408 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332116100 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332119254
2014-07-14 03:02:00,079 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8659, memsize=245.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/7951c585794b499c84a6dc40ffae830f
2014-07-14 03:02:01,185 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/7951c585794b499c84a6dc40ffae830f as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7951c585794b499c84a6dc40ffae830f
2014-07-14 03:02:01,208 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7951c585794b499c84a6dc40ffae830f, entries=893720, sequenceid=8659, filesize=63.7m
2014-07-14 03:02:01,210 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~820.0m/859827040, currentsize=362.1m/379741040 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 20825ms, sequenceid=8659, compaction requested=true
2014-07-14 03:02:01,210 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:70), split_queue=0, merge_queue=0
2014-07-14 03:02:01,211 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 752.4m
2014-07-14 03:02:01,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:01,289 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:02:01,318 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35540 synced till here 35517
2014-07-14 03:02:01,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332119254 with entries=95, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332121289
2014-07-14 03:02:03,462 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:03,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:03,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35649 synced till here 35617
2014-07-14 03:02:03,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332121289 with entries=109, filesize=93.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332123504
2014-07-14 03:02:06,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:06,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35772 synced till here 35771
2014-07-14 03:02:07,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332123504 with entries=123, filesize=105.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332126048
2014-07-14 03:02:08,093 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8716, memsize=276.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4c50a526e0234ed695a89e7561d561f2
2014-07-14 03:02:08,106 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4c50a526e0234ed695a89e7561d561f2 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4c50a526e0234ed695a89e7561d561f2
2014-07-14 03:02:08,116 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4c50a526e0234ed695a89e7561d561f2, entries=1005240, sequenceid=8716, filesize=71.6m
2014-07-14 03:02:08,116 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~911.8m/956045440, currentsize=435.6m/456780160 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 23766ms, sequenceid=8716, compaction requested=true
2014-07-14 03:02:08,117 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-14 03:02:08,117 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 817.4m
2014-07-14 03:02:09,283 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:09,286 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:02:09,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35890 synced till here 35863
2014-07-14 03:02:09,833 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332126048 with entries=118, filesize=100.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332129284
2014-07-14 03:02:09,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332045843
2014-07-14 03:02:09,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332048115
2014-07-14 03:02:09,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332049736
2014-07-14 03:02:09,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332051112
2014-07-14 03:02:09,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332052751
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332053965
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332055478
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332057543
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332059941
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332061973
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332064022
2014-07-14 03:02:09,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332066356
2014-07-14 03:02:11,443 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:11,725 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:11,784 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35999 synced till here 35984
2014-07-14 03:02:11,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332129284 with entries=109, filesize=93.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332131725
2014-07-14 03:02:13,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:13,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36109 synced till here 36090
2014-07-14 03:02:13,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332131725 with entries=110, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332133733
2014-07-14 03:02:15,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:15,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36184 synced till here 36183
2014-07-14 03:02:15,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332133733 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332135416
2014-07-14 03:02:16,914 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:16,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36257 synced till here 36256
2014-07-14 03:02:16,954 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332135416 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332136914
2014-07-14 03:02:18,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:18,767 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332136914 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332138733
2014-07-14 03:02:19,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:20,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36420 synced till here 36419
2014-07-14 03:02:20,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332138733 with entries=90, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332139979
2014-07-14 03:02:20,916 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8932, memsize=231.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/24cab3e8b863443ca21bfc220773204b
2014-07-14 03:02:20,937 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/24cab3e8b863443ca21bfc220773204b as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/24cab3e8b863443ca21bfc220773204b
2014-07-14 03:02:20,969 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/24cab3e8b863443ca21bfc220773204b, entries=843740, sequenceid=8932, filesize=60.1m
2014-07-14 03:02:20,969 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~774.2m/811819760, currentsize=330.8m/346905280 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 19758ms, sequenceid=8932, compaction requested=true
2014-07-14 03:02:20,969 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:72), split_queue=0, merge_queue=0
2014-07-14 03:02:20,970 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 746.8m
2014-07-14 03:02:21,007 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:02:21,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:21,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36494 synced till here 36493
2014-07-14 03:02:21,955 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332139979 with entries=74, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332141914
2014-07-14 03:02:21,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332069537
2014-07-14 03:02:21,960 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:23,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:23,174 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36567 synced till here 36565
2014-07-14 03:02:23,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332141914 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332143153
2014-07-14 03:02:24,021 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:24,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36641 synced till here 36639
2014-07-14 03:02:24,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332143153 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332144021
2014-07-14 03:02:25,536 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:26,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36730 synced till here 36712
2014-07-14 03:02:26,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332144021 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332145537
2014-07-14 03:02:26,532 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8992, memsize=231.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e3f79e7605bb4271b19d32165a8d53f9
2014-07-14 03:02:26,550 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e3f79e7605bb4271b19d32165a8d53f9 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e3f79e7605bb4271b19d32165a8d53f9
2014-07-14 03:02:26,569 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e3f79e7605bb4271b19d32165a8d53f9, entries=844370, sequenceid=8992, filesize=60.1m
2014-07-14 03:02:26,570 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~847.1m/888220960, currentsize=330.3m/346297600 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 18453ms, sequenceid=8992, compaction requested=true
2014-07-14 03:02:26,570 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:73), split_queue=0, merge_queue=0
2014-07-14 03:02:26,570 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 773.4m
2014-07-14 03:02:26,582 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:02:27,368 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:27,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:27,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36803 synced till here 36802
2014-07-14 03:02:27,579 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332145537 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332147542
2014-07-14 03:02:27,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332072972
2014-07-14 03:02:27,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332076753
2014-07-14 03:02:27,579 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332078882
2014-07-14 03:02:27,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332081165
2014-07-14 03:02:27,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332083702
2014-07-14 03:02:27,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332084822
2014-07-14 03:02:27,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332086470
2014-07-14 03:02:27,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332088842
2014-07-14 03:02:27,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332094891
2014-07-14 03:02:28,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:28,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36882 synced till here 36875
2014-07-14 03:02:29,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332147542 with entries=79, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332148959
2014-07-14 03:02:30,568 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:31,713 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36977 synced till here 36975
2014-07-14 03:02:31,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332148959 with entries=95, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332150805
2014-07-14 03:02:33,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:33,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37071 synced till here 37058
2014-07-14 03:02:33,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332150805 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332153407
2014-07-14 03:02:35,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:35,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37171 synced till here 37146
2014-07-14 03:02:35,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332153407 with entries=100, filesize=85.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332155142
2014-07-14 03:02:37,182 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:37,249 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37277 synced till here 37250
2014-07-14 03:02:37,518 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332155142 with entries=106, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332157182
2014-07-14 03:02:38,726 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9144, memsize=226.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/3ad8983f5d954a769ff77626cc1f787a
2014-07-14 03:02:38,751 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/3ad8983f5d954a769ff77626cc1f787a as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3ad8983f5d954a769ff77626cc1f787a
2014-07-14 03:02:38,812 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3ad8983f5d954a769ff77626cc1f787a, entries=824460, sequenceid=9144, filesize=58.7m
2014-07-14 03:02:38,814 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~748.4m/784720880, currentsize=324.4m/340198640 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 17844ms, sequenceid=9144, compaction requested=true
2014-07-14 03:02:38,816 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-14 03:02:38,817 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 676.7m
2014-07-14 03:02:38,850 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:02:38,990 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:39,031 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37363 synced till here 37349
2014-07-14 03:02:39,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332157182 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332158991
2014-07-14 03:02:39,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332096481
2014-07-14 03:02:39,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332101881
2014-07-14 03:02:39,552 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:40,486 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:40,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37458 synced till here 37454
2014-07-14 03:02:40,725 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332158991 with entries=95, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332160486
2014-07-14 03:02:41,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:41,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37534 synced till here 37531
2014-07-14 03:02:41,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332160486 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332161864
2014-07-14 03:02:43,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:43,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37621 synced till here 37617
2014-07-14 03:02:43,359 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332161864 with entries=87, filesize=74.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332163119
2014-07-14 03:02:44,899 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:44,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332163119 with entries=73, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332164899
2014-07-14 03:02:46,466 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:46,488 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9222, memsize=311.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/3b558572af19428d9bc7c40fae0c17b7
2014-07-14 03:02:46,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332164899 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332166466
2014-07-14 03:02:46,499 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/3b558572af19428d9bc7c40fae0c17b7 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/3b558572af19428d9bc7c40fae0c17b7
2014-07-14 03:02:46,511 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/3b558572af19428d9bc7c40fae0c17b7, entries=1134500, sequenceid=9222, filesize=80.8m
2014-07-14 03:02:46,511 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~785.6m/823754320, currentsize=385.4m/404118800 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 19941ms, sequenceid=9222, compaction requested=true
2014-07-14 03:02:46,511 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-14 03:02:46,512 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 736.4m
2014-07-14 03:02:46,521 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:02:47,137 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:47,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:47,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37839 synced till here 37837
2014-07-14 03:02:47,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332166466 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332167649
2014-07-14 03:02:47,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332103915
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332105739
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332107440
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332109750
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332110973
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332112249
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332113543
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332116100
2014-07-14 03:02:47,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332119254
2014-07-14 03:02:49,645 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:49,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332167649 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332169646
2014-07-14 03:02:51,025 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:51,438 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332169646 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332171026
2014-07-14 03:02:51,698 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9371, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/25b3a90ad4254a4db34b6f25aa0a3c85
2014-07-14 03:02:51,714 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/25b3a90ad4254a4db34b6f25aa0a3c85 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25b3a90ad4254a4db34b6f25aa0a3c85
2014-07-14 03:02:51,726 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25b3a90ad4254a4db34b6f25aa0a3c85, entries=938890, sequenceid=9371, filesize=66.9m
2014-07-14 03:02:51,727 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~681.4m/714498800, currentsize=254.8m/267205360 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 12910ms, sequenceid=9371, compaction requested=true
2014-07-14 03:02:51,727 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-14 03:02:51,727 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 602.6m
2014-07-14 03:02:51,742 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:02:52,448 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:02:52,549 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:52,659 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332171026 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332172549
2014-07-14 03:02:52,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332121289
2014-07-14 03:02:52,660 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332123504
2014-07-14 03:02:53,996 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:54,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38148 synced till here 38146
2014-07-14 03:02:54,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332172549 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332173996
2014-07-14 03:02:55,361 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:55,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38225 synced till here 38221
2014-07-14 03:02:55,462 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332173996 with entries=77, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332175361
2014-07-14 03:02:56,578 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:56,919 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38302 synced till here 38297
2014-07-14 03:02:56,972 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332175361 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332176578
2014-07-14 03:02:57,889 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:58,753 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38379 synced till here 38376
2014-07-14 03:02:58,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332176578 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332177889
2014-07-14 03:02:59,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:02:59,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38453 synced till here 38452
2014-07-14 03:02:59,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332177889 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332179900
2014-07-14 03:03:00,760 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/f01de928b17045a0a000fc4558682c0c as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/f01de928b17045a0a000fc4558682c0c
2014-07-14 03:03:01,237 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:03:01,281 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1ac925dbf3e44680a9a82dcdeb8659e1, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1ac925dbf3e44680a9a82dcdeb8659e1
2014-07-14 03:03:01,285 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e657209a6c524e119a0a068d049ef82f, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e657209a6c524e119a0a068d049ef82f
2014-07-14 03:03:01,293 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/53dadd8e152e4f30a415f397166157ef, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/53dadd8e152e4f30a415f397166157ef
2014-07-14 03:03:01,297 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2f18d3375e86420e875f970f6d55a1dd, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2f18d3375e86420e875f970f6d55a1dd
2014-07-14 03:03:01,302 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e7cd8ba87b3c4b6b9960df077eb2988e, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e7cd8ba87b3c4b6b9960df077eb2988e
2014-07-14 03:03:01,306 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8e2bc380dc154e208dac6baa47a9ce60, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8e2bc380dc154e208dac6baa47a9ce60
2014-07-14 03:03:01,311 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/51a652194db8439499f7cc708dec7822, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/51a652194db8439499f7cc708dec7822
2014-07-14 03:03:01,314 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1c9c12a789394f8da144bff3d4ba927d, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1c9c12a789394f8da144bff3d4ba927d
2014-07-14 03:03:01,322 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ca59963ec855454d94d8ec8fb7605a3e, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ca59963ec855454d94d8ec8fb7605a3e
2014-07-14 03:03:01,325 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/6fbfd4d1de084d33a90e6a30944ecaa8, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/6fbfd4d1de084d33a90e6a30944ecaa8
2014-07-14 03:03:01,326 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into f01de928b17045a0a000fc4558682c0c(size=724.5m), total size for store is 1.7g. This selection was in queue for 0sec, and took 2mins, 55sec to execute.
2014-07-14 03:03:01,326 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=10, fileSize=746.1m, priority=5, time=285913127317072; duration=2mins, 55sec
2014-07-14 03:03:01,326 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-14 03:03:01,327 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-14 03:03:01,330 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 810141413 starting at candidate #1 after considering 84 permutations with 80 in ratio
2014-07-14 03:03:01,330 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating minor compaction
2014-07-14 03:03:01,330 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:03:01,331 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=772.6m
2014-07-14 03:03:01,331 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3636ba02ff5f4b04a71388acc2ba40d5, keycount=104665, bloomtype=ROW, size=74.5m, encoding=NONE, seqNum=2943
2014-07-14 03:03:01,331 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/a572f3f58e4440d180fec70e488039d7, keycount=94336, bloomtype=ROW, size=67.2m, encoding=NONE, seqNum=3111
2014-07-14 03:03:01,331 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6c574588a5a04f098cc3e4697553a2f7, keycount=103593, bloomtype=ROW, size=73.8m, encoding=NONE, seqNum=3305
2014-07-14 03:03:01,331 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/9a4d1f08029f4b039e87e5f746709f3a, keycount=89891, bloomtype=ROW, size=64.0m, encoding=NONE, seqNum=3476
2014-07-14 03:03:01,331 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/38ea92f9e37a4c879ae98b544b012c42, keycount=108052, bloomtype=ROW, size=77.0m, encoding=NONE, seqNum=3692
2014-07-14 03:03:01,331 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e2a81427f41b4664a4007d094cc2ba88, keycount=148197, bloomtype=ROW, size=105.5m, encoding=NONE, seqNum=4106
2014-07-14 03:03:01,332 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/343f0b3993d54f8e84e593c725960411, keycount=110952, bloomtype=ROW, size=79.0m, encoding=NONE, seqNum=4662
2014-07-14 03:03:01,332 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/99038c7fc14c492f8b8e5126baffa108, keycount=89379, bloomtype=ROW, size=63.7m, encoding=NONE, seqNum=5243
2014-07-14 03:03:01,332 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/96fe258015bc42cc9e1dca11eb762ea1, keycount=116699, bloomtype=ROW, size=83.2m, encoding=NONE, seqNum=5737
2014-07-14 03:03:01,332 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f5d15748d5bd4be780a1b5bfccdcc72c, keycount=119130, bloomtype=ROW, size=84.8m, encoding=NONE, seqNum=6315
2014-07-14 03:03:01,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:01,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38529 synced till here 38525
2014-07-14 03:03:01,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332179900 with entries=76, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332181509
2014-07-14 03:03:02,323 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:03:02,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:03,574 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38629 synced till here 38624
2014-07-14 03:03:03,606 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332181509 with entries=100, filesize=85.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332182924
2014-07-14 03:03:04,249 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9468, memsize=382.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/aa0fdeb77f7a4cdcbb162f76e78590e5
2014-07-14 03:03:04,262 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/aa0fdeb77f7a4cdcbb162f76e78590e5 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/aa0fdeb77f7a4cdcbb162f76e78590e5
2014-07-14 03:03:04,336 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/aa0fdeb77f7a4cdcbb162f76e78590e5, entries=1392690, sequenceid=9468, filesize=99.2m
2014-07-14 03:03:04,337 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~738.0m/773805280, currentsize=349.4m/366391840 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 17824ms, sequenceid=9468, compaction requested=true
2014-07-14 03:03:04,337 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-14 03:03:04,337 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 736.1m
2014-07-14 03:03:04,409 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:03:04,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:04,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38701 synced till here 38700
2014-07-14 03:03:04,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332182924 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332184887
2014-07-14 03:03:04,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332126048
2014-07-14 03:03:04,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332129284
2014-07-14 03:03:04,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332131725
2014-07-14 03:03:04,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332133733
2014-07-14 03:03:04,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332135416
2014-07-14 03:03:04,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332136914
2014-07-14 03:03:04,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332138733
2014-07-14 03:03:04,954 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:03:06,089 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:06,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332184887 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332186090
2014-07-14 03:03:07,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:07,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38861 synced till here 38860
2014-07-14 03:03:07,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332186090 with entries=87, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332187709
2014-07-14 03:03:09,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:09,480 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38950 synced till here 38945
2014-07-14 03:03:09,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332187709 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332189302
2014-07-14 03:03:10,039 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9535, memsize=376.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/211eab77913b4dd795661ff72dbd6ff8
2014-07-14 03:03:10,059 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/211eab77913b4dd795661ff72dbd6ff8 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/211eab77913b4dd795661ff72dbd6ff8
2014-07-14 03:03:10,092 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/211eab77913b4dd795661ff72dbd6ff8, entries=1370180, sequenceid=9535, filesize=97.6m
2014-07-14 03:03:10,092 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~605.6m/635062000, currentsize=359.8m/377262640 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 18365ms, sequenceid=9535, compaction requested=true
2014-07-14 03:03:10,093 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:77), split_queue=0, merge_queue=0
2014-07-14 03:03:10,093 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 623.7m
2014-07-14 03:03:10,125 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:03:10,609 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:03:10,641 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:10,759 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332189302 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332190641
2014-07-14 03:03:10,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332139979
2014-07-14 03:03:10,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332141914
2014-07-14 03:03:10,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332143153
2014-07-14 03:03:10,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332144021
2014-07-14 03:03:11,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:11,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39102 synced till here 39100
2014-07-14 03:03:11,980 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332190641 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332191936
2014-07-14 03:03:13,745 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:13,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39176 synced till here 39175
2014-07-14 03:03:13,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332191936 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332193746
2014-07-14 03:03:14,910 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:14,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39251 synced till here 39249
2014-07-14 03:03:15,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332193746 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332194911
2014-07-14 03:03:16,352 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:16,783 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39352 synced till here 39351
2014-07-14 03:03:16,803 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332194911 with entries=101, filesize=86.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332196352
2014-07-14 03:03:18,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:18,078 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39426 synced till here 39422
2014-07-14 03:03:18,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332196352 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332198055
2014-07-14 03:03:19,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:19,469 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39502 synced till here 39500
2014-07-14 03:03:19,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332198055 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332199441
2014-07-14 03:03:20,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:20,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39577 synced till here 39576
2014-07-14 03:03:20,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332199441 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332200790
2014-07-14 03:03:22,491 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:22,512 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39652 synced till here 39651
2014-07-14 03:03:22,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332200790 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332202492
2014-07-14 03:03:23,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:23,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39725 synced till here 39724
2014-07-14 03:03:23,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332202492 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332203931
2014-07-14 03:03:25,190 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:25,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39827 synced till here 39826
2014-07-14 03:03:25,528 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332203931 with entries=102, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332205190
2014-07-14 03:03:27,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:27,896 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332205190 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332207407
2014-07-14 03:03:28,036 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9699, memsize=553.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/9d5ef2bbdd9d4362b1edbdf9dbb3fabf
2014-07-14 03:03:28,049 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/9d5ef2bbdd9d4362b1edbdf9dbb3fabf as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/9d5ef2bbdd9d4362b1edbdf9dbb3fabf
2014-07-14 03:03:28,060 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/9d5ef2bbdd9d4362b1edbdf9dbb3fabf, entries=2016450, sequenceid=9699, filesize=143.5m
2014-07-14 03:03:28,060 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~737.7m/773484880, currentsize=484.8m/508319200 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 23723ms, sequenceid=9699, compaction requested=true
2014-07-14 03:03:28,060 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:78), split_queue=0, merge_queue=0
2014-07-14 03:03:28,061 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 833.7m
2014-07-14 03:03:28,094 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:03:28,743 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:03:29,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:29,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39984 synced till here 39981
2014-07-14 03:03:29,196 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332207407 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332209059
2014-07-14 03:03:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332145537
2014-07-14 03:03:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332147542
2014-07-14 03:03:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332148959
2014-07-14 03:03:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332150805
2014-07-14 03:03:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332153407
2014-07-14 03:03:29,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332155142
2014-07-14 03:03:30,409 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:30,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40059 synced till here 40056
2014-07-14 03:03:30,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332209059 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332210409
2014-07-14 03:03:31,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:31,878 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40135 synced till here 40133
2014-07-14 03:03:31,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332210409 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332211803
2014-07-14 03:03:33,198 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:33,216 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40209 synced till here 40207
2014-07-14 03:03:33,239 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332211803 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332213199
2014-07-14 03:03:34,165 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9777, memsize=603.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/73115d9b68f44465b0081b867c554cd7
2014-07-14 03:03:34,179 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/73115d9b68f44465b0081b867c554cd7 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/73115d9b68f44465b0081b867c554cd7
2014-07-14 03:03:34,193 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/73115d9b68f44465b0081b867c554cd7, entries=2196880, sequenceid=9777, filesize=156.3m
2014-07-14 03:03:34,194 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~630.1m/660667680, currentsize=498.6m/522824160 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 24101ms, sequenceid=9777, compaction requested=true
2014-07-14 03:03:34,194 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:79), split_queue=0, merge_queue=0
2014-07-14 03:03:34,195 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 869.1m
2014-07-14 03:03:34,196 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:03:34,330 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:34,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40285 synced till here 40281
2014-07-14 03:03:34,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332213199 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332214331
2014-07-14 03:03:34,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332157182
2014-07-14 03:03:34,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332158991
2014-07-14 03:03:34,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332160486
2014-07-14 03:03:34,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332161864
2014-07-14 03:03:34,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332163119
2014-07-14 03:03:34,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332164899
2014-07-14 03:03:35,127 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:03:35,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:35,819 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40359 synced till here 40357
2014-07-14 03:03:35,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332214331 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332215801
2014-07-14 03:03:37,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:37,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40437 synced till here 40433
2014-07-14 03:03:37,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332215801 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332217131
2014-07-14 03:03:38,417 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:38,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40517 synced till here 40514
2014-07-14 03:03:38,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332217131 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332218418
2014-07-14 03:03:40,280 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:40,303 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40591 synced till here 40589
2014-07-14 03:03:40,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332218418 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332220282
2014-07-14 03:03:41,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:41,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40692 synced till here 40691
2014-07-14 03:03:41,925 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332220282 with entries=101, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332221582
2014-07-14 03:03:43,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:43,250 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40772 synced till here 40766
2014-07-14 03:03:43,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332221582 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332223203
2014-07-14 03:03:44,666 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:44,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40861 synced till here 40859
2014-07-14 03:03:44,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332223203 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332224667
2014-07-14 03:03:46,336 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:03:46,377 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40944 synced till here 40934
2014-07-14 03:03:47,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332224667 with entries=83, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332226337
2014-07-14 03:03:47,705 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,705 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,708 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,710 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,711 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,734 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,773 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,777 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,781 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,781 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,781 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,782 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,783 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,785 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,785 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,802 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,831 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,831 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,834 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,834 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,835 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,835 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,837 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,837 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,838 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,864 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,895 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,925 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,954 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:47,982 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,013 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,040 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,069 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,096 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,125 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,153 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,182 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,209 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,237 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,266 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,294 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,323 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,353 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,382 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,465 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,489 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:48,518 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:49,650 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:49,659 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:49,947 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:03:52,705 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,706 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,708 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,710 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,711 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,735 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,773 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,778 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,781 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,782 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,782 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,783 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,783 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:03:52,785 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,785 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,803 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,831 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,831 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,834 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,835 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,836 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,836 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:03:52,838 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,838 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,838 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,864 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,896 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,925 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:52,955 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:52,983 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:53,013 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:53,040 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:53,070 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:53,097 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:53,125 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:53,154 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:53,859 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5341ms
2014-07-14 03:03:53,859 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5565ms
2014-07-14 03:03:53,859 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5650ms
2014-07-14 03:03:53,860 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5537ms
2014-07-14 03:03:53,860 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5507ms
2014-07-14 03:03:53,860 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5478ms
2014-07-14 03:03:53,861 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5396ms
2014-07-14 03:03:53,861 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5372ms
2014-07-14 03:03:53,862 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5679ms
2014-07-14 03:03:53,862 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5625ms
2014-07-14 03:03:53,862 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5596ms
2014-07-14 03:03:54,651 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:03:54,660 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:54,948 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:03:58,013 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10031ms
2014-07-14 03:03:58,014 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10177ms
2014-07-14 03:03:58,014 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10176ms
2014-07-14 03:03:58,014 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:03:58,015 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10152ms
2014-07-14 03:03:58,015 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10120ms
2014-07-14 03:03:58,016 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10090ms
2014-07-14 03:03:58,016 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10062ms
2014-07-14 03:03:58,016 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10311ms
2014-07-14 03:03:58,017 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10311ms
2014-07-14 03:03:58,017 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10309ms
2014-07-14 03:03:58,018 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10307ms
2014-07-14 03:03:58,018 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10307ms
2014-07-14 03:03:58,018 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10284ms
2014-07-14 03:03:58,018 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10245ms
2014-07-14 03:03:58,019 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10242ms
2014-07-14 03:03:58,019 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10238ms
2014-07-14 03:03:58,020 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10238ms
2014-07-14 03:03:58,020 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10239ms
2014-07-14 03:03:58,020 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10238ms
2014-07-14 03:03:58,021 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10240ms
2014-07-14 03:03:58,021 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10237ms
2014-07-14 03:03:58,022 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10236ms
2014-07-14 03:03:58,022 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10220ms
2014-07-14 03:03:58,022 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10191ms
2014-07-14 03:03:58,023 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10192ms
2014-07-14 03:03:58,023 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10189ms
2014-07-14 03:03:58,023 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10189ms
2014-07-14 03:03:58,024 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10189ms
2014-07-14 03:03:58,024 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10190ms
2014-07-14 03:03:58,024 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10187ms
2014-07-14 03:03:58,041 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:03:58,070 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:03:58,097 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:03:58,125 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:03:58,154 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:03:58,859 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10341ms
2014-07-14 03:03:58,860 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10651ms
2014-07-14 03:03:58,860 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10507ms
2014-07-14 03:03:58,861 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10567ms
2014-07-14 03:03:58,861 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10538ms
2014-07-14 03:03:58,861 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10479ms
2014-07-14 03:03:58,862 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10396ms
2014-07-14 03:03:58,862 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10680ms
2014-07-14 03:03:58,862 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10373ms
2014-07-14 03:03:58,863 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10597ms
2014-07-14 03:03:58,864 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10626ms
2014-07-14 03:03:59,651 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:03:59,660 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:03:59,949 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:04:00,337 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10008, memsize=779.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/dbbc7c5baa924fcb939e3992f3907d32
2014-07-14 03:04:00,349 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/dbbc7c5baa924fcb939e3992f3907d32 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/dbbc7c5baa924fcb939e3992f3907d32
2014-07-14 03:04:00,360 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/dbbc7c5baa924fcb939e3992f3907d32, entries=2837020, sequenceid=10008, filesize=201.8m
2014-07-14 03:04:00,360 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~836.8m/877422560, currentsize=406.0m/425766800 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 32299ms, sequenceid=10008, compaction requested=true
2014-07-14 03:04:00,360 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:80), split_queue=0, merge_queue=0
2014-07-14 03:04:00,360 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10413ms
2014-07-14 03:04:00,361 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,361 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10702ms
2014-07-14 03:04:00,361 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 908.6m
2014-07-14 03:04:00,361 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,361 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10711ms
2014-07-14 03:04:00,361 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,361 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12124ms
2014-07-14 03:04:00,361 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,361 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12095ms
2014-07-14 03:04:00,362 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,366 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11877ms
2014-07-14 03:04:00,366 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,366 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12184ms
2014-07-14 03:04:00,366 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,367 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11902ms
2014-07-14 03:04:00,367 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,367 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11985ms
2014-07-14 03:04:00,367 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,367 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12044ms
2014-07-14 03:04:00,368 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,369 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12075ms
2014-07-14 03:04:00,369 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,370 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12017ms
2014-07-14 03:04:00,370 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,370 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12161ms
2014-07-14 03:04:00,370 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,370 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11852ms
2014-07-14 03:04:00,370 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,371 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12218ms
2014-07-14 03:04:00,371 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,373 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12248ms
2014-07-14 03:04:00,373 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,373 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12277ms
2014-07-14 03:04:00,373 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,373 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12304ms
2014-07-14 03:04:00,373 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,377 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12337ms
2014-07-14 03:04:00,377 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,381 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12544ms
2014-07-14 03:04:00,381 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,383 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12549ms
2014-07-14 03:04:00,383 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,384 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12549ms
2014-07-14 03:04:00,384 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,384 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12550ms
2014-07-14 03:04:00,384 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,384 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12550ms
2014-07-14 03:04:00,384 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,384 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12553ms
2014-07-14 03:04:00,384 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,387 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12556ms
2014-07-14 03:04:00,387 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,387 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12585ms
2014-07-14 03:04:00,387 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,387 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12602ms
2014-07-14 03:04:00,387 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,389 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12605ms
2014-07-14 03:04:00,389 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,389 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12608ms
2014-07-14 03:04:00,389 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,389 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12607ms
2014-07-14 03:04:00,389 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,390 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12609ms
2014-07-14 03:04:00,391 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,392 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12611ms
2014-07-14 03:04:00,392 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,397 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12616ms
2014-07-14 03:04:00,397 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,397 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12620ms
2014-07-14 03:04:00,397 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,397 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12624ms
2014-07-14 03:04:00,397 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,397 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12663ms
2014-07-14 03:04:00,397 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,455 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12743ms
2014-07-14 03:04:00,455 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,457 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12747ms
2014-07-14 03:04:00,457 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,465 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12757ms
2014-07-14 03:04:00,465 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,465 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12760ms
2014-07-14 03:04:00,465 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,473 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12768ms
2014-07-14 03:04:00,473 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,481 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12527ms
2014-07-14 03:04:00,481 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,481 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12556ms
2014-07-14 03:04:00,481 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,481 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12586ms
2014-07-14 03:04:00,481 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,488 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14275,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226212,"queuetimems":0,"class":"HRegionServer","responsesize":15622,"method":"Multi"}
2014-07-14 03:04:00,489 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12626ms
2014-07-14 03:04:00,489 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,493 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12481ms
2014-07-14 03:04:00,493 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,493 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12655ms
2014-07-14 03:04:00,493 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,497 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12660ms
2014-07-14 03:04:00,497 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,501 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12519ms
2014-07-14 03:04:00,501 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:00,521 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:04:01,530 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:01,533 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227413,"queuetimems":0,"class":"HRegionServer","responsesize":15784,"method":"Multi"}
2014-07-14 03:04:01,533 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226244,"queuetimems":0,"class":"HRegionServer","responsesize":16010,"method":"Multi"}
2014-07-14 03:04:01,533 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15350,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226183,"queuetimems":0,"class":"HRegionServer","responsesize":15922,"method":"Multi"}
2014-07-14 03:04:01,533 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15234,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226299,"queuetimems":1,"class":"HRegionServer","responsesize":15613,"method":"Multi"}
2014-07-14 03:04:01,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41048 synced till here 41020
2014-07-14 03:04:01,775 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332226337 with entries=104, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332241530
2014-07-14 03:04:01,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332166466
2014-07-14 03:04:01,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332167649
2014-07-14 03:04:01,775 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332169646
2014-07-14 03:04:01,926 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14526,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227399,"queuetimems":0,"class":"HRegionServer","responsesize":16064,"method":"Multi"}
2014-07-14 03:04:01,972 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:04:02,075 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227576,"queuetimems":0,"class":"HRegionServer","responsesize":15887,"method":"Multi"}
2014-07-14 03:04:02,075 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226446,"queuetimems":1,"class":"HRegionServer","responsesize":16178,"method":"Multi"}
2014-07-14 03:04:03,577 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17088,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226488,"queuetimems":1,"class":"HRegionServer","responsesize":15699,"method":"Multi"}
2014-07-14 03:04:03,577 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226537,"queuetimems":1,"class":"HRegionServer","responsesize":15118,"method":"Multi"}
2014-07-14 03:04:03,577 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227387,"queuetimems":0,"class":"HRegionServer","responsesize":16054,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15918,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227659,"queuetimems":0,"class":"HRegionServer","responsesize":15508,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15950,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227627,"queuetimems":0,"class":"HRegionServer","responsesize":15915,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15883,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227694,"queuetimems":1,"class":"HRegionServer","responsesize":15911,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16986,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226592,"queuetimems":0,"class":"HRegionServer","responsesize":16106,"method":"Multi"}
2014-07-14 03:04:03,577 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16136,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227441,"queuetimems":0,"class":"HRegionServer","responsesize":15922,"method":"Multi"}
2014-07-14 03:04:03,577 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17184,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226393,"queuetimems":1,"class":"HRegionServer","responsesize":15768,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227507,"queuetimems":0,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16042,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227536,"queuetimems":1,"class":"HRegionServer","responsesize":15586,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16103,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227475,"queuetimems":0,"class":"HRegionServer","responsesize":16039,"method":"Multi"}
2014-07-14 03:04:03,578 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17245,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332226332,"queuetimems":1,"class":"HRegionServer","responsesize":15763,"method":"Multi"}
2014-07-14 03:04:03,698 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:03,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41123 synced till here 41119
2014-07-14 03:04:03,766 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13820,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332229945,"queuetimems":0,"class":"HRegionServer","responsesize":16106,"method":"Multi"}
2014-07-14 03:04:04,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332241530 with entries=75, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332243699
2014-07-14 03:04:04,350 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15969,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228380,"queuetimems":1,"class":"HRegionServer","responsesize":15887,"method":"Multi"}
2014-07-14 03:04:04,356 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15870,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228486,"queuetimems":0,"class":"HRegionServer","responsesize":15922,"method":"Multi"}
2014-07-14 03:04:04,366 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332229658,"queuetimems":1,"class":"HRegionServer","responsesize":15785,"method":"Multi"}
2014-07-14 03:04:04,373 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228207,"queuetimems":0,"class":"HRegionServer","responsesize":16004,"method":"Multi"}
2014-07-14 03:04:04,382 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16258,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228123,"queuetimems":0,"class":"HRegionServer","responsesize":16178,"method":"Multi"}
2014-07-14 03:04:04,386 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15922,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228463,"queuetimems":0,"class":"HRegionServer","responsesize":15911,"method":"Multi"}
2014-07-14 03:04:04,386 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16121,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228264,"queuetimems":0,"class":"HRegionServer","responsesize":15691,"method":"Multi"}
2014-07-14 03:04:04,386 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16206,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228179,"queuetimems":0,"class":"HRegionServer","responsesize":15829,"method":"Multi"}
2014-07-14 03:04:05,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:05,407 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16863,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228544,"queuetimems":0,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 03:04:05,411 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17488,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227923,"queuetimems":1,"class":"HRegionServer","responsesize":15922,"method":"Multi"}
2014-07-14 03:04:05,411 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227800,"queuetimems":1,"class":"HRegionServer","responsesize":15613,"method":"Multi"}
2014-07-14 03:04:05,429 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17419,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228010,"queuetimems":0,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 03:04:05,437 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228351,"queuetimems":0,"class":"HRegionServer","responsesize":15915,"method":"Multi"}
2014-07-14 03:04:05,441 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17403,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228038,"queuetimems":0,"class":"HRegionServer","responsesize":15699,"method":"Multi"}
2014-07-14 03:04:05,450 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17678,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227771,"queuetimems":1,"class":"HRegionServer","responsesize":15903,"method":"Multi"}
2014-07-14 03:04:05,454 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228292,"queuetimems":0,"class":"HRegionServer","responsesize":15508,"method":"Multi"}
2014-07-14 03:04:05,461 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228235,"queuetimems":0,"class":"HRegionServer","responsesize":15968,"method":"Multi"}
2014-07-14 03:04:05,463 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227832,"queuetimems":1,"class":"HRegionServer","responsesize":15622,"method":"Multi"}
2014-07-14 03:04:05,469 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17737,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227732,"queuetimems":0,"class":"HRegionServer","responsesize":15785,"method":"Multi"}
2014-07-14 03:04:05,470 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17608,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227862,"queuetimems":1,"class":"HRegionServer","responsesize":15540,"method":"Multi"}
2014-07-14 03:04:05,474 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17407,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228067,"queuetimems":0,"class":"HRegionServer","responsesize":15913,"method":"Multi"}
2014-07-14 03:04:05,481 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17500,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227981,"queuetimems":1,"class":"HRegionServer","responsesize":16010,"method":"Multi"}
2014-07-14 03:04:05,489 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228094,"queuetimems":0,"class":"HRegionServer","responsesize":15768,"method":"Multi"}
2014-07-14 03:04:05,497 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17545,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227952,"queuetimems":0,"class":"HRegionServer","responsesize":16255,"method":"Multi"}
2014-07-14 03:04:05,501 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17608,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332227893,"queuetimems":1,"class":"HRegionServer","responsesize":15906,"method":"Multi"}
2014-07-14 03:04:05,504 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228321,"queuetimems":0,"class":"HRegionServer","responsesize":15586,"method":"Multi"}
2014-07-14 03:04:05,517 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17001,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228515,"queuetimems":0,"class":"HRegionServer","responsesize":16039,"method":"Multi"}
2014-07-14 03:04:05,524 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17372,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332228151,"queuetimems":0,"class":"HRegionServer","responsesize":15763,"method":"Multi"}
2014-07-14 03:04:05,723 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41257 synced till here 41243
2014-07-14 03:04:05,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332243699 with entries=134, filesize=115.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332245407
2014-07-14 03:04:07,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:07,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41361 synced till here 41338
2014-07-14 03:04:07,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332245407 with entries=104, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332247513
2014-07-14 03:04:09,152 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:09,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41461 synced till here 41436
2014-07-14 03:04:09,565 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332247513 with entries=100, filesize=86.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332249153
2014-07-14 03:04:10,614 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,732 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,732 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,733 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,733 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,753 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,782 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,846 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:10,855 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,856 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,859 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,874 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41554 synced till here 41533
2014-07-14 03:04:10,983 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,983 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,983 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,983 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,984 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:10,984 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,024 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,029 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,030 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,031 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,032 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,032 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,033 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,033 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,034 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,034 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,035 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,035 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,035 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,036 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,036 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,036 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,037 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,037 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332249153 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332250847
2014-07-14 03:04:11,037 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,038 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,038 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,038 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,038 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,038 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,038 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,039 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,039 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,042 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,044 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,045 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,045 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,054 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,068 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,068 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:11,229 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10098, memsize=798.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/87cd1176f0da4daa96f054d0fda238f5
2014-07-14 03:04:11,246 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/87cd1176f0da4daa96f054d0fda238f5 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/87cd1176f0da4daa96f054d0fda238f5
2014-07-14 03:04:11,257 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/87cd1176f0da4daa96f054d0fda238f5, entries=2907550, sequenceid=10098, filesize=206.8m
2014-07-14 03:04:11,257 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~872.2m/914597440, currentsize=475.0m/498030880 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 37062ms, sequenceid=10098, compaction requested=true
2014-07-14 03:04:11,258 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:81), split_queue=0, merge_queue=0
2014-07-14 03:04:11,258 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 190ms
2014-07-14 03:04:11,258 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,258 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 190ms
2014-07-14 03:04:11,258 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,258 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 1.0g
2014-07-14 03:04:11,258 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 204ms
2014-07-14 03:04:11,258 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,258 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 214ms
2014-07-14 03:04:11,258 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,259 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 215ms
2014-07-14 03:04:11,259 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,259 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 215ms
2014-07-14 03:04:11,259 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,259 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 217ms
2014-07-14 03:04:11,259 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,261 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 222ms
2014-07-14 03:04:11,261 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,261 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 223ms
2014-07-14 03:04:11,261 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,261 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 223ms
2014-07-14 03:04:11,261 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,265 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 227ms
2014-07-14 03:04:11,265 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,268 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 231ms
2014-07-14 03:04:11,268 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,272 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 234ms
2014-07-14 03:04:11,272 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,272 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 235ms
2014-07-14 03:04:11,272 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,273 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 235ms
2014-07-14 03:04:11,273 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,273 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 236ms
2014-07-14 03:04:11,273 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,273 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 248ms
2014-07-14 03:04:11,273 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,275 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 239ms
2014-07-14 03:04:11,275 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,275 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 240ms
2014-07-14 03:04:11,275 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,285 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 249ms
2014-07-14 03:04:11,285 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,285 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 249ms
2014-07-14 03:04:11,285 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,285 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 250ms
2014-07-14 03:04:11,285 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,285 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 250ms
2014-07-14 03:04:11,285 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,287 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 252ms
2014-07-14 03:04:11,287 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,288 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 253ms
2014-07-14 03:04:11,288 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,288 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 254ms
2014-07-14 03:04:11,288 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,288 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 255ms
2014-07-14 03:04:11,288 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,288 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 256ms
2014-07-14 03:04:11,288 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,293 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 261ms
2014-07-14 03:04:11,293 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,293 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 261ms
2014-07-14 03:04:11,293 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,293 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 262ms
2014-07-14 03:04:11,293 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,293 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 264ms
2014-07-14 03:04:11,293 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,293 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 264ms
2014-07-14 03:04:11,293 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,293 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 269ms
2014-07-14 03:04:11,294 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,294 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 310ms
2014-07-14 03:04:11,294 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,297 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 314ms
2014-07-14 03:04:11,297 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,297 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 314ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,298 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 315ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,298 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 315ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,298 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 315ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,298 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 440ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,298 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 442ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,298 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 443ms
2014-07-14 03:04:11,298 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,302 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 520ms
2014-07-14 03:04:11,302 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,302 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 549ms
2014-07-14 03:04:11,302 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,302 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 688ms
2014-07-14 03:04:11,302 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,302 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 682ms
2014-07-14 03:04:11,302 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,304 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 683ms
2014-07-14 03:04:11,305 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,309 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 688ms
2014-07-14 03:04:11,309 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,313 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 699ms
2014-07-14 03:04:11,313 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:11,466 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:04:12,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:12,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41638 synced till here 41630
2014-07-14 03:04:12,912 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:04:12,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332250847 with entries=84, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332252470
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332171026
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332172549
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332173996
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332175361
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332176578
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332177889
2014-07-14 03:04:12,948 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332179900
2014-07-14 03:04:12,949 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332181509
2014-07-14 03:04:14,699 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:14,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41752 synced till here 41749
2014-07-14 03:04:15,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332252470 with entries=114, filesize=98.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332254699
2014-07-14 03:04:16,334 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:16,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41866 synced till here 41826
2014-07-14 03:04:16,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332254699 with entries=114, filesize=98.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332256334
2014-07-14 03:04:18,248 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:18,451 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41969 synced till here 41962
2014-07-14 03:04:18,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332256334 with entries=103, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332258249
2014-07-14 03:04:25,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:25,546 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42051 synced till here 42041
2014-07-14 03:04:25,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332258249 with entries=82, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332265474
2014-07-14 03:04:26,080 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,131 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,155 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,155 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,157 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,158 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,158 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,158 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,158 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,170 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,190 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,190 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,265 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,351 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,424 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:26,486 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:27,856 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:27,887 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:27,916 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:27,949 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:27,991 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,035 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,070 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,103 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,146 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,201 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,245 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,363 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,405 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,441 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,483 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,521 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,567 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,613 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:28,657 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:30,359 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:30,399 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:30,432 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:30,469 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:31,080 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:31,132 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:31,156 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:31,156 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:31,158 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:31,158 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:31,158 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:31,158 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:31,159 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:31,170 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:31,190 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:31,190 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:31,675 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5189ms
2014-07-14 03:04:31,676 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5411ms
2014-07-14 03:04:31,676 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5325ms
2014-07-14 03:04:31,677 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5253ms
2014-07-14 03:04:32,470 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,511 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,547 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,588 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,630 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,665 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,702 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,750 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:32,856 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:32,888 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:32,917 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:32,950 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:32,992 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:33,036 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,070 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,104 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,147 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:33,202 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:33,245 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,363 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,405 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,441 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:33,484 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:33,522 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,568 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,613 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:04:33,658 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:04:34,466 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:34,506 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:34,537 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:04:35,235 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10284, memsize=774.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/83b46a02ba044306ac57e459923fc5ee
2014-07-14 03:04:35,257 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/83b46a02ba044306ac57e459923fc5ee as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/83b46a02ba044306ac57e459923fc5ee
2014-07-14 03:04:35,269 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/83b46a02ba044306ac57e459923fc5ee, entries=2818530, sequenceid=10284, filesize=200.6m
2014-07-14 03:04:35,270 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~908.6m/952741200, currentsize=423.6m/444133840 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 34908ms, sequenceid=10284, compaction requested=true
2014-07-14 03:04:35,270 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:82), split_queue=0, merge_queue=0
2014-07-14 03:04:35,270 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 733ms
2014-07-14 03:04:35,270 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 838.7m
2014-07-14 03:04:35,270 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,270 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 764ms
2014-07-14 03:04:35,271 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,271 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 805ms
2014-07-14 03:04:35,271 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,271 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6614ms
2014-07-14 03:04:35,271 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,271 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6658ms
2014-07-14 03:04:35,271 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,271 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6704ms
2014-07-14 03:04:35,271 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,271 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6750ms
2014-07-14 03:04:35,272 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,273 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6790ms
2014-07-14 03:04:35,273 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,274 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6834ms
2014-07-14 03:04:35,274 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,274 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6869ms
2014-07-14 03:04:35,274 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,274 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6911ms
2014-07-14 03:04:35,274 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,275 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7029ms
2014-07-14 03:04:35,275 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,275 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7074ms
2014-07-14 03:04:35,275 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,277 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7131ms
2014-07-14 03:04:35,277 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,279 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7176ms
2014-07-14 03:04:35,279 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,287 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7217ms
2014-07-14 03:04:35,287 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,287 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7252ms
2014-07-14 03:04:35,288 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,288 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7297ms
2014-07-14 03:04:35,288 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,288 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7339ms
2014-07-14 03:04:35,288 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,288 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7372ms
2014-07-14 03:04:35,288 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,290 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7403ms
2014-07-14 03:04:35,290 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,290 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7434ms
2014-07-14 03:04:35,290 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,293 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2543ms
2014-07-14 03:04:35,293 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,293 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2592ms
2014-07-14 03:04:35,293 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,293 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2628ms
2014-07-14 03:04:35,294 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,294 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2664ms
2014-07-14 03:04:35,294 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,294 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2706ms
2014-07-14 03:04:35,294 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,294 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2747ms
2014-07-14 03:04:35,294 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,304 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2793ms
2014-07-14 03:04:35,304 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,304 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2835ms
2014-07-14 03:04:35,304 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,304 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8880ms
2014-07-14 03:04:35,304 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,308 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8957ms
2014-07-14 03:04:35,308 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,308 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9043ms
2014-07-14 03:04:35,308 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,309 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8822ms
2014-07-14 03:04:35,309 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,310 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9119ms
2014-07-14 03:04:35,310 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,313 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9124ms
2014-07-14 03:04:35,314 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,314 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9144ms
2014-07-14 03:04:35,314 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,314 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9156ms
2014-07-14 03:04:35,314 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,316 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9157ms
2014-07-14 03:04:35,316 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,316 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9158ms
2014-07-14 03:04:35,316 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,329 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9171ms
2014-07-14 03:04:35,329 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,329 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9172ms
2014-07-14 03:04:35,329 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,333 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9178ms
2014-07-14 03:04:35,333 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,336 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9179ms
2014-07-14 03:04:35,337 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,337 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9206ms
2014-07-14 03:04:35,337 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,337 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9257ms
2014-07-14 03:04:35,337 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,337 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4868ms
2014-07-14 03:04:35,337 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,338 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4906ms
2014-07-14 03:04:35,338 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,338 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4939ms
2014-07-14 03:04:35,338 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,338 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4979ms
2014-07-14 03:04:35,338 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:04:35,473 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:04:35,595 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10033,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265561,"queuetimems":1,"class":"HRegionServer","responsesize":15717,"method":"Multi"}
2014-07-14 03:04:35,597 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10315,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265282,"queuetimems":0,"class":"HRegionServer","responsesize":15911,"method":"Multi"}
2014-07-14 03:04:35,599 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10414,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265184,"queuetimems":0,"class":"HRegionServer","responsesize":15922,"method":"Multi"}
2014-07-14 03:04:35,599 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10221,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265378,"queuetimems":1,"class":"HRegionServer","responsesize":15915,"method":"Multi"}
2014-07-14 03:04:35,600 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265454,"queuetimems":0,"class":"HRegionServer","responsesize":15586,"method":"Multi"}
2014-07-14 03:04:35,686 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10179,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265507,"queuetimems":0,"class":"HRegionServer","responsesize":15865,"method":"Multi"}
2014-07-14 03:04:35,686 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10020,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332265666,"queuetimems":1,"class":"HRegionServer","responsesize":15983,"method":"Multi"}
2014-07-14 03:04:36,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:36,208 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42148 synced till here 42127
2014-07-14 03:04:36,341 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266058,"queuetimems":1,"class":"HRegionServer","responsesize":15909,"method":"Multi"}
2014-07-14 03:04:36,345 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10344,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266001,"queuetimems":1,"class":"HRegionServer","responsesize":16217,"method":"Multi"}
2014-07-14 03:04:36,459 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:04:36,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332265474 with entries=97, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332276138
2014-07-14 03:04:36,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332182924
2014-07-14 03:04:36,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332184887
2014-07-14 03:04:36,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332186090
2014-07-14 03:04:36,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332187709
2014-07-14 03:04:37,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:37,987 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42264 synced till here 42253
2014-07-14 03:04:38,081 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10195,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332267885,"queuetimems":0,"class":"HRegionServer","responsesize":16004,"method":"Multi"}
2014-07-14 03:04:38,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332276138 with entries=116, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332277810
2014-07-14 03:04:38,521 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10462,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268059,"queuetimems":0,"class":"HRegionServer","responsesize":15118,"method":"Multi"}
2014-07-14 03:04:38,522 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266349,"queuetimems":0,"class":"HRegionServer","responsesize":15911,"method":"Multi"}
2014-07-14 03:04:38,524 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268475,"queuetimems":0,"class":"HRegionServer","responsesize":15717,"method":"Multi"}
2014-07-14 03:04:38,524 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266484,"queuetimems":0,"class":"HRegionServer","responsesize":15818,"method":"Multi"}
2014-07-14 03:04:38,524 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10164,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268360,"queuetimems":1,"class":"HRegionServer","responsesize":15649,"method":"Multi"}
2014-07-14 03:04:38,524 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10123,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268401,"queuetimems":0,"class":"HRegionServer","responsesize":15983,"method":"Multi"}
2014-07-14 03:04:38,525 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268142,"queuetimems":1,"class":"HRegionServer","responsesize":16064,"method":"Multi"}
2014-07-14 03:04:38,525 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10426,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268099,"queuetimems":0,"class":"HRegionServer","responsesize":15968,"method":"Multi"}
2014-07-14 03:04:38,525 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12396,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266129,"queuetimems":0,"class":"HRegionServer","responsesize":16008,"method":"Multi"}
2014-07-14 03:04:38,537 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332267988,"queuetimems":0,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 03:04:38,537 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10623,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332267914,"queuetimems":0,"class":"HRegionServer","responsesize":15829,"method":"Multi"}
2014-07-14 03:04:38,538 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332267947,"queuetimems":1,"class":"HRegionServer","responsesize":16039,"method":"Multi"}
2014-07-14 03:04:38,537 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12274,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266263,"queuetimems":0,"class":"HRegionServer","responsesize":15673,"method":"Multi"}
2014-07-14 03:04:38,538 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332267854,"queuetimems":0,"class":"HRegionServer","responsesize":15691,"method":"Multi"}
2014-07-14 03:04:38,539 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268235,"queuetimems":0,"class":"HRegionServer","responsesize":15785,"method":"Multi"}
2014-07-14 03:04:38,540 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10515,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268024,"queuetimems":0,"class":"HRegionServer","responsesize":16106,"method":"Multi"}
2014-07-14 03:04:38,709 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12541,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266168,"queuetimems":0,"class":"HRegionServer","responsesize":15707,"method":"Multi"}
2014-07-14 03:04:38,710 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10272,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332268437,"queuetimems":0,"class":"HRegionServer","responsesize":16217,"method":"Multi"}
2014-07-14 03:04:38,761 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12339,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332266421,"queuetimems":0,"class":"HRegionServer","responsesize":15583,"method":"Multi"}
2014-07-14 03:04:39,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:39,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42339 synced till here 42336
2014-07-14 03:04:39,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332277810 with entries=75, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332279266
2014-07-14 03:04:40,227 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:40,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42420 synced till here 42418
2014-07-14 03:04:40,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332279266 with entries=81, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332280228
2014-07-14 03:04:41,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:41,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42496 synced till here 42492
2014-07-14 03:04:41,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332280228 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332281604
2014-07-14 03:04:42,357 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10448, memsize=678.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/c440e72bc9594ec5800340f0942fb923
2014-07-14 03:04:42,369 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/c440e72bc9594ec5800340f0942fb923 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/c440e72bc9594ec5800340f0942fb923
2014-07-14 03:04:42,383 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/c440e72bc9594ec5800340f0942fb923, entries=2470310, sequenceid=10448, filesize=175.9m
2014-07-14 03:04:42,383 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.0g/1087560960, currentsize=331.0m/347063920 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 31125ms, sequenceid=10448, compaction requested=true
2014-07-14 03:04:42,383 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:83), split_queue=0, merge_queue=0
2014-07-14 03:04:42,384 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 873.8m
2014-07-14 03:04:42,395 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:04:42,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:42,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42569 synced till here 42568
2014-07-14 03:04:42,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332281604 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332282789
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332189302
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332190641
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332191936
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332193746
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332194911
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332196352
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332198055
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332199441
2014-07-14 03:04:42,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332200790
2014-07-14 03:04:42,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332202492
2014-07-14 03:04:42,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332203931
2014-07-14 03:04:42,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332205190
2014-07-14 03:04:43,323 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:04:43,983 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:44,198 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42653 synced till here 42651
2014-07-14 03:04:44,255 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332282789 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332283983
2014-07-14 03:04:46,040 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:46,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42727 synced till here 42726
2014-07-14 03:04:46,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332283983 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332286040
2014-07-14 03:04:47,305 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:47,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42819 synced till here 42816
2014-07-14 03:04:47,523 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332286040 with entries=92, filesize=79.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332287306
2014-07-14 03:04:48,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:48,886 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42899 synced till here 42892
2014-07-14 03:04:48,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332287306 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332288717
2014-07-14 03:04:50,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:50,250 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42992 synced till here 42990
2014-07-14 03:04:50,655 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332288717 with entries=93, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332290046
2014-07-14 03:04:51,372 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:51,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43068 synced till here 43062
2014-07-14 03:04:51,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332290046 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332291372
2014-07-14 03:04:52,422 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:52,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43142 synced till here 43139
2014-07-14 03:04:52,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332291372 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332292423
2014-07-14 03:04:53,828 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:53,836 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10549, memsize=353.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/055a90e66bb2470fa4410d79ba790d5a
2014-07-14 03:04:53,854 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/055a90e66bb2470fa4410d79ba790d5a as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/055a90e66bb2470fa4410d79ba790d5a
2014-07-14 03:04:53,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43217 synced till here 43216
2014-07-14 03:04:53,865 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/055a90e66bb2470fa4410d79ba790d5a, entries=1286890, sequenceid=10549, filesize=91.7m
2014-07-14 03:04:53,865 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~838.7m/879444240, currentsize=437.2m/458461360 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 18595ms, sequenceid=10549, compaction requested=true
2014-07-14 03:04:53,865 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:84), split_queue=0, merge_queue=0
2014-07-14 03:04:53,866 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 856.9m
2014-07-14 03:04:53,890 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332292423 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332293828
2014-07-14 03:04:53,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332207407
2014-07-14 03:04:53,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332209059
2014-07-14 03:04:53,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332210409
2014-07-14 03:04:53,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332211803
2014-07-14 03:04:53,963 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:04:54,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:54,928 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:04:55,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43294 synced till here 43291
2014-07-14 03:04:55,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332293828 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332294906
2014-07-14 03:04:56,447 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:56,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43378 synced till here 43368
2014-07-14 03:04:56,605 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332294906 with entries=84, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332296448
2014-07-14 03:04:58,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:04:59,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43502 synced till here 43493
2014-07-14 03:04:59,604 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332296448 with entries=124, filesize=106.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332298149
2014-07-14 03:05:00,168 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10665, memsize=307.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/3a7e17cacba3457e9178d1b28d1c730a
2014-07-14 03:05:00,203 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/3a7e17cacba3457e9178d1b28d1c730a as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3a7e17cacba3457e9178d1b28d1c730a
2014-07-14 03:05:00,220 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3a7e17cacba3457e9178d1b28d1c730a, entries=1118250, sequenceid=10665, filesize=79.7m
2014-07-14 03:05:00,221 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~876.9m/919492480, currentsize=387.4m/406223200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 17838ms, sequenceid=10665, compaction requested=true
2014-07-14 03:05:00,221 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-14 03:05:00,221 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 741.5m
2014-07-14 03:05:00,273 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:05:01,293 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:01,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43609 synced till here 43598
2014-07-14 03:05:01,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332298149 with entries=107, filesize=91.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332301294
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332213199
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332214331
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332215801
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332217131
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332218418
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332220282
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332221582
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332223203
2014-07-14 03:05:01,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332224667
2014-07-14 03:05:01,975 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:05:02,975 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:02,999 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43694 synced till here 43683
2014-07-14 03:05:03,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332301294 with entries=85, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332302976
2014-07-14 03:05:04,643 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:04,666 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43772 synced till here 43768
2014-07-14 03:05:04,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332302976 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332304643
2014-07-14 03:05:06,048 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:06,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43847 synced till here 43844
2014-07-14 03:05:06,522 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332304643 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332306048
2014-07-14 03:05:07,157 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.83 MB, free=3.95 GB, max=3.96 GB, blocks=10, accesses=219154, hits=43619, hitRatio=19.90%, , cachingAccesses=43641, cachingHits=43597, cachingHitsRatio=99.89%, evictions=0, evicted=34, evictedPerRun=Infinity
2014-07-14 03:05:07,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:07,493 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43922 synced till here 43921
2014-07-14 03:05:07,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332306048 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332307428
2014-07-14 03:05:09,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:09,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43999 synced till here 43997
2014-07-14 03:05:09,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332307428 with entries=77, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332309084
2014-07-14 03:05:10,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:10,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44085 synced till here 44071
2014-07-14 03:05:11,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332309084 with entries=86, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332310604
2014-07-14 03:05:12,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:13,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44164 synced till here 44158
2014-07-14 03:05:13,702 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332310604 with entries=79, filesize=67.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332312728
2014-07-14 03:05:15,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:15,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44274 synced till here 44249
2014-07-14 03:05:15,895 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332312728 with entries=110, filesize=93.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332315602
2014-07-14 03:05:17,829 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:17,917 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44388 synced till here 44355
2014-07-14 03:05:18,135 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10838, memsize=324.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/185e1a9ea88e4c54b1c083646bbea3ba
2014-07-14 03:05:18,166 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/185e1a9ea88e4c54b1c083646bbea3ba as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/185e1a9ea88e4c54b1c083646bbea3ba
2014-07-14 03:05:18,215 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/185e1a9ea88e4c54b1c083646bbea3ba, entries=1182690, sequenceid=10838, filesize=84.3m
2014-07-14 03:05:18,231 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~861.5m/903323920, currentsize=464.2m/486749600 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 24365ms, sequenceid=10838, compaction requested=true
2014-07-14 03:05:18,232 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:86), split_queue=0, merge_queue=0
2014-07-14 03:05:18,232 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 885.5m
2014-07-14 03:05:18,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332315602 with entries=114, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332317829
2014-07-14 03:05:18,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332226337
2014-07-14 03:05:18,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332241530
2014-07-14 03:05:18,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332243699
2014-07-14 03:05:18,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332245407
2014-07-14 03:05:18,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332247513
2014-07-14 03:05:18,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332249153
2014-07-14 03:05:19,409 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:05:20,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:21,518 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44505 synced till here 44497
2014-07-14 03:05:21,665 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332317829 with entries=117, filesize=100.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332320322
2014-07-14 03:05:21,908 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:05:23,760 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:23,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44606 synced till here 44581
2014-07-14 03:05:23,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332320322 with entries=101, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332323761
2014-07-14 03:05:25,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:25,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44727 synced till here 44677
2014-07-14 03:05:26,122 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332323761 with entries=121, filesize=104.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332325503
2014-07-14 03:05:28,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:28,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44846 synced till here 44814
2014-07-14 03:05:28,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332325503 with entries=119, filesize=102.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332328260
2014-07-14 03:05:30,139 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:30,454 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332328260 with entries=112, filesize=95.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332330140
2014-07-14 03:05:31,480 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,485 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,516 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,523 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,573 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,618 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,663 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,705 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,845 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:31,912 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10939, memsize=439.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ba77e984183d4582937f9a841be7b2cd
2014-07-14 03:05:31,928 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ba77e984183d4582937f9a841be7b2cd as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ba77e984183d4582937f9a841be7b2cd
2014-07-14 03:05:31,941 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ba77e984183d4582937f9a841be7b2cd, entries=1598530, sequenceid=10939, filesize=113.9m
2014-07-14 03:05:31,942 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~752.3m/788873120, currentsize=535.5m/561478320 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 31721ms, sequenceid=10939, compaction requested=true
2014-07-14 03:05:31,942 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-14 03:05:31,942 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 97ms
2014-07-14 03:05:31,942 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,942 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 237ms
2014-07-14 03:05:31,942 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 957.0m
2014-07-14 03:05:31,942 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,945 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 282ms
2014-07-14 03:05:31,945 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,947 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 329ms
2014-07-14 03:05:31,947 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,947 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 374ms
2014-07-14 03:05:31,947 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,947 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 424ms
2014-07-14 03:05:31,948 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,948 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 432ms
2014-07-14 03:05:31,948 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,948 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 463ms
2014-07-14 03:05:31,948 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:31,949 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 469ms
2014-07-14 03:05:31,949 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:32,115 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:05:33,239 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:33,284 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45039 synced till here 45032
2014-07-14 03:05:33,372 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332330140 with entries=81, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332333239
2014-07-14 03:05:33,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332250847
2014-07-14 03:05:33,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332252470
2014-07-14 03:05:33,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332254699
2014-07-14 03:05:33,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332256334
2014-07-14 03:05:33,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332258249
2014-07-14 03:05:33,632 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:05:34,961 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:35,033 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45134 synced till here 45114
2014-07-14 03:05:35,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332333239 with entries=95, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332334962
2014-07-14 03:05:36,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:36,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45230 synced till here 45218
2014-07-14 03:05:36,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332334962 with entries=96, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332336708
2014-07-14 03:05:37,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:37,916 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45305 synced till here 45304
2014-07-14 03:05:37,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332336708 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332337893
2014-07-14 03:05:39,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:39,402 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45387 synced till here 45385
2014-07-14 03:05:39,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332337893 with entries=82, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332339272
2014-07-14 03:05:39,445 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/1b4d44d9ce2448d787d885ec8419ffab as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/1b4d44d9ce2448d787d885ec8419ffab
2014-07-14 03:05:39,503 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:05:39,515 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3636ba02ff5f4b04a71388acc2ba40d5, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3636ba02ff5f4b04a71388acc2ba40d5
2014-07-14 03:05:39,521 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/a572f3f58e4440d180fec70e488039d7, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/a572f3f58e4440d180fec70e488039d7
2014-07-14 03:05:39,526 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6c574588a5a04f098cc3e4697553a2f7, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6c574588a5a04f098cc3e4697553a2f7
2014-07-14 03:05:39,534 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/9a4d1f08029f4b039e87e5f746709f3a, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/9a4d1f08029f4b039e87e5f746709f3a
2014-07-14 03:05:39,536 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/38ea92f9e37a4c879ae98b544b012c42, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/38ea92f9e37a4c879ae98b544b012c42
2014-07-14 03:05:39,562 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e2a81427f41b4664a4007d094cc2ba88, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e2a81427f41b4664a4007d094cc2ba88
2014-07-14 03:05:39,566 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/343f0b3993d54f8e84e593c725960411, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/343f0b3993d54f8e84e593c725960411
2014-07-14 03:05:39,568 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/99038c7fc14c492f8b8e5126baffa108, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/99038c7fc14c492f8b8e5126baffa108
2014-07-14 03:05:39,571 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/96fe258015bc42cc9e1dca11eb762ea1, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/96fe258015bc42cc9e1dca11eb762ea1
2014-07-14 03:05:39,573 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f5d15748d5bd4be780a1b5bfccdcc72c, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f5d15748d5bd4be780a1b5bfccdcc72c
2014-07-14 03:05:39,573 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into 1b4d44d9ce2448d787d885ec8419ffab(size=749.8m), total size for store is 2.1g. This selection was in queue for 0sec, and took 2mins, 38sec to execute.
2014-07-14 03:05:39,573 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=10, fileSize=772.6m, priority=4, time=286088757325819; duration=2mins, 38sec
2014-07-14 03:05:39,573 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-14 03:05:39,574 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 16 store files, 0 compacting, 16 eligible, 20 blocking
2014-07-14 03:05:39,576 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 869419973 starting at candidate #1 after considering 84 permutations with 77 in ratio
2014-07-14 03:05:39,577 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating minor compaction
2014-07-14 03:05:39,577 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:05:39,578 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=829.1m
2014-07-14 03:05:39,578 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/622c243dba10405caadc972d113be024, keycount=88114, bloomtype=ROW, size=62.8m, encoding=NONE, seqNum=3554
2014-07-14 03:05:39,578 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/aabc1e48d7454c2a96ba3903ffa7eeb2, keycount=110628, bloomtype=ROW, size=78.8m, encoding=NONE, seqNum=3894
2014-07-14 03:05:39,578 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/b57b130742d7455caeda14f8e4b295d0, keycount=182795, bloomtype=ROW, size=130.2m, encoding=NONE, seqNum=4436
2014-07-14 03:05:39,578 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/512e8366de0749049f98ad3c0ec9b13f, keycount=83784, bloomtype=ROW, size=59.7m, encoding=NONE, seqNum=4928
2014-07-14 03:05:39,578 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cdea6eebefa74bffad5a8efedfff6f8d, keycount=97982, bloomtype=ROW, size=69.8m, encoding=NONE, seqNum=5402
2014-07-14 03:05:39,578 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/45f731b667e1494888d97dd00b4f4124, keycount=146500, bloomtype=ROW, size=104.3m, encoding=NONE, seqNum=5927
2014-07-14 03:05:39,579 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/8411fb05fa494445a7270baa6d5916de, keycount=109366, bloomtype=ROW, size=77.9m, encoding=NONE, seqNum=6483
2014-07-14 03:05:39,579 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/df124f1db16b4722bd1a28e72550a91c, keycount=95742, bloomtype=ROW, size=68.2m, encoding=NONE, seqNum=7044
2014-07-14 03:05:39,579 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6dad2e20f5d245208ed6c708b00398f0, keycount=109224, bloomtype=ROW, size=77.8m, encoding=NONE, seqNum=7597
2014-07-14 03:05:39,579 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4535ee5b109147b284a70138992fe1b8, keycount=139985, bloomtype=ROW, size=99.7m, encoding=NONE, seqNum=8125
2014-07-14 03:05:39,980 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:05:41,043 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:41,245 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,260 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,281 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,293 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,293 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,295 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,311 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,315 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,317 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,358 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,406 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,454 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,460 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332339272 with entries=97, filesize=82.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332341043
2014-07-14 03:05:41,501 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,647 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,774 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:41,951 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:42,218 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:42,505 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,066 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,312 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,599 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,635 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,672 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,716 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,755 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,797 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,834 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,893 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:43,918 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,644 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,655 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,663 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,693 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,723 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,751 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,790 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,824 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:44,856 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,480 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,518 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,558 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,599 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,636 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,671 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,707 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,743 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,787 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,824 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,869 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:45,900 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:05:46,246 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,260 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,281 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,294 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,294 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,295 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,312 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,315 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,317 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,359 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,407 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,455 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,501 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,647 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:46,775 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:46,952 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:47,219 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:47,506 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:48,792 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5037ms
2014-07-14 03:05:48,792 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5480ms
2014-07-14 03:05:48,793 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5193ms
2014-07-14 03:05:48,793 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5158ms
2014-07-14 03:05:48,793 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5077ms
2014-07-14 03:05:48,793 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5121ms
2014-07-14 03:05:48,793 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5728ms
2014-07-14 03:05:48,798 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:48,835 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:48,893 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:48,919 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:49,645 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:49,656 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:49,664 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:49,694 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:49,723 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:49,751 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:49,791 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:49,823 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11135, memsize=518.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/c39512310e004251843b48e9966ed083
2014-07-14 03:05:49,824 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:49,857 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:05:50,437 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/c39512310e004251843b48e9966ed083 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c39512310e004251843b48e9966ed083
2014-07-14 03:05:50,455 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c39512310e004251843b48e9966ed083, entries=1888790, sequenceid=11135, filesize=134.5m
2014-07-14 03:05:50,455 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~907.2m/951264560, currentsize=408.4m/428268560 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 32223ms, sequenceid=11135, compaction requested=true
2014-07-14 03:05:50,455 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-14 03:05:50,455 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5599ms
2014-07-14 03:05:50,455 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,455 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 882.2m
2014-07-14 03:05:50,455 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5631ms
2014-07-14 03:05:50,456 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,456 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5666ms
2014-07-14 03:05:50,456 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,459 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5708ms
2014-07-14 03:05:50,459 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,463 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5740ms
2014-07-14 03:05:50,463 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,463 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5770ms
2014-07-14 03:05:50,463 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,464 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5801ms
2014-07-14 03:05:50,464 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,464 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5809ms
2014-07-14 03:05:50,464 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,464 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5820ms
2014-07-14 03:05:50,464 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,464 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6546ms
2014-07-14 03:05:50,464 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,465 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6572ms
2014-07-14 03:05:50,465 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,465 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6631ms
2014-07-14 03:05:50,465 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,467 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6670ms
2014-07-14 03:05:50,467 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,469 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7404ms
2014-07-14 03:05:50,469 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,469 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6797ms
2014-07-14 03:05:50,469 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,469 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6753ms
2014-07-14 03:05:50,469 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,472 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6837ms
2014-07-14 03:05:50,472 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,472 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6873ms
2014-07-14 03:05:50,472 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,472 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7160ms
2014-07-14 03:05:50,472 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,472 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6717ms
2014-07-14 03:05:50,472 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,472 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7967ms
2014-07-14 03:05:50,473 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,473 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8255ms
2014-07-14 03:05:50,473 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,474 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8523ms
2014-07-14 03:05:50,474 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,479 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8705ms
2014-07-14 03:05:50,479 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,480 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:05:50,480 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,489 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8843ms
2014-07-14 03:05:50,489 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,489 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8988ms
2014-07-14 03:05:50,489 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,490 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9036ms
2014-07-14 03:05:50,490 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,490 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9084ms
2014-07-14 03:05:50,491 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,492 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9134ms
2014-07-14 03:05:50,492 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,493 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9175ms
2014-07-14 03:05:50,493 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,499 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9184ms
2014-07-14 03:05:50,499 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,499 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9188ms
2014-07-14 03:05:50,499 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,500 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9204ms
2014-07-14 03:05:50,500 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,500 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9207ms
2014-07-14 03:05:50,500 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,501 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9208ms
2014-07-14 03:05:50,501 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,501 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9220ms
2014-07-14 03:05:50,501 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,501 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9241ms
2014-07-14 03:05:50,501 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,502 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9257ms
2014-07-14 03:05:50,502 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,503 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4603ms
2014-07-14 03:05:50,503 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,503 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4634ms
2014-07-14 03:05:50,503 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,509 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4685ms
2014-07-14 03:05:50,509 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,509 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4722ms
2014-07-14 03:05:50,509 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,509 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4766ms
2014-07-14 03:05:50,509 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,510 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4802ms
2014-07-14 03:05:50,510 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,510 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4840ms
2014-07-14 03:05:50,510 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,510 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4874ms
2014-07-14 03:05:50,510 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,510 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4911ms
2014-07-14 03:05:50,510 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,510 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4952ms
2014-07-14 03:05:50,510 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,511 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4993ms
2014-07-14 03:05:50,511 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:05:50,635 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:05:50,642 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10155,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332340486,"queuetimems":1,"class":"HRegionServer","responsesize":15381,"method":"Multi"}
2014-07-14 03:05:51,043 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10477,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332340566,"queuetimems":0,"class":"HRegionServer","responsesize":16062,"method":"Multi"}
2014-07-14 03:05:51,043 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10512,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332340531,"queuetimems":0,"class":"HRegionServer","responsesize":15680,"method":"Multi"}
2014-07-14 03:05:51,043 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341040,"queuetimems":0,"class":"HRegionServer","responsesize":15716,"method":"Multi"}
2014-07-14 03:05:51,171 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:05:52,137 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:52,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45595 synced till here 45561
2014-07-14 03:05:52,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332341043 with entries=111, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332352138
2014-07-14 03:05:52,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332265474
2014-07-14 03:05:52,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332276138
2014-07-14 03:05:52,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332277810
2014-07-14 03:05:52,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332279266
2014-07-14 03:05:52,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332280228
2014-07-14 03:05:53,110 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10052,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332343057,"queuetimems":0,"class":"HRegionServer","responsesize":15756,"method":"Multi"}
2014-07-14 03:05:53,748 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:53,820 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45687 synced till here 45670
2014-07-14 03:05:53,897 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332343596,"queuetimems":1,"class":"HRegionServer","responsesize":16211,"method":"Multi"}
2014-07-14 03:05:53,897 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332342216,"queuetimems":0,"class":"HRegionServer","responsesize":15888,"method":"Multi"}
2014-07-14 03:05:53,990 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332352138 with entries=92, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332353748
2014-07-14 03:05:54,289 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12932,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341356,"queuetimems":0,"class":"HRegionServer","responsesize":15761,"method":"Multi"}
2014-07-14 03:05:54,289 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332343790,"queuetimems":1,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-14 03:05:54,290 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12790,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341499,"queuetimems":0,"class":"HRegionServer","responsesize":15844,"method":"Multi"}
2014-07-14 03:05:54,290 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332343916,"queuetimems":1,"class":"HRegionServer","responsesize":15924,"method":"Multi"}
2014-07-14 03:05:54,291 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12341,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341949,"queuetimems":0,"class":"HRegionServer","responsesize":15748,"method":"Multi"}
2014-07-14 03:05:54,291 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12646,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341644,"queuetimems":0,"class":"HRegionServer","responsesize":15859,"method":"Multi"}
2014-07-14 03:05:54,292 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10413,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332343878,"queuetimems":0,"class":"HRegionServer","responsesize":15716,"method":"Multi"}
2014-07-14 03:05:54,289 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11785,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332342503,"queuetimems":1,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 03:05:54,301 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332343832,"queuetimems":1,"class":"HRegionServer","responsesize":16131,"method":"Multi"}
2014-07-14 03:05:54,303 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13044,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341258,"queuetimems":0,"class":"HRegionServer","responsesize":15446,"method":"Multi"}
2014-07-14 03:05:54,304 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12994,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341309,"queuetimems":0,"class":"HRegionServer","responsesize":15924,"method":"Multi"}
2014-07-14 03:05:54,304 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341404,"queuetimems":0,"class":"HRegionServer","responsesize":15674,"method":"Multi"}
2014-07-14 03:05:54,422 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12650,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341772,"queuetimems":0,"class":"HRegionServer","responsesize":15407,"method":"Multi"}
2014-07-14 03:05:54,450 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12997,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332341452,"queuetimems":0,"class":"HRegionServer","responsesize":15749,"method":"Multi"}
2014-07-14 03:05:55,948 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:56,203 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45803 synced till here 45785
2014-07-14 03:05:56,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332353748 with entries=116, filesize=97.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332355948
2014-07-14 03:05:56,679 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11282, memsize=440.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/69dc568c29cb492ca88fa57573216f74
2014-07-14 03:05:56,721 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/69dc568c29cb492ca88fa57573216f74 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/69dc568c29cb492ca88fa57573216f74
2014-07-14 03:05:56,750 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/69dc568c29cb492ca88fa57573216f74, entries=1603450, sequenceid=11282, filesize=114.2m
2014-07-14 03:05:56,751 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~957.0m/1003479120, currentsize=294.5m/308789520 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 24809ms, sequenceid=11282, compaction requested=true
2014-07-14 03:05:56,751 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:88), split_queue=0, merge_queue=0
2014-07-14 03:05:56,751 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 882.2m
2014-07-14 03:05:57,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:57,469 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:05:57,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45890 synced till here 45880
2014-07-14 03:05:57,640 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332355948 with entries=87, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332357469
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332281604
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332282789
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332283983
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332286040
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332287306
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332288717
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332290046
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332291372
2014-07-14 03:05:57,641 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332292423
2014-07-14 03:05:58,045 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:05:59,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:05:59,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45985 synced till here 45972
2014-07-14 03:05:59,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332357469 with entries=95, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332359212
2014-07-14 03:06:00,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:00,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332359212 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332360613
2014-07-14 03:06:01,612 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:01,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46134 synced till here 46130
2014-07-14 03:06:01,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332360613 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332361612
2014-07-14 03:06:02,915 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:03,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46217 synced till here 46216
2014-07-14 03:06:03,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332361612 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332362916
2014-07-14 03:06:04,957 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:04,986 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46291 synced till here 46290
2014-07-14 03:06:05,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332362916 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332364957
2014-07-14 03:06:06,136 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:06,239 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46372 synced till here 46365
2014-07-14 03:06:06,593 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332364957 with entries=81, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332366137
2014-07-14 03:06:07,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:07,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46445 synced till here 46444
2014-07-14 03:06:07,689 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332366137 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332367637
2014-07-14 03:06:08,859 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:09,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46537 synced till here 46536
2014-07-14 03:06:09,166 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332367637 with entries=92, filesize=78.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332368860
2014-07-14 03:06:10,314 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11405, memsize=349.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/c8ce92bc0e9f4bff9b6b45071ff3ec66
2014-07-14 03:06:10,325 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/c8ce92bc0e9f4bff9b6b45071ff3ec66 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c8ce92bc0e9f4bff9b6b45071ff3ec66
2014-07-14 03:06:10,359 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c8ce92bc0e9f4bff9b6b45071ff3ec66, entries=1273840, sequenceid=11405, filesize=90.7m
2014-07-14 03:06:10,359 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~882.2m/925103680, currentsize=430.0m/450891360 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 19904ms, sequenceid=11405, compaction requested=true
2014-07-14 03:06:10,360 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:89), split_queue=0, merge_queue=0
2014-07-14 03:06:10,360 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 843.1m
2014-07-14 03:06:10,384 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:10,390 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:06:10,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332368860 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332370385
2014-07-14 03:06:10,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332293828
2014-07-14 03:06:10,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332294906
2014-07-14 03:06:10,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332296448
2014-07-14 03:06:11,401 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:06:11,509 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:11,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46685 synced till here 46684
2014-07-14 03:06:12,100 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332370385 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332371509
2014-07-14 03:06:13,621 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:13,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46783 synced till here 46760
2014-07-14 03:06:14,552 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11513, memsize=296.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ada31c1fcf6f48d88eb8a2d1535ade91
2014-07-14 03:06:14,565 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ada31c1fcf6f48d88eb8a2d1535ade91 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ada31c1fcf6f48d88eb8a2d1535ade91
2014-07-14 03:06:14,588 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ada31c1fcf6f48d88eb8a2d1535ade91, entries=1080320, sequenceid=11513, filesize=76.9m
2014-07-14 03:06:14,588 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~882.2m/925053920, currentsize=352.9m/370018560 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 17837ms, sequenceid=11513, compaction requested=true
2014-07-14 03:06:14,588 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:90), split_queue=0, merge_queue=0
2014-07-14 03:06:14,589 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 678.4m
2014-07-14 03:06:14,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332371509 with entries=98, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332373621
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332298149
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332301294
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332302976
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332304643
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332306048
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332307428
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332309084
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332310604
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332312728
2014-07-14 03:06:14,594 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332315602
2014-07-14 03:06:14,762 DEBUG [RpcServer.handler=30,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:06:15,352 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:06:16,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:16,133 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46873 synced till here 46863
2014-07-14 03:06:16,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332373621 with entries=90, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332376108
2014-07-14 03:06:17,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:17,669 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46958 synced till here 46948
2014-07-14 03:06:17,745 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332376108 with entries=85, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332377651
2014-07-14 03:06:18,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:18,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47041 synced till here 47029
2014-07-14 03:06:19,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332377651 with entries=83, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332378374
2014-07-14 03:06:20,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:21,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47155 synced till here 47122
2014-07-14 03:06:21,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332378374 with entries=114, filesize=98.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332380998
2014-07-14 03:06:23,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:23,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47255 synced till here 47235
2014-07-14 03:06:23,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332380998 with entries=100, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332383146
2014-07-14 03:06:24,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:25,080 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47339 synced till here 47329
2014-07-14 03:06:25,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332383146 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332385000
2014-07-14 03:06:26,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:26,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47420 synced till here 47415
2014-07-14 03:06:26,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332385000 with entries=81, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332386526
2014-07-14 03:06:27,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:28,259 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47525 synced till here 47524
2014-07-14 03:06:28,356 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332386526 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332387848
2014-07-14 03:06:29,767 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:30,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47627 synced till here 47626
2014-07-14 03:06:30,501 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332387848 with entries=102, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332389768
2014-07-14 03:06:31,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:31,612 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332389768 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332391391
2014-07-14 03:06:32,646 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:32,680 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47787 synced till here 47782
2014-07-14 03:06:32,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332391391 with entries=79, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332392646
2014-07-14 03:06:33,496 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,502 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,509 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,509 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,509 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,520 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,541 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,542 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,553 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11685, memsize=381.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/5fe96c37d07d4bc6a7d78ba9688c8e27
2014-07-14 03:06:33,564 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,564 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/5fe96c37d07d4bc6a7d78ba9688c8e27 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/5fe96c37d07d4bc6a7d78ba9688c8e27
2014-07-14 03:06:33,564 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:33,574 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/5fe96c37d07d4bc6a7d78ba9688c8e27, entries=1389310, sequenceid=11685, filesize=98.9m
2014-07-14 03:06:33,574 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~846.2m/887277360, currentsize=475.3m/498440240 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 23214ms, sequenceid=11685, compaction requested=true
2014-07-14 03:06:33,574 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:91), split_queue=0, merge_queue=0
2014-07-14 03:06:33,575 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11ms
2014-07-14 03:06:33,575 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,575 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11ms
2014-07-14 03:06:33,575 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 903.5m
2014-07-14 03:06:33,575 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,575 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 33ms
2014-07-14 03:06:33,575 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,575 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 34ms
2014-07-14 03:06:33,575 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,575 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 55ms
2014-07-14 03:06:33,575 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,576 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 67ms
2014-07-14 03:06:33,576 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,576 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 67ms
2014-07-14 03:06:33,576 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,576 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 67ms
2014-07-14 03:06:33,576 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,576 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 74ms
2014-07-14 03:06:33,576 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,580 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 84ms
2014-07-14 03:06:33,580 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:33,656 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:06:33,915 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:34,516 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47883 synced till here 47878
2014-07-14 03:06:34,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332392646 with entries=96, filesize=82.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332393917
2014-07-14 03:06:34,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332317829
2014-07-14 03:06:34,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332320322
2014-07-14 03:06:34,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332323761
2014-07-14 03:06:34,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332325503
2014-07-14 03:06:34,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332328260
2014-07-14 03:06:34,687 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:06:35,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:35,999 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47960 synced till here 47958
2014-07-14 03:06:36,015 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332393917 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332395693
2014-07-14 03:06:36,644 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11726, memsize=404.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/c75e87a89cdc40c7a92ee4d26b1389ca
2014-07-14 03:06:36,659 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/c75e87a89cdc40c7a92ee4d26b1389ca as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c75e87a89cdc40c7a92ee4d26b1389ca
2014-07-14 03:06:36,668 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c75e87a89cdc40c7a92ee4d26b1389ca, entries=1473030, sequenceid=11726, filesize=104.9m
2014-07-14 03:06:36,669 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~686.2m/719546880, currentsize=475.9m/499009280 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 22080ms, sequenceid=11726, compaction requested=true
2014-07-14 03:06:36,669 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-14 03:06:36,669 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 823.0m
2014-07-14 03:06:36,682 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:06:36,842 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:37,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48044 synced till here 48043
2014-07-14 03:06:37,300 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332395693 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332396842
2014-07-14 03:06:37,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332330140
2014-07-14 03:06:37,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332333239
2014-07-14 03:06:37,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332334962
2014-07-14 03:06:37,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332336708
2014-07-14 03:06:37,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332337893
2014-07-14 03:06:37,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332339272
2014-07-14 03:06:37,617 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:06:38,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:38,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332396842 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332398159
2014-07-14 03:06:39,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:39,381 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332398159 with entries=72, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332399352
2014-07-14 03:06:40,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:40,408 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48266 synced till here 48261
2014-07-14 03:06:40,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332399352 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332400386
2014-07-14 03:06:41,553 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:41,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48353 synced till here 48352
2014-07-14 03:06:41,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332400386 with entries=87, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332401553
2014-07-14 03:06:43,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:43,099 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48433 synced till here 48424
2014-07-14 03:06:43,291 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332401553 with entries=80, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332403047
2014-07-14 03:06:44,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:45,730 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48546 synced till here 48540
2014-07-14 03:06:45,797 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332403047 with entries=113, filesize=96.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332404778
2014-07-14 03:06:46,982 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:47,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48622 synced till here 48619
2014-07-14 03:06:47,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332404778 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332406983
2014-07-14 03:06:48,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:48,422 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48705 synced till here 48696
2014-07-14 03:06:49,388 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332406983 with entries=83, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332408254
2014-07-14 03:06:50,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:50,896 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48786 synced till here 48779
2014-07-14 03:06:51,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332408254 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332410866
2014-07-14 03:06:51,172 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,188 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,189 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,192 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,202 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,214 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,222 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,225 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,236 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,243 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,275 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,279 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,279 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,279 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,302 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,302 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,303 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,305 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,337 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,371 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,403 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,439 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,472 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,505 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,538 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,569 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,604 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,636 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,668 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,699 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,732 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,765 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,798 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,831 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,863 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,897 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,927 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,959 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:51,990 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:52,025 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:52,057 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,431 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,462 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,534 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,571 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,608 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,641 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,690 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,733 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:53,769 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:06:56,172 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,188 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,189 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,192 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,202 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,214 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,223 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:06:56,226 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,237 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,243 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,276 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,279 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,279 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,279 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,302 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,302 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,303 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,305 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,338 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,371 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,403 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,439 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,472 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,506 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,538 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,569 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,604 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,636 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,668 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,700 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:06:56,719 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11990, memsize=452.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ecad64f904434c04afadee4cc4000e24
2014-07-14 03:06:56,733 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,735 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ecad64f904434c04afadee4cc4000e24 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ecad64f904434c04afadee4cc4000e24
2014-07-14 03:06:56,751 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ecad64f904434c04afadee4cc4000e24, entries=1648560, sequenceid=11990, filesize=117.3m
2014-07-14 03:06:56,752 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~903.5m/947372640, currentsize=388.8m/407733760 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 23177ms, sequenceid=11990, compaction requested=true
2014-07-14 03:06:56,752 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-14 03:06:56,752 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5020ms
2014-07-14 03:06:56,752 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,752 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5053ms
2014-07-14 03:06:56,752 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 854.4m
2014-07-14 03:06:56,752 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,753 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5085ms
2014-07-14 03:06:56,753 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,753 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5118ms
2014-07-14 03:06:56,753 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,753 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5150ms
2014-07-14 03:06:56,753 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,754 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5184ms
2014-07-14 03:06:56,754 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,754 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5217ms
2014-07-14 03:06:56,754 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,761 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5256ms
2014-07-14 03:06:56,761 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,761 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5289ms
2014-07-14 03:06:56,761 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,761 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5322ms
2014-07-14 03:06:56,761 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,761 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5358ms
2014-07-14 03:06:56,761 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,765 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5394ms
2014-07-14 03:06:56,765 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,765 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5428ms
2014-07-14 03:06:56,765 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,766 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:06:56,766 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,768 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5463ms
2014-07-14 03:06:56,769 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,773 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5470ms
2014-07-14 03:06:56,773 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,773 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5471ms
2014-07-14 03:06:56,773 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,773 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5471ms
2014-07-14 03:06:56,773 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,775 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5496ms
2014-07-14 03:06:56,775 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,775 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5496ms
2014-07-14 03:06:56,775 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,775 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5497ms
2014-07-14 03:06:56,776 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,776 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5501ms
2014-07-14 03:06:56,776 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,777 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5533ms
2014-07-14 03:06:56,777 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,777 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5541ms
2014-07-14 03:06:56,777 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,777 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5552ms
2014-07-14 03:06:56,777 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,778 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5556ms
2014-07-14 03:06:56,778 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,778 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5564ms
2014-07-14 03:06:56,778 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:56,778 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5576ms
2014-07-14 03:06:56,778 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,439 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5381ms
2014-07-14 03:06:57,439 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,440 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5609ms
2014-07-14 03:06:57,469 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,469 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6277ms
2014-07-14 03:06:57,469 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,474 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6285ms
2014-07-14 03:06:57,474 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,474 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6286ms
2014-07-14 03:06:57,474 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,474 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6302ms
2014-07-14 03:06:57,474 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,480 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3710ms
2014-07-14 03:06:57,480 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,481 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3747ms
2014-07-14 03:06:57,481 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,482 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3791ms
2014-07-14 03:06:57,482 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,482 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3841ms
2014-07-14 03:06:57,482 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,483 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3875ms
2014-07-14 03:06:57,483 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,484 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3913ms
2014-07-14 03:06:57,484 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,485 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3951ms
2014-07-14 03:06:57,486 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,486 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4024ms
2014-07-14 03:06:57,487 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,487 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4056ms
2014-07-14 03:06:57,488 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,488 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5463ms
2014-07-14 03:06:57,488 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,488 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5498ms
2014-07-14 03:06:57,488 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,489 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5529ms
2014-07-14 03:06:57,489 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,489 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5562ms
2014-07-14 03:06:57,489 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,491 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5594ms
2014-07-14 03:06:57,491 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,492 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5629ms
2014-07-14 03:06:57,492 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,492 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5694ms
2014-07-14 03:06:57,492 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:06:57,831 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:06:58,109 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:06:58,208 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48887 synced till here 48878
2014-07-14 03:06:58,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332410866 with entries=101, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332418109
2014-07-14 03:06:58,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332341043
2014-07-14 03:06:58,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332352138
2014-07-14 03:06:58,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332353748
2014-07-14 03:06:58,340 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:07:00,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:00,400 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49012 synced till here 48992
2014-07-14 03:07:01,389 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332418109 with entries=125, filesize=103.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332420278
2014-07-14 03:07:01,825 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411234,"queuetimems":0,"class":"HRegionServer","responsesize":16085,"method":"Multi"}
2014-07-14 03:07:01,845 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10444,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411400,"queuetimems":0,"class":"HRegionServer","responsesize":15473,"method":"Multi"}
2014-07-14 03:07:01,847 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411191,"queuetimems":0,"class":"HRegionServer","responsesize":15492,"method":"Multi"}
2014-07-14 03:07:02,058 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10262,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411795,"queuetimems":0,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 03:07:02,062 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10758,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411303,"queuetimems":0,"class":"HRegionServer","responsesize":15543,"method":"Multi"}
2014-07-14 03:07:02,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:02,443 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49117 synced till here 49094
2014-07-14 03:07:03,326 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11498,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411828,"queuetimems":0,"class":"HRegionServer","responsesize":15590,"method":"Multi"}
2014-07-14 03:07:03,326 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12054,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411272,"queuetimems":0,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 03:07:03,326 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11401,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332411925,"queuetimems":0,"class":"HRegionServer","responsesize":15473,"method":"Multi"}
2014-07-14 03:07:03,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332420278 with entries=105, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332422357
2014-07-14 03:07:05,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:05,784 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49242 synced till here 49240
2014-07-14 03:07:05,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332422357 with entries=125, filesize=107.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332425526
2014-07-14 03:07:06,115 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12047, memsize=516.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1ed89338438041d4bbab49645bee8449
2014-07-14 03:07:06,132 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/1ed89338438041d4bbab49645bee8449 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1ed89338438041d4bbab49645bee8449
2014-07-14 03:07:06,147 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1ed89338438041d4bbab49645bee8449, entries=1880810, sequenceid=12047, filesize=133.8m
2014-07-14 03:07:06,148 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~827.9m/868065680, currentsize=490.9m/514706800 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 29479ms, sequenceid=12047, compaction requested=true
2014-07-14 03:07:06,148 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:94), split_queue=0, merge_queue=0
2014-07-14 03:07:06,148 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 911.8m
2014-07-14 03:07:06,183 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:07:07,588 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:07,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49356 synced till here 49352
2014-07-14 03:07:07,851 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332425526 with entries=114, filesize=97.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332427588
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332355948
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332357469
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332359212
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332360613
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332361612
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332362916
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332364957
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332366137
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332367637
2014-07-14 03:07:07,851 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332368860
2014-07-14 03:07:09,070 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:07:09,491 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:09,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49498 synced till here 49468
2014-07-14 03:07:10,118 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332427588 with entries=142, filesize=120.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332429492
2014-07-14 03:07:11,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:11,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49576 synced till here 49571
2014-07-14 03:07:11,690 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332429492 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332431593
2014-07-14 03:07:12,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:12,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49655 synced till here 49647
2014-07-14 03:07:12,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332431593 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332432861
2014-07-14 03:07:14,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:14,729 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49740 synced till here 49736
2014-07-14 03:07:14,784 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332432861 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332434101
2014-07-14 03:07:16,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:16,316 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49818 synced till here 49812
2014-07-14 03:07:16,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332434101 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332436292
2014-07-14 03:07:17,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:17,835 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49893 synced till here 49890
2014-07-14 03:07:17,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332436292 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332437809
2014-07-14 03:07:18,277 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,280 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,300 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,306 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,316 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,662 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,663 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,683 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,689 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,694 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,725 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,756 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,787 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,819 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,850 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,883 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,915 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,961 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:18,999 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,036 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,072 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,108 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,147 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,185 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,224 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,261 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,302 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,347 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:19,380 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,499 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,537 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,574 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,611 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,655 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,702 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,739 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,792 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,842 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,894 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,947 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:20,991 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,030 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,064 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,103 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,142 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,183 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,230 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,270 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,314 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:21,351 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:23,277 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,280 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,300 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,306 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,316 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,663 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,663 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:23,683 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,690 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,694 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,726 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,757 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,788 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,819 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:23,851 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,883 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,915 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:23,962 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:24,000 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:24,037 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:24,073 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:24,109 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:24,148 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:24,185 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:24,225 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:24,262 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:24,302 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:24,347 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:24,381 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:25,500 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,538 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:25,575 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,611 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,656 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,702 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,740 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:25,793 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:25,843 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:25,895 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,947 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:25,991 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:26,031 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:26,065 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:26,103 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:26,142 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:26,184 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:26,231 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:07:26,271 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:07:26,962 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5612ms
2014-07-14 03:07:26,963 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5648ms
2014-07-14 03:07:27,232 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12234, memsize=471.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2c896d5e8b204d4cbc0f756b985ed184
2014-07-14 03:07:27,251 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2c896d5e8b204d4cbc0f756b985ed184 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2c896d5e8b204d4cbc0f756b985ed184
2014-07-14 03:07:27,267 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2c896d5e8b204d4cbc0f756b985ed184, entries=1716570, sequenceid=12234, filesize=122.2m
2014-07-14 03:07:27,267 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~854.4m/895930960, currentsize=435.3m/456440800 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 30515ms, sequenceid=12234, compaction requested=true
2014-07-14 03:07:27,268 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:95), split_queue=0, merge_queue=0
2014-07-14 03:07:27,268 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5954ms
2014-07-14 03:07:27,268 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,268 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 815.5m
2014-07-14 03:07:27,268 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5918ms
2014-07-14 03:07:27,268 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,268 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5998ms
2014-07-14 03:07:27,269 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,269 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6039ms
2014-07-14 03:07:27,269 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,269 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6086ms
2014-07-14 03:07:27,269 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,269 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6127ms
2014-07-14 03:07:27,269 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,269 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6166ms
2014-07-14 03:07:27,270 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,270 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6206ms
2014-07-14 03:07:27,270 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,270 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6240ms
2014-07-14 03:07:27,270 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,271 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6281ms
2014-07-14 03:07:27,271 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,273 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6326ms
2014-07-14 03:07:27,273 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,274 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6380ms
2014-07-14 03:07:27,274 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,275 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6433ms
2014-07-14 03:07:27,275 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,275 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6483ms
2014-07-14 03:07:27,275 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,277 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6538ms
2014-07-14 03:07:27,277 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,277 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6575ms
2014-07-14 03:07:27,277 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,289 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6634ms
2014-07-14 03:07:27,289 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,289 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6678ms
2014-07-14 03:07:27,289 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,289 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6715ms
2014-07-14 03:07:27,289 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,289 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6752ms
2014-07-14 03:07:27,290 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,291 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6792ms
2014-07-14 03:07:27,291 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,293 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7913ms
2014-07-14 03:07:27,293 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,293 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7946ms
2014-07-14 03:07:27,293 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,293 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7991ms
2014-07-14 03:07:27,293 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,294 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8033ms
2014-07-14 03:07:27,294 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,294 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8070ms
2014-07-14 03:07:27,294 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,295 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8110ms
2014-07-14 03:07:27,295 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,295 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8148ms
2014-07-14 03:07:27,295 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,297 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8189ms
2014-07-14 03:07:27,297 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,297 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8225ms
2014-07-14 03:07:27,297 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,297 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8261ms
2014-07-14 03:07:27,297 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,298 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8298ms
2014-07-14 03:07:27,298 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,298 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8337ms
2014-07-14 03:07:27,298 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,298 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8383ms
2014-07-14 03:07:27,298 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,301 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8418ms
2014-07-14 03:07:27,301 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,305 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8455ms
2014-07-14 03:07:27,305 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,305 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8487ms
2014-07-14 03:07:27,305 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,305 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8518ms
2014-07-14 03:07:27,305 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,305 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8549ms
2014-07-14 03:07:27,306 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,306 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8581ms
2014-07-14 03:07:27,306 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,306 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8612ms
2014-07-14 03:07:27,306 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,307 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8617ms
2014-07-14 03:07:27,307 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,317 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8634ms
2014-07-14 03:07:27,317 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,325 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8663ms
2014-07-14 03:07:27,326 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,326 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8664ms
2014-07-14 03:07:27,326 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,327 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9010ms
2014-07-14 03:07:27,327 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,327 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9021ms
2014-07-14 03:07:27,333 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,333 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9033ms
2014-07-14 03:07:27,333 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,334 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9053ms
2014-07-14 03:07:27,334 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,335 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9057ms
2014-07-14 03:07:27,335 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:27,492 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:07:27,947 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:28,021 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49995 synced till here 49980
2014-07-14 03:07:28,158 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332437809 with entries=102, filesize=86.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332447947
2014-07-14 03:07:28,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332370385
2014-07-14 03:07:28,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332371509
2014-07-14 03:07:28,207 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:07:28,290 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438268,"queuetimems":0,"class":"HRegionServer","responsesize":15327,"method":"Multi"}
2014-07-14 03:07:28,290 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10088,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438202,"queuetimems":0,"class":"HRegionServer","responsesize":15521,"method":"Multi"}
2014-07-14 03:07:28,298 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438238,"queuetimems":0,"class":"HRegionServer","responsesize":16034,"method":"Multi"}
2014-07-14 03:07:29,527 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:29,562 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50088 synced till here 50069
2014-07-14 03:07:29,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332447947 with entries=93, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332449528
2014-07-14 03:07:30,038 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11734,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438304,"queuetimems":1,"class":"HRegionServer","responsesize":15600,"method":"Multi"}
2014-07-14 03:07:30,038 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11221,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438817,"queuetimems":1,"class":"HRegionServer","responsesize":15928,"method":"Multi"}
2014-07-14 03:07:30,931 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10240,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440690,"queuetimems":1,"class":"HRegionServer","responsesize":15775,"method":"Multi"}
2014-07-14 03:07:30,931 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10200,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440731,"queuetimems":0,"class":"HRegionServer","responsesize":15670,"method":"Multi"}
2014-07-14 03:07:30,933 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11635,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439298,"queuetimems":0,"class":"HRegionServer","responsesize":15494,"method":"Multi"}
2014-07-14 03:07:30,934 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440607,"queuetimems":1,"class":"HRegionServer","responsesize":15327,"method":"Multi"}
2014-07-14 03:07:30,945 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11876,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439069,"queuetimems":1,"class":"HRegionServer","responsesize":15552,"method":"Multi"}
2014-07-14 03:07:30,946 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11764,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439182,"queuetimems":1,"class":"HRegionServer","responsesize":15890,"method":"Multi"}
2014-07-14 03:07:30,947 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11950,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438996,"queuetimems":0,"class":"HRegionServer","responsesize":16115,"method":"Multi"}
2014-07-14 03:07:30,947 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12034,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438913,"queuetimems":1,"class":"HRegionServer","responsesize":15958,"method":"Multi"}
2014-07-14 03:07:30,948 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440888,"queuetimems":1,"class":"HRegionServer","responsesize":15816,"method":"Multi"}
2014-07-14 03:07:30,945 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12160,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438785,"queuetimems":0,"class":"HRegionServer","responsesize":16110,"method":"Multi"}
2014-07-14 03:07:30,948 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10416,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440532,"queuetimems":0,"class":"HRegionServer","responsesize":15996,"method":"Multi"}
2014-07-14 03:07:30,949 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439340,"queuetimems":0,"class":"HRegionServer","responsesize":15744,"method":"Multi"}
2014-07-14 03:07:30,949 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440652,"queuetimems":1,"class":"HRegionServer","responsesize":15870,"method":"Multi"}
2014-07-14 03:07:30,948 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12067,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438881,"queuetimems":1,"class":"HRegionServer","responsesize":15819,"method":"Multi"}
2014-07-14 03:07:30,949 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11844,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439105,"queuetimems":0,"class":"HRegionServer","responsesize":15656,"method":"Multi"}
2014-07-14 03:07:30,950 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438723,"queuetimems":0,"class":"HRegionServer","responsesize":16257,"method":"Multi"}
2014-07-14 03:07:30,947 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11914,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439032,"queuetimems":0,"class":"HRegionServer","responsesize":15373,"method":"Multi"}
2014-07-14 03:07:30,946 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440788,"queuetimems":1,"class":"HRegionServer","responsesize":15934,"method":"Multi"}
2014-07-14 03:07:31,188 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10696,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440492,"queuetimems":1,"class":"HRegionServer","responsesize":16257,"method":"Multi"}
2014-07-14 03:07:31,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:31,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50193 synced till here 50171
2014-07-14 03:07:31,561 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12901,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438660,"queuetimems":0,"class":"HRegionServer","responsesize":15870,"method":"Multi"}
2014-07-14 03:07:31,562 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10723,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440838,"queuetimems":0,"class":"HRegionServer","responsesize":16110,"method":"Multi"}
2014-07-14 03:07:31,562 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12870,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438692,"queuetimems":1,"class":"HRegionServer","responsesize":15320,"method":"Multi"}
2014-07-14 03:07:31,561 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12303,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439258,"queuetimems":1,"class":"HRegionServer","responsesize":15576,"method":"Multi"}
2014-07-14 03:07:31,570 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10628,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440941,"queuetimems":0,"class":"HRegionServer","responsesize":15958,"method":"Multi"}
2014-07-14 03:07:31,571 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10548,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332441022,"queuetimems":0,"class":"HRegionServer","responsesize":15552,"method":"Multi"}
2014-07-14 03:07:31,572 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11001,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332440570,"queuetimems":0,"class":"HRegionServer","responsesize":15600,"method":"Multi"}
2014-07-14 03:07:31,575 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439143,"queuetimems":1,"class":"HRegionServer","responsesize":15670,"method":"Multi"}
2014-07-14 03:07:31,577 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438754,"queuetimems":1,"class":"HRegionServer","responsesize":15897,"method":"Multi"}
2014-07-14 03:07:31,578 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12200,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439378,"queuetimems":1,"class":"HRegionServer","responsesize":15816,"method":"Multi"}
2014-07-14 03:07:31,561 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438958,"queuetimems":0,"class":"HRegionServer","responsesize":15848,"method":"Multi"}
2014-07-14 03:07:31,561 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10339,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332441222,"queuetimems":0,"class":"HRegionServer","responsesize":15494,"method":"Multi"}
2014-07-14 03:07:31,584 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12362,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332439221,"queuetimems":0,"class":"HRegionServer","responsesize":15775,"method":"Multi"}
2014-07-14 03:07:31,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332449528 with entries=105, filesize=89.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332451391
2014-07-14 03:07:33,082 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14234,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332438848,"queuetimems":0,"class":"HRegionServer","responsesize":15783,"method":"Multi"}
2014-07-14 03:07:33,923 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:33,937 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50299 synced till here 50279
2014-07-14 03:07:34,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332451391 with entries=106, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332453924
2014-07-14 03:07:35,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:36,051 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50410 synced till here 50385
2014-07-14 03:07:37,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332453924 with entries=111, filesize=95.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332455980
2014-07-14 03:07:37,575 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12344, memsize=447.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/81ddf15644ec4b809644ee3d6e170149
2014-07-14 03:07:37,599 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/81ddf15644ec4b809644ee3d6e170149 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/81ddf15644ec4b809644ee3d6e170149
2014-07-14 03:07:37,619 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/81ddf15644ec4b809644ee3d6e170149, entries=1630900, sequenceid=12344, filesize=116.1m
2014-07-14 03:07:37,620 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~956.5m/1002991680, currentsize=431.1m/452011520 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 31471ms, sequenceid=12344, compaction requested=true
2014-07-14 03:07:37,620 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:96), split_queue=0, merge_queue=0
2014-07-14 03:07:37,620 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 957.0m
2014-07-14 03:07:37,749 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:07:37,910 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:38,015 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50517 synced till here 50484
2014-07-14 03:07:38,902 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332455980 with entries=107, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332457911
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332373621
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332376108
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332377651
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332378374
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332380998
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332383146
2014-07-14 03:07:38,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332385000
2014-07-14 03:07:38,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332386526
2014-07-14 03:07:38,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332387848
2014-07-14 03:07:38,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332389768
2014-07-14 03:07:38,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332391391
2014-07-14 03:07:39,369 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:07:39,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:39,883 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50620 synced till here 50595
2014-07-14 03:07:40,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332457911 with entries=103, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332459813
2014-07-14 03:07:41,547 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:41,615 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50708 synced till here 50690
2014-07-14 03:07:41,722 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332459813 with entries=88, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332461548
2014-07-14 03:07:43,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:43,509 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50794 synced till here 50793
2014-07-14 03:07:43,523 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332461548 with entries=86, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332463212
2014-07-14 03:07:44,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:45,012 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332463212 with entries=72, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332464982
2014-07-14 03:07:46,287 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:46,318 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50945 synced till here 50937
2014-07-14 03:07:46,387 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332464982 with entries=79, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332466287
2014-07-14 03:07:47,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:47,701 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51028 synced till here 51019
2014-07-14 03:07:47,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332466287 with entries=83, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332467541
2014-07-14 03:07:49,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:49,055 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,059 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,059 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,060 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,061 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,075 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51107 synced till here 51101
2014-07-14 03:07:49,086 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,119 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,144 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,144 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,149 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332467541 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332469042
2014-07-14 03:07:49,163 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,187 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,210 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,832 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,885 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,929 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:49,969 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,182 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,201 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,231 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,262 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,297 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,330 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,362 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,391 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,421 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,453 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,483 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,515 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,548 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,579 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,608 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,637 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,666 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,694 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:07:51,761 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12518, memsize=378.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ffb40c90d2074205a327fd19f31d2d68
2014-07-14 03:07:51,773 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ffb40c90d2074205a327fd19f31d2d68 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ffb40c90d2074205a327fd19f31d2d68
2014-07-14 03:07:51,787 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ffb40c90d2074205a327fd19f31d2d68, entries=1376980, sequenceid=12518, filesize=98.1m
2014-07-14 03:07:51,787 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~815.5m/855115840, currentsize=452.5m/474481600 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 24519ms, sequenceid=12518, compaction requested=true
2014-07-14 03:07:51,787 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:97), split_queue=0, merge_queue=0
2014-07-14 03:07:51,788 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 94ms
2014-07-14 03:07:51,788 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,788 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 893.7m
2014-07-14 03:07:51,788 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 122ms
2014-07-14 03:07:51,788 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,788 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 152ms
2014-07-14 03:07:51,788 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,789 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 181ms
2014-07-14 03:07:51,789 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,789 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 210ms
2014-07-14 03:07:51,789 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,789 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 241ms
2014-07-14 03:07:51,789 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,793 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 278ms
2014-07-14 03:07:51,793 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,793 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 310ms
2014-07-14 03:07:51,793 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,793 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 340ms
2014-07-14 03:07:51,793 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,793 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 372ms
2014-07-14 03:07:51,794 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,794 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 403ms
2014-07-14 03:07:51,794 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,797 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 435ms
2014-07-14 03:07:51,797 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,797 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 467ms
2014-07-14 03:07:51,797 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,797 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 500ms
2014-07-14 03:07:51,797 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,805 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 543ms
2014-07-14 03:07:51,805 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,807 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 576ms
2014-07-14 03:07:51,807 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,807 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 606ms
2014-07-14 03:07:51,807 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,807 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 625ms
2014-07-14 03:07:51,807 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,808 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1839ms
2014-07-14 03:07:51,808 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,808 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1879ms
2014-07-14 03:07:51,808 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,808 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1923ms
2014-07-14 03:07:51,808 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,809 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1977ms
2014-07-14 03:07:51,809 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,809 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2599ms
2014-07-14 03:07:51,809 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,809 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2623ms
2014-07-14 03:07:51,809 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,814 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2651ms
2014-07-14 03:07:51,814 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,814 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2670ms
2014-07-14 03:07:51,814 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,815 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2670ms
2014-07-14 03:07:51,815 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,817 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2698ms
2014-07-14 03:07:51,817 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,817 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2731ms
2014-07-14 03:07:51,817 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,817 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2756ms
2014-07-14 03:07:51,817 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,817 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2757ms
2014-07-14 03:07:51,817 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,829 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2770ms
2014-07-14 03:07:51,829 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,829 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2770ms
2014-07-14 03:07:51,829 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:51,833 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2778ms
2014-07-14 03:07:51,833 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:07:52,101 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:07:52,539 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:07:53,387 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:53,425 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51199 synced till here 51181
2014-07-14 03:07:53,688 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332469042 with entries=92, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332473388
2014-07-14 03:07:53,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332392646
2014-07-14 03:07:53,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332393917
2014-07-14 03:07:54,431 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:54,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51285 synced till here 51275
2014-07-14 03:07:55,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332473388 with entries=86, filesize=73.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332474432
2014-07-14 03:07:55,911 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:55,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51365 synced till here 51357
2014-07-14 03:07:56,458 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332474432 with entries=80, filesize=68.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332475912
2014-07-14 03:07:57,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:57,514 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51438 synced till here 51436
2014-07-14 03:07:57,545 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332475912 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332477496
2014-07-14 03:07:58,549 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12678, memsize=336.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f8c771e9ff7743a38f7c65a324903301
2014-07-14 03:07:58,566 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f8c771e9ff7743a38f7c65a324903301 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f8c771e9ff7743a38f7c65a324903301
2014-07-14 03:07:58,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:07:58,723 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f8c771e9ff7743a38f7c65a324903301, entries=1226090, sequenceid=12678, filesize=87.3m
2014-07-14 03:07:58,724 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~974.0m/1021260800, currentsize=373.9m/392012000 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 21104ms, sequenceid=12678, compaction requested=true
2014-07-14 03:07:58,724 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:98), split_queue=0, merge_queue=0
2014-07-14 03:07:58,724 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 873.3m
2014-07-14 03:07:58,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51516 synced till here 51511
2014-07-14 03:07:58,811 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:07:58,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332477496 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332478671
2014-07-14 03:07:58,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332395693
2014-07-14 03:07:58,824 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332396842
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332398159
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332399352
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332400386
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332401553
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332403047
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332404778
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332406983
2014-07-14 03:07:58,825 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332408254
2014-07-14 03:08:00,109 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:08:00,236 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:00,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51605 synced till here 51596
2014-07-14 03:08:00,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332478671 with entries=89, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332480237
2014-07-14 03:08:01,886 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:01,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51684 synced till here 51679
2014-07-14 03:08:01,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332480237 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332481887
2014-07-14 03:08:03,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:03,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51770 synced till here 51765
2014-07-14 03:08:03,511 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332481887 with entries=86, filesize=73.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332483189
2014-07-14 03:08:04,765 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:04,784 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51845 synced till here 51841
2014-07-14 03:08:04,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332483189 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332484765
2014-07-14 03:08:06,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:06,429 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51925 synced till here 51918
2014-07-14 03:08:06,544 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332484765 with entries=80, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332486395
2014-07-14 03:08:08,001 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:08,040 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52010 synced till here 51998
2014-07-14 03:08:08,130 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332486395 with entries=85, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332488001
2014-07-14 03:08:09,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:09,525 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52094 synced till here 52093
2014-07-14 03:08:09,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332488001 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332489387
2014-07-14 03:08:10,694 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12814, memsize=305.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2e40f34af51b450aa2cad025ade6dd25
2014-07-14 03:08:10,710 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2e40f34af51b450aa2cad025ade6dd25 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2e40f34af51b450aa2cad025ade6dd25
2014-07-14 03:08:10,796 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2e40f34af51b450aa2cad025ade6dd25, entries=1111680, sequenceid=12814, filesize=79.1m
2014-07-14 03:08:10,797 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~893.7m/937152000, currentsize=410.3m/430190320 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 19009ms, sequenceid=12814, compaction requested=true
2014-07-14 03:08:10,798 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-14 03:08:10,800 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 860.8m
2014-07-14 03:08:10,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:10,940 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:08:11,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52204 synced till here 52199
2014-07-14 03:08:11,329 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332489387 with entries=110, filesize=94.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332490800
2014-07-14 03:08:11,329 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332410866
2014-07-14 03:08:11,329 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332418109
2014-07-14 03:08:11,329 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332420278
2014-07-14 03:08:11,329 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332422357
2014-07-14 03:08:12,037 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:08:12,500 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:13,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52306 synced till here 52300
2014-07-14 03:08:13,552 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332490800 with entries=102, filesize=87.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332492500
2014-07-14 03:08:15,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:15,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52400 synced till here 52382
2014-07-14 03:08:15,523 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332492500 with entries=94, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332495252
2014-07-14 03:08:17,194 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:17,317 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52503 synced till here 52491
2014-07-14 03:08:17,438 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332495252 with entries=103, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332497195
2014-07-14 03:08:19,024 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:19,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52603 synced till here 52582
2014-07-14 03:08:20,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332497195 with entries=100, filesize=85.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332499024
2014-07-14 03:08:21,309 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:22,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52716 synced till here 52683
2014-07-14 03:08:22,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332499024 with entries=113, filesize=96.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332501309
2014-07-14 03:08:24,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:24,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52835 synced till here 52796
2014-07-14 03:08:25,039 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,039 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,051 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,052 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,053 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,059 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,094 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,105 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332501309 with entries=119, filesize=101.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332504573
2014-07-14 03:08:25,191 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,239 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,247 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:25,280 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,234 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,235 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,236 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,237 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,238 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,238 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,238 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,240 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,240 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,241 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,241 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,241 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,242 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,242 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,242 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,242 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,242 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,243 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,243 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,243 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,290 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,291 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,291 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,291 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,291 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,291 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,292 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,294 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,295 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,295 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,295 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,296 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,296 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,297 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,297 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,298 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,298 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,298 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:26,299 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:27,319 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12909, memsize=399.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e08ad62a63af45acbac423a83e22f0a0
2014-07-14 03:08:27,332 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e08ad62a63af45acbac423a83e22f0a0 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e08ad62a63af45acbac423a83e22f0a0
2014-07-14 03:08:27,349 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e08ad62a63af45acbac423a83e22f0a0, entries=1453490, sequenceid=12909, filesize=103.4m
2014-07-14 03:08:27,350 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~876.6m/919149120, currentsize=499.6m/523882000 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 28626ms, sequenceid=12909, compaction requested=true
2014-07-14 03:08:27,350 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-14 03:08:27,350 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1051ms
2014-07-14 03:08:27,350 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,350 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 931.6m
2014-07-14 03:08:27,350 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1052ms
2014-07-14 03:08:27,350 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,350 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1052ms
2014-07-14 03:08:27,351 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,353 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1055ms
2014-07-14 03:08:27,353 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,353 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1056ms
2014-07-14 03:08:27,353 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,353 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1056ms
2014-07-14 03:08:27,354 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,354 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1058ms
2014-07-14 03:08:27,354 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,357 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1061ms
2014-07-14 03:08:27,357 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,357 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1062ms
2014-07-14 03:08:27,357 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,359 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1064ms
2014-07-14 03:08:27,360 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,361 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1067ms
2014-07-14 03:08:27,361 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,361 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1067ms
2014-07-14 03:08:27,361 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,361 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1069ms
2014-07-14 03:08:27,361 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,377 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1086ms
2014-07-14 03:08:27,377 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,377 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1086ms
2014-07-14 03:08:27,377 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,377 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1087ms
2014-07-14 03:08:27,377 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,377 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1087ms
2014-07-14 03:08:27,377 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,377 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1086ms
2014-07-14 03:08:27,378 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,381 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1091ms
2014-07-14 03:08:27,381 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,385 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1142ms
2014-07-14 03:08:27,385 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,385 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1142ms
2014-07-14 03:08:27,385 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,385 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1142ms
2014-07-14 03:08:27,385 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,393 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1153ms
2014-07-14 03:08:27,393 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,401 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1165ms
2014-07-14 03:08:27,401 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,401 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1163ms
2014-07-14 03:08:27,401 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,402 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1164ms
2014-07-14 03:08:27,402 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,402 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1164ms
2014-07-14 03:08:27,402 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,402 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1161ms
2014-07-14 03:08:27,402 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,409 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1168ms
2014-07-14 03:08:27,409 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,409 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1171ms
2014-07-14 03:08:27,409 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,411 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1171ms
2014-07-14 03:08:27,437 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,438 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1198ms
2014-07-14 03:08:27,438 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,441 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1207ms
2014-07-14 03:08:27,441 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,449 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1215ms
2014-07-14 03:08:27,449 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,457 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1219ms
2014-07-14 03:08:27,457 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,465 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1228ms
2014-07-14 03:08:27,465 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,469 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1234ms
2014-07-14 03:08:27,469 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,469 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1235ms
2014-07-14 03:08:27,469 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,474 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1240ms
2014-07-14 03:08:27,474 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,474 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2194ms
2014-07-14 03:08:27,474 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,485 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2238ms
2014-07-14 03:08:27,485 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,486 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2247ms
2014-07-14 03:08:27,487 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,493 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2302ms
2014-07-14 03:08:27,493 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,493 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2399ms
2014-07-14 03:08:27,493 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,494 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2435ms
2014-07-14 03:08:27,494 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,496 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2443ms
2014-07-14 03:08:27,497 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,497 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2445ms
2014-07-14 03:08:27,497 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,497 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2446ms
2014-07-14 03:08:27,497 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,505 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2466ms
2014-07-14 03:08:27,505 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:27,509 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2470ms
2014-07-14 03:08:27,509 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:28,916 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1226ms
GC pool 'ParNew' had collection(s): count=1 time=1277ms
2014-07-14 03:08:29,051 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:08:29,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:29,562 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52959 synced till here 52928
2014-07-14 03:08:29,601 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:08:29,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332504573 with entries=124, filesize=105.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332509387
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332425526
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332427588
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332429492
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332431593
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332432861
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332434101
2014-07-14 03:08:29,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332436292
2014-07-14 03:08:31,313 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:31,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53061 synced till here 53037
2014-07-14 03:08:31,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332509387 with entries=102, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332511313
2014-07-14 03:08:33,648 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:33,679 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53175 synced till here 53138
2014-07-14 03:08:34,745 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332511313 with entries=114, filesize=97.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332513649
2014-07-14 03:08:35,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:35,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53286 synced till here 53250
2014-07-14 03:08:36,409 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332513649 with entries=111, filesize=95.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332515607
2014-07-14 03:08:37,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:37,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53379 synced till here 53359
2014-07-14 03:08:37,624 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332515607 with entries=93, filesize=79.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332517328
2014-07-14 03:08:38,505 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,506 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,507 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,508 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,512 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,517 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,539 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,583 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,583 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,586 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,588 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,589 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,591 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,595 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,607 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,610 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,610 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,610 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,618 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,620 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,634 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,672 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,718 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,765 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,811 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,854 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:38,898 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,471 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,522 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,583 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,622 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,690 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,734 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,780 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:39,825 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:41,275 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:41,313 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:41,350 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:41,991 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:42,003 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:08:42,219 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/06fc19c3af1247b3b6319c34d793aff9 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/06fc19c3af1247b3b6319c34d793aff9
2014-07-14 03:08:42,247 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:08:42,262 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/622c243dba10405caadc972d113be024, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/622c243dba10405caadc972d113be024
2014-07-14 03:08:42,265 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/aabc1e48d7454c2a96ba3903ffa7eeb2, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/aabc1e48d7454c2a96ba3903ffa7eeb2
2014-07-14 03:08:42,269 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/b57b130742d7455caeda14f8e4b295d0, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/b57b130742d7455caeda14f8e4b295d0
2014-07-14 03:08:42,273 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/512e8366de0749049f98ad3c0ec9b13f, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/512e8366de0749049f98ad3c0ec9b13f
2014-07-14 03:08:42,277 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cdea6eebefa74bffad5a8efedfff6f8d, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cdea6eebefa74bffad5a8efedfff6f8d
2014-07-14 03:08:42,281 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/45f731b667e1494888d97dd00b4f4124, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/45f731b667e1494888d97dd00b4f4124
2014-07-14 03:08:42,284 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/8411fb05fa494445a7270baa6d5916de, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/8411fb05fa494445a7270baa6d5916de
2014-07-14 03:08:42,289 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/df124f1db16b4722bd1a28e72550a91c, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/df124f1db16b4722bd1a28e72550a91c
2014-07-14 03:08:42,291 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6dad2e20f5d245208ed6c708b00398f0, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6dad2e20f5d245208ed6c708b00398f0
2014-07-14 03:08:42,297 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4535ee5b109147b284a70138992fe1b8, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4535ee5b109147b284a70138992fe1b8
2014-07-14 03:08:42,297 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into 06fc19c3af1247b3b6319c34d793aff9(size=779.8m), total size for store is 2.4g. This selection was in queue for 0sec, and took 3mins, 2sec to execute.
2014-07-14 03:08:42,297 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=10, fileSize=829.1m, priority=4, time=286247004313904; duration=3mins, 2sec
2014-07-14 03:08:42,297 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-14 03:08:42,298 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-14 03:08:42,300 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1091617771 starting at candidate #6 after considering 100 permutations with 82 in ratio
2014-07-14 03:08:42,301 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating minor compaction
2014-07-14 03:08:42,301 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:08:42,301 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=1.0g
2014-07-14 03:08:42,301 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/d3944f55c0314e95a8a6b5c1562f3ac0, keycount=120392, bloomtype=ROW, size=85.8m, encoding=NONE, seqNum=6800
2014-07-14 03:08:42,301 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec2060d272084041a58e0a640d89ae50, keycount=138546, bloomtype=ROW, size=98.7m, encoding=NONE, seqNum=7302
2014-07-14 03:08:42,301 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1fffb2fc3fe34f3eb0fc575e4eb76ac8, keycount=123432, bloomtype=ROW, size=87.8m, encoding=NONE, seqNum=7866
2014-07-14 03:08:42,301 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/574b67612cc24c3c85d9013b47a771ad, keycount=167038, bloomtype=ROW, size=118.9m, encoding=NONE, seqNum=8432
2014-07-14 03:08:42,302 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/24cab3e8b863443ca21bfc220773204b, keycount=84374, bloomtype=ROW, size=60.1m, encoding=NONE, seqNum=8932
2014-07-14 03:08:42,302 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25b3a90ad4254a4db34b6f25aa0a3c85, keycount=93889, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=9371
2014-07-14 03:08:42,302 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/73115d9b68f44465b0081b867c554cd7, keycount=219688, bloomtype=ROW, size=156.3m, encoding=NONE, seqNum=9777
2014-07-14 03:08:42,302 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/c440e72bc9594ec5800340f0942fb923, keycount=247031, bloomtype=ROW, size=175.9m, encoding=NONE, seqNum=10448
2014-07-14 03:08:42,302 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ba77e984183d4582937f9a841be7b2cd, keycount=159853, bloomtype=ROW, size=113.9m, encoding=NONE, seqNum=10939
2014-07-14 03:08:42,302 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ada31c1fcf6f48d88eb8a2d1535ade91, keycount=108032, bloomtype=ROW, size=76.9m, encoding=NONE, seqNum=11513
2014-07-14 03:08:42,591 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:08:43,280 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13075, memsize=471.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/42998a48681944ed8cfd034aada2bb09
2014-07-14 03:08:43,297 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/42998a48681944ed8cfd034aada2bb09 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/42998a48681944ed8cfd034aada2bb09
2014-07-14 03:08:43,315 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/42998a48681944ed8cfd034aada2bb09, entries=1717480, sequenceid=13075, filesize=122.3m
2014-07-14 03:08:43,315 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~862.6m/904479440, currentsize=484.5m/507993040 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 32515ms, sequenceid=13075, compaction requested=true
2014-07-14 03:08:43,316 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-14 03:08:43,316 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1313ms
2014-07-14 03:08:43,316 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,316 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 887.9m
2014-07-14 03:08:43,316 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1325ms
2014-07-14 03:08:43,316 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,317 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1966ms
2014-07-14 03:08:43,317 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,317 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2004ms
2014-07-14 03:08:43,317 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,317 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2042ms
2014-07-14 03:08:43,317 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,321 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3496ms
2014-07-14 03:08:43,322 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,322 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3542ms
2014-07-14 03:08:43,322 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,324 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3590ms
2014-07-14 03:08:43,324 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,325 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3634ms
2014-07-14 03:08:43,325 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,325 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3703ms
2014-07-14 03:08:43,325 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,326 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3743ms
2014-07-14 03:08:43,326 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,332 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3810ms
2014-07-14 03:08:43,332 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,332 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3862ms
2014-07-14 03:08:43,332 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,332 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4434ms
2014-07-14 03:08:43,333 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,333 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4479ms
2014-07-14 03:08:43,333 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,334 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4522ms
2014-07-14 03:08:43,334 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,337 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4570ms
2014-07-14 03:08:43,337 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,337 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4619ms
2014-07-14 03:08:43,337 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,340 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4668ms
2014-07-14 03:08:43,340 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,341 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4706ms
2014-07-14 03:08:43,341 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,342 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4722ms
2014-07-14 03:08:43,342 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,342 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4724ms
2014-07-14 03:08:43,342 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,346 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4735ms
2014-07-14 03:08:43,346 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,346 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4736ms
2014-07-14 03:08:43,346 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,346 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4736ms
2014-07-14 03:08:43,347 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,347 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4740ms
2014-07-14 03:08:43,347 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,349 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4754ms
2014-07-14 03:08:43,350 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,350 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4759ms
2014-07-14 03:08:43,350 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,354 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4765ms
2014-07-14 03:08:43,354 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,361 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4774ms
2014-07-14 03:08:43,361 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,362 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4775ms
2014-07-14 03:08:43,362 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,362 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4779ms
2014-07-14 03:08:43,362 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,362 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4780ms
2014-07-14 03:08:43,362 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,363 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4823ms
2014-07-14 03:08:43,363 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,363 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4846ms
2014-07-14 03:08:43,363 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,369 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4857ms
2014-07-14 03:08:43,369 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,369 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4861ms
2014-07-14 03:08:43,369 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,373 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4866ms
2014-07-14 03:08:43,373 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,389 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4883ms
2014-07-14 03:08:43,389 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,390 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4884ms
2014-07-14 03:08:43,390 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:08:43,838 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:44,131 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53468 synced till here 53453
2014-07-14 03:08:44,245 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:08:44,245 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:08:44,301 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332517328 with entries=89, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332523838
2014-07-14 03:08:44,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332437809
2014-07-14 03:08:44,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332447947
2014-07-14 03:08:44,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332449528
2014-07-14 03:08:44,301 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332451391
2014-07-14 03:08:44,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332453924
2014-07-14 03:08:45,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:45,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53547 synced till here 53541
2014-07-14 03:08:45,587 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332523838 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332525514
2014-07-14 03:08:52,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:52,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53626 synced till here 53619
2014-07-14 03:08:52,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332525514 with entries=79, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332532189
2014-07-14 03:08:53,157 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:53,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53713 synced till here 53700
2014-07-14 03:08:54,362 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332532189 with entries=87, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332533157
2014-07-14 03:08:55,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:55,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332533157 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332535185
2014-07-14 03:08:56,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:56,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53860 synced till here 53858
2014-07-14 03:08:56,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332535185 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332536747
2014-07-14 03:08:58,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:08:58,186 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13279, memsize=574.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/be306e2648ac4631bf760f19ee78b0eb
2014-07-14 03:08:58,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53937 synced till here 53935
2014-07-14 03:08:58,235 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332536747 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332538154
2014-07-14 03:08:58,273 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/be306e2648ac4631bf760f19ee78b0eb as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/be306e2648ac4631bf760f19ee78b0eb
2014-07-14 03:08:58,298 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/be306e2648ac4631bf760f19ee78b0eb, entries=2092790, sequenceid=13279, filesize=149.0m
2014-07-14 03:08:58,299 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~931.6m/976844880, currentsize=383.8m/402472640 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 30949ms, sequenceid=13279, compaction requested=true
2014-07-14 03:08:58,299 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:101), split_queue=0, merge_queue=0
2014-07-14 03:08:58,299 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 938.5m
2014-07-14 03:08:58,314 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:08:59,452 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:08:59,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:00,090 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332538154 with entries=91, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332539594
2014-07-14 03:09:00,090 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332455980
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332457911
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332459813
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332461548
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332463212
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332464982
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332466287
2014-07-14 03:09:00,091 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332467541
2014-07-14 03:09:01,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:02,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54122 synced till here 54120
2014-07-14 03:09:02,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332539594 with entries=94, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332541601
2014-07-14 03:09:03,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:03,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54203 synced till here 54199
2014-07-14 03:09:03,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332541601 with entries=81, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332543363
2014-07-14 03:09:04,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:04,886 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332543363 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332544836
2014-07-14 03:09:05,913 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13389, memsize=432.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/ba449af0a5ee408f906ddfa55c4d3a52
2014-07-14 03:09:05,930 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/ba449af0a5ee408f906ddfa55c4d3a52 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/ba449af0a5ee408f906ddfa55c4d3a52
2014-07-14 03:09:06,024 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/ba449af0a5ee408f906ddfa55c4d3a52, entries=1573010, sequenceid=13389, filesize=112.0m
2014-07-14 03:09:06,024 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~887.9m/930999120, currentsize=363.4m/381087120 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 22708ms, sequenceid=13389, compaction requested=true
2014-07-14 03:09:06,024 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-14 03:09:06,025 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 840.2m
2014-07-14 03:09:06,621 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:09:06,665 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:06,725 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54355 synced till here 54350
2014-07-14 03:09:06,727 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:09:06,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332544836 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332546665
2014-07-14 03:09:06,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332469042
2014-07-14 03:09:06,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332473388
2014-07-14 03:09:06,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332474432
2014-07-14 03:09:06,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332475912
2014-07-14 03:09:06,814 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332477496
2014-07-14 03:09:08,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:08,219 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54439 synced till here 54429
2014-07-14 03:09:09,092 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332546665 with entries=84, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332548196
2014-07-14 03:09:09,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:10,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54531 synced till here 54510
2014-07-14 03:09:11,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332548196 with entries=92, filesize=79.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332550000
2014-07-14 03:09:12,862 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:12,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54634 synced till here 54619
2014-07-14 03:09:13,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332550000 with entries=103, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332552863
2014-07-14 03:09:14,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:15,178 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54730 synced till here 54716
2014-07-14 03:09:15,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332552863 with entries=96, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332554997
2014-07-14 03:09:17,033 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:17,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54827 synced till here 54805
2014-07-14 03:09:17,466 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332554997 with entries=97, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332557141
2014-07-14 03:09:19,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:19,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54940 synced till here 54911
2014-07-14 03:09:20,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332557141 with entries=113, filesize=97.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332559394
2014-07-14 03:09:22,695 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:22,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55056 synced till here 55029
2014-07-14 03:09:23,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332559394 with entries=116, filesize=99.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332562695
2014-07-14 03:09:24,987 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,018 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,041 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,043 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,072 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:25,084 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,124 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55159 synced till here 55130
2014-07-14 03:09:25,159 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,167 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,167 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,195 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,232 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,269 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,284 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,284 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,284 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,284 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,285 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,285 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,285 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,285 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,286 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,287 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,287 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,288 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,288 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,290 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,290 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,292 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332562695 with entries=103, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332565072
2014-07-14 03:09:25,303 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,342 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,342 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,342 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,343 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,344 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,346 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,348 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,365 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,368 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,395 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,425 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,456 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,487 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,518 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,548 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,579 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,609 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,939 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,949 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:25,974 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:26,004 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:09:28,477 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13519, memsize=397.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/4bdd6d2f5adc4122a39d294492ed0217
2014-07-14 03:09:28,496 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/4bdd6d2f5adc4122a39d294492ed0217 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/4bdd6d2f5adc4122a39d294492ed0217
2014-07-14 03:09:28,510 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/4bdd6d2f5adc4122a39d294492ed0217, entries=1447740, sequenceid=13519, filesize=103.2m
2014-07-14 03:09:28,510 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~943.2m/988995200, currentsize=459.9m/482235680 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 30211ms, sequenceid=13519, compaction requested=true
2014-07-14 03:09:28,511 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:103), split_queue=0, merge_queue=0
2014-07-14 03:09:28,511 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2507ms
2014-07-14 03:09:28,511 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 882.7m
2014-07-14 03:09:28,511 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,512 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2538ms
2014-07-14 03:09:28,512 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,512 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2563ms
2014-07-14 03:09:28,513 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,513 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2574ms
2014-07-14 03:09:28,513 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,515 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2905ms
2014-07-14 03:09:28,516 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,516 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2937ms
2014-07-14 03:09:28,516 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,519 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2971ms
2014-07-14 03:09:28,519 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,519 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3001ms
2014-07-14 03:09:28,519 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,519 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3032ms
2014-07-14 03:09:28,519 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,521 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3065ms
2014-07-14 03:09:28,521 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,521 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3096ms
2014-07-14 03:09:28,521 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,522 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3126ms
2014-07-14 03:09:28,522 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,524 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3156ms
2014-07-14 03:09:28,524 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,524 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3159ms
2014-07-14 03:09:28,524 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,524 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3176ms
2014-07-14 03:09:28,524 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,525 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3179ms
2014-07-14 03:09:28,525 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,526 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3182ms
2014-07-14 03:09:28,526 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,530 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3187ms
2014-07-14 03:09:28,530 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,531 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3188ms
2014-07-14 03:09:28,531 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,531 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3189ms
2014-07-14 03:09:28,531 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,531 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3189ms
2014-07-14 03:09:28,531 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,532 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3228ms
2014-07-14 03:09:28,532 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,532 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3240ms
2014-07-14 03:09:28,532 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,535 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3245ms
2014-07-14 03:09:28,535 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,535 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3245ms
2014-07-14 03:09:28,535 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,536 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3248ms
2014-07-14 03:09:28,536 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,536 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3248ms
2014-07-14 03:09:28,536 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,536 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3249ms
2014-07-14 03:09:28,536 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,536 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3249ms
2014-07-14 03:09:28,537 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,538 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3253ms
2014-07-14 03:09:28,538 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,538 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3254ms
2014-07-14 03:09:28,538 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,544 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3259ms
2014-07-14 03:09:28,544 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,545 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3260ms
2014-07-14 03:09:28,545 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,545 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3261ms
2014-07-14 03:09:28,545 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,551 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3267ms
2014-07-14 03:09:28,551 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,551 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3267ms
2014-07-14 03:09:28,551 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,552 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3268ms
2014-07-14 03:09:28,552 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,561 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3278ms
2014-07-14 03:09:28,561 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,561 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3292ms
2014-07-14 03:09:28,561 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,561 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3329ms
2014-07-14 03:09:28,561 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,562 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3367ms
2014-07-14 03:09:28,562 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,570 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3402ms
2014-07-14 03:09:28,570 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,570 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3403ms
2014-07-14 03:09:28,571 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,571 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3412ms
2014-07-14 03:09:28,571 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,571 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3447ms
2014-07-14 03:09:28,571 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,571 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3487ms
2014-07-14 03:09:28,571 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,572 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3529ms
2014-07-14 03:09:28,572 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,573 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3533ms
2014-07-14 03:09:28,573 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,573 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3555ms
2014-07-14 03:09:28,573 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:28,577 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3590ms
2014-07-14 03:09:28,577 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:09:29,173 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:09:29,429 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:09:29,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:30,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55265 synced till here 55234
2014-07-14 03:09:30,496 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332565072 with entries=106, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332569475
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332478671
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332480237
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332481887
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332483189
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332484765
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332486395
2014-07-14 03:09:30,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332488001
2014-07-14 03:09:31,328 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:32,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55375 synced till here 55339
2014-07-14 03:09:32,627 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332569475 with entries=110, filesize=94.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332571329
2014-07-14 03:09:32,702 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13619, memsize=312.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4bd38bc522e04cdfbceb4aa70b3bb696
2014-07-14 03:09:32,739 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4bd38bc522e04cdfbceb4aa70b3bb696 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4bd38bc522e04cdfbceb4aa70b3bb696
2014-07-14 03:09:32,758 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4bd38bc522e04cdfbceb4aa70b3bb696, entries=1139220, sequenceid=13619, filesize=81.1m
2014-07-14 03:09:32,759 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~840.2m/880996800, currentsize=404.5m/424105040 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 26734ms, sequenceid=13619, compaction requested=true
2014-07-14 03:09:32,759 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:104), split_queue=0, merge_queue=0
2014-07-14 03:09:32,759 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 760.0m
2014-07-14 03:09:32,993 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:09:34,189 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:34,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55468 synced till here 55448
2014-07-14 03:09:34,470 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332571329 with entries=93, filesize=79.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332574190
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332489387
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332490800
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332492500
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332495252
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332497195
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332499024
2014-07-14 03:09:34,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332501309
2014-07-14 03:09:34,657 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:09:35,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:35,145 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332574190 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332575112
2014-07-14 03:09:37,505 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:37,539 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332575112 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332577506
2014-07-14 03:09:38,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:38,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55696 synced till here 55695
2014-07-14 03:09:38,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332577506 with entries=81, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332578658
2014-07-14 03:09:40,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:40,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55771 synced till here 55769
2014-07-14 03:09:40,413 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332578658 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332580321
2014-07-14 03:09:41,712 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:41,987 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55859 synced till here 55857
2014-07-14 03:09:42,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332580321 with entries=88, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332581712
2014-07-14 03:09:43,354 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:43,423 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55937 synced till here 55933
2014-07-14 03:09:43,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332581712 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332583354
2014-07-14 03:09:45,036 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:45,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56009 synced till here 56008
2014-07-14 03:09:45,462 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332583354 with entries=72, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332585037
2014-07-14 03:09:46,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:47,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56091 synced till here 56081
2014-07-14 03:09:47,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332585037 with entries=82, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332586606
2014-07-14 03:09:48,080 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13849, memsize=341.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/a217cda44d994a5e862cc8f2206932e1
2014-07-14 03:09:48,113 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/a217cda44d994a5e862cc8f2206932e1 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/a217cda44d994a5e862cc8f2206932e1
2014-07-14 03:09:48,163 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/a217cda44d994a5e862cc8f2206932e1, entries=1242600, sequenceid=13849, filesize=88.5m
2014-07-14 03:09:48,163 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~882.7m/925595520, currentsize=366.1m/383859760 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 19652ms, sequenceid=13849, compaction requested=true
2014-07-14 03:09:48,163 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:105), split_queue=0, merge_queue=0
2014-07-14 03:09:48,164 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 824.9m
2014-07-14 03:09:48,190 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:09:48,456 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:49,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56182 synced till here 56168
2014-07-14 03:09:49,437 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332586606 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332588456
2014-07-14 03:09:49,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332504573
2014-07-14 03:09:49,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332509387
2014-07-14 03:09:49,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332511313
2014-07-14 03:09:49,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332513649
2014-07-14 03:09:49,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332515607
2014-07-14 03:09:49,889 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:09:50,190 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:51,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56271 synced till here 56267
2014-07-14 03:09:51,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332588456 with entries=89, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332590191
2014-07-14 03:09:51,700 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13884, memsize=342.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/db087f6d8de34bd4b87c1ccebb04e49e
2014-07-14 03:09:51,721 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/db087f6d8de34bd4b87c1ccebb04e49e as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/db087f6d8de34bd4b87c1ccebb04e49e
2014-07-14 03:09:51,744 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/db087f6d8de34bd4b87c1ccebb04e49e, entries=1245450, sequenceid=13884, filesize=88.7m
2014-07-14 03:09:51,744 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~767.6m/804889760, currentsize=369.6m/387555520 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 18985ms, sequenceid=13884, compaction requested=true
2014-07-14 03:09:51,745 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-14 03:09:51,745 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 778.8m
2014-07-14 03:09:51,832 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:09:51,947 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:52,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56360 synced till here 56357
2014-07-14 03:09:52,414 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332590191 with entries=89, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332591947
2014-07-14 03:09:52,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332517328
2014-07-14 03:09:52,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332523838
2014-07-14 03:09:52,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332525514
2014-07-14 03:09:52,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332532189
2014-07-14 03:09:52,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332533157
2014-07-14 03:09:52,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332535185
2014-07-14 03:09:52,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332536747
2014-07-14 03:09:52,931 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:09:53,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:53,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332591947 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332593400
2014-07-14 03:09:54,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:54,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56512 synced till here 56508
2014-07-14 03:09:54,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332593400 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332594706
2014-07-14 03:09:55,968 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:56,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56594 synced till here 56586
2014-07-14 03:09:56,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332594706 with entries=82, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332596110
2014-07-14 03:09:57,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:58,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56686 synced till here 56685
2014-07-14 03:09:58,102 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332596110 with entries=92, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332597809
2014-07-14 03:09:59,491 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:09:59,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56769 synced till here 56767
2014-07-14 03:09:59,982 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332597809 with entries=83, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332599491
2014-07-14 03:10:01,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:01,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56860 synced till here 56843
2014-07-14 03:10:02,074 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332599491 with entries=91, filesize=78.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332601798
2014-07-14 03:10:02,897 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:03,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332601798 with entries=74, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332602897
2014-07-14 03:10:04,268 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:04,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57011 synced till here 57005
2014-07-14 03:10:04,841 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332602897 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332604269
2014-07-14 03:10:05,542 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:05,566 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57088 synced till here 57084
2014-07-14 03:10:05,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332604269 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332605542
2014-07-14 03:10:06,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:06,828 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332605542 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332606789
2014-07-14 03:10:07,491 DEBUG [LruStats #0] hfile.LruBlockCache: Total=5.29 MB, free=3.95 GB, max=3.96 GB, blocks=11, accesses=290676, hits=70038, hitRatio=24.09%, , cachingAccesses=70075, cachingHits=70007, cachingHitsRatio=99.90%, evictions=0, evicted=57, evictedPerRun=Infinity
2014-07-14 03:10:07,730 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14123, memsize=279.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4131ee96f3e0492b8baa3838078d2909
2014-07-14 03:10:07,744 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/4131ee96f3e0492b8baa3838078d2909 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4131ee96f3e0492b8baa3838078d2909
2014-07-14 03:10:07,756 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4131ee96f3e0492b8baa3838078d2909, entries=1018220, sequenceid=14123, filesize=72.5m
2014-07-14 03:10:07,756 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~782.0m/819985120, currentsize=332.7m/348904560 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 16011ms, sequenceid=14123, compaction requested=true
2014-07-14 03:10:07,757 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-14 03:10:07,757 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 767.5m
2014-07-14 03:10:07,763 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:10:08,157 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:08,344 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:10:08,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332606789 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332608158
2014-07-14 03:10:09,688 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:10,030 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14066, memsize=399.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/5b71fe3b2c1b45ffb91eadebb85d7108
2014-07-14 03:10:10,059 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/5b71fe3b2c1b45ffb91eadebb85d7108 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5b71fe3b2c1b45ffb91eadebb85d7108
2014-07-14 03:10:10,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57345 synced till here 57343
2014-07-14 03:10:10,526 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5b71fe3b2c1b45ffb91eadebb85d7108, entries=1453430, sequenceid=14066, filesize=103.6m
2014-07-14 03:10:10,527 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~848.4m/889618000, currentsize=470.2m/493004160 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 22363ms, sequenceid=14066, compaction requested=true
2014-07-14 03:10:10,527 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-14 03:10:10,527 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 762.9m
2014-07-14 03:10:10,544 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332608158 with entries=98, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332609689
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332538154
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332539594
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332541601
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332543363
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332544836
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332546665
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332548196
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332550000
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332552863
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332554997
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332557141
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332559394
2014-07-14 03:10:10,544 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332562695
2014-07-14 03:10:10,595 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:10:11,147 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:10:11,405 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:11,800 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332609689 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332611406
2014-07-14 03:10:13,290 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:13,679 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57500 synced till here 57498
2014-07-14 03:10:13,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332611406 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332613290
2014-07-14 03:10:15,109 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:15,130 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57573 synced till here 57572
2014-07-14 03:10:15,147 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332613290 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332615111
2014-07-14 03:10:16,349 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:16,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57647 synced till here 57645
2014-07-14 03:10:16,406 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332615111 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332616349
2014-07-14 03:10:17,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:17,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332616349 with entries=95, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332617484
2014-07-14 03:10:19,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:19,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57826 synced till here 57823
2014-07-14 03:10:20,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332617484 with entries=84, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332619445
2014-07-14 03:10:22,097 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:22,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57909 synced till here 57901
2014-07-14 03:10:22,275 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332619445 with entries=83, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332622097
2014-07-14 03:10:23,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:24,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58008 synced till here 58005
2014-07-14 03:10:24,247 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332622097 with entries=99, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332623770
2014-07-14 03:10:25,795 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:25,817 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58087 synced till here 58080
2014-07-14 03:10:25,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332623770 with entries=79, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332625796
2014-07-14 03:10:27,535 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:27,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58196 synced till here 58187
2014-07-14 03:10:27,910 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332625796 with entries=109, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332627536
2014-07-14 03:10:29,465 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:29,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58278 synced till here 58268
2014-07-14 03:10:29,587 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332627536 with entries=82, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332629465
2014-07-14 03:10:31,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:31,375 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58369 synced till here 58353
2014-07-14 03:10:31,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332629465 with entries=91, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332631292
2014-07-14 03:10:32,696 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,697 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,702 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,702 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,702 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,703 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,705 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,705 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,705 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,708 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,708 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,708 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,708 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,709 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,711 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,735 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,768 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,772 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,772 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,773 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,775 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,776 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,776 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,779 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,803 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,804 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,804 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,834 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,866 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,896 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,928 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,959 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:32,988 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,018 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,047 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,075 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,104 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,135 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,164 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,193 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,225 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,256 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,285 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,319 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,351 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,381 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,413 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,445 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,477 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:33,505 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:35,079 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1019ms
GC pool 'ParNew' had collection(s): count=1 time=1118ms
2014-07-14 03:10:36,371 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14345, memsize=567.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/643b11b0fc1d40c3a689dc4578d8bb27
2014-07-14 03:10:36,391 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/643b11b0fc1d40c3a689dc4578d8bb27 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/643b11b0fc1d40c3a689dc4578d8bb27
2014-07-14 03:10:36,403 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/643b11b0fc1d40c3a689dc4578d8bb27, entries=2066480, sequenceid=14345, filesize=147.1m
2014-07-14 03:10:36,403 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~768.9m/806302080, currentsize=482.6m/505990480 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 28646ms, sequenceid=14345, compaction requested=true
2014-07-14 03:10:36,404 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:109), split_queue=0, merge_queue=0
2014-07-14 03:10:36,404 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2899ms
2014-07-14 03:10:36,404 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,404 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 800.9m
2014-07-14 03:10:36,404 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2928ms
2014-07-14 03:10:36,404 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,405 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2960ms
2014-07-14 03:10:36,405 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,409 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2996ms
2014-07-14 03:10:36,409 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,409 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3028ms
2014-07-14 03:10:36,409 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,410 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3058ms
2014-07-14 03:10:36,410 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,410 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3091ms
2014-07-14 03:10:36,410 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,411 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3126ms
2014-07-14 03:10:36,411 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,411 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3155ms
2014-07-14 03:10:36,411 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,412 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3186ms
2014-07-14 03:10:36,412 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,413 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3220ms
2014-07-14 03:10:36,413 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,414 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3249ms
2014-07-14 03:10:36,414 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,414 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3279ms
2014-07-14 03:10:36,414 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,415 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3311ms
2014-07-14 03:10:36,415 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,417 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3342ms
2014-07-14 03:10:36,417 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,417 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3370ms
2014-07-14 03:10:36,417 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,417 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3399ms
2014-07-14 03:10:36,417 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,419 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3431ms
2014-07-14 03:10:36,419 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,419 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3460ms
2014-07-14 03:10:36,419 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,420 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3492ms
2014-07-14 03:10:36,420 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,420 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3524ms
2014-07-14 03:10:36,420 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,420 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3554ms
2014-07-14 03:10:36,420 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,420 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3586ms
2014-07-14 03:10:36,420 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,422 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3617ms
2014-07-14 03:10:36,422 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,422 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3619ms
2014-07-14 03:10:36,422 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,422 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3619ms
2014-07-14 03:10:36,422 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,429 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3650ms
2014-07-14 03:10:36,454 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,454 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3681ms
2014-07-14 03:10:36,454 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,461 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3689ms
2014-07-14 03:10:36,461 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,469 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3694ms
2014-07-14 03:10:36,469 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,469 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3696ms
2014-07-14 03:10:36,469 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,469 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3697ms
2014-07-14 03:10:36,469 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,470 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3697ms
2014-07-14 03:10:36,470 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,470 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3702ms
2014-07-14 03:10:36,470 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,470 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3735ms
2014-07-14 03:10:36,470 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,471 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3759ms
2014-07-14 03:10:36,471 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,477 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3769ms
2014-07-14 03:10:36,477 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,477 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3769ms
2014-07-14 03:10:36,477 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,478 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3769ms
2014-07-14 03:10:36,478 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,485 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3777ms
2014-07-14 03:10:36,485 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,485 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3777ms
2014-07-14 03:10:36,485 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,493 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3789ms
2014-07-14 03:10:36,493 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,501 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3796ms
2014-07-14 03:10:36,501 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,505 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3801ms
2014-07-14 03:10:36,505 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,505 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3802ms
2014-07-14 03:10:36,505 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,509 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3807ms
2014-07-14 03:10:36,509 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,509 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3807ms
2014-07-14 03:10:36,509 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,510 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3807ms
2014-07-14 03:10:36,510 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,512 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3815ms
2014-07-14 03:10:36,512 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:36,513 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3816ms
2014-07-14 03:10:36,513 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:10:38,087 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1006ms
GC pool 'ParNew' had collection(s): count=1 time=1148ms
2014-07-14 03:10:38,281 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:38,282 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:10:38,328 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:10:38,412 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58479 synced till here 58465
2014-07-14 03:10:38,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332631292 with entries=110, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332638281
2014-07-14 03:10:38,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332565072
2014-07-14 03:10:38,521 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332569475
2014-07-14 03:10:40,186 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:40,202 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58578 synced till here 58563
2014-07-14 03:10:40,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332638281 with entries=99, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332640186
2014-07-14 03:10:42,359 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:42,437 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58696 synced till here 58658
2014-07-14 03:10:42,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332640186 with entries=118, filesize=97.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332642359
2014-07-14 03:10:44,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:44,554 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58806 synced till here 58778
2014-07-14 03:10:45,742 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14377, memsize=610.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2ad7aad5404449e68ae401cf9c9a2c28
2014-07-14 03:10:45,753 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/2ad7aad5404449e68ae401cf9c9a2c28 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2ad7aad5404449e68ae401cf9c9a2c28
2014-07-14 03:10:45,769 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2ad7aad5404449e68ae401cf9c9a2c28, entries=2223180, sequenceid=14377, filesize=158.2m
2014-07-14 03:10:45,769 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~764.5m/801624800, currentsize=546.5m/573020240 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 35242ms, sequenceid=14377, compaction requested=true
2014-07-14 03:10:45,769 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:110), split_queue=0, merge_queue=0
2014-07-14 03:10:45,769 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 990.1m
2014-07-14 03:10:45,774 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:10:45,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332642359 with entries=110, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332644484
2014-07-14 03:10:45,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332571329
2014-07-14 03:10:45,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332574190
2014-07-14 03:10:45,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332575112
2014-07-14 03:10:45,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332577506
2014-07-14 03:10:45,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332578658
2014-07-14 03:10:45,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332580321
2014-07-14 03:10:45,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332581712
2014-07-14 03:10:45,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332583354
2014-07-14 03:10:45,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332585037
2014-07-14 03:10:46,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:47,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58907 synced till here 58898
2014-07-14 03:10:47,780 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332644484 with entries=101, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332646941
2014-07-14 03:10:47,837 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:10:48,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:48,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59015 synced till here 58992
2014-07-14 03:10:49,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332646941 with entries=108, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332648706
2014-07-14 03:10:51,213 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:51,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59177 synced till here 59142
2014-07-14 03:10:52,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332648706 with entries=162, filesize=138.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332651213
2014-07-14 03:10:54,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:54,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59280 synced till here 59254
2014-07-14 03:10:54,552 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332651213 with entries=103, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332654212
2014-07-14 03:10:55,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:10:56,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59359 synced till here 59358
2014-07-14 03:10:56,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332654212 with entries=79, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332655772
2014-07-14 03:10:56,765 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:56,805 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:57,044 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:57,096 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:57,797 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,039 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,055 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,766 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,803 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,858 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,890 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,920 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,955 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:58,990 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:59,023 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:59,055 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:10:59,095 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:00,908 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:00,954 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:01,015 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:01,060 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:01,108 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:01,161 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:01,766 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:01,806 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:02,044 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:02,097 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:02,884 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-14 03:11:02,995 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,039 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:03,056 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:03,698 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,745 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,767 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:03,804 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:03,809 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,843 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,859 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:03,878 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,891 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:03,911 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,921 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:03,943 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,955 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:03,980 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:03,990 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:04,010 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,024 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:04,043 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,056 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:04,079 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,096 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:04,115 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,153 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,189 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,226 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,262 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,310 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,346 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,383 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,429 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,467 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,504 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,542 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,579 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:04,618 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:05,012 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:11:05,908 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:05,955 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:06,016 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:11:06,060 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:06,108 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:06,161 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:06,878 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10072ms
2014-07-14 03:11:06,878 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10113ms
2014-07-14 03:11:07,045 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:11:07,097 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:11:07,885 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10088ms
2014-07-14 03:11:07,995 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:11:08,039 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:11:08,056 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:11:08,260 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14640, memsize=619.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cab3364468e0438d861ac2c8dabbde37
2014-07-14 03:11:08,282 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/cab3364468e0438d861ac2c8dabbde37 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cab3364468e0438d861ac2c8dabbde37
2014-07-14 03:11:08,559 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/cab3364468e0438d861ac2c8dabbde37, entries=2256780, sequenceid=14640, filesize=160.7m
2014-07-14 03:11:08,559 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~800.9m/839765840, currentsize=368.2m/386123280 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 32155ms, sequenceid=14640, compaction requested=true
2014-07-14 03:11:08,560 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-14 03:11:08,560 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10505ms
2014-07-14 03:11:08,560 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:11:08,560 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,560 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:112), split_queue=0, merge_queue=0
2014-07-14 03:11:08,560 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10522ms
2014-07-14 03:11:08,560 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,560 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5565ms
2014-07-14 03:11:08,560 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,561 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10764ms
2014-07-14 03:11:08,561 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,560 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 788.2m
2014-07-14 03:11:08,573 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11477ms
2014-07-14 03:11:08,573 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,581 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11537ms
2014-07-14 03:11:08,581 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,589 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11824ms
2014-07-14 03:11:08,589 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,589 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11784ms
2014-07-14 03:11:08,589 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,589 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7428ms
2014-07-14 03:11:08,589 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,589 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7481ms
2014-07-14 03:11:08,589 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,591 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7531ms
2014-07-14 03:11:08,591 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,591 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7576ms
2014-07-14 03:11:08,591 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,591 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7637ms
2014-07-14 03:11:08,591 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,591 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7683ms
2014-07-14 03:11:08,591 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,591 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3579ms
2014-07-14 03:11:08,591 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,592 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3974ms
2014-07-14 03:11:08,592 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,592 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4014ms
2014-07-14 03:11:08,592 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,593 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4051ms
2014-07-14 03:11:08,593 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,593 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4089ms
2014-07-14 03:11:08,593 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,593 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4126ms
2014-07-14 03:11:08,593 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,609 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4180ms
2014-07-14 03:11:08,609 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,609 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4226ms
2014-07-14 03:11:08,609 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,615 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4269ms
2014-07-14 03:11:08,615 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,615 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4306ms
2014-07-14 03:11:08,615 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,620 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4358ms
2014-07-14 03:11:08,620 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,620 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4394ms
2014-07-14 03:11:08,620 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,620 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4431ms
2014-07-14 03:11:08,620 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,620 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4467ms
2014-07-14 03:11:08,620 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,620 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4505ms
2014-07-14 03:11:08,621 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,621 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9526ms
2014-07-14 03:11:08,621 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,631 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4552ms
2014-07-14 03:11:08,631 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,631 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9576ms
2014-07-14 03:11:08,631 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,631 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4588ms
2014-07-14 03:11:08,631 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,634 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9611ms
2014-07-14 03:11:08,634 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,635 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4625ms
2014-07-14 03:11:08,635 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,637 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9648ms
2014-07-14 03:11:08,637 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,638 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4657ms
2014-07-14 03:11:08,638 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,649 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9694ms
2014-07-14 03:11:08,649 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,655 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4712ms
2014-07-14 03:11:08,655 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,655 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9735ms
2014-07-14 03:11:08,655 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,655 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4744ms
2014-07-14 03:11:08,655 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,656 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9765ms
2014-07-14 03:11:08,656 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,656 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4779ms
2014-07-14 03:11:08,656 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,656 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9798ms
2014-07-14 03:11:08,656 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,658 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4815ms
2014-07-14 03:11:08,658 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,659 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4850ms
2014-07-14 03:11:08,659 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,660 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9856ms
2014-07-14 03:11:08,660 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,660 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9894ms
2014-07-14 03:11:08,660 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,662 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4917ms
2014-07-14 03:11:08,662 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,664 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4966ms
2014-07-14 03:11:08,664 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:11:08,886 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:11:09,448 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:09,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59456 synced till here 59447
2014-07-14 03:11:09,996 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11961,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658035,"queuetimems":201,"class":"HRegionServer","responsesize":15967,"method":"Multi"}
2014-07-14 03:11:10,068 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:11:10,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332655772 with entries=97, filesize=81.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332669448
2014-07-14 03:11:11,381 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:11,391 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14296,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332657094,"queuetimems":0,"class":"HRegionServer","responsesize":15524,"method":"Multi"}
2014-07-14 03:11:11,391 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14587,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332656803,"queuetimems":0,"class":"HRegionServer","responsesize":15662,"method":"Multi"}
2014-07-14 03:11:11,397 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14355,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332657042,"queuetimems":1,"class":"HRegionServer","responsesize":15864,"method":"Multi"}
2014-07-14 03:11:11,398 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13344,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658054,"queuetimems":1,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 03:11:11,397 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332657794,"queuetimems":1,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 03:11:11,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59555 synced till here 59553
2014-07-14 03:11:12,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332669448 with entries=99, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332671381
2014-07-14 03:11:12,230 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13279,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658951,"queuetimems":0,"class":"HRegionServer","responsesize":15593,"method":"Multi"}
2014-07-14 03:11:12,230 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658918,"queuetimems":0,"class":"HRegionServer","responsesize":15790,"method":"Multi"}
2014-07-14 03:11:12,231 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15468,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332656763,"queuetimems":0,"class":"HRegionServer","responsesize":15285,"method":"Multi"}
2014-07-14 03:11:12,231 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11326,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332660905,"queuetimems":1,"class":"HRegionServer","responsesize":15967,"method":"Multi"}
2014-07-14 03:11:12,468 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13415,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332659053,"queuetimems":0,"class":"HRegionServer","responsesize":16034,"method":"Multi"}
2014-07-14 03:11:12,469 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658762,"queuetimems":0,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 03:11:12,470 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13583,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658887,"queuetimems":0,"class":"HRegionServer","responsesize":15622,"method":"Multi"}
2014-07-14 03:11:12,470 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11520,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332660950,"queuetimems":1,"class":"HRegionServer","responsesize":15734,"method":"Multi"}
2014-07-14 03:11:12,471 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13378,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332659093,"queuetimems":0,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:11:12,472 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13485,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658986,"queuetimems":0,"class":"HRegionServer","responsesize":15751,"method":"Multi"}
2014-07-14 03:11:12,475 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13620,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658855,"queuetimems":0,"class":"HRegionServer","responsesize":15576,"method":"Multi"}
2014-07-14 03:11:12,476 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11322,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332661154,"queuetimems":1,"class":"HRegionServer","responsesize":15864,"method":"Multi"}
2014-07-14 03:11:12,477 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11373,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332661103,"queuetimems":1,"class":"HRegionServer","responsesize":15662,"method":"Multi"}
2014-07-14 03:11:12,478 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332661011,"queuetimems":1,"class":"HRegionServer","responsesize":15524,"method":"Multi"}
2014-07-14 03:11:12,479 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13677,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332658802,"queuetimems":1,"class":"HRegionServer","responsesize":15435,"method":"Multi"}
2014-07-14 03:11:12,535 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332661056,"queuetimems":1,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 03:11:12,604 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13584,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47240","starttimems":1405332659020,"queuetimems":0,"class":"HRegionServer","responsesize":15285,"method":"Multi"}
2014-07-14 03:11:12,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:12,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59658 synced till here 59652
2014-07-14 03:11:12,995 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332671381 with entries=103, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332672673
2014-07-14 03:11:17,065 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14725, memsize=673.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/2c12dd83afc14fbd9c851186d25263a6
2014-07-14 03:11:17,079 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/2c12dd83afc14fbd9c851186d25263a6 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c12dd83afc14fbd9c851186d25263a6
2014-07-14 03:11:17,093 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c12dd83afc14fbd9c851186d25263a6, entries=2453030, sequenceid=14725, filesize=174.7m
2014-07-14 03:11:17,094 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1019.7m/1069260000, currentsize=375.2m/393387040 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 31325ms, sequenceid=14725, compaction requested=true
2014-07-14 03:11:17,094 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:113), split_queue=0, merge_queue=0
2014-07-14 03:11:17,095 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 500.9m
2014-07-14 03:11:17,133 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:17,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59733 synced till here 59731
2014-07-14 03:11:17,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332672673 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332677134
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332586606
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332588456
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332590191
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332591947
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332593400
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332594706
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332596110
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332597809
2014-07-14 03:11:17,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332599491
2014-07-14 03:11:17,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332601798
2014-07-14 03:11:17,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332602897
2014-07-14 03:11:17,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332604269
2014-07-14 03:11:17,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332605542
2014-07-14 03:11:17,289 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:11:17,624 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:11:18,513 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:18,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59813 synced till here 59805
2014-07-14 03:11:18,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332677134 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332678514
2014-07-14 03:11:19,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:19,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59888 synced till here 59887
2014-07-14 03:11:19,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332678514 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332679447
2014-07-14 03:11:22,381 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14884, memsize=271.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/42a1555fa34a48fc9a5de3ba5f869f24
2014-07-14 03:11:22,399 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/42a1555fa34a48fc9a5de3ba5f869f24 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/42a1555fa34a48fc9a5de3ba5f869f24
2014-07-14 03:11:22,415 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/42a1555fa34a48fc9a5de3ba5f869f24, entries=989280, sequenceid=14884, filesize=70.5m
2014-07-14 03:11:22,416 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~788.2m/826466080, currentsize=199.8m/209497840 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 13856ms, sequenceid=14884, compaction requested=true
2014-07-14 03:11:22,416 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:114), split_queue=0, merge_queue=0
2014-07-14 03:11:22,416 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 442.0m
2014-07-14 03:11:22,734 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:11:22,923 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14971, memsize=96.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/61d1c4af05aa4f25a50ba55ce77716c5
2014-07-14 03:11:22,937 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/61d1c4af05aa4f25a50ba55ce77716c5 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/61d1c4af05aa4f25a50ba55ce77716c5
2014-07-14 03:11:22,956 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/61d1c4af05aa4f25a50ba55ce77716c5, entries=352260, sequenceid=14971, filesize=25.1m
2014-07-14 03:11:22,956 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~505.6m/530110480, currentsize=60.3m/63254800 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 5861ms, sequenceid=14971, compaction requested=true
2014-07-14 03:11:22,956 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:115), split_queue=0, merge_queue=0
2014-07-14 03:11:27,760 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15013, memsize=125.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/7d3b4afaf9514a13a3c7dc94932bf58d
2014-07-14 03:11:27,776 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/7d3b4afaf9514a13a3c7dc94932bf58d as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7d3b4afaf9514a13a3c7dc94932bf58d
2014-07-14 03:11:27,787 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7d3b4afaf9514a13a3c7dc94932bf58d, entries=457430, sequenceid=15013, filesize=32.6m
2014-07-14 03:11:27,788 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~442.0m/463435520, currentsize=9.4m/9901200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 5372ms, sequenceid=15013, compaction requested=true
2014-07-14 03:11:27,789 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:116), split_queue=0, merge_queue=0
2014-07-14 03:11:30,070 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:30,102 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332679447 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332690070
2014-07-14 03:11:41,390 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:41,421 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332690070 with entries=73, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332701391
2014-07-14 03:11:41,520 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:11:41,520 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.2m
2014-07-14 03:11:41,693 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:11:42,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:42,907 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60106 synced till here 60105
2014-07-14 03:11:43,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332701391 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332702870
2014-07-14 03:11:45,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:45,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60209 synced till here 60199
2014-07-14 03:11:46,135 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332702870 with entries=103, filesize=87.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332705125
2014-07-14 03:11:46,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:11:46,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:46,951 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60304 synced till here 60289
2014-07-14 03:11:47,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332705125 with entries=95, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332706894
2014-07-14 03:11:47,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:11:49,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:49,642 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60409 synced till here 60388
2014-07-14 03:11:49,729 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:11:49,729 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 259.1m
2014-07-14 03:11:49,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332706894 with entries=105, filesize=89.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332709618
2014-07-14 03:11:49,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:11:50,173 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:11:50,253 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15050, memsize=145.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f9cb748e37894cc6a51327dda13a9523
2014-07-14 03:11:50,349 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f9cb748e37894cc6a51327dda13a9523 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9cb748e37894cc6a51327dda13a9523
2014-07-14 03:11:50,387 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9cb748e37894cc6a51327dda13a9523, entries=531320, sequenceid=15050, filesize=37.9m
2014-07-14 03:11:50,387 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.2m/268628320, currentsize=155.0m/162565760 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 8867ms, sequenceid=15050, compaction requested=true
2014-07-14 03:11:50,388 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-14 03:11:51,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:51,562 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60519 synced till here 60493
2014-07-14 03:11:52,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332709618 with entries=110, filesize=94.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332711473
2014-07-14 03:11:52,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:11:53,914 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:53,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60607 synced till here 60592
2014-07-14 03:11:54,607 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332711473 with entries=88, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332713914
2014-07-14 03:11:54,608 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:11:56,048 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:11:56,049 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files; delaying flush up to 90000ms
2014-07-14 03:11:56,049 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-14 03:11:57,430 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:11:58,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60712 synced till here 60707
2014-07-14 03:11:58,448 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332713914 with entries=105, filesize=89.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332717430
2014-07-14 03:11:58,448 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:11:59,605 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:11:59,633 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 275.9m
2014-07-14 03:11:59,888 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:00,717 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60819 synced till here 60784
2014-07-14 03:12:01,605 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15146, memsize=190.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/6acbfd0f62724f5289f52e22bb7cbf6c
2014-07-14 03:12:01,624 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/6acbfd0f62724f5289f52e22bb7cbf6c as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6acbfd0f62724f5289f52e22bb7cbf6c
2014-07-14 03:12:01,694 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:01,742 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332717430 with entries=107, filesize=91.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332719889
2014-07-14 03:12:01,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:12:01,791 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6acbfd0f62724f5289f52e22bb7cbf6c, entries=694920, sequenceid=15146, filesize=49.5m
2014-07-14 03:12:01,791 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~270.0m/283109440, currentsize=153.7m/161179200 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 12062ms, sequenceid=15146, compaction requested=true
2014-07-14 03:12:01,792 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-14 03:12:03,249 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1038ms
GC pool 'ParNew' had collection(s): count=1 time=1062ms
2014-07-14 03:12:03,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:03,670 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60930 synced till here 60899
2014-07-14 03:12:03,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332719889 with entries=111, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332723649
2014-07-14 03:12:03,986 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:12:05,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:05,318 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61034 synced till here 61007
2014-07-14 03:12:05,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332723649 with entries=104, filesize=87.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332725302
2014-07-14 03:12:05,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:12:05,724 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/5f36168043d04b54915caf036159ed28 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/5f36168043d04b54915caf036159ed28
2014-07-14 03:12:05,878 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:12:05,950 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 1.5g
2014-07-14 03:12:05,985 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:12:05,993 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/d3944f55c0314e95a8a6b5c1562f3ac0, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/d3944f55c0314e95a8a6b5c1562f3ac0
2014-07-14 03:12:06,124 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec2060d272084041a58e0a640d89ae50, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec2060d272084041a58e0a640d89ae50
2014-07-14 03:12:06,137 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1fffb2fc3fe34f3eb0fc575e4eb76ac8, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/1fffb2fc3fe34f3eb0fc575e4eb76ac8
2014-07-14 03:12:06,144 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/574b67612cc24c3c85d9013b47a771ad, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/574b67612cc24c3c85d9013b47a771ad
2014-07-14 03:12:06,153 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/24cab3e8b863443ca21bfc220773204b, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/24cab3e8b863443ca21bfc220773204b
2014-07-14 03:12:06,164 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25b3a90ad4254a4db34b6f25aa0a3c85, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/25b3a90ad4254a4db34b6f25aa0a3c85
2014-07-14 03:12:06,741 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/73115d9b68f44465b0081b867c554cd7, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/73115d9b68f44465b0081b867c554cd7
2014-07-14 03:12:06,745 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/c440e72bc9594ec5800340f0942fb923, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/c440e72bc9594ec5800340f0942fb923
2014-07-14 03:12:06,749 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ba77e984183d4582937f9a841be7b2cd, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ba77e984183d4582937f9a841be7b2cd
2014-07-14 03:12:06,753 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ada31c1fcf6f48d88eb8a2d1535ade91, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ada31c1fcf6f48d88eb8a2d1535ade91
2014-07-14 03:12:06,753 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 5f36168043d04b54915caf036159ed28(size=927.9m), total size for store is 2.8g. This selection was in queue for 0sec, and took 3mins, 24sec to execute.
2014-07-14 03:12:06,754 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=10, fileSize=1.0g, priority=2, time=286429727864202; duration=3mins, 24sec
2014-07-14 03:12:06,754 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-14 03:12:06,754 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:12:06,759 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 305074781 starting at candidate #6 after considering 124 permutations with 114 in ratio
2014-07-14 03:12:06,759 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating minor compaction
2014-07-14 03:12:06,760 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:12:06,760 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=290.9m
2014-07-14 03:12:06,760 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/55017e76254b453ab438e14dcf1edc82, keycount=102700, bloomtype=ROW, size=73.1m, encoding=NONE, seqNum=7643
2014-07-14 03:12:06,760 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ee6eb26fe7d94c7394ab48bd7d31bbfe, keycount=134056, bloomtype=ROW, size=95.4m, encoding=NONE, seqNum=8131
2014-07-14 03:12:06,760 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7951c585794b499c84a6dc40ffae830f, keycount=89372, bloomtype=ROW, size=63.7m, encoding=NONE, seqNum=8659
2014-07-14 03:12:06,760 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3ad8983f5d954a769ff77626cc1f787a, keycount=82446, bloomtype=ROW, size=58.7m, encoding=NONE, seqNum=9144
2014-07-14 03:12:06,792 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:06,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61113 synced till here 61106
2014-07-14 03:12:06,873 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:06,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332725302 with entries=79, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332726792
2014-07-14 03:12:07,686 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15239, memsize=82.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/0fae34243bc841809be31f0c255c76e2
2014-07-14 03:12:07,700 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/0fae34243bc841809be31f0c255c76e2 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/0fae34243bc841809be31f0c255c76e2
2014-07-14 03:12:07,709 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/0fae34243bc841809be31f0c255c76e2, entries=299570, sequenceid=15239, filesize=21.4m
2014-07-14 03:12:07,710 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~291.2m/305303840, currentsize=125.5m/131590080 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 8077ms, sequenceid=15239, compaction requested=true
2014-07-14 03:12:07,710 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-14 03:12:07,710 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 264.0m
2014-07-14 03:12:07,841 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:08,016 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:09,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:09,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61215 synced till here 61204
2014-07-14 03:12:09,953 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332726792 with entries=102, filesize=86.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332729639
2014-07-14 03:12:10,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:10,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61290 synced till here 61287
2014-07-14 03:12:11,228 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15317, memsize=55.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/249102027d454ecc8e09f4c59f4b38bc
2014-07-14 03:12:11,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332729639 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332730943
2014-07-14 03:12:11,291 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/249102027d454ecc8e09f4c59f4b38bc as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/249102027d454ecc8e09f4c59f4b38bc
2014-07-14 03:12:11,301 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/249102027d454ecc8e09f4c59f4b38bc, entries=203640, sequenceid=15317, filesize=14.5m
2014-07-14 03:12:11,301 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.0m/276832800, currentsize=69.7m/73091760 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 3591ms, sequenceid=15317, compaction requested=true
2014-07-14 03:12:11,302 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-14 03:12:20,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:20,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61365 synced till here 61362
2014-07-14 03:12:20,437 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332730943 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332740363
2014-07-14 03:12:21,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:21,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61438 synced till here 61436
2014-07-14 03:12:21,725 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332740363 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332741320
2014-07-14 03:12:22,013 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:12:22,014 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 259.0m
2014-07-14 03:12:22,225 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:23,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:24,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61512 synced till here 61511
2014-07-14 03:12:24,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332741320 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332743748
2014-07-14 03:12:26,203 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:26,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61587 synced till here 61585
2014-07-14 03:12:27,094 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332743748 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332746203
2014-07-14 03:12:27,917 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15411, memsize=144.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e0c9de28db7c4a76be68fc8bd70d96bd
2014-07-14 03:12:27,928 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/e0c9de28db7c4a76be68fc8bd70d96bd as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e0c9de28db7c4a76be68fc8bd70d96bd
2014-07-14 03:12:27,939 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e0c9de28db7c4a76be68fc8bd70d96bd, entries=526160, sequenceid=15411, filesize=37.5m
2014-07-14 03:12:27,939 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~265.3m/278165920, currentsize=46.5m/48740320 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 5925ms, sequenceid=15411, compaction requested=true
2014-07-14 03:12:27,940 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:121), split_queue=0, merge_queue=0
2014-07-14 03:12:30,399 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15322, memsize=497.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/0199c89cb3154940ba863e9565941484
2014-07-14 03:12:30,410 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/0199c89cb3154940ba863e9565941484 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/0199c89cb3154940ba863e9565941484
2014-07-14 03:12:30,417 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/0199c89cb3154940ba863e9565941484, entries=1810200, sequenceid=15322, filesize=129.0m
2014-07-14 03:12:30,417 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.5g/1583203760, currentsize=185.5m/194476000 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 24467ms, sequenceid=15322, compaction requested=true
2014-07-14 03:12:30,418 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-14 03:12:42,666 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:42,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61659 synced till here 61658
2014-07-14 03:12:42,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332746203 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332762667
2014-07-14 03:12:42,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332606789
2014-07-14 03:12:42,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332608158
2014-07-14 03:12:42,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332609689
2014-07-14 03:12:42,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332611406
2014-07-14 03:12:42,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332613290
2014-07-14 03:12:42,707 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332615111
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332616349
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332617484
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332619445
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332622097
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332623770
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332625796
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332627536
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332629465
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332631292
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332638281
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332640186
2014-07-14 03:12:42,708 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332642359
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332644484
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332646941
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332648706
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332651213
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332654212
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332655772
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332669448
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332671381
2014-07-14 03:12:42,709 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332672673
2014-07-14 03:12:42,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332677134
2014-07-14 03:12:42,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332678514
2014-07-14 03:12:44,011 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:44,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61743 synced till here 61742
2014-07-14 03:12:44,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332762667 with entries=84, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332764011
2014-07-14 03:12:44,909 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:12:44,909 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.1m
2014-07-14 03:12:44,961 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:12:44,962 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 257.0m
2014-07-14 03:12:45,083 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:45,142 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:47,809 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/064fa18c9c58461ab0e7606cc6865d8d as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/064fa18c9c58461ab0e7606cc6865d8d
2014-07-14 03:12:47,826 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:12:47,836 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/55017e76254b453ab438e14dcf1edc82, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/55017e76254b453ab438e14dcf1edc82
2014-07-14 03:12:47,839 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ee6eb26fe7d94c7394ab48bd7d31bbfe, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/ee6eb26fe7d94c7394ab48bd7d31bbfe
2014-07-14 03:12:47,841 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7951c585794b499c84a6dc40ffae830f, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7951c585794b499c84a6dc40ffae830f
2014-07-14 03:12:47,844 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3ad8983f5d954a769ff77626cc1f787a, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3ad8983f5d954a769ff77626cc1f787a
2014-07-14 03:12:47,844 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into 064fa18c9c58461ab0e7606cc6865d8d(size=265.5m), total size for store is 2.9g. This selection was in queue for 0sec, and took 41sec to execute.
2014-07-14 03:12:47,844 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=4, fileSize=290.9m, priority=-1, time=286634186621047; duration=41sec
2014-07-14 03:12:47,844 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-14 03:12:47,845 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:12:47,850 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 101397003 starting at candidate #18 after considering 124 permutations with 116 in ratio
2014-07-14 03:12:47,850 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating minor compaction
2014-07-14 03:12:47,850 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:12:47,851 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=96.7m
2014-07-14 03:12:47,851 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9cb748e37894cc6a51327dda13a9523, keycount=53132, bloomtype=ROW, size=37.9m, encoding=NONE, seqNum=15050
2014-07-14 03:12:47,851 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/0fae34243bc841809be31f0c255c76e2, keycount=29957, bloomtype=ROW, size=21.4m, encoding=NONE, seqNum=15239
2014-07-14 03:12:47,851 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e0c9de28db7c4a76be68fc8bd70d96bd, keycount=52616, bloomtype=ROW, size=37.5m, encoding=NONE, seqNum=15411
2014-07-14 03:12:47,875 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:48,754 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:48,787 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332764011 with entries=73, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332768755
2014-07-14 03:12:52,851 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15489, memsize=239.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ec1eed89a07e4449ae1ed8efbcce2db2
2014-07-14 03:12:52,870 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/ec1eed89a07e4449ae1ed8efbcce2db2 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec1eed89a07e4449ae1ed8efbcce2db2
2014-07-14 03:12:52,892 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec1eed89a07e4449ae1ed8efbcce2db2, entries=871420, sequenceid=15489, filesize=62.1m
2014-07-14 03:12:52,892 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270252560, currentsize=32.5m/34074960 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 7983ms, sequenceid=15489, compaction requested=true
2014-07-14 03:12:52,892 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-14 03:12:52,892 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 759.4m
2014-07-14 03:12:53,502 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:53,527 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61893 synced till here 61890
2014-07-14 03:12:53,576 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332768755 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332773503
2014-07-14 03:12:53,614 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15484, memsize=239.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f22a57b19dd34cbbbc8d3ab00c4872d9
2014-07-14 03:12:53,628 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f22a57b19dd34cbbbc8d3ab00c4872d9 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f22a57b19dd34cbbbc8d3ab00c4872d9
2014-07-14 03:12:53,640 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f22a57b19dd34cbbbc8d3ab00c4872d9, entries=873060, sequenceid=15484, filesize=62.2m
2014-07-14 03:12:53,640 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.6m/271167440, currentsize=46.8m/49024560 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8678ms, sequenceid=15484, compaction requested=true
2014-07-14 03:12:53,640 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-14 03:12:53,770 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:12:54,605 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:55,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61997 synced till here 61995
2014-07-14 03:12:55,296 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332773503 with entries=104, filesize=89.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332774605
2014-07-14 03:12:58,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:12:58,322 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62071 synced till here 62070
2014-07-14 03:12:58,741 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332774605 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332778293
2014-07-14 03:13:00,933 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/3edbf950d48e4b638870c1a330c5524a as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3edbf950d48e4b638870c1a330c5524a
2014-07-14 03:13:00,949 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:13:00,969 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9cb748e37894cc6a51327dda13a9523, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9cb748e37894cc6a51327dda13a9523
2014-07-14 03:13:00,973 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/0fae34243bc841809be31f0c255c76e2, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/0fae34243bc841809be31f0c255c76e2
2014-07-14 03:13:00,976 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e0c9de28db7c4a76be68fc8bd70d96bd, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e0c9de28db7c4a76be68fc8bd70d96bd
2014-07-14 03:13:00,976 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into 3edbf950d48e4b638870c1a330c5524a(size=82.2m), total size for store is 3.0g. This selection was in queue for 0sec, and took 13sec to execute.
2014-07-14 03:13:00,976 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=3, fileSize=96.7m, priority=-1, time=286675277022610; duration=13sec
2014-07-14 03:13:00,977 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-14 03:13:00,977 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 18 store files, 0 compacting, 18 eligible, 20 blocking
2014-07-14 03:13:00,979 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 1194433813 starting at candidate #8 after considering 100 permutations with 91 in ratio
2014-07-14 03:13:00,979 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating minor compaction
2014-07-14 03:13:00,979 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:13:00,979 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=1.1g
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/87cd1176f0da4daa96f054d0fda238f5, keycount=290755, bloomtype=ROW, size=206.8m, encoding=NONE, seqNum=10098
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3a7e17cacba3457e9178d1b28d1c730a, keycount=111825, bloomtype=ROW, size=79.7m, encoding=NONE, seqNum=10665
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/69dc568c29cb492ca88fa57573216f74, keycount=160345, bloomtype=ROW, size=114.2m, encoding=NONE, seqNum=11282
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c75e87a89cdc40c7a92ee4d26b1389ca, keycount=147303, bloomtype=ROW, size=104.9m, encoding=NONE, seqNum=11726
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/81ddf15644ec4b809644ee3d6e170149, keycount=163090, bloomtype=ROW, size=116.1m, encoding=NONE, seqNum=12344
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e08ad62a63af45acbac423a83e22f0a0, keycount=145349, bloomtype=ROW, size=103.4m, encoding=NONE, seqNum=12909
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/4bdd6d2f5adc4122a39d294492ed0217, keycount=144774, bloomtype=ROW, size=103.2m, encoding=NONE, seqNum=13519
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5b71fe3b2c1b45ffb91eadebb85d7108, keycount=145343, bloomtype=ROW, size=103.6m, encoding=NONE, seqNum=14066
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c12dd83afc14fbd9c851186d25263a6, keycount=245303, bloomtype=ROW, size=174.7m, encoding=NONE, seqNum=14725
2014-07-14 03:13:00,980 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7d3b4afaf9514a13a3c7dc94932bf58d, keycount=45743, bloomtype=ROW, size=32.6m, encoding=NONE, seqNum=15013
2014-07-14 03:13:01,244 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:02,032 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:13:02,032 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.5m
2014-07-14 03:13:02,113 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:02,138 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62147 synced till here 62146
2014-07-14 03:13:02,168 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332778293 with entries=76, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332782113
2014-07-14 03:13:02,284 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:03,499 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:03,633 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62228 synced till here 62227
2014-07-14 03:13:03,653 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332782113 with entries=81, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332783499
2014-07-14 03:13:06,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:06,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62307 synced till here 62302
2014-07-14 03:13:07,031 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332783499 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332786864
2014-07-14 03:13:07,998 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15507, memsize=372.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e4714ba6bf094f48be31b1edf00d5bf1
2014-07-14 03:13:08,010 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/e4714ba6bf094f48be31b1edf00d5bf1 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e4714ba6bf094f48be31b1edf00d5bf1
2014-07-14 03:13:08,028 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e4714ba6bf094f48be31b1edf00d5bf1, entries=1356760, sequenceid=15507, filesize=96.6m
2014-07-14 03:13:08,029 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~761.0m/797988720, currentsize=187.9m/197076480 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 15136ms, sequenceid=15507, compaction requested=true
2014-07-14 03:13:08,029 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-14 03:13:08,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:08,972 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332786864 with entries=82, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332788541
2014-07-14 03:13:08,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332679447
2014-07-14 03:13:08,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332690070
2014-07-14 03:13:08,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332701391
2014-07-14 03:13:08,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332702870
2014-07-14 03:13:08,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332705125
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332706894
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332709618
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332711473
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332713914
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332717430
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332719889
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332723649
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332725302
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332726792
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332729639
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332730943
2014-07-14 03:13:08,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332740363
2014-07-14 03:13:10,809 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15579, memsize=257.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/c1fcd27ac6044c1094c763f0699b2866
2014-07-14 03:13:10,820 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/c1fcd27ac6044c1094c763f0699b2866 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c1fcd27ac6044c1094c763f0699b2866
2014-07-14 03:13:10,833 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c1fcd27ac6044c1094c763f0699b2866, entries=939000, sequenceid=15579, filesize=66.9m
2014-07-14 03:13:10,833 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.9m/270424560, currentsize=105.8m/110887680 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 8801ms, sequenceid=15579, compaction requested=true
2014-07-14 03:13:10,834 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-14 03:13:11,352 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:13:11,352 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.2m
2014-07-14 03:13:11,417 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:13:11,418 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.8m
2014-07-14 03:13:11,574 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:11,927 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:11,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:12,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62475 synced till here 62472
2014-07-14 03:13:12,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332788541 with entries=86, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332791981
2014-07-14 03:13:12,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332741320
2014-07-14 03:13:12,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332743748
2014-07-14 03:13:12,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332746203
2014-07-14 03:13:12,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332762667
2014-07-14 03:13:13,058 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:13:13,603 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:13,644 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332791981 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332793603
2014-07-14 03:13:19,534 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15656, memsize=257.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/14b0fab44c414c908102d161a97853cd
2014-07-14 03:13:19,546 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/14b0fab44c414c908102d161a97853cd as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14b0fab44c414c908102d161a97853cd
2014-07-14 03:13:19,562 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14b0fab44c414c908102d161a97853cd, entries=938260, sequenceid=15656, filesize=66.8m
2014-07-14 03:13:19,562 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.7m/270211600, currentsize=63.8m/66885360 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 8210ms, sequenceid=15656, compaction requested=true
2014-07-14 03:13:19,563 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:125), split_queue=0, merge_queue=0
2014-07-14 03:13:19,563 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 290.6m
2014-07-14 03:13:19,727 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:19,925 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:20,322 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62626 synced till here 62624
2014-07-14 03:13:20,337 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332793603 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332799925
2014-07-14 03:13:20,880 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15652, memsize=259.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/1714123abc894347b180b29dc806c20c
2014-07-14 03:13:20,893 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/1714123abc894347b180b29dc806c20c as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/1714123abc894347b180b29dc806c20c
2014-07-14 03:13:20,904 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/1714123abc894347b180b29dc806c20c, entries=946260, sequenceid=15652, filesize=67.4m
2014-07-14 03:13:20,904 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.9m/272514800, currentsize=83.3m/87379520 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9487ms, sequenceid=15652, compaction requested=true
2014-07-14 03:13:20,904 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-14 03:13:21,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:21,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62702 synced till here 62698
2014-07-14 03:13:21,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332799925 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332801159
2014-07-14 03:13:21,217 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332764011
2014-07-14 03:13:22,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:23,214 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62793 synced till here 62792
2014-07-14 03:13:23,236 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332801159 with entries=91, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332802567
2014-07-14 03:13:23,413 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:13:23,414 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 256.5m
2014-07-14 03:13:23,609 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:24,268 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:24,312 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62869 synced till here 62866
2014-07-14 03:13:24,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332802567 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332804269
2014-07-14 03:13:25,743 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:25,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62944 synced till here 62943
2014-07-14 03:13:25,812 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332804269 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332805743
2014-07-14 03:13:27,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:27,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63036 synced till here 63035
2014-07-14 03:13:27,795 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332805743 with entries=92, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332807241
2014-07-14 03:13:29,651 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:13:30,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:30,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332807241 with entries=72, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332810109
2014-07-14 03:13:30,237 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:13:30,250 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15695, memsize=290.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/c940c5b9e5a8437ba5e86b6aa7a29ad7
2014-07-14 03:13:30,263 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/c940c5b9e5a8437ba5e86b6aa7a29ad7 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c940c5b9e5a8437ba5e86b6aa7a29ad7
2014-07-14 03:13:30,273 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c940c5b9e5a8437ba5e86b6aa7a29ad7, entries=1057950, sequenceid=15695, filesize=75.3m
2014-07-14 03:13:30,273 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~290.6m/304681920, currentsize=192.8m/202201200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 10710ms, sequenceid=15695, compaction requested=true
2014-07-14 03:13:30,273 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:127), split_queue=0, merge_queue=0
2014-07-14 03:13:30,274 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 260.8m
2014-07-14 03:13:30,436 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:32,368 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15746, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/476477d25b2d47a6aa2c1908239b6a9c
2014-07-14 03:13:32,392 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/476477d25b2d47a6aa2c1908239b6a9c as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/476477d25b2d47a6aa2c1908239b6a9c
2014-07-14 03:13:32,409 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/476477d25b2d47a6aa2c1908239b6a9c, entries=939420, sequenceid=15746, filesize=66.9m
2014-07-14 03:13:32,409 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.0m/270544800, currentsize=139.5m/146323520 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 8995ms, sequenceid=15746, compaction requested=true
2014-07-14 03:13:32,409 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:128), split_queue=0, merge_queue=0
2014-07-14 03:13:32,410 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 277.3m
2014-07-14 03:13:32,559 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:32,989 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:33,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332810109 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332812990
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332768755
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332773503
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332774605
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332778293
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332782113
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332783499
2014-07-14 03:13:33,201 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332786864
2014-07-14 03:13:34,939 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:34,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63266 synced till here 63265
2014-07-14 03:13:34,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332812990 with entries=83, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332814939
2014-07-14 03:13:35,207 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:13:36,267 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:36,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63347 synced till here 63340
2014-07-14 03:13:36,477 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332814939 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332816370
2014-07-14 03:13:38,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:38,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63425 synced till here 63421
2014-07-14 03:13:38,482 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332816370 with entries=78, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332818277
2014-07-14 03:13:38,853 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15826, memsize=262.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/bdccb9a24ca8492aa3f3f5f8c6fc673e
2014-07-14 03:13:38,865 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/bdccb9a24ca8492aa3f3f5f8c6fc673e as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bdccb9a24ca8492aa3f3f5f8c6fc673e
2014-07-14 03:13:38,883 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bdccb9a24ca8492aa3f3f5f8c6fc673e, entries=955060, sequenceid=15826, filesize=68.0m
2014-07-14 03:13:38,883 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~262.3m/275048480, currentsize=120.9m/126725840 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 8609ms, sequenceid=15826, compaction requested=true
2014-07-14 03:13:38,883 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:129), split_queue=0, merge_queue=0
2014-07-14 03:13:38,884 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 320.5m
2014-07-14 03:13:39,088 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:39,721 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:13:39,965 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:39,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63499 synced till here 63498
2014-07-14 03:13:39,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332818277 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332819965
2014-07-14 03:13:41,811 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15832, memsize=277.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ebae0da248eb4d6ba738430fbf3cfeb9
2014-07-14 03:13:41,825 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ebae0da248eb4d6ba738430fbf3cfeb9 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ebae0da248eb4d6ba738430fbf3cfeb9
2014-07-14 03:13:41,838 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ebae0da248eb4d6ba738430fbf3cfeb9, entries=1009810, sequenceid=15832, filesize=71.9m
2014-07-14 03:13:41,839 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~277.3m/290816800, currentsize=155.8m/163343200 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9429ms, sequenceid=15832, compaction requested=true
2014-07-14 03:13:41,839 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-14 03:13:41,839 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:13:41,839 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-14 03:13:41,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:41,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63574 synced till here 63571
2014-07-14 03:13:41,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332819965 with entries=75, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332821887
2014-07-14 03:13:41,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332788541
2014-07-14 03:13:41,962 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332791981
2014-07-14 03:13:43,547 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:43,728 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63655 synced till here 63648
2014-07-14 03:13:43,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332821887 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332823547
2014-07-14 03:13:45,455 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:45,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63735 synced till here 63729
2014-07-14 03:13:45,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332823547 with entries=80, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332825456
2014-07-14 03:13:47,383 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:13:47,383 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.4m
2014-07-14 03:13:47,569 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:47,823 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:47,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332825456 with entries=72, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332827823
2014-07-14 03:13:48,321 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:13:50,224 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:50,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63881 synced till here 63878
2014-07-14 03:13:50,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332827823 with entries=74, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332830224
2014-07-14 03:13:50,893 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15902, memsize=320.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/03e6c897201c42f4be55e18b23f11dcb
2014-07-14 03:13:50,907 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/03e6c897201c42f4be55e18b23f11dcb as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/03e6c897201c42f4be55e18b23f11dcb
2014-07-14 03:13:50,923 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/03e6c897201c42f4be55e18b23f11dcb, entries=1167120, sequenceid=15902, filesize=83.1m
2014-07-14 03:13:50,923 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~320.5m/336120640, currentsize=177.8m/186411440 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 12039ms, sequenceid=15902, compaction requested=true
2014-07-14 03:13:50,924 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:132), split_queue=0, merge_queue=0
2014-07-14 03:13:50,924 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 287.3m
2014-07-14 03:13:51,178 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:13:51,658 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:51,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63965 synced till here 63956
2014-07-14 03:13:52,050 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332830224 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332831658
2014-07-14 03:13:52,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332793603
2014-07-14 03:13:52,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332799925
2014-07-14 03:13:52,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332801159
2014-07-14 03:13:53,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:53,608 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332831658 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332833277
2014-07-14 03:13:54,745 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:13:55,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:55,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64129 synced till here 64124
2014-07-14 03:13:55,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332833277 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332835085
2014-07-14 03:13:56,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:13:56,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64210 synced till here 64208
2014-07-14 03:13:56,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332835085 with entries=81, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332836832
2014-07-14 03:13:57,799 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15993, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/fd166056397042a085a13fa0c7d58591
2014-07-14 03:13:57,811 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/fd166056397042a085a13fa0c7d58591 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/fd166056397042a085a13fa0c7d58591
2014-07-14 03:13:57,824 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/fd166056397042a085a13fa0c7d58591, entries=939500, sequenceid=15993, filesize=66.9m
2014-07-14 03:13:57,824 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.0m/270569120, currentsize=171.3m/179661040 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 10441ms, sequenceid=15993, compaction requested=true
2014-07-14 03:13:57,825 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-14 03:13:57,825 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files; delaying flush up to 90000ms
2014-07-14 03:13:57,825 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-14 03:14:02,544 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16020, memsize=290.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/91b5546b51d74db28da15c89ee467f3e
2014-07-14 03:14:02,558 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/91b5546b51d74db28da15c89ee467f3e as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/91b5546b51d74db28da15c89ee467f3e
2014-07-14 03:14:02,568 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/91b5546b51d74db28da15c89ee467f3e, entries=1057390, sequenceid=16020, filesize=75.3m
2014-07-14 03:14:02,568 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~290.4m/304519920, currentsize=142.1m/149020800 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 11644ms, sequenceid=16020, compaction requested=true
2014-07-14 03:14:02,569 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:135), split_queue=0, merge_queue=0
2014-07-14 03:14:02,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:02,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332836832 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332842883
2014-07-14 03:14:04,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:04,437 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64358 synced till here 64354
2014-07-14 03:14:04,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332842883 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332844401
2014-07-14 03:14:05,568 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:05,600 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64435 synced till here 64432
2014-07-14 03:14:05,630 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:14:05,630 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.5m
2014-07-14 03:14:05,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332844401 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332845569
2014-07-14 03:14:06,104 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:14:06,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:06,840 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332845569 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332846819
2014-07-14 03:14:07,894 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:14:07,898 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files; delaying flush up to 90000ms
2014-07-14 03:14:07,898 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-14 03:14:08,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:08,060 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64588 synced till here 64580
2014-07-14 03:14:08,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332846819 with entries=81, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332848020
2014-07-14 03:14:10,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:10,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64662 synced till here 64659
2014-07-14 03:14:10,158 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332848020 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332850119
2014-07-14 03:14:11,615 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:11,648 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64739 synced till here 64733
2014-07-14 03:14:11,716 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332850119 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332851615
2014-07-14 03:14:13,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:13,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64815 synced till here 64810
2014-07-14 03:14:13,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332851615 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332853323
2014-07-14 03:14:14,902 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:14,936 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332853323 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332854902
2014-07-14 03:14:15,780 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16159, memsize=245.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/bad04fbfdde943ed94a3772cb673c556
2014-07-14 03:14:15,794 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/bad04fbfdde943ed94a3772cb673c556 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bad04fbfdde943ed94a3772cb673c556
2014-07-14 03:14:16,124 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bad04fbfdde943ed94a3772cb673c556, entries=894180, sequenceid=16159, filesize=63.7m
2014-07-14 03:14:16,125 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.5m/268973280, currentsize=189.1m/198304800 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 10494ms, sequenceid=16159, compaction requested=true
2014-07-14 03:14:16,125 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:137), split_queue=0, merge_queue=0
2014-07-14 03:14:17,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:17,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332854902 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332857018
2014-07-14 03:14:19,000 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:19,111 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65045 synced till here 65039
2014-07-14 03:14:19,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332857018 with entries=82, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332859001
2014-07-14 03:14:19,840 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:14:19,841 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 257.5m
2014-07-14 03:14:20,003 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:14:20,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:20,424 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65121 synced till here 65119
2014-07-14 03:14:20,464 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332859001 with entries=76, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332860402
2014-07-14 03:14:27,480 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16326, memsize=231.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/31b98797489b4499bef00173753418a3
2014-07-14 03:14:27,534 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/31b98797489b4499bef00173753418a3 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/31b98797489b4499bef00173753418a3
2014-07-14 03:14:27,552 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/31b98797489b4499bef00173753418a3, entries=842070, sequenceid=16326, filesize=60.0m
2014-07-14 03:14:27,555 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.5m/270012000, currentsize=19.6m/20579600 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 7712ms, sequenceid=16326, compaction requested=true
2014-07-14 03:14:27,555 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:138), split_queue=0, merge_queue=0
2014-07-14 03:14:28,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:28,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332860402 with entries=72, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332868694
2014-07-14 03:14:31,533 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:31,560 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65268 synced till here 65266
2014-07-14 03:14:31,615 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332868694 with entries=75, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332871534
2014-07-14 03:14:33,234 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:33,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65340 synced till here 65339
2014-07-14 03:14:33,285 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332871534 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332873234
2014-07-14 03:14:33,286 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:37,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:37,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332873234 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332877810
2014-07-14 03:14:37,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:39,208 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:39,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65508 synced till here 65501
2014-07-14 03:14:39,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332877810 with entries=96, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332879208
2014-07-14 03:14:39,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:41,125 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:41,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65582 synced till here 65581
2014-07-14 03:14:41,188 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332879208 with entries=74, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332881126
2014-07-14 03:14:41,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:43,407 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:43,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332881126 with entries=86, filesize=74.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332883407
2014-07-14 03:14:43,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:45,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:45,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65746 synced till here 65742
2014-07-14 03:14:45,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332883407 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332885379
2014-07-14 03:14:45,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:45,477 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:14:45,477 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.4m
2014-07-14 03:14:45,649 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:14:46,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:46,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65820 synced till here 65819
2014-07-14 03:14:46,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332885379 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332886618
2014-07-14 03:14:46,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:48,013 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:14:48,028 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65894 synced till here 65892
2014-07-14 03:14:48,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332886618 with entries=74, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332888014
2014-07-14 03:14:48,045 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:14:53,704 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16493, memsize=241.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/e43243fdda484b428d433057075717b0
2014-07-14 03:14:53,725 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/e43243fdda484b428d433057075717b0 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e43243fdda484b428d433057075717b0
2014-07-14 03:14:53,810 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e43243fdda484b428d433057075717b0, entries=877410, sequenceid=16493, filesize=62.5m
2014-07-14 03:14:53,811 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.0m/270563440, currentsize=64.7m/67839200 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 8334ms, sequenceid=16493, compaction requested=true
2014-07-14 03:14:53,811 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:139), split_queue=0, merge_queue=0
2014-07-14 03:15:07,157 DEBUG [LruStats #0] hfile.LruBlockCache: Total=6.16 MB, free=3.95 GB, max=3.96 GB, blocks=20, accesses=393557, hits=111751, hitRatio=28.39%, , cachingAccesses=111799, cachingHits=111700, cachingHitsRatio=99.91%, evictions=0, evicted=79, evictedPerRun=Infinity
2014-07-14 03:15:07,753 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:07,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332888014 with entries=71, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332907753
2014-07-14 03:15:07,819 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:15:09,537 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:09,767 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90046ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:15:09,767 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 1.2g
2014-07-14 03:15:10,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66079 synced till here 66075
2014-07-14 03:15:10,526 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332907753 with entries=114, filesize=97.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332909538
2014-07-14 03:15:11,148 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:15:11,435 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:12,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66175 synced till here 66174
2014-07-14 03:15:12,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332909538 with entries=96, filesize=82.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332911435
2014-07-14 03:15:13,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:13,475 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66249 synced till here 66248
2014-07-14 03:15:13,901 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332911435 with entries=74, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332913460
2014-07-14 03:15:14,656 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:14,688 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66325 synced till here 66323
2014-07-14 03:15:14,731 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332913460 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332914656
2014-07-14 03:15:16,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:16,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66411 synced till here 66406
2014-07-14 03:15:17,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332914656 with entries=86, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332916636
2014-07-14 03:15:17,400 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:15:17,400 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.1m
2014-07-14 03:15:17,668 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:15:18,414 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:18,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332916636 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332918414
2014-07-14 03:15:19,830 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:20,005 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66571 synced till here 66565
2014-07-14 03:15:20,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332918414 with entries=87, filesize=74.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332919830
2014-07-14 03:15:20,961 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,963 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,964 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,965 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,967 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,985 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,997 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,998 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,998 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:20,998 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,000 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,038 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,038 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,043 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,050 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,927 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:21,975 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,040 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,103 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,156 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,211 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,267 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,322 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,382 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,442 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,508 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,695 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,745 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,803 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,846 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,884 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,930 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:22,975 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:23,015 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:23,960 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:23,974 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,003 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,034 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,063 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,098 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,132 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,169 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,212 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,240 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,278 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,310 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,344 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,374 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:24,410 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:25,235 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:25,962 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:25,964 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:25,964 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:25,965 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:25,968 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:25,985 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:25,998 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:25,998 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:25,998 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:25,999 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:26,001 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:26,038 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:26,038 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:26,043 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:26,050 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:26,927 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:26,976 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:27,040 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:27,103 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:27,157 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:27,212 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:27,852 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:15:27,852 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5585ms
2014-07-14 03:15:27,853 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5530ms
2014-07-14 03:15:27,853 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5471ms
2014-07-14 03:15:27,853 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5411ms
2014-07-14 03:15:27,854 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5347ms
2014-07-14 03:15:27,854 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5159ms
2014-07-14 03:15:27,854 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5109ms
2014-07-14 03:15:27,854 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5051ms
2014-07-14 03:15:27,885 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:27,930 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:27,976 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:27,993 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16662, memsize=251.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/8c7b149ed0504198a7cb60e3ecb4deda
2014-07-14 03:15:28,005 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/8c7b149ed0504198a7cb60e3ecb4deda as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8c7b149ed0504198a7cb60e3ecb4deda
2014-07-14 03:15:28,014 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8c7b149ed0504198a7cb60e3ecb4deda, entries=915720, sequenceid=16662, filesize=65.2m
2014-07-14 03:15:28,015 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.8m/273503200, currentsize=71.1m/74552080 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 10615ms, sequenceid=16662, compaction requested=true
2014-07-14 03:15:28,015 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-14 03:15:28,015 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:28,015 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,015 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5040ms
2014-07-14 03:15:28,015 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,015 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 93270ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:15:28,016 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 1.2g
2014-07-14 03:15:28,017 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-14 03:15:28,017 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,017 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5133ms
2014-07-14 03:15:28,017 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,017 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5214ms
2014-07-14 03:15:28,017 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,021 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5276ms
2014-07-14 03:15:28,021 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,021 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5326ms
2014-07-14 03:15:28,021 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,021 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5514ms
2014-07-14 03:15:28,021 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,021 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5579ms
2014-07-14 03:15:28,022 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,022 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5640ms
2014-07-14 03:15:28,022 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,025 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5703ms
2014-07-14 03:15:28,025 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,025 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5758ms
2014-07-14 03:15:28,025 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,030 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5184ms
2014-07-14 03:15:28,030 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,032 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5821ms
2014-07-14 03:15:28,032 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,033 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5877ms
2014-07-14 03:15:28,033 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,033 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5930ms
2014-07-14 03:15:28,034 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,035 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5995ms
2014-07-14 03:15:28,035 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,037 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6062ms
2014-07-14 03:15:28,037 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,037 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6110ms
2014-07-14 03:15:28,037 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,037 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6987ms
2014-07-14 03:15:28,037 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,039 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6996ms
2014-07-14 03:15:28,039 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,042 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7004ms
2014-07-14 03:15:28,042 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,042 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7004ms
2014-07-14 03:15:28,042 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,043 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7043ms
2014-07-14 03:15:28,043 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,043 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7045ms
2014-07-14 03:15:28,043 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,043 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7046ms
2014-07-14 03:15:28,043 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,045 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7048ms
2014-07-14 03:15:28,045 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,045 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7048ms
2014-07-14 03:15:28,045 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,045 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7060ms
2014-07-14 03:15:28,045 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,046 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7079ms
2014-07-14 03:15:28,046 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,047 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7081ms
2014-07-14 03:15:28,047 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,053 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7089ms
2014-07-14 03:15:28,053 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,053 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7090ms
2014-07-14 03:15:28,053 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,053 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7092ms
2014-07-14 03:15:28,053 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,053 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2818ms
2014-07-14 03:15:28,053 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,054 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3644ms
2014-07-14 03:15:28,054 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,055 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3680ms
2014-07-14 03:15:28,055 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,055 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3711ms
2014-07-14 03:15:28,055 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,056 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3746ms
2014-07-14 03:15:28,056 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,097 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3820ms
2014-07-14 03:15:28,097 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,098 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3858ms
2014-07-14 03:15:28,098 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,098 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3886ms
2014-07-14 03:15:28,098 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,099 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3930ms
2014-07-14 03:15:28,099 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,099 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3967ms
2014-07-14 03:15:28,100 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,100 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4002ms
2014-07-14 03:15:28,100 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,101 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4037ms
2014-07-14 03:15:28,101 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,102 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4067ms
2014-07-14 03:15:28,102 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,102 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4099ms
2014-07-14 03:15:28,103 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,103 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4130ms
2014-07-14 03:15:28,103 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,103 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4143ms
2014-07-14 03:15:28,103 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:28,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:30,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66683 synced till here 66675
2014-07-14 03:15:30,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332919830 with entries=112, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332928818
2014-07-14 03:15:30,249 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:15:32,225 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:32,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66800 synced till here 66761
2014-07-14 03:15:32,396 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,397 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,397 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,400 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,402 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,404 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,406 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,407 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,408 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,411 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,413 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,413 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,417 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,420 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,420 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,422 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,423 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,423 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,424 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,424 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,425 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,427 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,498 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10179,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922319,"queuetimems":1,"class":"HRegionServer","responsesize":15529,"method":"Multi"}
2014-07-14 03:15:32,498 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922379,"queuetimems":0,"class":"HRegionServer","responsesize":15607,"method":"Multi"}
2014-07-14 03:15:32,499 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11451,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332921047,"queuetimems":0,"class":"HRegionServer","responsesize":16111,"method":"Multi"}
2014-07-14 03:15:32,501 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,502 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,502 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,503 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,503 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,504 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,507 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,507 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,507 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,508 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,509 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,511 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,511 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,511 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,511 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,514 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,658 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332928818 with entries=117, filesize=96.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332932225
2014-07-14 03:15:32,771 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,771 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10029,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922742,"queuetimems":0,"class":"HRegionServer","responsesize":15600,"method":"Multi"}
2014-07-14 03:15:32,774 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,775 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,775 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,775 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,778 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,778 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,779 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,779 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,781 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,810 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:32,810 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:15:37,397 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,397 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,398 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,400 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,402 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,404 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,406 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,407 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,409 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,412 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,414 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,414 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,417 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,420 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,421 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,422 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,424 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,424 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,424 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,425 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,427 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,501 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,502 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,503 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,503 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,504 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,504 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,507 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,507 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,507 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:15:37,508 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,509 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,511 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,511 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,511 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,511 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,515 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,771 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,775 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,775 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,775 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,775 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,778 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,779 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,779 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,780 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,782 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:15:37,810 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:37,810 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:15:42,397 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,398 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:15:42,399 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,401 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,403 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,404 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,407 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,409 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,412 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,414 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,414 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,418 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,421 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,421 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,423 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,424 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,425 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,425 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,425 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,426 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,428 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,502 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,503 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,504 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,504 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,505 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,505 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:15:42,507 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,508 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,509 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-14 03:15:42,509 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,510 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,511 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,512 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,512 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,513 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,515 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,771 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,775 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,776 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,776 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,776 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,778 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:15:42,780 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,780 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,780 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,782 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,810 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:42,811 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:15:47,398 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,398 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,399 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,401 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,403 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,405 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,407 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,409 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,412 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,414 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,415 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,418 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,421 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,421 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,423 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,424 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,425 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,426 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,426 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,426 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,428 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,502 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,503 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,504 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,505 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,505 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,506 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,507 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:15:47,508 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,509 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-14 03:15:47,510 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,510 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,512 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,512 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,512 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,513 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,516 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,772 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,775 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,776 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,776 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,776 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,779 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,780 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:47,780 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,781 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,783 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,810 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:15:47,811 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:15:52,398 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,399 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-14 03:15:52,399 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,401 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,404 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,405 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,407 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,410 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,412 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,415 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,415 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,418 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,422 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,422 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,423 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,425 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,425 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,426 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,426 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,427 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,428 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,502 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,503 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,504 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,505 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,505 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,506 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-14 03:15:52,508 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,509 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,510 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-14 03:15:52,510 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,511 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,512 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,513 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,513 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,513 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,516 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,772 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,775 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,776 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,776 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,777 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,779 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,780 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,781 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:15:52,781 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,783 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,811 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:52,811 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:15:57,217 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16559, memsize=1.2g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/5e71e4cbe7934faf94e9cb2390621b29
2014-07-14 03:15:57,399 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,399 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,400 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,401 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,404 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,405 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,408 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,408 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,410 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,413 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,415 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,415 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,419 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,422 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,422 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,423 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,425 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,426 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,427 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,427 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,427 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,428 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,502 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,504 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,504 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,505 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,506 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,506 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25003ms
2014-07-14 03:15:57,508 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-14 03:15:57,509 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,510 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25005ms
2014-07-14 03:15:57,510 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,511 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,512 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,513 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,513 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,513 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,516 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25002ms
2014-07-14 03:15:57,550 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/5e71e4cbe7934faf94e9cb2390621b29 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/5e71e4cbe7934faf94e9cb2390621b29
2014-07-14 03:15:57,564 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/5e71e4cbe7934faf94e9cb2390621b29, entries=4356510, sequenceid=16559, filesize=310.0m
2014-07-14 03:15:57,565 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1323160320, currentsize=298.4m/312882160 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 47798ms, sequenceid=16559, compaction requested=true
2014-07-14 03:15:57,565 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-14 03:15:57,565 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25051ms
2014-07-14 03:15:57,565 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 109671ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:15:57,565 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,566 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25055ms
2014-07-14 03:15:57,566 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,566 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 1.1g
2014-07-14 03:15:57,566 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25055ms
2014-07-14 03:15:57,566 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,573 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25062ms
2014-07-14 03:15:57,573 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,575 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25065ms
2014-07-14 03:15:57,575 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,575 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25066ms
2014-07-14 03:15:57,575 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,576 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25067ms
2014-07-14 03:15:57,576 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,577 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25072ms
2014-07-14 03:15:57,577 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,577 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25070ms
2014-07-14 03:15:57,577 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,577 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25070ms
2014-07-14 03:15:57,577 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,583 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25080ms
2014-07-14 03:15:57,583 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,584 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25080ms
2014-07-14 03:15:57,584 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,584 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25081ms
2014-07-14 03:15:57,584 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,584 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25082ms
2014-07-14 03:15:57,584 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,584 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25082ms
2014-07-14 03:15:57,584 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,585 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25084ms
2014-07-14 03:15:57,585 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,585 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25158ms
2014-07-14 03:15:57,585 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,589 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25164ms
2014-07-14 03:15:57,589 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,589 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25165ms
2014-07-14 03:15:57,589 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,589 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25165ms
2014-07-14 03:15:57,589 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,592 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25169ms
2014-07-14 03:15:57,592 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,592 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25169ms
2014-07-14 03:15:57,592 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,597 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25175ms
2014-07-14 03:15:57,597 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,605 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25185ms
2014-07-14 03:15:57,605 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,605 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25185ms
2014-07-14 03:15:57,605 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,613 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25196ms
2014-07-14 03:15:57,614 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,614 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25201ms
2014-07-14 03:15:57,614 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,614 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25201ms
2014-07-14 03:15:57,614 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,625 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25214ms
2014-07-14 03:15:57,625 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,633 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25225ms
2014-07-14 03:15:57,633 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,635 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25228ms
2014-07-14 03:15:57,635 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,635 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25229ms
2014-07-14 03:15:57,635 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,636 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25232ms
2014-07-14 03:15:57,636 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,645 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25244ms
2014-07-14 03:15:57,645 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,653 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25253ms
2014-07-14 03:15:57,653 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,653 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25256ms
2014-07-14 03:15:57,653 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,653 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25257ms
2014-07-14 03:15:57,653 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,655 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25259ms
2014-07-14 03:15:57,655 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,661 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24852ms
2014-07-14 03:15:57,661 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,661 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24852ms
2014-07-14 03:15:57,661 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,667 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24885ms
2014-07-14 03:15:57,667 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,668 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24889ms
2014-07-14 03:15:57,668 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,673 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24894ms
2014-07-14 03:15:57,673 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,673 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24895ms
2014-07-14 03:15:57,673 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,675 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24897ms
2014-07-14 03:15:57,675 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,676 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24901ms
2014-07-14 03:15:57,676 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,677 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24901ms
2014-07-14 03:15:57,677 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,677 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24902ms
2014-07-14 03:15:57,677 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,677 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24903ms
2014-07-14 03:15:57,677 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,677 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24906ms
2014-07-14 03:15:57,677 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:15:57,711 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:15:58,546 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332930181,"queuetimems":4362,"class":"HRegionServer","responsesize":15949,"method":"Multi"}
2014-07-14 03:15:58,561 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28392,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332930169,"queuetimems":4404,"class":"HRegionServer","responsesize":15943,"method":"Multi"}
2014-07-14 03:15:58,569 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28416,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332930153,"queuetimems":4490,"class":"HRegionServer","responsesize":16221,"method":"Multi"}
2014-07-14 03:15:58,569 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34227,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924342,"queuetimems":1,"class":"HRegionServer","responsesize":15962,"method":"Multi"}
2014-07-14 03:15:58,569 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28404,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332930165,"queuetimems":4455,"class":"HRegionServer","responsesize":15607,"method":"Multi"}
2014-07-14 03:15:58,569 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924237,"queuetimems":0,"class":"HRegionServer","responsesize":15815,"method":"Multi"}
2014-07-14 03:15:58,570 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36310,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922260,"queuetimems":1,"class":"HRegionServer","responsesize":15700,"method":"Multi"}
2014-07-14 03:15:58,585 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924203,"queuetimems":0,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 03:15:58,585 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":30392,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332928193,"queuetimems":2829,"class":"HRegionServer","responsesize":15577,"method":"Multi"}
2014-07-14 03:15:58,587 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332923971,"queuetimems":0,"class":"HRegionServer","responsesize":15586,"method":"Multi"}
2014-07-14 03:15:58,585 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29757,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332928828,"queuetimems":3346,"class":"HRegionServer","responsesize":16360,"method":"Multi"}
2014-07-14 03:15:58,587 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36664,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332921923,"queuetimems":0,"class":"HRegionServer","responsesize":16165,"method":"Multi"}
2014-07-14 03:15:58,587 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332930150,"queuetimems":4545,"class":"HRegionServer","responsesize":15986,"method":"Multi"}
2014-07-14 03:15:58,598 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332921972,"queuetimems":0,"class":"HRegionServer","responsesize":15620,"method":"Multi"}
2014-07-14 03:15:58,599 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924095,"queuetimems":1,"class":"HRegionServer","responsesize":15505,"method":"Multi"}
2014-07-14 03:15:58,599 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36447,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922152,"queuetimems":0,"class":"HRegionServer","responsesize":15903,"method":"Multi"}
2014-07-14 03:15:58,600 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34228,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924372,"queuetimems":0,"class":"HRegionServer","responsesize":15765,"method":"Multi"}
2014-07-14 03:15:58,609 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36510,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922099,"queuetimems":1,"class":"HRegionServer","responsesize":15868,"method":"Multi"}
2014-07-14 03:15:58,599 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36392,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922206,"queuetimems":0,"class":"HRegionServer","responsesize":15753,"method":"Multi"}
2014-07-14 03:15:58,617 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":35774,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922843,"queuetimems":0,"class":"HRegionServer","responsesize":15684,"method":"Multi"}
2014-07-14 03:15:58,621 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":33389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332925232,"queuetimems":0,"class":"HRegionServer","responsesize":14852,"method":"Multi"}
2014-07-14 03:15:58,621 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34559,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924062,"queuetimems":1,"class":"HRegionServer","responsesize":15903,"method":"Multi"}
2014-07-14 03:15:58,609 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34651,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332923958,"queuetimems":0,"class":"HRegionServer","responsesize":16044,"method":"Multi"}
2014-07-14 03:15:58,600 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34435,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924165,"queuetimems":1,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 03:15:58,621 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":30498,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332928123,"queuetimems":2801,"class":"HRegionServer","responsesize":15841,"method":"Multi"}
2014-07-14 03:15:58,629 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":34221,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332924408,"queuetimems":1,"class":"HRegionServer","responsesize":16111,"method":"Multi"}
2014-07-14 03:15:58,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:58,744 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29914,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332928829,"queuetimems":3266,"class":"HRegionServer","responsesize":15684,"method":"Multi"}
2014-07-14 03:15:58,753 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28401,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332930352,"queuetimems":4487,"class":"HRegionServer","responsesize":15903,"method":"Multi"}
2014-07-14 03:15:58,759 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29931,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332928828,"queuetimems":3312,"class":"HRegionServer","responsesize":15529,"method":"Multi"}
2014-07-14 03:15:58,767 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":37783,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332920983,"queuetimems":1,"class":"HRegionServer","responsesize":15815,"method":"Multi"}
2014-07-14 03:15:58,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66902 synced till here 66881
2014-07-14 03:15:58,864 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:15:58,881 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":36845,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332922036,"queuetimems":0,"class":"HRegionServer","responsesize":16221,"method":"Multi"}
2014-07-14 03:15:58,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332932225 with entries=102, filesize=86.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332958737
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332802567
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332804269
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332805743
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332807241
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332810109
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332812990
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332814939
2014-07-14 03:15:58,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332816370
2014-07-14 03:15:59,250 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26863,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932386,"queuetimems":6369,"class":"HRegionServer","responsesize":15700,"method":"Multi"}
2014-07-14 03:15:59,250 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26742,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932507,"queuetimems":4356,"class":"HRegionServer","responsesize":16044,"method":"Multi"}
2014-07-14 03:15:59,253 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27021,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932232,"queuetimems":6251,"class":"HRegionServer","responsesize":15740,"method":"Multi"}
2014-07-14 03:15:59,253 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932231,"queuetimems":6290,"class":"HRegionServer","responsesize":15600,"method":"Multi"}
2014-07-14 03:15:59,258 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26758,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932499,"queuetimems":4492,"class":"HRegionServer","responsesize":16044,"method":"Multi"}
2014-07-14 03:15:59,266 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26758,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932507,"queuetimems":4317,"class":"HRegionServer","responsesize":15903,"method":"Multi"}
2014-07-14 03:15:59,266 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26768,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932498,"queuetimems":4554,"class":"HRegionServer","responsesize":15884,"method":"Multi"}
2014-07-14 03:15:59,266 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27036,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932230,"queuetimems":6329,"class":"HRegionServer","responsesize":16165,"method":"Multi"}
2014-07-14 03:15:59,273 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26765,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932508,"queuetimems":4253,"class":"HRegionServer","responsesize":15962,"method":"Multi"}
2014-07-14 03:15:59,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27602,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932387,"queuetimems":4532,"class":"HRegionServer","responsesize":15586,"method":"Multi"}
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27221,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932768,"queuetimems":4452,"class":"HRegionServer","responsesize":15824,"method":"Multi"}
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932397,"queuetimems":4514,"class":"HRegionServer","responsesize":15162,"method":"Multi"}
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27581,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932408,"queuetimems":4496,"class":"HRegionServer","responsesize":15640,"method":"Multi"}
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27600,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932389,"queuetimems":4524,"class":"HRegionServer","responsesize":15765,"method":"Multi"}
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27490,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932499,"queuetimems":4527,"class":"HRegionServer","responsesize":15505,"method":"Multi"}
2014-07-14 03:15:59,990 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932807,"queuetimems":4403,"class":"HRegionServer","responsesize":15589,"method":"Multi"}
2014-07-14 03:15:59,989 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27490,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932499,"queuetimems":4452,"class":"HRegionServer","responsesize":15815,"method":"Multi"}
2014-07-14 03:15:59,993 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27221,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932772,"queuetimems":4404,"class":"HRegionServer","responsesize":15738,"method":"Multi"}
2014-07-14 03:15:59,993 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27186,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332932807,"queuetimems":4372,"class":"HRegionServer","responsesize":16111,"method":"Multi"}
2014-07-14 03:16:00,197 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67023 synced till here 66973
2014-07-14 03:16:00,469 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:16:00,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332958737 with entries=121, filesize=103.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332959987
2014-07-14 03:16:01,439 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:01,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67127 synced till here 67096
2014-07-14 03:16:01,694 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332959987 with entries=104, filesize=87.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332961440
2014-07-14 03:16:02,862 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:02,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67242 synced till here 67201
2014-07-14 03:16:03,437 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332961440 with entries=115, filesize=97.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332962862
2014-07-14 03:16:04,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:04,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67360 synced till here 67355
2014-07-14 03:16:04,963 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8fc3572095c44b8dafb1fe179035591c as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8fc3572095c44b8dafb1fe179035591c
2014-07-14 03:16:05,063 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332962862 with entries=118, filesize=101.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332964733
2014-07-14 03:16:05,290 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:16:05,312 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/87cd1176f0da4daa96f054d0fda238f5, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/87cd1176f0da4daa96f054d0fda238f5
2014-07-14 03:16:05,325 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3a7e17cacba3457e9178d1b28d1c730a, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/3a7e17cacba3457e9178d1b28d1c730a
2014-07-14 03:16:05,334 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/69dc568c29cb492ca88fa57573216f74, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/69dc568c29cb492ca88fa57573216f74
2014-07-14 03:16:05,337 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c75e87a89cdc40c7a92ee4d26b1389ca, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/c75e87a89cdc40c7a92ee4d26b1389ca
2014-07-14 03:16:05,341 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/81ddf15644ec4b809644ee3d6e170149, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/81ddf15644ec4b809644ee3d6e170149
2014-07-14 03:16:05,345 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e08ad62a63af45acbac423a83e22f0a0, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/e08ad62a63af45acbac423a83e22f0a0
2014-07-14 03:16:05,349 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/4bdd6d2f5adc4122a39d294492ed0217, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/4bdd6d2f5adc4122a39d294492ed0217
2014-07-14 03:16:05,352 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5b71fe3b2c1b45ffb91eadebb85d7108, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5b71fe3b2c1b45ffb91eadebb85d7108
2014-07-14 03:16:05,367 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c12dd83afc14fbd9c851186d25263a6, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c12dd83afc14fbd9c851186d25263a6
2014-07-14 03:16:05,375 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7d3b4afaf9514a13a3c7dc94932bf58d, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/7d3b4afaf9514a13a3c7dc94932bf58d
2014-07-14 03:16:05,375 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into 8fc3572095c44b8dafb1fe179035591c(size=1.0g), total size for store is 3.1g. This selection was in queue for 0sec, and took 3mins, 4sec to execute.
2014-07-14 03:16:05,376 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=10, fileSize=1.1g, priority=2, time=286688406142744; duration=3mins, 4sec
2014-07-14 03:16:05,376 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-14 03:16:05,376 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 03:16:05,378 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 230292879 starting at candidate #17 after considering 132 permutations with 124 in ratio
2014-07-14 03:16:05,378 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating minor compaction
2014-07-14 03:16:05,378 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:16:05,379 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=219.6m
2014-07-14 03:16:05,379 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/42a1555fa34a48fc9a5de3ba5f869f24, keycount=98928, bloomtype=ROW, size=70.5m, encoding=NONE, seqNum=14884
2014-07-14 03:16:05,379 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3edbf950d48e4b638870c1a330c5524a, keycount=115414, bloomtype=ROW, size=82.2m, encoding=NONE, seqNum=15411
2014-07-14 03:16:05,379 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c1fcd27ac6044c1094c763f0699b2866, keycount=93900, bloomtype=ROW, size=66.9m, encoding=NONE, seqNum=15579
2014-07-14 03:16:05,481 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:16:06,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:06,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67475 synced till here 67459
2014-07-14 03:16:07,127 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332964733 with entries=115, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332966826
2014-07-14 03:16:08,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:08,864 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67579 synced till here 67554
2014-07-14 03:16:09,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332966826 with entries=104, filesize=88.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332968813
2014-07-14 03:16:09,360 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,361 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,362 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,362 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,362 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,362 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,363 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,364 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,365 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,365 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,367 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,370 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,954 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,955 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,955 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,956 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,957 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,958 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,958 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,959 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,959 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,960 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,960 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,962 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,962 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,962 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,963 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,963 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,964 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:09,964 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,025 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,025 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,025 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,026 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,026 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,028 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,028 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,028 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,028 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,029 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,029 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,029 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,029 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,030 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,031 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,031 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,032 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,032 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,032 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:10,062 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:14,361 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:14,362 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:14,362 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:14,363 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:14,363 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:14,363 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:14,363 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:14,365 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:14,365 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:14,366 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:14,367 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:14,371 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 03:16:15,029 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:15,029 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 03:16:15,030 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5067ms
2014-07-14 03:16:15,030 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5076ms
2014-07-14 03:16:15,031 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:16:15,031 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:16:15,032 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:16:15,032 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:16:15,032 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 03:16:15,033 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 03:16:15,034 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 03:16:15,034 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:16:15,034 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:16:15,035 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:16:15,035 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:16:15,035 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:16:15,035 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 03:16:15,035 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-14 03:16:15,036 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 03:16:15,036 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-14 03:16:15,036 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5081ms
2014-07-14 03:16:15,036 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-14 03:16:15,036 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-14 03:16:15,037 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-14 03:16:15,038 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-14 03:16:15,039 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-14 03:16:15,039 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-14 03:16:15,040 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-14 03:16:15,040 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-14 03:16:15,040 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-14 03:16:15,040 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-14 03:16:15,041 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5012ms
2014-07-14 03:16:15,041 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5079ms
2014-07-14 03:16:15,041 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-14 03:16:15,041 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-14 03:16:15,042 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5078ms
2014-07-14 03:16:15,042 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5014ms
2014-07-14 03:16:15,062 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:15,214 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16689, memsize=1.1g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/1d1dfa3a059d42ca8c3fdb47c302a3ee
2014-07-14 03:16:15,232 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/1d1dfa3a059d42ca8c3fdb47c302a3ee as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1d1dfa3a059d42ca8c3fdb47c302a3ee
2014-07-14 03:16:15,266 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/1d1dfa3a059d42ca8c3fdb47c302a3ee, entries=4180940, sequenceid=16689, filesize=297.5m
2014-07-14 03:16:15,268 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.2g/1281150960, currentsize=380.5m/398975040 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 47251ms, sequenceid=16689, compaction requested=true
2014-07-14 03:16:15,268 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-14 03:16:15,268 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5206ms
2014-07-14 03:16:15,268 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:16:15,268 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,269 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5241ms
2014-07-14 03:16:15,269 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,269 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:142), split_queue=0, merge_queue=0
2014-07-14 03:16:15,269 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5306ms
2014-07-14 03:16:15,269 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,269 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:16:15,269 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5306ms
2014-07-14 03:16:15,269 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,269 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-14 03:16:15,270 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5307ms
2014-07-14 03:16:15,270 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,270 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5308ms
2014-07-14 03:16:15,270 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,270 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5241ms
2014-07-14 03:16:15,270 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,273 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5311ms
2014-07-14 03:16:15,273 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,273 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5312ms
2014-07-14 03:16:15,273 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,281 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5321ms
2014-07-14 03:16:15,281 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,281 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5321ms
2014-07-14 03:16:15,281 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,281 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5322ms
2014-07-14 03:16:15,281 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,281 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5322ms
2014-07-14 03:16:15,281 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,281 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5323ms
2014-07-14 03:16:15,281 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,282 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5324ms
2014-07-14 03:16:15,282 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,284 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5327ms
2014-07-14 03:16:15,284 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,289 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5333ms
2014-07-14 03:16:15,289 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,289 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5334ms
2014-07-14 03:16:15,289 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,289 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5335ms
2014-07-14 03:16:15,289 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,289 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5259ms
2014-07-14 03:16:15,289 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,289 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5258ms
2014-07-14 03:16:15,289 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,290 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5259ms
2014-07-14 03:16:15,290 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,292 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5260ms
2014-07-14 03:16:15,292 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,296 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5264ms
2014-07-14 03:16:15,296 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,297 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5265ms
2014-07-14 03:16:15,297 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,298 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-14 03:16:15,298 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,298 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-14 03:16:15,298 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,298 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-14 03:16:15,298 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,298 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-14 03:16:15,298 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,298 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-14 03:16:15,299 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,299 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5273ms
2014-07-14 03:16:15,299 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,299 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5273ms
2014-07-14 03:16:15,299 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,309 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5284ms
2014-07-14 03:16:15,309 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,309 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5284ms
2014-07-14 03:16:15,309 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,309 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5355ms
2014-07-14 03:16:15,309 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,309 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5346ms
2014-07-14 03:16:15,309 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,313 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5288ms
2014-07-14 03:16:15,313 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,313 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5284ms
2014-07-14 03:16:15,313 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,315 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5948ms
2014-07-14 03:16:15,315 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,315 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5948ms
2014-07-14 03:16:15,315 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,316 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5950ms
2014-07-14 03:16:15,316 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,321 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5957ms
2014-07-14 03:16:15,321 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,321 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5957ms
2014-07-14 03:16:15,321 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,321 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5958ms
2014-07-14 03:16:15,321 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,323 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5961ms
2014-07-14 03:16:15,323 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,323 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5961ms
2014-07-14 03:16:15,323 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,323 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5961ms
2014-07-14 03:16:15,323 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,323 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5961ms
2014-07-14 03:16:15,323 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,323 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5962ms
2014-07-14 03:16:15,323 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,324 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5964ms
2014-07-14 03:16:15,324 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:15,630 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:16:15,631 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 383.5m
2014-07-14 03:16:15,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:15,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67690 synced till here 67667
2014-07-14 03:16:15,903 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:16:16,070 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332968813 with entries=111, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332975796
2014-07-14 03:16:16,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332818277
2014-07-14 03:16:16,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332819965
2014-07-14 03:16:16,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332821887
2014-07-14 03:16:16,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332823547
2014-07-14 03:16:16,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332825456
2014-07-14 03:16:16,070 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332827823
2014-07-14 03:16:17,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:17,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67801 synced till here 67771
2014-07-14 03:16:17,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332975796 with entries=111, filesize=91.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332977705
2014-07-14 03:16:19,179 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:19,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67878 synced till here 67874
2014-07-14 03:16:19,272 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332977705 with entries=77, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332979179
2014-07-14 03:16:19,897 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16940, memsize=52.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/2c96483177344d64b0078a33d5f6d5f4
2014-07-14 03:16:19,909 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/2c96483177344d64b0078a33d5f6d5f4 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c96483177344d64b0078a33d5f6d5f4
2014-07-14 03:16:19,922 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c96483177344d64b0078a33d5f6d5f4, entries=192260, sequenceid=16940, filesize=13.7m
2014-07-14 03:16:19,923 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~383.5m/402114160, currentsize=124.0m/130045280 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 4293ms, sequenceid=16940, compaction requested=true
2014-07-14 03:16:19,923 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-14 03:16:20,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:20,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67956 synced till here 67951
2014-07-14 03:16:20,833 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332979179 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332980639
2014-07-14 03:16:21,528 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:22,010 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68035 synced till here 68031
2014-07-14 03:16:22,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332980639 with entries=79, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332981529
2014-07-14 03:16:22,811 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:22,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68112 synced till here 68108
2014-07-14 03:16:22,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332981529 with entries=77, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332982811
2014-07-14 03:16:24,153 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:24,373 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68200 synced till here 68198
2014-07-14 03:16:24,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332982811 with entries=88, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332984153
2014-07-14 03:16:25,680 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:16:25,681 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 256.3m
2014-07-14 03:16:25,827 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:16:26,126 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:26,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68278 synced till here 68277
2014-07-14 03:16:26,214 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332984153 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332986127
2014-07-14 03:16:27,655 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:28,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68367 synced till here 68366
2014-07-14 03:16:28,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332986127 with entries=89, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332987655
2014-07-14 03:16:29,619 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:29,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68442 synced till here 68439
2014-07-14 03:16:30,005 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332987655 with entries=75, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332989620
2014-07-14 03:16:30,941 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:30,984 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332989620 with entries=71, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332990941
2014-07-14 03:16:32,482 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:32,512 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332990941 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332992482
2014-07-14 03:16:32,642 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17108, memsize=166.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/632cd2d88f7e487992d626c88c78701b
2014-07-14 03:16:32,661 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/632cd2d88f7e487992d626c88c78701b as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/632cd2d88f7e487992d626c88c78701b
2014-07-14 03:16:33,060 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/632cd2d88f7e487992d626c88c78701b, entries=604700, sequenceid=17108, filesize=43.1m
2014-07-14 03:16:33,061 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.3m/268710560, currentsize=132.1m/138469680 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 7380ms, sequenceid=17108, compaction requested=true
2014-07-14 03:16:33,062 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-14 03:16:33,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:33,953 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:16:34,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68685 synced till here 68683
2014-07-14 03:16:34,699 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332992482 with entries=99, filesize=84.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332993849
2014-07-14 03:16:34,721 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files, but is 1010.4m vs best flushable region's 164.3m. Choosing the bigger.
2014-07-14 03:16:34,721 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. due to global heap pressure
2014-07-14 03:16:34,721 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 1010.4m
2014-07-14 03:16:35,942 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:35,967 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68765 synced till here 68755
2014-07-14 03:16:36,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332993849 with entries=80, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332995942
2014-07-14 03:16:36,060 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:16:37,200 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,204 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,204 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,204 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,210 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,268 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,275 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,275 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,276 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,279 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,279 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,279 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,280 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,280 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,280 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,281 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,289 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,308 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,308 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,308 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,309 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,312 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,373 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,428 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,466 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,505 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,544 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,581 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:37,616 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,590 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,623 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,654 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,683 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,711 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,743 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,774 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,805 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,835 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,871 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,927 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:39,985 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,033 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,090 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,135 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,173 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,212 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,255 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:40,296 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:41,453 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:41,495 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:42,201 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,204 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,204 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,205 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,210 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,269 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,275 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,276 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,276 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,279 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,280 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,280 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,280 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,280 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,280 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,282 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,289 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,308 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,309 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,309 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,309 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,313 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,374 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:16:42,429 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,466 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,505 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,544 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,581 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:42,616 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:16:44,391 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16754, memsize=1013.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/5e0c07179b4f4cd0bfd39cae96201dad
2014-07-14 03:16:44,404 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/5e0c07179b4f4cd0bfd39cae96201dad as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5e0c07179b4f4cd0bfd39cae96201dad
2014-07-14 03:16:44,416 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5e0c07179b4f4cd0bfd39cae96201dad, entries=3688360, sequenceid=16754, filesize=262.6m
2014-07-14 03:16:44,416 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1189438560, currentsize=767.2m/804518880 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 46850ms, sequenceid=16754, compaction requested=true
2014-07-14 03:16:44,417 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:146), split_queue=0, merge_queue=0
2014-07-14 03:16:44,417 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6801ms
2014-07-14 03:16:44,418 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,418 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6837ms
2014-07-14 03:16:44,418 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,418 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6874ms
2014-07-14 03:16:44,419 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,419 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6914ms
2014-07-14 03:16:44,419 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,421 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6955ms
2014-07-14 03:16:44,421 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,421 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6993ms
2014-07-14 03:16:44,421 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,421 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7048ms
2014-07-14 03:16:44,421 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,421 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7109ms
2014-07-14 03:16:44,422 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,422 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7113ms
2014-07-14 03:16:44,422 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,425 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7117ms
2014-07-14 03:16:44,426 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,426 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7118ms
2014-07-14 03:16:44,426 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,426 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7118ms
2014-07-14 03:16:44,426 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,427 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7137ms
2014-07-14 03:16:44,427 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,427 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7146ms
2014-07-14 03:16:44,427 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,433 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7154ms
2014-07-14 03:16:44,433 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,434 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7154ms
2014-07-14 03:16:44,434 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,434 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7155ms
2014-07-14 03:16:44,434 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,441 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7162ms
2014-07-14 03:16:44,441 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,442 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7162ms
2014-07-14 03:16:44,442 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,442 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7163ms
2014-07-14 03:16:44,442 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,443 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7166ms
2014-07-14 03:16:44,443 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,443 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7168ms
2014-07-14 03:16:44,443 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,444 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7169ms
2014-07-14 03:16:44,445 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,447 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7179ms
2014-07-14 03:16:44,448 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,452 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7242ms
2014-07-14 03:16:44,452 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,452 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7248ms
2014-07-14 03:16:44,452 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,452 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7248ms
2014-07-14 03:16:44,452 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,453 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7250ms
2014-07-14 03:16:44,453 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,456 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7256ms
2014-07-14 03:16:44,456 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,456 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2962ms
2014-07-14 03:16:44,456 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,461 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3008ms
2014-07-14 03:16:44,461 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,462 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4165ms
2014-07-14 03:16:44,462 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,464 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4209ms
2014-07-14 03:16:44,464 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,465 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4253ms
2014-07-14 03:16:44,465 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,466 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4293ms
2014-07-14 03:16:44,466 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,466 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4331ms
2014-07-14 03:16:44,466 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,466 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4376ms
2014-07-14 03:16:44,466 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,467 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4434ms
2014-07-14 03:16:44,468 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,469 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4484ms
2014-07-14 03:16:44,469 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,477 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4550ms
2014-07-14 03:16:44,477 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,478 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4606ms
2014-07-14 03:16:44,478 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,489 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4654ms
2014-07-14 03:16:44,489 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,495 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4690ms
2014-07-14 03:16:44,495 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,501 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4727ms
2014-07-14 03:16:44,501 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,506 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4763ms
2014-07-14 03:16:44,506 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,507 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4795ms
2014-07-14 03:16:44,507 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,512 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4829ms
2014-07-14 03:16:44,512 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,512 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4858ms
2014-07-14 03:16:44,512 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,517 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4894ms
2014-07-14 03:16:44,517 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,521 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4931ms
2014-07-14 03:16:44,521 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:16:44,622 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:16:44,622 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files; delaying flush up to 90000ms
2014-07-14 03:16:44,622 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-14 03:16:44,949 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:45,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68882 synced till here 68846
2014-07-14 03:16:45,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332995942 with entries=117, filesize=99.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333004949
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332830224
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332831658
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332833277
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332835085
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332836832
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332842883
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332844401
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332845569
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332846819
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332848020
2014-07-14 03:16:45,426 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332850119
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332851615
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332853323
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332854902
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332857018
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332859001
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332860402
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332868694
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332871534
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332873234
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332877810
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332879208
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332881126
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332883407
2014-07-14 03:16:45,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332885379
2014-07-14 03:16:45,428 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332886618
2014-07-14 03:16:45,428 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332888014
2014-07-14 03:16:46,768 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10728,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332996039,"queuetimems":1,"class":"HRegionServer","responsesize":16015,"method":"Multi"}
2014-07-14 03:16:47,136 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/60075c8a74a34b48aaee5113db11e4e6 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/60075c8a74a34b48aaee5113db11e4e6
2014-07-14 03:16:47,217 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10162,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997055,"queuetimems":0,"class":"HRegionServer","responsesize":15107,"method":"Multi"}
2014-07-14 03:16:47,218 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10246,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332996971,"queuetimems":0,"class":"HRegionServer","responsesize":15621,"method":"Multi"}
2014-07-14 03:16:47,218 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10211,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997006,"queuetimems":1,"class":"HRegionServer","responsesize":15409,"method":"Multi"}
2014-07-14 03:16:47,410 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:47,433 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68997 synced till here 68963
2014-07-14 03:16:47,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333004949 with entries=115, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333007410
2014-07-14 03:16:47,649 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997503,"queuetimems":0,"class":"HRegionServer","responsesize":15762,"method":"Multi"}
2014-07-14 03:16:47,655 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10113,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997542,"queuetimems":1,"class":"HRegionServer","responsesize":15632,"method":"Multi"}
2014-07-14 03:16:47,659 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:16:47,673 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/42a1555fa34a48fc9a5de3ba5f869f24, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/42a1555fa34a48fc9a5de3ba5f869f24
2014-07-14 03:16:47,685 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3edbf950d48e4b638870c1a330c5524a, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/3edbf950d48e4b638870c1a330c5524a
2014-07-14 03:16:47,655 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997579,"queuetimems":0,"class":"HRegionServer","responsesize":15787,"method":"Multi"}
2014-07-14 03:16:47,691 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c1fcd27ac6044c1094c763f0699b2866, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/c1fcd27ac6044c1094c763f0699b2866
2014-07-14 03:16:47,691 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into 60075c8a74a34b48aaee5113db11e4e6(size=205.0m), total size for store is 3.4g. This selection was in queue for 0sec, and took 42sec to execute.
2014-07-14 03:16:47,691 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=3, fileSize=219.6m, priority=-2, time=286872805418238; duration=42sec
2014-07-14 03:16:47,692 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-14 03:16:47,692 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-14 03:16:47,692 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 03:16:47,694 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 93486649 starting at candidate #14 after considering 132 permutations with 125 in ratio
2014-07-14 03:16:47,694 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating minor compaction
2014-07-14 03:16:47,694 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:16:47,694 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=89.2m
2014-07-14 03:16:47,694 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/61d1c4af05aa4f25a50ba55ce77716c5, keycount=35226, bloomtype=ROW, size=25.1m, encoding=NONE, seqNum=14971
2014-07-14 03:16:47,694 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6acbfd0f62724f5289f52e22bb7cbf6c, keycount=69492, bloomtype=ROW, size=49.5m, encoding=NONE, seqNum=15146
2014-07-14 03:16:47,694 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/249102027d454ecc8e09f4c59f4b38bc, keycount=20364, bloomtype=ROW, size=14.5m, encoding=NONE, seqNum=15317
2014-07-14 03:16:47,756 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:16:47,766 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10558,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997207,"queuetimems":0,"class":"HRegionServer","responsesize":15650,"method":"Multi"}
2014-07-14 03:16:48,453 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10990,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997463,"queuetimems":0,"class":"HRegionServer","responsesize":15689,"method":"Multi"}
2014-07-14 03:16:48,467 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11096,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997371,"queuetimems":0,"class":"HRegionServer","responsesize":15795,"method":"Multi"}
2014-07-14 03:16:48,902 DEBUG [RpcServer.handler=12,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:16:48,903 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11593,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997310,"queuetimems":0,"class":"HRegionServer","responsesize":15540,"method":"Multi"}
2014-07-14 03:16:48,904 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11638,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997266,"queuetimems":0,"class":"HRegionServer","responsesize":16176,"method":"Multi"}
2014-07-14 03:16:48,915 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 268.2m
2014-07-14 03:16:48,946 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11520,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405332997426,"queuetimems":0,"class":"HRegionServer","responsesize":15637,"method":"Multi"}
2014-07-14 03:16:49,102 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:49,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69090 synced till here 69072
2014-07-14 03:16:49,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333007410 with entries=93, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333009103
2014-07-14 03:16:49,354 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:16:50,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:50,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69195 synced till here 69169
2014-07-14 03:16:51,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333009103 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333010901
2014-07-14 03:16:52,378 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:52,611 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333010901 with entries=84, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333012378
2014-07-14 03:16:54,255 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:54,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69364 synced till here 69350
2014-07-14 03:16:54,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333012378 with entries=85, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333014255
2014-07-14 03:16:55,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:56,077 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69452 synced till here 69443
2014-07-14 03:16:56,148 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333014255 with entries=88, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333015951
2014-07-14 03:16:57,401 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:16:57,423 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69526 synced till here 69524
2014-07-14 03:16:57,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333015951 with entries=74, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333017402
2014-07-14 03:16:57,524 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,533 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,540 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,542 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,553 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,584 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,587 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,595 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,604 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,693 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,732 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,783 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,837 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,870 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,918 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,947 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:57,982 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,031 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,594 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,607 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,623 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,653 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,698 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,729 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:58,880 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,690 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,732 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,781 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,823 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,864 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,911 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,948 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:16:59,981 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17307, memsize=223.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/27ffbfdb1baa4ea7aa0dd1c9517a2458
2014-07-14 03:16:59,997 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:00,002 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/27ffbfdb1baa4ea7aa0dd1c9517a2458 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/27ffbfdb1baa4ea7aa0dd1c9517a2458
2014-07-14 03:17:00,018 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/27ffbfdb1baa4ea7aa0dd1c9517a2458, entries=812930, sequenceid=17307, filesize=57.9m
2014-07-14 03:17:00,019 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~305.1m/319893600, currentsize=185.4m/194423200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 11104ms, sequenceid=17307, compaction requested=true
2014-07-14 03:17:00,019 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-14 03:17:00,019 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22ms
2014-07-14 03:17:00,019 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,020 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 71ms
2014-07-14 03:17:00,020 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,020 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 109ms
2014-07-14 03:17:00,020 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,020 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 156ms
2014-07-14 03:17:00,020 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,021 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 198ms
2014-07-14 03:17:00,021 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,029 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 248ms
2014-07-14 03:17:00,029 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,029 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 297ms
2014-07-14 03:17:00,029 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,029 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 339ms
2014-07-14 03:17:00,029 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,029 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1149ms
2014-07-14 03:17:00,030 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,030 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1301ms
2014-07-14 03:17:00,030 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,045 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1347ms
2014-07-14 03:17:00,045 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,045 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1392ms
2014-07-14 03:17:00,045 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,046 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1423ms
2014-07-14 03:17:00,046 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,047 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1440ms
2014-07-14 03:17:00,047 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,049 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1454ms
2014-07-14 03:17:00,049 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,053 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2021ms
2014-07-14 03:17:00,054 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,054 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2072ms
2014-07-14 03:17:00,054 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,054 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2107ms
2014-07-14 03:17:00,054 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,054 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2136ms
2014-07-14 03:17:00,054 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,055 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2185ms
2014-07-14 03:17:00,055 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,055 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2218ms
2014-07-14 03:17:00,055 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,057 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2274ms
2014-07-14 03:17:00,057 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,065 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2333ms
2014-07-14 03:17:00,065 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,065 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2372ms
2014-07-14 03:17:00,065 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,067 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2463ms
2014-07-14 03:17:00,067 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,067 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2472ms
2014-07-14 03:17:00,068 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,068 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2481ms
2014-07-14 03:17:00,068 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,069 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2486ms
2014-07-14 03:17:00,069 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,073 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2520ms
2014-07-14 03:17:00,073 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,077 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2535ms
2014-07-14 03:17:00,077 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,077 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2538ms
2014-07-14 03:17:00,077 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,078 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2545ms
2014-07-14 03:17:00,078 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:00,078 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2554ms
2014-07-14 03:17:00,078 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:01,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:01,798 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:17:01,886 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files, but is 1.2g vs best flushable region's 196.3m. Choosing the bigger.
2014-07-14 03:17:01,886 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. due to global heap pressure
2014-07-14 03:17:01,887 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 1.2g
2014-07-14 03:17:01,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69627 synced till here 69626
2014-07-14 03:17:02,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333017402 with entries=101, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333021886
2014-07-14 03:17:03,527 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:03,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333021886 with entries=82, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333023527
2014-07-14 03:17:03,625 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:03,787 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:17:03,791 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,831 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,854 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,854 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,854 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,854 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,872 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,885 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,885 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,885 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,886 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,894 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,902 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:03,988 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:04,027 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:04,070 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:04,123 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:04,131 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17220, memsize=513.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/79a968ec33ee4d0fad3b492c609aa496
2014-07-14 03:17:04,141 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/79a968ec33ee4d0fad3b492c609aa496 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/79a968ec33ee4d0fad3b492c609aa496
2014-07-14 03:17:04,151 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/79a968ec33ee4d0fad3b492c609aa496, entries=1868940, sequenceid=17220, filesize=133.1m
2014-07-14 03:17:04,151 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1015.2m/1064463040, currentsize=403.0m/422610080 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 29430ms, sequenceid=17220, compaction requested=true
2014-07-14 03:17:04,151 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:149), split_queue=0, merge_queue=0
2014-07-14 03:17:04,151 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 28ms
2014-07-14 03:17:04,151 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,152 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 82ms
2014-07-14 03:17:04,152 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 260.3m
2014-07-14 03:17:04,152 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,153 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 126ms
2014-07-14 03:17:04,153 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,153 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 165ms
2014-07-14 03:17:04,153 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,153 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 251ms
2014-07-14 03:17:04,153 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,153 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 259ms
2014-07-14 03:17:04,153 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,162 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 276ms
2014-07-14 03:17:04,162 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,162 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 277ms
2014-07-14 03:17:04,162 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,162 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 277ms
2014-07-14 03:17:04,162 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,162 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 277ms
2014-07-14 03:17:04,162 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,163 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 291ms
2014-07-14 03:17:04,163 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,163 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 309ms
2014-07-14 03:17:04,163 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,163 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 309ms
2014-07-14 03:17:04,163 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,165 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 311ms
2014-07-14 03:17:04,165 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,185 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 332ms
2014-07-14 03:17:04,185 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,185 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 354ms
2014-07-14 03:17:04,185 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,196 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 405ms
2014-07-14 03:17:04,197 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:04,358 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:04,361 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:17:04,416 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/92bf334e21f044f4ac01cc078f4a266f as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/92bf334e21f044f4ac01cc078f4a266f
2014-07-14 03:17:05,189 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:17:05,216 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/61d1c4af05aa4f25a50ba55ce77716c5, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/61d1c4af05aa4f25a50ba55ce77716c5
2014-07-14 03:17:05,221 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6acbfd0f62724f5289f52e22bb7cbf6c, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/6acbfd0f62724f5289f52e22bb7cbf6c
2014-07-14 03:17:05,224 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/249102027d454ecc8e09f4c59f4b38bc, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/249102027d454ecc8e09f4c59f4b38bc
2014-07-14 03:17:05,224 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into 92bf334e21f044f4ac01cc078f4a266f(size=65.0m), total size for store is 3.4g. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-14 03:17:05,226 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=3, fileSize=89.2m, priority=-2, time=286915120999373; duration=17sec
2014-07-14 03:17:05,226 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-14 03:17:05,226 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-14 03:17:05,227 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:17:05,229 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 195244475 starting at candidate #17 after considering 124 permutations with 100 in ratio
2014-07-14 03:17:05,229 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating minor compaction
2014-07-14 03:17:05,229 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:17:05,229 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=186.2m
2014-07-14 03:17:05,229 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bad04fbfdde943ed94a3772cb673c556, keycount=89418, bloomtype=ROW, size=63.7m, encoding=NONE, seqNum=16159
2014-07-14 03:17:05,230 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/31b98797489b4499bef00173753418a3, keycount=84207, bloomtype=ROW, size=60.0m, encoding=NONE, seqNum=16326
2014-07-14 03:17:05,230 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e43243fdda484b428d433057075717b0, keycount=87741, bloomtype=ROW, size=62.5m, encoding=NONE, seqNum=16493
2014-07-14 03:17:05,352 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:05,387 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:05,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69798 synced till here 69787
2014-07-14 03:17:05,484 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333023527 with entries=89, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333025352
2014-07-14 03:17:05,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332907753
2014-07-14 03:17:05,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332909538
2014-07-14 03:17:05,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332911435
2014-07-14 03:17:05,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332913460
2014-07-14 03:17:05,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332914656
2014-07-14 03:17:07,510 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:07,554 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69898 synced till here 69873
2014-07-14 03:17:07,869 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333025352 with entries=100, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333027510
2014-07-14 03:17:09,614 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:09,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70000 synced till here 69982
2014-07-14 03:17:09,861 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333027510 with entries=102, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333029614
2014-07-14 03:17:11,764 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:11,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70103 synced till here 70088
2014-07-14 03:17:12,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333029614 with entries=103, filesize=88.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333031764
2014-07-14 03:17:13,117 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17476, memsize=115.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/20e7ef6b67c14fbdb58e6485e1687e4e
2014-07-14 03:17:13,142 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/20e7ef6b67c14fbdb58e6485e1687e4e as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/20e7ef6b67c14fbdb58e6485e1687e4e
2014-07-14 03:17:13,160 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/20e7ef6b67c14fbdb58e6485e1687e4e, entries=418900, sequenceid=17476, filesize=29.8m
2014-07-14 03:17:13,160 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.3m/272932400, currentsize=121.9m/127872000 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 9008ms, sequenceid=17476, compaction requested=true
2014-07-14 03:17:13,161 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-14 03:17:13,161 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:17:13,161 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-14 03:17:13,161 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 1.2g
2014-07-14 03:17:13,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:14,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70207 synced till here 70185
2014-07-14 03:17:14,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333031764 with entries=104, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333033751
2014-07-14 03:17:15,487 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:16,547 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:16,638 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70305 synced till here 70279
2014-07-14 03:17:17,072 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333033751 with entries=98, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333036547
2014-07-14 03:17:19,241 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:19,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70422 synced till here 70404
2014-07-14 03:17:19,525 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333036547 with entries=117, filesize=100.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333039242
2014-07-14 03:17:21,245 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:17:21,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:22,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70532 synced till here 70510
2014-07-14 03:17:23,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333039242 with entries=110, filesize=94.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333041801
2014-07-14 03:17:23,629 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,631 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,634 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,636 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,636 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,642 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,643 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,645 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,645 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,646 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,647 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,655 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,655 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,656 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,656 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,657 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,657 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,657 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,659 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,660 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,660 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,660 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,660 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,664 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,665 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,666 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,670 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,670 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,672 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,678 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,678 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,679 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,680 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,769 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,769 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,770 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,771 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,774 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,786 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,837 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,837 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,837 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,839 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,843 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,843 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,843 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,846 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,855 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,855 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:23,859 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:17:28,629 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,632 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,635 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,636 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,637 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,643 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,644 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5008ms
2014-07-14 03:17:28,646 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,646 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,647 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,647 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,655 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,656 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,656 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,657 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,657 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,658 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:17:28,658 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,659 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,661 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:17:28,661 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,662 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,662 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5006ms
2014-07-14 03:17:28,664 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,665 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,666 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,670 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,671 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,672 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,679 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,679 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5013ms
2014-07-14 03:17:28,680 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,681 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,770 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,770 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,771 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,771 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,775 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,786 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,837 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,837 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,838 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,839 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,843 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,843 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,844 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:17:28,846 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,855 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,855 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:28,859 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:17:33,630 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,632 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,635 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,637 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,637 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,644 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:17:33,644 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-14 03:17:33,646 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,647 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,647 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,648 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,656 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,656 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,657 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,657 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,658 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,658 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-14 03:17:33,659 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,659 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,661 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-14 03:17:33,662 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,662 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:17:33,662 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10006ms
2014-07-14 03:17:33,665 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,666 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,667 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,671 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,671 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,673 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,679 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,679 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10013ms
2014-07-14 03:17:33,680 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,681 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,770 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:17:33,771 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:17:33,771 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:17:33,772 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,775 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,787 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,837 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,838 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,838 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,839 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,844 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,844 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,845 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,847 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,856 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:17:33,856 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:33,860 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:17:36,060 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17469, memsize=500.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/9343683a1f0945eea8f8b9786fe545e4
2014-07-14 03:17:36,072 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/9343683a1f0945eea8f8b9786fe545e4 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9343683a1f0945eea8f8b9786fe545e4
2014-07-14 03:17:36,079 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9343683a1f0945eea8f8b9786fe545e4, entries=1822430, sequenceid=17469, filesize=129.9m
2014-07-14 03:17:36,080 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1307219840, currentsize=373.0m/391141120 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 34193ms, sequenceid=17469, compaction requested=true
2014-07-14 03:17:36,080 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:152), split_queue=0, merge_queue=0
2014-07-14 03:17:36,081 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 311.0m
2014-07-14 03:17:36,081 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12221ms
2014-07-14 03:17:36,081 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,081 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12226ms
2014-07-14 03:17:36,081 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,081 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12226ms
2014-07-14 03:17:36,081 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,082 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12236ms
2014-07-14 03:17:36,082 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,082 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12239ms
2014-07-14 03:17:36,082 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,082 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12239ms
2014-07-14 03:17:36,082 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,093 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12246ms
2014-07-14 03:17:36,094 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,105 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12266ms
2014-07-14 03:17:36,105 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,107 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12270ms
2014-07-14 03:17:36,107 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,109 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12272ms
2014-07-14 03:17:36,109 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,110 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12273ms
2014-07-14 03:17:36,110 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,125 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12339ms
2014-07-14 03:17:36,125 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,125 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12351ms
2014-07-14 03:17:36,125 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,126 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12355ms
2014-07-14 03:17:36,126 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,126 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12357ms
2014-07-14 03:17:36,126 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,137 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12368ms
2014-07-14 03:17:36,137 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,137 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12369ms
2014-07-14 03:17:36,137 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,138 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14865,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041273,"queuetimems":259,"class":"HRegionServer","responsesize":15175,"method":"Multi"}
2014-07-14 03:17:36,138 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14873,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041265,"queuetimems":310,"class":"HRegionServer","responsesize":16025,"method":"Multi"}
2014-07-14 03:17:36,140 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12460ms
2014-07-14 03:17:36,140 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,140 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12461ms
2014-07-14 03:17:36,140 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,140 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12474ms
2014-07-14 03:17:36,140 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,146 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12468ms
2014-07-14 03:17:36,147 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,147 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12475ms
2014-07-14 03:17:36,147 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,149 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12479ms
2014-07-14 03:17:36,149 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,149 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14884,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041265,"queuetimems":341,"class":"HRegionServer","responsesize":16075,"method":"Multi"}
2014-07-14 03:17:36,157 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12487ms
2014-07-14 03:17:36,157 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,157 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12491ms
2014-07-14 03:17:36,157 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,161 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12496ms
2014-07-14 03:17:36,161 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,161 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12498ms
2014-07-14 03:17:36,161 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,161 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12505ms
2014-07-14 03:17:36,161 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,162 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12501ms
2014-07-14 03:17:36,162 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,165 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12505ms
2014-07-14 03:17:36,165 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,165 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12508ms
2014-07-14 03:17:36,165 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,167 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12508ms
2014-07-14 03:17:36,168 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,173 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12516ms
2014-07-14 03:17:36,173 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,176 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12521ms
2014-07-14 03:17:36,176 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,179 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12522ms
2014-07-14 03:17:36,179 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,180 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12523ms
2014-07-14 03:17:36,180 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,181 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12525ms
2014-07-14 03:17:36,181 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,189 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12534ms
2014-07-14 03:17:36,189 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,189 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12534ms
2014-07-14 03:17:36,190 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,190 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12543ms
2014-07-14 03:17:36,190 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,190 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12544ms
2014-07-14 03:17:36,190 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,191 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12546ms
2014-07-14 03:17:36,191 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,197 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12552ms
2014-07-14 03:17:36,197 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,198 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12561ms
2014-07-14 03:17:36,198 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,203 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12561ms
2014-07-14 03:17:36,203 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,209 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12573ms
2014-07-14 03:17:36,209 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,209 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12574ms
2014-07-14 03:17:36,209 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,209 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12575ms
2014-07-14 03:17:36,209 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,217 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12586ms
2014-07-14 03:17:36,217 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,217 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12588ms
2014-07-14 03:17:36,217 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:17:36,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:36,300 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:17:36,314 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:36,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70616 synced till here 70605
2014-07-14 03:17:36,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333041801 with entries=84, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333056290
2014-07-14 03:17:36,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332916636
2014-07-14 03:17:36,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332918414
2014-07-14 03:17:36,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332919830
2014-07-14 03:17:36,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332928818
2014-07-14 03:17:36,849 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17606,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333039243,"queuetimems":227,"class":"HRegionServer","responsesize":16057,"method":"Multi"}
2014-07-14 03:17:36,849 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15602,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041247,"queuetimems":444,"class":"HRegionServer","responsesize":15550,"method":"Multi"}
2014-07-14 03:17:36,849 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041259,"queuetimems":396,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:17:36,855 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17577,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333039277,"queuetimems":8,"class":"HRegionServer","responsesize":15107,"method":"Multi"}
2014-07-14 03:17:36,855 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17473,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333039382,"queuetimems":1,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 03:17:36,855 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17338,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333039517,"queuetimems":75,"class":"HRegionServer","responsesize":15635,"method":"Multi"}
2014-07-14 03:17:36,856 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041246,"queuetimems":472,"class":"HRegionServer","responsesize":15689,"method":"Multi"}
2014-07-14 03:17:36,856 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17526,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333039329,"queuetimems":0,"class":"HRegionServer","responsesize":15643,"method":"Multi"}
2014-07-14 03:17:36,856 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15608,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041247,"queuetimems":414,"class":"HRegionServer","responsesize":15631,"method":"Multi"}
2014-07-14 03:17:36,855 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15610,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041245,"queuetimems":530,"class":"HRegionServer","responsesize":16182,"method":"Multi"}
2014-07-14 03:17:36,855 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041246,"queuetimems":503,"class":"HRegionServer","responsesize":15754,"method":"Multi"}
2014-07-14 03:17:36,855 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333039270,"queuetimems":97,"class":"HRegionServer","responsesize":16915,"method":"Multi"}
2014-07-14 03:17:37,928 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16684,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041244,"queuetimems":1531,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:17:37,933 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16656,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041277,"queuetimems":233,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:17:37,933 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16132,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041801,"queuetimems":609,"class":"HRegionServer","responsesize":15871,"method":"Multi"}
2014-07-14 03:17:37,938 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041234,"queuetimems":1731,"class":"HRegionServer","responsesize":15505,"method":"Multi"}
2014-07-14 03:17:37,938 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16137,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041800,"queuetimems":638,"class":"HRegionServer","responsesize":15565,"method":"Multi"}
2014-07-14 03:17:38,009 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16732,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041277,"queuetimems":203,"class":"HRegionServer","responsesize":15979,"method":"Multi"}
2014-07-14 03:17:38,010 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16768,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041241,"queuetimems":1576,"class":"HRegionServer","responsesize":15636,"method":"Multi"}
2014-07-14 03:17:38,011 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041328,"queuetimems":224,"class":"HRegionServer","responsesize":16100,"method":"Multi"}
2014-07-14 03:17:38,012 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043605,"queuetimems":2297,"class":"HRegionServer","responsesize":15814,"method":"Multi"}
2014-07-14 03:17:38,014 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16749,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041265,"queuetimems":372,"class":"HRegionServer","responsesize":15888,"method":"Multi"}
2014-07-14 03:17:38,019 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041238,"queuetimems":1704,"class":"HRegionServer","responsesize":15874,"method":"Multi"}
2014-07-14 03:17:38,019 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16749,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041269,"queuetimems":284,"class":"HRegionServer","responsesize":15945,"method":"Multi"}
2014-07-14 03:17:38,331 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:38,334 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16529,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041804,"queuetimems":583,"class":"HRegionServer","responsesize":15643,"method":"Multi"}
2014-07-14 03:17:38,334 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16533,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041800,"queuetimems":667,"class":"HRegionServer","responsesize":15073,"method":"Multi"}
2014-07-14 03:17:38,334 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16527,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333041806,"queuetimems":543,"class":"HRegionServer","responsesize":15555,"method":"Multi"}
2014-07-14 03:17:38,334 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14728,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043605,"queuetimems":2253,"class":"HRegionServer","responsesize":15991,"method":"Multi"}
2014-07-14 03:17:38,357 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70732 synced till here 70698
2014-07-14 03:17:38,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333056290 with entries=116, filesize=98.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333058331
2014-07-14 03:17:39,086 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043834,"queuetimems":638,"class":"HRegionServer","responsesize":15678,"method":"Multi"}
2014-07-14 03:17:39,087 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043838,"queuetimems":480,"class":"HRegionServer","responsesize":15635,"method":"Multi"}
2014-07-14 03:17:39,086 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043838,"queuetimems":577,"class":"HRegionServer","responsesize":15429,"method":"Multi"}
2014-07-14 03:17:39,086 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043833,"queuetimems":711,"class":"HRegionServer","responsesize":15879,"method":"Multi"}
2014-07-14 03:17:39,086 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15248,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043838,"queuetimems":530,"class":"HRegionServer","responsesize":16187,"method":"Multi"}
2014-07-14 03:17:39,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:39,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70838 synced till here 70806
2014-07-14 03:17:40,009 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043645,"queuetimems":722,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:17:40,022 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16384,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043637,"queuetimems":2007,"class":"HRegionServer","responsesize":15879,"method":"Multi"}
2014-07-14 03:17:40,029 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043639,"queuetimems":805,"class":"HRegionServer","responsesize":15073,"method":"Multi"}
2014-07-14 03:17:40,037 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16398,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043639,"queuetimems":786,"class":"HRegionServer","responsesize":15979,"method":"Multi"}
2014-07-14 03:17:40,077 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16439,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043638,"queuetimems":1976,"class":"HRegionServer","responsesize":15936,"method":"Multi"}
2014-07-14 03:17:40,078 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16456,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043622,"queuetimems":2153,"class":"HRegionServer","responsesize":15740,"method":"Multi"}
2014-07-14 03:17:40,081 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16458,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043623,"queuetimems":2089,"class":"HRegionServer","responsesize":15733,"method":"Multi"}
2014-07-14 03:17:40,082 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16459,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043622,"queuetimems":2196,"class":"HRegionServer","responsesize":16266,"method":"Multi"}
2014-07-14 03:17:40,086 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043646,"queuetimems":671,"class":"HRegionServer","responsesize":16100,"method":"Multi"}
2014-07-14 03:17:40,119 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16489,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043630,"queuetimems":2065,"class":"HRegionServer","responsesize":15678,"method":"Multi"}
2014-07-14 03:17:40,120 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16459,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043623,"queuetimems":2118,"class":"HRegionServer","responsesize":15770,"method":"Multi"}
2014-07-14 03:17:40,129 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043646,"queuetimems":619,"class":"HRegionServer","responsesize":16057,"method":"Multi"}
2014-07-14 03:17:40,119 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16473,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043646,"queuetimems":573,"class":"HRegionServer","responsesize":15936,"method":"Multi"}
2014-07-14 03:17:40,150 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333058331 with entries=106, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333059788
2014-07-14 03:17:40,831 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333043637,"queuetimems":2037,"class":"HRegionServer","responsesize":16057,"method":"Multi"}
2014-07-14 03:17:41,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:41,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70944 synced till here 70914
2014-07-14 03:17:41,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333059788 with entries=106, filesize=91.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333061488
2014-07-14 03:17:42,184 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17678, memsize=85.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/86ce30f6e8ae4edd9fa0a298b5f59254
2014-07-14 03:17:42,209 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/86ce30f6e8ae4edd9fa0a298b5f59254 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/86ce30f6e8ae4edd9fa0a298b5f59254
2014-07-14 03:17:43,227 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/86ce30f6e8ae4edd9fa0a298b5f59254, entries=309360, sequenceid=17678, filesize=22.0m
2014-07-14 03:17:43,229 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~311.0m/326138640, currentsize=136.5m/143173120 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 7148ms, sequenceid=17678, compaction requested=true
2014-07-14 03:17:43,230 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-14 03:17:43,230 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:17:43,230 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-14 03:17:43,659 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:43,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71059 synced till here 71036
2014-07-14 03:17:43,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333061488 with entries=115, filesize=98.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333063659
2014-07-14 03:17:45,600 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:45,623 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71151 synced till here 71139
2014-07-14 03:17:45,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333063659 with entries=92, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333065601
2014-07-14 03:17:45,764 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17593, memsize=509.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/415f49c9abb54236a6059529ed9fdd81
2014-07-14 03:17:45,775 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/415f49c9abb54236a6059529ed9fdd81 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/415f49c9abb54236a6059529ed9fdd81
2014-07-14 03:17:45,791 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/415f49c9abb54236a6059529ed9fdd81, entries=1855710, sequenceid=17593, filesize=132.2m
2014-07-14 03:17:45,791 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.3g/1347352320, currentsize=385.0m/403667760 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 32630ms, sequenceid=17593, compaction requested=true
2014-07-14 03:17:45,792 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:155), split_queue=0, merge_queue=0
2014-07-14 03:17:46,128 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:17:46,129 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files; delaying flush up to 90000ms
2014-07-14 03:17:46,129 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:156), split_queue=0, merge_queue=0
2014-07-14 03:17:46,664 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:17:46,664 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 257.4m
2014-07-14 03:17:46,898 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:47,104 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/321d34ad5a954eb99f8b6f025ea73a60 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/321d34ad5a954eb99f8b6f025ea73a60
2014-07-14 03:17:47,120 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:17:47,137 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bad04fbfdde943ed94a3772cb673c556, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bad04fbfdde943ed94a3772cb673c556
2014-07-14 03:17:47,140 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/31b98797489b4499bef00173753418a3, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/31b98797489b4499bef00173753418a3
2014-07-14 03:17:47,144 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e43243fdda484b428d433057075717b0, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/e43243fdda484b428d433057075717b0
2014-07-14 03:17:47,144 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 321d34ad5a954eb99f8b6f025ea73a60(size=185.3m), total size for store is 3.6g. This selection was in queue for 0sec, and took 41sec to execute.
2014-07-14 03:17:47,144 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=3, fileSize=186.2m, priority=-1, time=286932656054862; duration=41sec
2014-07-14 03:17:47,144 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-14 03:17:47,144 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-14 03:17:47,145 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:17:47,146 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 204086167 starting at candidate #14 after considering 124 permutations with 116 in ratio
2014-07-14 03:17:47,146 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating minor compaction
2014-07-14 03:17:47,147 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:17:47,147 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=194.6m
2014-07-14 03:17:47,147 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/92bf334e21f044f4ac01cc078f4a266f, keycount=91251, bloomtype=ROW, size=65.0m, encoding=NONE, seqNum=15317
2014-07-14 03:17:47,147 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f22a57b19dd34cbbbc8d3ab00c4872d9, keycount=87306, bloomtype=ROW, size=62.2m, encoding=NONE, seqNum=15484
2014-07-14 03:17:47,147 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/1714123abc894347b180b29dc806c20c, keycount=94626, bloomtype=ROW, size=67.4m, encoding=NONE, seqNum=15652
2014-07-14 03:17:47,201 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:47,822 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 585.2m
2014-07-14 03:17:48,413 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:17:48,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:48,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71224 synced till here 71223
2014-07-14 03:17:48,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333065601 with entries=73, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333068639
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332932225
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332958737
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332959987
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332961440
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332962862
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332964733
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332966826
2014-07-14 03:17:48,671 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332968813
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332975796
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332977705
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332979179
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332980639
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332981529
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332982811
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332984153
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332986127
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332987655
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332989620
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332990941
2014-07-14 03:17:48,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332992482
2014-07-14 03:17:49,857 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17848, memsize=71.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8c705e2b149e4badaaac755915b7c473
2014-07-14 03:17:49,868 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/8c705e2b149e4badaaac755915b7c473 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8c705e2b149e4badaaac755915b7c473
2014-07-14 03:17:49,878 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8c705e2b149e4badaaac755915b7c473, entries=259280, sequenceid=17848, filesize=18.5m
2014-07-14 03:17:49,878 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.4m/273038160, currentsize=20.3m/21256720 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 3214ms, sequenceid=17848, compaction requested=true
2014-07-14 03:17:49,878 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-14 03:17:51,382 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:51,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333068639 with entries=72, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333071382
2014-07-14 03:17:52,996 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17848, memsize=102.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/40f6a449b48b4a5f93f9f3b89ae85993
2014-07-14 03:17:53,014 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/40f6a449b48b4a5f93f9f3b89ae85993 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/40f6a449b48b4a5f93f9f3b89ae85993
2014-07-14 03:17:53,022 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/40f6a449b48b4a5f93f9f3b89ae85993, entries=372770, sequenceid=17848, filesize=26.6m
2014-07-14 03:17:53,023 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~585.2m/613671120, currentsize=53.2m/55769680 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 5201ms, sequenceid=17848, compaction requested=true
2014-07-14 03:17:53,023 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:158), split_queue=0, merge_queue=0
2014-07-14 03:17:54,099 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:54,197 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333071382 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333074099
2014-07-14 03:17:56,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:56,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71453 synced till here 71449
2014-07-14 03:17:56,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333074099 with entries=84, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333076275
2014-07-14 03:17:58,209 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:17:58,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71552 synced till here 71544
2014-07-14 03:17:58,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333076275 with entries=99, filesize=85.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333078210
2014-07-14 03:18:00,702 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:00,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333078210 with entries=80, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333080703
2014-07-14 03:18:02,466 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:02,479 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71708 synced till here 71702
2014-07-14 03:18:02,578 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333080703 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333082466
2014-07-14 03:18:04,223 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:04,245 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333082466 with entries=73, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333084224
2014-07-14 03:18:04,245 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:05,499 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:18:05,499 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:18:05,500 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:159), split_queue=0, merge_queue=0
2014-07-14 03:18:05,564 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:06,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71863 synced till here 71861
2014-07-14 03:18:06,625 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333084224 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333085564
2014-07-14 03:18:06,626 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:06,841 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:18:06,841 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 256.5m
2014-07-14 03:18:07,079 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:18:09,088 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:09,261 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71968 synced till here 71958
2014-07-14 03:18:09,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333085564 with entries=105, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333089088
2014-07-14 03:18:09,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:11,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:12,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333089088 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333091985
2014-07-14 03:18:12,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:13,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:13,341 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333091985 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333093321
2014-07-14 03:18:13,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:15,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:15,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333093321 with entries=72, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333095185
2014-07-14 03:18:15,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:17,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:17,437 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72266 synced till here 72263
2014-07-14 03:18:17,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333095185 with entries=80, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333097289
2014-07-14 03:18:17,486 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:18,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:18,911 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72347 synced till here 72340
2014-07-14 03:18:19,093 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333097289 with entries=81, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333098866
2014-07-14 03:18:19,094 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:19,245 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18016, memsize=214.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/426ef96c49254a58b811f31fa1491e98
2014-07-14 03:18:19,264 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/426ef96c49254a58b811f31fa1491e98 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/426ef96c49254a58b811f31fa1491e98
2014-07-14 03:18:19,420 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/426ef96c49254a58b811f31fa1491e98, entries=781040, sequenceid=18016, filesize=55.7m
2014-07-14 03:18:19,420 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.6m/272253920, currentsize=187.0m/196109040 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 12579ms, sequenceid=18016, compaction requested=true
2014-07-14 03:18:19,420 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:160), split_queue=0, merge_queue=0
2014-07-14 03:18:20,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:21,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72430 synced till here 72428
2014-07-14 03:18:21,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333098866 with entries=83, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333100997
2014-07-14 03:18:21,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:23,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:23,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72516 synced till here 72507
2014-07-14 03:18:23,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333100997 with entries=86, filesize=73.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333103311
2014-07-14 03:18:23,383 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:23,600 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:18:23,600 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 256.8m
2014-07-14 03:18:23,795 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:18:25,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:25,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72596 synced till here 72590
2014-07-14 03:18:25,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333103311 with entries=80, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333105162
2014-07-14 03:18:25,307 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:27,215 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:27,598 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72695 synced till here 72692
2014-07-14 03:18:27,679 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333105162 with entries=99, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333107216
2014-07-14 03:18:27,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:29,235 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/a778297c325c4d6d84bd5b773ec43cbc as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/a778297c325c4d6d84bd5b773ec43cbc
2014-07-14 03:18:29,639 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:18:29,757 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/92bf334e21f044f4ac01cc078f4a266f, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/92bf334e21f044f4ac01cc078f4a266f
2014-07-14 03:18:29,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:30,062 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f22a57b19dd34cbbbc8d3ab00c4872d9, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f22a57b19dd34cbbbc8d3ab00c4872d9
2014-07-14 03:18:31,278 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 1.0g
2014-07-14 03:18:31,279 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/1714123abc894347b180b29dc806c20c, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/1714123abc894347b180b29dc806c20c
2014-07-14 03:18:31,287 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into a778297c325c4d6d84bd5b773ec43cbc(size=185.3m), total size for store is 3.5g. This selection was in queue for 0sec, and took 44sec to execute.
2014-07-14 03:18:31,287 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=3, fileSize=194.6m, priority=-1, time=286974573802470; duration=44sec
2014-07-14 03:18:31,288 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:160), split_queue=0, merge_queue=0
2014-07-14 03:18:31,288 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:18:31,292 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 206522734 starting at candidate #13 after considering 124 permutations with 98 in ratio
2014-07-14 03:18:31,292 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating minor compaction
2014-07-14 03:18:31,292 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:18:31,293 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=197.0m
2014-07-14 03:18:31,293 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec1eed89a07e4449ae1ed8efbcce2db2, keycount=87142, bloomtype=ROW, size=62.1m, encoding=NONE, seqNum=15489
2014-07-14 03:18:31,293 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14b0fab44c414c908102d161a97853cd, keycount=93826, bloomtype=ROW, size=66.8m, encoding=NONE, seqNum=15656
2014-07-14 03:18:31,293 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bdccb9a24ca8492aa3f3f5f8c6fc673e, keycount=95506, bloomtype=ROW, size=68.0m, encoding=NONE, seqNum=15826
2014-07-14 03:18:31,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72812 synced till here 72803
2014-07-14 03:18:31,384 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333107216 with entries=117, filesize=99.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333109833
2014-07-14 03:18:31,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:31,417 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:18:32,269 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:18:32,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:32,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72886 synced till here 72885
2014-07-14 03:18:32,324 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333109833 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333112289
2014-07-14 03:18:32,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:33,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:33,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 72961 synced till here 72960
2014-07-14 03:18:33,872 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333112289 with entries=75, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333113813
2014-07-14 03:18:33,878 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:35,348 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1306ms
GC pool 'ParNew' had collection(s): count=1 time=1308ms
2014-07-14 03:18:36,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:36,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73056 synced till here 73052
2014-07-14 03:18:36,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333113813 with entries=95, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333116150
2014-07-14 03:18:36,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:18:37,627 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18185, memsize=218.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/f4a9aac2605e44cbad07b997569b0ce5
2014-07-14 03:18:37,641 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/f4a9aac2605e44cbad07b997569b0ce5 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/f4a9aac2605e44cbad07b997569b0ce5
2014-07-14 03:18:37,678 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:37,679 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:37,681 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:37,682 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:37,688 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/f4a9aac2605e44cbad07b997569b0ce5, entries=794230, sequenceid=18185, filesize=56.6m
2014-07-14 03:18:37,689 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.6m/274342320, currentsize=209.1m/219293440 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 14089ms, sequenceid=18185, compaction requested=true
2014-07-14 03:18:37,689 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:160), split_queue=0, merge_queue=0
2014-07-14 03:18:37,689 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7ms
2014-07-14 03:18:37,689 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 93329ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:18:37,689 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:37,690 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9ms
2014-07-14 03:18:37,690 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:37,693 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14ms
2014-07-14 03:18:37,693 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:37,693 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15ms
2014-07-14 03:18:37,693 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:37,697 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 1.7g
2014-07-14 03:18:38,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:38,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73136 synced till here 73128
2014-07-14 03:18:38,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333116150 with entries=80, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333118106
2014-07-14 03:18:39,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:39,538 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:18:39,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73213 synced till here 73211
2014-07-14 03:18:39,692 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333118106 with entries=77, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333119538
2014-07-14 03:18:41,089 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:18:41,459 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,512 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,513 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,513 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,518 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,524 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,547 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,586 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,647 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,700 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,748 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,801 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,841 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,883 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,920 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:41,964 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:42,678 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:42,780 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:42,834 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:42,899 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,014 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,088 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,146 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,190 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,233 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,271 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,308 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:43,366 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,211 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,218 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,227 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,258 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,287 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,317 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,347 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,385 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,426 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,459 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,495 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:44,534 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:45,776 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:45,813 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:45,855 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:45,896 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:45,937 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:45,970 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:46,015 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:46,069 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:46,114 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:46,155 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:18:46,459 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,513 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:46,513 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,514 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:18:46,518 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,524 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,547 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,586 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,648 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:46,701 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:46,749 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:46,801 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,842 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:46,883 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,920 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:46,965 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:47,679 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:47,781 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:47,834 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:47,899 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:48,014 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:48,675 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5309ms
2014-07-14 03:18:48,675 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5485ms
2014-07-14 03:18:48,675 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5404ms
2014-07-14 03:18:48,675 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5442ms
2014-07-14 03:18:48,676 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5368ms
2014-07-14 03:18:48,676 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5588ms
2014-07-14 03:18:48,676 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5530ms
2014-07-14 03:18:49,212 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:49,218 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:49,227 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:49,259 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:49,288 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:49,318 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:49,347 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:49,386 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:49,426 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:49,460 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:49,496 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:49,534 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:50,777 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:50,814 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:50,855 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:50,896 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:50,938 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:50,971 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:51,015 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:51,070 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:18:51,114 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:51,155 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:18:51,459 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,513 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:51,513 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,514 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:18:51,518 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,525 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,547 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,587 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,648 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:51,701 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:51,749 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:51,801 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,842 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:51,884 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:51,921 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:51,965 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:52,679 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:52,782 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:52,835 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:52,899 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:53,015 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:53,675 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10309ms
2014-07-14 03:18:53,676 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10368ms
2014-07-14 03:18:53,677 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10530ms
2014-07-14 03:18:53,677 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10444ms
2014-07-14 03:18:53,678 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10406ms
2014-07-14 03:18:53,678 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10488ms
2014-07-14 03:18:53,678 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10590ms
2014-07-14 03:18:54,212 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,219 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,228 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,259 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,288 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,318 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,348 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:54,386 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,427 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,460 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,496 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:54,534 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:55,778 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:18:55,814 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:55,855 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:55,896 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:55,938 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:55,971 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:56,015 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:56,070 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:18:56,114 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:56,155 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:18:56,376 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18257, memsize=489.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/d62908ac3bb64e938b565c5d710f8b53
2014-07-14 03:18:56,394 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/d62908ac3bb64e938b565c5d710f8b53 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d62908ac3bb64e938b565c5d710f8b53
2014-07-14 03:18:56,415 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d62908ac3bb64e938b565c5d710f8b53, entries=1781480, sequenceid=18257, filesize=126.9m
2014-07-14 03:18:56,415 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1077537280, currentsize=171.2m/179464400 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 25137ms, sequenceid=18257, compaction requested=true
2014-07-14 03:18:56,416 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:161), split_queue=0, merge_queue=0
2014-07-14 03:18:56,416 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10261ms
2014-07-14 03:18:56,416 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files; delaying flush up to 90000ms
2014-07-14 03:18:56,416 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,416 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:162), split_queue=0, merge_queue=0
2014-07-14 03:18:56,416 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10302ms
2014-07-14 03:18:56,416 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,416 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10347ms
2014-07-14 03:18:56,416 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,416 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10401ms
2014-07-14 03:18:56,416 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,420 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10450ms
2014-07-14 03:18:56,420 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,421 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10484ms
2014-07-14 03:18:56,421 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,421 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10525ms
2014-07-14 03:18:56,421 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,421 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10566ms
2014-07-14 03:18:56,421 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,422 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10609ms
2014-07-14 03:18:56,422 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,422 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10646ms
2014-07-14 03:18:56,422 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,422 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11888ms
2014-07-14 03:18:56,422 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,433 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11938ms
2014-07-14 03:18:56,433 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,433 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11974ms
2014-07-14 03:18:56,433 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,441 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12015ms
2014-07-14 03:18:56,441 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,441 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12056ms
2014-07-14 03:18:56,441 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,441 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12094ms
2014-07-14 03:18:56,441 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,443 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12126ms
2014-07-14 03:18:56,443 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,446 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12159ms
2014-07-14 03:18:56,447 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,447 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12189ms
2014-07-14 03:18:56,447 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,457 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12230ms
2014-07-14 03:18:56,457 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,457 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12239ms
2014-07-14 03:18:56,457 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,460 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:18:56,460 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,461 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12250ms
2014-07-14 03:18:56,461 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,461 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13373ms
2014-07-14 03:18:56,461 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,466 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13276ms
2014-07-14 03:18:56,467 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,467 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13196ms
2014-07-14 03:18:56,467 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,467 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13234ms
2014-07-14 03:18:56,467 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,469 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13322ms
2014-07-14 03:18:56,469 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,469 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13161ms
2014-07-14 03:18:56,469 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,469 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13103ms
2014-07-14 03:18:56,469 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,469 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13455ms
2014-07-14 03:18:56,469 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,471 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13573ms
2014-07-14 03:18:56,471 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,471 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13638ms
2014-07-14 03:18:56,471 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,471 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13691ms
2014-07-14 03:18:56,471 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,471 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13793ms
2014-07-14 03:18:56,471 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,472 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14508ms
2014-07-14 03:18:56,472 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,472 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14552ms
2014-07-14 03:18:56,473 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,474 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14591ms
2014-07-14 03:18:56,474 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,474 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14633ms
2014-07-14 03:18:56,474 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,474 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14673ms
2014-07-14 03:18:56,475 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,475 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14727ms
2014-07-14 03:18:56,475 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,476 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14776ms
2014-07-14 03:18:56,476 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,476 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14829ms
2014-07-14 03:18:56,476 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,476 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14890ms
2014-07-14 03:18:56,476 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,476 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14929ms
2014-07-14 03:18:56,476 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,481 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14957ms
2014-07-14 03:18:56,481 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,481 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14963ms
2014-07-14 03:18:56,481 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,482 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14969ms
2014-07-14 03:18:56,482 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,489 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14976ms
2014-07-14 03:18:56,489 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,497 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14985ms
2014-07-14 03:18:56,497 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:18:56,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:56,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73320 synced till here 73290
2014-07-14 03:18:57,776 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333119538 with entries=107, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333136878
2014-07-14 03:18:57,908 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16783,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121124,"queuetimems":0,"class":"HRegionServer","responsesize":15496,"method":"Multi"}
2014-07-14 03:18:58,114 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16713,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121400,"queuetimems":0,"class":"HRegionServer","responsesize":16008,"method":"Multi"}
2014-07-14 03:18:58,324 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17098,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121226,"queuetimems":0,"class":"HRegionServer","responsesize":15872,"method":"Multi"}
2014-07-14 03:18:58,347 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17058,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121288,"queuetimems":1,"class":"HRegionServer","responsesize":15741,"method":"Multi"}
2014-07-14 03:18:58,348 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17175,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121172,"queuetimems":0,"class":"HRegionServer","responsesize":15450,"method":"Multi"}
2014-07-14 03:18:58,347 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17001,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121345,"queuetimems":1,"class":"HRegionServer","responsesize":15942,"method":"Multi"}
2014-07-14 03:18:58,393 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12385,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333126008,"queuetimems":0,"class":"HRegionServer","responsesize":15607,"method":"Multi"}
2014-07-14 03:18:58,480 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12708,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333125772,"queuetimems":0,"class":"HRegionServer","responsesize":15279,"method":"Multi"}
2014-07-14 03:18:58,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:18:58,602 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73403 synced till here 73393
2014-07-14 03:18:58,692 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333136878 with entries=83, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333138571
2014-07-14 03:18:59,813 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:18:59,813 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.6m
2014-07-14 03:18:59,817 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16732,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123085,"queuetimems":1,"class":"HRegionServer","responsesize":15945,"method":"Multi"}
2014-07-14 03:18:59,818 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16514,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123304,"queuetimems":0,"class":"HRegionServer","responsesize":15733,"method":"Multi"}
2014-07-14 03:18:59,964 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15754,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124209,"queuetimems":2,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:19:00,108 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:19:00,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:00,324 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16037,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124286,"queuetimems":0,"class":"HRegionServer","responsesize":15971,"method":"Multi"}
2014-07-14 03:19:00,328 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15983,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124344,"queuetimems":0,"class":"HRegionServer","responsesize":16008,"method":"Multi"}
2014-07-14 03:19:00,328 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17552,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333122776,"queuetimems":0,"class":"HRegionServer","responsesize":15468,"method":"Multi"}
2014-07-14 03:19:00,328 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124217,"queuetimems":1,"class":"HRegionServer","responsesize":15631,"method":"Multi"}
2014-07-14 03:19:00,330 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14365,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333125965,"queuetimems":1,"class":"HRegionServer","responsesize":16166,"method":"Multi"}
2014-07-14 03:19:00,330 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123011,"queuetimems":1,"class":"HRegionServer","responsesize":15526,"method":"Multi"}
2014-07-14 03:19:00,337 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18375,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121962,"queuetimems":0,"class":"HRegionServer","responsesize":15899,"method":"Multi"}
2014-07-14 03:19:00,348 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73504 synced till here 73489
2014-07-14 03:19:00,365 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17468,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333122896,"queuetimems":1,"class":"HRegionServer","responsesize":15687,"method":"Multi"}
2014-07-14 03:19:00,365 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17179,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123186,"queuetimems":0,"class":"HRegionServer","responsesize":16060,"method":"Multi"}
2014-07-14 03:19:00,365 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18669,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121696,"queuetimems":0,"class":"HRegionServer","responsesize":15279,"method":"Multi"}
2014-07-14 03:19:00,366 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14554,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333125810,"queuetimems":0,"class":"HRegionServer","responsesize":15928,"method":"Multi"}
2014-07-14 03:19:00,369 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15985,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124383,"queuetimems":1,"class":"HRegionServer","responsesize":16887,"method":"Multi"}
2014-07-14 03:19:00,370 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17007,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123362,"queuetimems":0,"class":"HRegionServer","responsesize":15689,"method":"Multi"}
2014-07-14 03:19:00,370 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124456,"queuetimems":0,"class":"HRegionServer","responsesize":15741,"method":"Multi"}
2014-07-14 03:19:00,376 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16151,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124225,"queuetimems":0,"class":"HRegionServer","responsesize":14172,"method":"Multi"}
2014-07-14 03:19:00,376 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17701,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333122675,"queuetimems":1,"class":"HRegionServer","responsesize":15207,"method":"Multi"}
2014-07-14 03:19:00,406 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16090,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124315,"queuetimems":0,"class":"HRegionServer","responsesize":15872,"method":"Multi"}
2014-07-14 03:19:00,417 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18835,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121582,"queuetimems":1,"class":"HRegionServer","responsesize":16062,"method":"Multi"}
2014-07-14 03:19:00,417 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18772,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121645,"queuetimems":0,"class":"HRegionServer","responsesize":16887,"method":"Multi"}
2014-07-14 03:19:00,422 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14274,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333126147,"queuetimems":1,"class":"HRegionServer","responsesize":15413,"method":"Multi"}
2014-07-14 03:19:00,422 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15891,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124530,"queuetimems":0,"class":"HRegionServer","responsesize":15450,"method":"Multi"}
2014-07-14 03:19:00,427 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14500,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333125926,"queuetimems":0,"class":"HRegionServer","responsesize":15526,"method":"Multi"}
2014-07-14 03:19:00,432 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17203,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123229,"queuetimems":0,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:19:00,432 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15940,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124492,"queuetimems":0,"class":"HRegionServer","responsesize":15942,"method":"Multi"}
2014-07-14 03:19:00,432 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17290,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123142,"queuetimems":0,"class":"HRegionServer","responsesize":15770,"method":"Multi"}
2014-07-14 03:19:00,422 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17591,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333122830,"queuetimems":0,"class":"HRegionServer","responsesize":15607,"method":"Multi"}
2014-07-14 03:19:00,437 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17169,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333123268,"queuetimems":1,"class":"HRegionServer","responsesize":16182,"method":"Multi"}
2014-07-14 03:19:00,442 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14552,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333125890,"queuetimems":0,"class":"HRegionServer","responsesize":15687,"method":"Multi"}
2014-07-14 03:19:00,443 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18922,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121520,"queuetimems":0,"class":"HRegionServer","responsesize":15971,"method":"Multi"}
2014-07-14 03:19:00,442 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124420,"queuetimems":0,"class":"HRegionServer","responsesize":15496,"method":"Multi"}
2014-07-14 03:19:00,447 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14336,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333126111,"queuetimems":0,"class":"HRegionServer","responsesize":16055,"method":"Multi"}
2014-07-14 03:19:00,448 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16191,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333124256,"queuetimems":0,"class":"HRegionServer","responsesize":16062,"method":"Multi"}
2014-07-14 03:19:00,448 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18532,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121916,"queuetimems":0,"class":"HRegionServer","responsesize":16353,"method":"Multi"}
2014-07-14 03:19:00,442 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18561,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121881,"queuetimems":0,"class":"HRegionServer","responsesize":15928,"method":"Multi"}
2014-07-14 03:19:00,442 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18644,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121798,"queuetimems":0,"class":"HRegionServer","responsesize":16055,"method":"Multi"}
2014-07-14 03:19:00,448 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121838,"queuetimems":0,"class":"HRegionServer","responsesize":15413,"method":"Multi"}
2014-07-14 03:19:00,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333138571 with entries=101, filesize=83.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333140322
2014-07-14 03:19:01,320 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333125851,"queuetimems":0,"class":"HRegionServer","responsesize":15207,"method":"Multi"}
2014-07-14 03:19:01,329 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15267,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333126062,"queuetimems":0,"class":"HRegionServer","responsesize":15468,"method":"Multi"}
2014-07-14 03:19:01,331 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19585,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333121746,"queuetimems":1,"class":"HRegionServer","responsesize":16166,"method":"Multi"}
2014-07-14 03:19:01,715 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:01,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73616 synced till here 73578
2014-07-14 03:19:03,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333140322 with entries=112, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333141716
2014-07-14 03:19:03,985 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:04,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73724 synced till here 73693
2014-07-14 03:19:04,445 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333141716 with entries=108, filesize=90.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333143986
2014-07-14 03:19:05,853 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:05,927 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 73826 synced till here 73811
2014-07-14 03:19:07,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333143986 with entries=102, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333145853
2014-07-14 03:19:07,914 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:08,167 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333145853 with entries=101, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333147914
2014-07-14 03:19:08,805 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:08,810 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:08,820 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:08,829 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,426 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,463 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,512 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,553 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,597 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,636 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:09,674 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:19:10,207 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18427, memsize=194.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/c301d9e638dc45eda465285e3afe6e7b
2014-07-14 03:19:10,233 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/c301d9e638dc45eda465285e3afe6e7b as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c301d9e638dc45eda465285e3afe6e7b
2014-07-14 03:19:10,249 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c301d9e638dc45eda465285e3afe6e7b, entries=707860, sequenceid=18427, filesize=50.4m
2014-07-14 03:19:10,250 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.5m/274253760, currentsize=168.6m/176743520 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 10437ms, sequenceid=18427, compaction requested=true
2014-07-14 03:19:10,250 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:163), split_queue=0, merge_queue=0
2014-07-14 03:19:10,250 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 576ms
2014-07-14 03:19:10,250 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,250 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 614ms
2014-07-14 03:19:10,250 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,253 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 656ms
2014-07-14 03:19:10,253 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,253 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 701ms
2014-07-14 03:19:10,253 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,257 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 745ms
2014-07-14 03:19:10,257 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,261 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 799ms
2014-07-14 03:19:10,261 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,261 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 835ms
2014-07-14 03:19:10,261 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,269 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1440ms
2014-07-14 03:19:10,269 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,272 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1452ms
2014-07-14 03:19:10,272 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,272 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1462ms
2014-07-14 03:19:10,272 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,273 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1468ms
2014-07-14 03:19:10,273 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:19:10,718 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:19:10,718 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files, but is 1.1g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:19:10,718 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. due to global heap pressure
2014-07-14 03:19:10,718 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 1.1g
2014-07-14 03:19:11,235 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/37d15ced13484d38bd0e25683eb753bc as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/37d15ced13484d38bd0e25683eb753bc
2014-07-14 03:19:11,252 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:19:11,453 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec1eed89a07e4449ae1ed8efbcce2db2, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/ec1eed89a07e4449ae1ed8efbcce2db2
2014-07-14 03:19:11,456 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14b0fab44c414c908102d161a97853cd, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14b0fab44c414c908102d161a97853cd
2014-07-14 03:19:11,458 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bdccb9a24ca8492aa3f3f5f8c6fc673e, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/bdccb9a24ca8492aa3f3f5f8c6fc673e
2014-07-14 03:19:11,459 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 37d15ced13484d38bd0e25683eb753bc(size=196.8m), total size for store is 3.6g. This selection was in queue for 0sec, and took 40sec to execute.
2014-07-14 03:19:11,459 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=3, fileSize=197.0m, priority=-1, time=287018719346653; duration=40sec
2014-07-14 03:19:11,459 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:163), split_queue=0, merge_queue=0
2014-07-14 03:19:11,459 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:19:11,461 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 281727447 starting at candidate #2 after considering 124 permutations with 117 in ratio
2014-07-14 03:19:11,461 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating minor compaction
2014-07-14 03:19:11,461 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:19:11,461 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=268.7m
2014-07-14 03:19:11,461 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cc7f13d8a66a472499329d3cd46a668a, keycount=118209, bloomtype=ROW, size=84.2m, encoding=NONE, seqNum=6828
2014-07-14 03:19:11,461 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/425dd42150a748faa7415e0a8996267c, keycount=149877, bloomtype=ROW, size=106.7m, encoding=NONE, seqNum=7325
2014-07-14 03:19:11,462 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9e8f2e6b2bd4987be3c04fddef5e787, keycount=109181, bloomtype=ROW, size=77.7m, encoding=NONE, seqNum=7889
2014-07-14 03:19:11,522 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:11,536 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74001 synced till here 73999
2014-07-14 03:19:11,552 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:19:11,557 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333147914 with entries=74, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333151522
2014-07-14 03:19:11,903 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:19:13,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:13,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333151522 with entries=71, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333153407
2014-07-14 03:19:17,407 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18323, memsize=711.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f1e6a90bcaf342f092de2d61948dfe71
2014-07-14 03:19:17,426 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/f1e6a90bcaf342f092de2d61948dfe71 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f1e6a90bcaf342f092de2d61948dfe71
2014-07-14 03:19:17,437 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f1e6a90bcaf342f092de2d61948dfe71, entries=2589510, sequenceid=18323, filesize=184.4m
2014-07-14 03:19:17,438 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.7g/1797236320, currentsize=334.0m/350250240 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 39741ms, sequenceid=18323, compaction requested=true
2014-07-14 03:19:17,438 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:163), split_queue=0, merge_queue=0
2014-07-14 03:19:17,507 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:19:17,508 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:19:17,508 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:164), split_queue=0, merge_queue=0
2014-07-14 03:19:21,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:21,982 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333153407 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333161932
2014-07-14 03:19:21,982 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332993849
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405332995942
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333004949
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333007410
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333009103
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333010901
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333012378
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333014255
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333015951
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333017402
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333021886
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333023527
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333025352
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333027510
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333029614
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333031764
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333033751
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333036547
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333039242
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333041801
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333056290
2014-07-14 03:19:21,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333058331
2014-07-14 03:19:21,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333059788
2014-07-14 03:19:21,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333061488
2014-07-14 03:19:21,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333063659
2014-07-14 03:19:22,118 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:19:22,118 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files; delaying flush up to 90000ms
2014-07-14 03:19:22,193 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:165), split_queue=0, merge_queue=0
2014-07-14 03:19:28,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:28,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74220 synced till here 74219
2014-07-14 03:19:28,196 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333161932 with entries=74, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333168147
2014-07-14 03:19:29,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:29,421 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333168147 with entries=72, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333169379
2014-07-14 03:19:30,648 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:30,700 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74371 synced till here 74365
2014-07-14 03:19:30,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333169379 with entries=79, filesize=68.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333170648
2014-07-14 03:19:32,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:32,478 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333170648 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333172428
2014-07-14 03:19:34,027 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:34,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74523 synced till here 74520
2014-07-14 03:19:34,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333172428 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333174027
2014-07-14 03:19:35,863 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:36,424 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18550, memsize=628.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/14290ffa364a4c92bb6b7d8c3d4259a7
2014-07-14 03:19:36,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74626 synced till here 74620
2014-07-14 03:19:36,472 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/14290ffa364a4c92bb6b7d8c3d4259a7 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14290ffa364a4c92bb6b7d8c3d4259a7
2014-07-14 03:19:36,480 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/14290ffa364a4c92bb6b7d8c3d4259a7, entries=2286590, sequenceid=18550, filesize=162.8m
2014-07-14 03:19:36,481 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1129741760, currentsize=254.8m/267192960 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 25763ms, sequenceid=18550, compaction requested=true
2014-07-14 03:19:36,481 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:166), split_queue=0, merge_queue=0
2014-07-14 03:19:36,507 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333174027 with entries=103, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333175864
2014-07-14 03:19:36,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333065601
2014-07-14 03:19:36,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333068639
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333071382
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333074099
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333076275
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333078210
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333080703
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333082466
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333084224
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333085564
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333089088
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333091985
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333093321
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333095185
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333097289
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333098866
2014-07-14 03:19:36,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333100997
2014-07-14 03:19:37,129 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:19:37,129 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 256.5m
2014-07-14 03:19:37,318 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:19:38,276 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:38,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74704 synced till here 74697
2014-07-14 03:19:38,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333175864 with entries=78, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333178277
2014-07-14 03:19:39,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:40,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74801 synced till here 74795
2014-07-14 03:19:40,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333178277 with entries=97, filesize=82.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333179848
2014-07-14 03:19:42,008 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:42,171 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74881 synced till here 74875
2014-07-14 03:19:42,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333179848 with entries=80, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333182008
2014-07-14 03:19:43,555 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:43,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 74957 synced till here 74955
2014-07-14 03:19:43,614 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333182008 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333183555
2014-07-14 03:19:44,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:44,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75031 synced till here 75030
2014-07-14 03:19:44,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333183555 with entries=74, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333184879
2014-07-14 03:19:46,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:46,603 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75113 synced till here 75112
2014-07-14 03:19:46,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333184879 with entries=82, filesize=70.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333186480
2014-07-14 03:19:48,475 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18718, memsize=258.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/a2707bd2f2d74543b155ef628c212691
2014-07-14 03:19:48,486 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/a2707bd2f2d74543b155ef628c212691 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/a2707bd2f2d74543b155ef628c212691
2014-07-14 03:19:48,490 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:48,634 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/a2707bd2f2d74543b155ef628c212691, entries=939850, sequenceid=18718, filesize=66.9m
2014-07-14 03:19:48,635 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.1m/270669120, currentsize=214.5m/224881840 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 11506ms, sequenceid=18718, compaction requested=true
2014-07-14 03:19:48,635 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:167), split_queue=0, merge_queue=0
2014-07-14 03:19:48,643 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333186480 with entries=81, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333188490
2014-07-14 03:19:49,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:50,093 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333188490 with entries=87, filesize=74.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333189848
2014-07-14 03:19:50,355 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:19:50,355 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:19:50,355 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:168), split_queue=0, merge_queue=0
2014-07-14 03:19:51,347 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:51,397 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75359 synced till here 75355
2014-07-14 03:19:51,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333189848 with entries=78, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333191348
2014-07-14 03:19:51,419 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:19:54,847 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:54,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333191348 with entries=71, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333194847
2014-07-14 03:19:54,868 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:19:55,105 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/5b51702cf93e4501b45d7826c9669bee as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/5b51702cf93e4501b45d7826c9669bee
2014-07-14 03:19:55,123 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:19:55,152 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cc7f13d8a66a472499329d3cd46a668a, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cc7f13d8a66a472499329d3cd46a668a
2014-07-14 03:19:55,177 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/425dd42150a748faa7415e0a8996267c, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/425dd42150a748faa7415e0a8996267c
2014-07-14 03:19:55,186 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9e8f2e6b2bd4987be3c04fddef5e787, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/f9e8f2e6b2bd4987be3c04fddef5e787
2014-07-14 03:19:55,186 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into 5b51702cf93e4501b45d7826c9669bee(size=240.0m), total size for store is 3.7g. This selection was in queue for 0sec, and took 43sec to execute.
2014-07-14 03:19:55,186 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=3, fileSize=268.7m, priority=-1, time=287058888216931; duration=43sec
2014-07-14 03:19:55,187 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:169), split_queue=0, merge_queue=0
2014-07-14 03:19:55,187 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:169), split_queue=0, merge_queue=0
2014-07-14 03:19:55,187 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:19:55,189 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 392205735 starting at candidate #9 after considering 124 permutations with 117 in ratio
2014-07-14 03:19:55,189 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating minor compaction
2014-07-14 03:19:55,189 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:19:55,189 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=374.0m
2014-07-14 03:19:55,189 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ffb40c90d2074205a327fd19f31d2d68, keycount=137698, bloomtype=ROW, size=98.1m, encoding=NONE, seqNum=12518
2014-07-14 03:19:55,190 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/42998a48681944ed8cfd034aada2bb09, keycount=171748, bloomtype=ROW, size=122.3m, encoding=NONE, seqNum=13075
2014-07-14 03:19:55,190 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4bd38bc522e04cdfbceb4aa70b3bb696, keycount=113922, bloomtype=ROW, size=81.1m, encoding=NONE, seqNum=13619
2014-07-14 03:19:55,190 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4131ee96f3e0492b8baa3838078d2909, keycount=101822, bloomtype=ROW, size=72.5m, encoding=NONE, seqNum=14123
2014-07-14 03:19:55,876 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 913.5m
2014-07-14 03:19:55,969 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:19:56,745 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:56,777 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75506 synced till here 75505
2014-07-14 03:19:56,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333194847 with entries=76, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333196745
2014-07-14 03:19:56,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:19:56,963 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:19:58,517 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:58,541 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333196745 with entries=72, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333198517
2014-07-14 03:19:58,541 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:19:59,486 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:19:59,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333198517 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333199486
2014-07-14 03:19:59,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:20:01,016 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:01,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333199486 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333201017
2014-07-14 03:20:01,054 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:20:03,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:03,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333201017 with entries=83, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333203231
2014-07-14 03:20:03,398 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:20:04,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:04,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333203231 with entries=79, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333204636
2014-07-14 03:20:04,752 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 7f4e87d2eea7a637326e2204c730bf5a
2014-07-14 03:20:06,089 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:20:06,089 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files, but is 1.3g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:20:06,089 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. due to global heap pressure
2014-07-14 03:20:06,090 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 1.3g
2014-07-14 03:20:06,364 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:06,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 75989 synced till here 75986
2014-07-14 03:20:07,176 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.53 MB, free=3.95 GB, max=3.96 GB, blocks=5, accesses=463653, hits=130355, hitRatio=28.11%, , cachingAccesses=130410, cachingHits=130297, cachingHitsRatio=99.91%, evictions=0, evicted=108, evictedPerRun=Infinity
2014-07-14 03:20:07,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333204636 with entries=101, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333206364
2014-07-14 03:20:07,630 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:20:08,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:08,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76063 synced till here 76061
2014-07-14 03:20:08,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333206364 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333208289
2014-07-14 03:20:09,198 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,201 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,201 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,203 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,205 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,211 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,219 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,227 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,244 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,278 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,294 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,297 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,352 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,395 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,434 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,472 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,504 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:09,976 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,148 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,205 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,262 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,314 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,363 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,409 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,456 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,841 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,878 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,910 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,942 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:10,978 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,010 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,043 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,075 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,109 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,138 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,168 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,200 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,232 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,444 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,502 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,686 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,735 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:11,775 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,754 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,765 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,784 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,816 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,854 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,893 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:12,931 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:14,199 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,201 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:14,202 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,203 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:14,205 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:14,212 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,219 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:14,227 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:14,245 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,278 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,294 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,297 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:14,491 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5019ms
2014-07-14 03:20:14,491 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5139ms
2014-07-14 03:20:14,491 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5096ms
2014-07-14 03:20:14,492 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5058ms
2014-07-14 03:20:14,505 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:14,976 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:15,149 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:15,205 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:15,263 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:15,314 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:16,370 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5138ms
2014-07-14 03:20:16,578 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5410ms
2014-07-14 03:20:16,578 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5440ms
2014-07-14 03:20:16,578 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5134ms
2014-07-14 03:20:16,579 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5077ms
2014-07-14 03:20:16,580 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6216ms
2014-07-14 03:20:16,580 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6171ms
2014-07-14 03:20:16,580 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6125ms
2014-07-14 03:20:16,581 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5739ms
2014-07-14 03:20:16,581 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5703ms
2014-07-14 03:20:16,581 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5671ms
2014-07-14 03:20:16,581 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5639ms
2014-07-14 03:20:16,581 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5603ms
2014-07-14 03:20:16,582 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5572ms
2014-07-14 03:20:16,582 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5539ms
2014-07-14 03:20:16,582 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5507ms
2014-07-14 03:20:16,582 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5473ms
2014-07-14 03:20:16,583 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5383ms
2014-07-14 03:20:16,686 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:16,735 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:16,775 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,754 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,766 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,785 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,816 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,854 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,893 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:17,931 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:19,199 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,202 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,202 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,203 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:19,205 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:19,212 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,220 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,228 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:19,245 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,278 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,294 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:19,297 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:20,167 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10019ms
2014-07-14 03:20:20,167 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10695ms
2014-07-14 03:20:20,168 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10816ms
2014-07-14 03:20:20,168 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10773ms
2014-07-14 03:20:20,169 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10735ms
2014-07-14 03:20:20,170 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10665ms
2014-07-14 03:20:20,170 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10194ms
2014-07-14 03:20:20,205 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:20,263 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:20,314 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:21,578 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10346ms
2014-07-14 03:20:21,578 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10410ms
2014-07-14 03:20:21,578 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10440ms
2014-07-14 03:20:21,579 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10135ms
2014-07-14 03:20:21,579 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10077ms
2014-07-14 03:20:21,580 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11217ms
2014-07-14 03:20:21,580 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11171ms
2014-07-14 03:20:21,581 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11126ms
2014-07-14 03:20:21,581 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10740ms
2014-07-14 03:20:21,581 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10703ms
2014-07-14 03:20:21,581 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10671ms
2014-07-14 03:20:21,581 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10639ms
2014-07-14 03:20:21,582 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10604ms
2014-07-14 03:20:21,582 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10572ms
2014-07-14 03:20:21,582 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10539ms
2014-07-14 03:20:21,582 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10507ms
2014-07-14 03:20:21,583 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10474ms
2014-07-14 03:20:21,583 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10383ms
2014-07-14 03:20:21,687 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:21,736 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:21,776 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:22,754 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:22,766 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:22,785 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:22,817 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:22,855 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:22,894 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:22,932 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:24,200 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,203 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,204 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:20:24,204 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,206 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,213 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:20:24,221 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,228 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,245 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,278 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,295 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:24,298 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:25,168 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15019ms
2014-07-14 03:20:25,168 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15696ms
2014-07-14 03:20:25,168 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15816ms
2014-07-14 03:20:25,169 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15774ms
2014-07-14 03:20:25,170 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15736ms
2014-07-14 03:20:25,170 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15666ms
2014-07-14 03:20:25,171 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15195ms
2014-07-14 03:20:25,206 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:20:25,264 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:20:25,315 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:20:25,436 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18915, memsize=644.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/1c4dd76b0c39414791203e57ef58ff95
2014-07-14 03:20:25,450 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/1c4dd76b0c39414791203e57ef58ff95 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/1c4dd76b0c39414791203e57ef58ff95
2014-07-14 03:20:25,474 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/1c4dd76b0c39414791203e57ef58ff95, entries=2348080, sequenceid=18915, filesize=167.2m
2014-07-14 03:20:25,474 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~915.0m/959468560, currentsize=228.5m/239615440 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 29598ms, sequenceid=18915, compaction requested=true
2014-07-14 03:20:25,474 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:169), split_queue=0, merge_queue=0
2014-07-14 03:20:25,475 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15162ms
2014-07-14 03:20:25,475 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 105937ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:20:25,475 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,475 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15213ms
2014-07-14 03:20:25,475 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,475 DEBUG [MemStoreFlusher.1] regionserver.HRegion: NOT flushing memstore for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., flushing=true, writesEnabled=true
2014-07-14 03:20:25,481 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15277ms
2014-07-14 03:20:25,481 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,481 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15505ms
2014-07-14 03:20:25,481 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,481 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15977ms
2014-07-14 03:20:25,481 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,481 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16047ms
2014-07-14 03:20:25,481 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,481 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16086ms
2014-07-14 03:20:25,482 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,482 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16130ms
2014-07-14 03:20:25,482 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,491 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16019ms
2014-07-14 03:20:25,491 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,491 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15343ms
2014-07-14 03:20:25,491 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,493 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16196ms
2014-07-14 03:20:25,493 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,505 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16212ms
2014-07-14 03:20:25,505 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,505 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16228ms
2014-07-14 03:20:25,505 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,513 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16269ms
2014-07-14 03:20:25,513 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,513 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16286ms
2014-07-14 03:20:25,513 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,513 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16294ms
2014-07-14 03:20:25,513 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,513 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16302ms
2014-07-14 03:20:25,513 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,521 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16316ms
2014-07-14 03:20:25,521 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,521 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16318ms
2014-07-14 03:20:25,521 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,521 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16320ms
2014-07-14 03:20:25,522 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,529 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16328ms
2014-07-14 03:20:25,529 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,534 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16336ms
2014-07-14 03:20:25,534 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,534 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12603ms
2014-07-14 03:20:25,534 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,534 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12641ms
2014-07-14 03:20:25,535 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,535 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12681ms
2014-07-14 03:20:25,535 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,535 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12719ms
2014-07-14 03:20:25,535 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,539 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12755ms
2014-07-14 03:20:25,540 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,540 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12775ms
2014-07-14 03:20:25,540 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,541 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12787ms
2014-07-14 03:20:25,541 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,541 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13766ms
2014-07-14 03:20:25,541 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,545 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13808ms
2014-07-14 03:20:25,545 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,553 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13867ms
2014-07-14 03:20:25,554 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,554 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14354ms
2014-07-14 03:20:25,555 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,563 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14454ms
2014-07-14 03:20:25,563 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,573 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14498ms
2014-07-14 03:20:25,573 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,581 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14538ms
2014-07-14 03:20:25,581 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,581 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14571ms
2014-07-14 03:20:25,581 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,584 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14606ms
2014-07-14 03:20:25,585 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,585 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14643ms
2014-07-14 03:20:25,586 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,587 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14677ms
2014-07-14 03:20:25,587 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,588 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14709ms
2014-07-14 03:20:25,588 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,594 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14752ms
2014-07-14 03:20:25,595 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,596 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15140ms
2014-07-14 03:20:25,596 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,596 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15187ms
2014-07-14 03:20:25,596 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,597 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15233ms
2014-07-14 03:20:25,597 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,613 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14110ms
2014-07-14 03:20:25,613 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,613 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14169ms
2014-07-14 03:20:25,613 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,621 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14483ms
2014-07-14 03:20:25,621 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,622 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14453ms
2014-07-14 03:20:25,622 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,622 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14390ms
2014-07-14 03:20:25,622 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:25,626 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17337,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208287,"queuetimems":0,"class":"HRegionServer","responsesize":16052,"method":"Multi"}
2014-07-14 03:20:25,741 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17543,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208197,"queuetimems":0,"class":"HRegionServer","responsesize":15381,"method":"Multi"}
2014-07-14 03:20:25,745 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208241,"queuetimems":1,"class":"HRegionServer","responsesize":15715,"method":"Multi"}
2014-07-14 03:20:27,140 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:27,142 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18806,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208335,"queuetimems":0,"class":"HRegionServer","responsesize":15988,"method":"Multi"}
2014-07-14 03:20:27,145 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18722,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208423,"queuetimems":0,"class":"HRegionServer","responsesize":15843,"method":"Multi"}
2014-07-14 03:20:27,157 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18778,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208379,"queuetimems":1,"class":"HRegionServer","responsesize":15455,"method":"Multi"}
2014-07-14 03:20:27,230 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76151 synced till here 76142
2014-07-14 03:20:27,255 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18790,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208464,"queuetimems":0,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 03:20:27,326 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18150,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209175,"queuetimems":1,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-14 03:20:27,347 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333208289 with entries=88, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333227140
2014-07-14 03:20:27,494 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18976,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333208518,"queuetimems":1,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:20:27,894 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18461,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209432,"queuetimems":0,"class":"HRegionServer","responsesize":15877,"method":"Multi"}
2014-07-14 03:20:27,896 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210258,"queuetimems":0,"class":"HRegionServer","responsesize":14937,"method":"Multi"}
2014-07-14 03:20:27,896 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17922,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209973,"queuetimems":0,"class":"HRegionServer","responsesize":15180,"method":"Multi"}
2014-07-14 03:20:27,896 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17584,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210311,"queuetimems":1,"class":"HRegionServer","responsesize":15930,"method":"Multi"}
2014-07-14 03:20:28,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:28,802 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209471,"queuetimems":0,"class":"HRegionServer","responsesize":15923,"method":"Multi"}
2014-07-14 03:20:28,802 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18598,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210203,"queuetimems":1,"class":"HRegionServer","responsesize":16416,"method":"Multi"}
2014-07-14 03:20:28,802 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19408,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209393,"queuetimems":0,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-14 03:20:28,802 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19299,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209502,"queuetimems":0,"class":"HRegionServer","responsesize":16070,"method":"Multi"}
2014-07-14 03:20:28,802 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19452,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209350,"queuetimems":0,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:20:28,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76259 synced till here 76224
2014-07-14 03:20:29,139 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:20:29,139 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:20:29,140 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:170), split_queue=0, merge_queue=0
2014-07-14 03:20:29,171 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333227140 with entries=108, filesize=92.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333228800
2014-07-14 03:20:29,304 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19157,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210146,"queuetimems":0,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 03:20:30,608 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210940,"queuetimems":0,"class":"HRegionServer","responsesize":16052,"method":"Multi"}
2014-07-14 03:20:30,608 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212891,"queuetimems":1,"class":"HRegionServer","responsesize":16054,"method":"Multi"}
2014-07-14 03:20:30,610 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19411,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211198,"queuetimems":0,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 03:20:30,611 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17857,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212752,"queuetimems":1,"class":"HRegionServer","responsesize":15640,"method":"Multi"}
2014-07-14 03:20:30,608 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19535,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211073,"queuetimems":0,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 03:20:30,618 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21323,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209294,"queuetimems":0,"class":"HRegionServer","responsesize":16054,"method":"Multi"}
2014-07-14 03:20:30,618 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21375,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209242,"queuetimems":0,"class":"HRegionServer","responsesize":15270,"method":"Multi"}
2014-07-14 03:20:30,621 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19580,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211041,"queuetimems":0,"class":"HRegionServer","responsesize":16327,"method":"Multi"}
2014-07-14 03:20:30,622 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17839,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212782,"queuetimems":0,"class":"HRegionServer","responsesize":15854,"method":"Multi"}
2014-07-14 03:20:30,623 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19393,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211229,"queuetimems":0,"class":"HRegionServer","responsesize":15455,"method":"Multi"}
2014-07-14 03:20:30,623 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18940,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211683,"queuetimems":0,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:20:30,624 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19181,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211442,"queuetimems":1,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:20:30,624 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210976,"queuetimems":1,"class":"HRegionServer","responsesize":15843,"method":"Multi"}
2014-07-14 03:20:30,622 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19714,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210908,"queuetimems":0,"class":"HRegionServer","responsesize":15715,"method":"Multi"}
2014-07-14 03:20:30,624 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19457,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211166,"queuetimems":0,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:20:30,623 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19487,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211136,"queuetimems":0,"class":"HRegionServer","responsesize":15463,"method":"Multi"}
2014-07-14 03:20:30,637 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18864,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211772,"queuetimems":0,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 03:20:30,637 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21436,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333209201,"queuetimems":2,"class":"HRegionServer","responsesize":15912,"method":"Multi"}
2014-07-14 03:20:30,638 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20184,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210454,"queuetimems":0,"class":"HRegionServer","responsesize":15598,"method":"Multi"}
2014-07-14 03:20:30,649 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211107,"queuetimems":1,"class":"HRegionServer","responsesize":15774,"method":"Multi"}
2014-07-14 03:20:30,654 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211007,"queuetimems":0,"class":"HRegionServer","responsesize":15988,"method":"Multi"}
2014-07-14 03:20:30,655 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19156,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211499,"queuetimems":0,"class":"HRegionServer","responsesize":16061,"method":"Multi"}
2014-07-14 03:20:30,654 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19816,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210838,"queuetimems":0,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:20:30,661 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212928,"queuetimems":1,"class":"HRegionServer","responsesize":15647,"method":"Multi"}
2014-07-14 03:20:30,661 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17898,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212763,"queuetimems":1,"class":"HRegionServer","responsesize":15910,"method":"Multi"}
2014-07-14 03:20:30,669 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333211733,"queuetimems":1,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 03:20:30,669 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17855,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212814,"queuetimems":0,"class":"HRegionServer","responsesize":16094,"method":"Multi"}
2014-07-14 03:20:30,677 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20317,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210360,"queuetimems":0,"class":"HRegionServer","responsesize":15647,"method":"Multi"}
2014-07-14 03:20:30,669 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19794,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210875,"queuetimems":0,"class":"HRegionServer","responsesize":15381,"method":"Multi"}
2014-07-14 03:20:30,677 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333210407,"queuetimems":0,"class":"HRegionServer","responsesize":15549,"method":"Multi"}
2014-07-14 03:20:30,678 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17826,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333212852,"queuetimems":1,"class":"HRegionServer","responsesize":15930,"method":"Multi"}
2014-07-14 03:20:30,793 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:30,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76339 synced till here 76331
2014-07-14 03:20:30,913 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333228800 with entries=80, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333230794
2014-07-14 03:20:32,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:32,822 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76454 synced till here 76422
2014-07-14 03:20:33,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333230794 with entries=115, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333232800
2014-07-14 03:20:35,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:35,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76572 synced till here 76527
2014-07-14 03:20:35,267 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:20:35,267 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files, but is 1.2g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:20:35,267 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. due to global heap pressure
2014-07-14 03:20:35,268 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 1.2g
2014-07-14 03:20:35,642 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333232800 with entries=118, filesize=99.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333235091
2014-07-14 03:20:37,195 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:37,417 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76697 synced till here 76647
2014-07-14 03:20:37,433 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:20:38,136 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,137 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,138 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,138 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,139 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,140 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,141 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,142 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,142 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,142 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,144 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,302 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,302 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,302 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,308 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,315 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,315 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,315 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,319 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,320 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,322 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,322 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,322 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,322 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,322 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,322 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,323 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,323 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,323 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,323 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,324 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,325 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333235091 with entries=125, filesize=106.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333237196
2014-07-14 03:20:38,455 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,457 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,458 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,463 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,463 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,485 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,485 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,486 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,486 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,486 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,487 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,489 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,490 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,490 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,490 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,493 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,493 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:38,496 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:20:43,137 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,138 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,138 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,139 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,139 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,141 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,141 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,142 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,142 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,142 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,145 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,302 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,302 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,303 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,308 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,315 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,316 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,316 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,319 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,321 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,322 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,322 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:20:43,322 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,323 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,323 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,324 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:20:43,324 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:20:43,324 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,324 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:20:43,324 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:20:43,325 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:20:43,326 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,455 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,457 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,458 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,463 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,464 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,486 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,486 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,486 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,487 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,487 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,487 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,489 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,490 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,491 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,491 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,493 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:43,494 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:20:43,496 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:20:48,138 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:20:48,138 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,139 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:20:48,139 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,140 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:20:48,141 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,141 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,143 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,143 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,143 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,145 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,303 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,303 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,304 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,309 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,316 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,316 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,316 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,319 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,321 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,323 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,323 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,324 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-14 03:20:48,325 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:20:48,325 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-14 03:20:48,326 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-14 03:20:48,326 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-14 03:20:48,326 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,327 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-14 03:20:48,327 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-14 03:20:48,328 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-14 03:20:48,328 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-14 03:20:48,456 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,457 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,459 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,464 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,464 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,486 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,486 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,487 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,487 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,488 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,488 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,490 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,491 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:48,491 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,492 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:20:48,494 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,494 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:20:48,497 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:20:51,788 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19037, memsize=962.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/b5c40ac6a85b4a02912592b629dd092e
2014-07-14 03:20:51,802 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/b5c40ac6a85b4a02912592b629dd092e as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b5c40ac6a85b4a02912592b629dd092e
2014-07-14 03:20:51,817 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/b5c40ac6a85b4a02912592b629dd092e, entries=3504320, sequenceid=19037, filesize=249.4m
2014-07-14 03:20:51,817 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1376049840, currentsize=252.0m/264291920 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 45727ms, sequenceid=19037, compaction requested=true
2014-07-14 03:20:51,817 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:171), split_queue=0, merge_queue=0
2014-07-14 03:20:51,818 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13322ms
2014-07-14 03:20:51,818 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,818 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13325ms
2014-07-14 03:20:51,818 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,818 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13325ms
2014-07-14 03:20:51,818 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,819 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13329ms
2014-07-14 03:20:51,819 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,819 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13329ms
2014-07-14 03:20:51,819 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,819 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13329ms
2014-07-14 03:20:51,819 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,819 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13330ms
2014-07-14 03:20:51,819 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,819 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13332ms
2014-07-14 03:20:51,820 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,820 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13334ms
2014-07-14 03:20:51,820 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,820 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13334ms
2014-07-14 03:20:51,820 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,820 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13334ms
2014-07-14 03:20:51,820 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,825 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13340ms
2014-07-14 03:20:51,825 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,825 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13340ms
2014-07-14 03:20:51,825 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,825 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13362ms
2014-07-14 03:20:51,825 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,825 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13362ms
2014-07-14 03:20:51,825 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,825 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13367ms
2014-07-14 03:20:51,825 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,826 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13368ms
2014-07-14 03:20:51,826 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,832 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13377ms
2014-07-14 03:20:51,832 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,834 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13510ms
2014-07-14 03:20:51,834 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,841 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13519ms
2014-07-14 03:20:51,841 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,841 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13519ms
2014-07-14 03:20:51,841 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,841 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13519ms
2014-07-14 03:20:51,841 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,845 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13520ms
2014-07-14 03:20:51,845 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,845 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13523ms
2014-07-14 03:20:51,845 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,846 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13524ms
2014-07-14 03:20:51,846 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,846 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13524ms
2014-07-14 03:20:51,846 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,849 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13527ms
2014-07-14 03:20:51,849 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,849 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13529ms
2014-07-14 03:20:51,849 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,852 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13530ms
2014-07-14 03:20:51,852 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,853 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13531ms
2014-07-14 03:20:51,853 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,853 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13533ms
2014-07-14 03:20:51,853 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,853 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13534ms
2014-07-14 03:20:51,853 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,854 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13539ms
2014-07-14 03:20:51,854 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,854 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13539ms
2014-07-14 03:20:51,854 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,861 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13546ms
2014-07-14 03:20:51,861 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,861 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13553ms
2014-07-14 03:20:51,861 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,863 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13561ms
2014-07-14 03:20:51,863 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,865 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13562ms
2014-07-14 03:20:51,865 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,865 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13563ms
2014-07-14 03:20:51,865 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,868 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13724ms
2014-07-14 03:20:51,868 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,869 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13727ms
2014-07-14 03:20:51,870 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,875 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13733ms
2014-07-14 03:20:51,875 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,877 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13735ms
2014-07-14 03:20:51,877 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,877 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13736ms
2014-07-14 03:20:51,877 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,884 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13744ms
2014-07-14 03:20:51,884 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,884 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13746ms
2014-07-14 03:20:51,884 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,889 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13751ms
2014-07-14 03:20:51,889 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,889 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13752ms
2014-07-14 03:20:51,889 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,889 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13751ms
2014-07-14 03:20:51,889 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:51,893 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13757ms
2014-07-14 03:20:51,893 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:20:52,362 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16758,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235603,"queuetimems":14361,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:20:52,739 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:20:52,739 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files; delaying flush up to 90000ms
2014-07-14 03:20:52,740 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:172), split_queue=0, merge_queue=0
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17190,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235550,"queuetimems":14398,"class":"HRegionServer","responsesize":15877,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17455,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235285,"queuetimems":14977,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17199,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235541,"queuetimems":14814,"class":"HRegionServer","responsesize":15614,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235546,"queuetimems":14543,"class":"HRegionServer","responsesize":14937,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17450,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235290,"queuetimems":14593,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 03:20:52,741 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17199,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235541,"queuetimems":14718,"class":"HRegionServer","responsesize":15647,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17126,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235613,"queuetimems":12832,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:20:52,741 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17191,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235549,"queuetimems":14457,"class":"HRegionServer","responsesize":15270,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17198,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235542,"queuetimems":14660,"class":"HRegionServer","responsesize":15549,"method":"Multi"}
2014-07-14 03:20:52,741 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17139,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235602,"queuetimems":14420,"class":"HRegionServer","responsesize":15930,"method":"Multi"}
2014-07-14 03:20:52,741 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17196,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235545,"queuetimems":14601,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-14 03:20:52,742 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235624,"queuetimems":12750,"class":"HRegionServer","responsesize":15854,"method":"Multi"}
2014-07-14 03:20:52,743 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17480,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235263,"queuetimems":15997,"class":"HRegionServer","responsesize":15715,"method":"Multi"}
2014-07-14 03:20:52,750 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17208,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235541,"queuetimems":14778,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17463,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235277,"queuetimems":14999,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:20:52,740 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17191,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235549,"queuetimems":14427,"class":"HRegionServer","responsesize":15912,"method":"Multi"}
2014-07-14 03:20:53,073 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:53,074 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17784,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235290,"queuetimems":14623,"class":"HRegionServer","responsesize":15605,"method":"Multi"}
2014-07-14 03:20:53,075 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17813,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235262,"queuetimems":16037,"class":"HRegionServer","responsesize":15988,"method":"Multi"}
2014-07-14 03:20:53,075 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17811,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235264,"queuetimems":15877,"class":"HRegionServer","responsesize":16052,"method":"Multi"}
2014-07-14 03:20:53,075 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17965,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235110,"queuetimems":15924,"class":"HRegionServer","responsesize":16124,"method":"Multi"}
2014-07-14 03:20:53,074 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17807,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235267,"queuetimems":15049,"class":"HRegionServer","responsesize":15463,"method":"Multi"}
2014-07-14 03:20:53,078 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17814,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235263,"queuetimems":15959,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 03:20:53,074 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17811,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235263,"queuetimems":15920,"class":"HRegionServer","responsesize":15843,"method":"Multi"}
2014-07-14 03:20:53,074 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235266,"queuetimems":15089,"class":"HRegionServer","responsesize":15455,"method":"Multi"}
2014-07-14 03:20:53,074 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17808,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235266,"queuetimems":15078,"class":"HRegionServer","responsesize":15381,"method":"Multi"}
2014-07-14 03:20:53,086 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16381,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333236704,"queuetimems":13678,"class":"HRegionServer","responsesize":16061,"method":"Multi"}
2014-07-14 03:20:53,094 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333236704,"queuetimems":13709,"class":"HRegionServer","responsesize":15774,"method":"Multi"}
2014-07-14 03:20:53,094 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17824,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235269,"queuetimems":15020,"class":"HRegionServer","responsesize":16327,"method":"Multi"}
2014-07-14 03:20:53,097 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16393,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333236704,"queuetimems":13739,"class":"HRegionServer","responsesize":15996,"method":"Multi"}
2014-07-14 03:20:53,102 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16396,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333236705,"queuetimems":13647,"class":"HRegionServer","responsesize":15463,"method":"Multi"}
2014-07-14 03:20:53,094 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16406,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333236687,"queuetimems":13782,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 03:20:53,105 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17564,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235541,"queuetimems":14748,"class":"HRegionServer","responsesize":15643,"method":"Multi"}
2014-07-14 03:20:53,109 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16422,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333236687,"queuetimems":13753,"class":"HRegionServer","responsesize":15640,"method":"Multi"}
2014-07-14 03:20:53,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76827 synced till here 76806
2014-07-14 03:20:53,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333237196 with entries=130, filesize=111.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333253074
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333103311
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333105162
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333107216
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333109833
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333112289
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333113813
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333116150
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333118106
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333119538
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333136878
2014-07-14 03:20:53,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333138571
2014-07-14 03:20:54,385 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235622,"queuetimems":12778,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:20:54,386 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16899,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333237487,"queuetimems":13356,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 03:20:54,385 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235604,"queuetimems":14333,"class":"HRegionServer","responsesize":15598,"method":"Multi"}
2014-07-14 03:20:54,386 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18841,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235545,"queuetimems":14570,"class":"HRegionServer","responsesize":16070,"method":"Multi"}
2014-07-14 03:20:54,389 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16899,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333237486,"queuetimems":14278,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 03:20:54,390 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18787,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235602,"queuetimems":14390,"class":"HRegionServer","responsesize":15923,"method":"Multi"}
2014-07-14 03:20:54,397 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18848,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235549,"queuetimems":14486,"class":"HRegionServer","responsesize":15180,"method":"Multi"}
2014-07-14 03:20:54,398 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235605,"queuetimems":14303,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-14 03:20:54,398 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18855,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235542,"queuetimems":14689,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 03:20:54,409 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18860,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235549,"queuetimems":14515,"class":"HRegionServer","responsesize":16054,"method":"Multi"}
2014-07-14 03:20:54,385 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333237202,"queuetimems":14112,"class":"HRegionServer","responsesize":16327,"method":"Multi"}
2014-07-14 03:20:54,385 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16898,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333237487,"queuetimems":13346,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:20:54,385 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235622,"queuetimems":12809,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:20:54,398 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18853,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333235544,"queuetimems":14629,"class":"HRegionServer","responsesize":16416,"method":"Multi"}
2014-07-14 03:20:54,397 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333237486,"queuetimems":14365,"class":"HRegionServer","responsesize":15910,"method":"Multi"}
2014-07-14 03:20:54,397 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16911,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333237486,"queuetimems":14322,"class":"HRegionServer","responsesize":16094,"method":"Multi"}
2014-07-14 03:20:55,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:56,083 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 76934 synced till here 76923
2014-07-14 03:20:56,420 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333253074 with entries=107, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333255205
2014-07-14 03:20:57,190 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:57,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77052 synced till here 77011
2014-07-14 03:20:58,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333255205 with entries=118, filesize=101.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333257190
2014-07-14 03:20:59,129 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:20:59,778 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77176 synced till here 77158
2014-07-14 03:21:00,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333257190 with entries=124, filesize=106.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333259129
2014-07-14 03:21:01,196 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:01,710 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333259129 with entries=106, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333261196
2014-07-14 03:21:02,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:02,928 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77396 synced till here 77354
2014-07-14 03:21:03,651 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:21:03,651 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files, but is 1.1g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:21:03,651 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. due to global heap pressure
2014-07-14 03:21:03,652 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 1.1g
2014-07-14 03:21:03,749 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333261196 with entries=114, filesize=98.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333262714
2014-07-14 03:21:04,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:04,602 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77511 synced till here 77478
2014-07-14 03:21:04,729 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:05,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333262714 with entries=115, filesize=98.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333264564
2014-07-14 03:21:05,650 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,651 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,654 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,655 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,655 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,657 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,660 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,691 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,691 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,783 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,784 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,785 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,786 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,788 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,901 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,902 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,902 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,902 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,903 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,905 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,906 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,906 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,996 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,997 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,997 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:05,997 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,000 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,001 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,001 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,001 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,001 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,002 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,002 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,004 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,004 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,005 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,005 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,005 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,007 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,008 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,008 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,009 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,009 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,009 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,009 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,009 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,009 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,010 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,010 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:06,011 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:10,330 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/c6a246182e90430c9fffc2de251fe2fd as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c6a246182e90430c9fffc2de251fe2fd
2014-07-14 03:21:10,346 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:21:10,357 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ffb40c90d2074205a327fd19f31d2d68, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ffb40c90d2074205a327fd19f31d2d68
2014-07-14 03:21:10,359 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/42998a48681944ed8cfd034aada2bb09, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/42998a48681944ed8cfd034aada2bb09
2014-07-14 03:21:10,364 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4bd38bc522e04cdfbceb4aa70b3bb696, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4bd38bc522e04cdfbceb4aa70b3bb696
2014-07-14 03:21:10,370 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4131ee96f3e0492b8baa3838078d2909, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/4131ee96f3e0492b8baa3838078d2909
2014-07-14 03:21:10,370 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into c6a246182e90430c9fffc2de251fe2fd(size=364.7m), total size for store is 3.7g. This selection was in queue for 0sec, and took 1mins, 15sec to execute.
2014-07-14 03:21:10,370 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=4, fileSize=374.0m, priority=-1, time=287102616215303; duration=1mins, 15sec
2014-07-14 03:21:10,370 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:172), split_queue=0, merge_queue=0
2014-07-14 03:21:10,371 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 03:21:10,371 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 73753436 starting at candidate #16 after considering 132 permutations with 72 in ratio
2014-07-14 03:21:10,371 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating minor compaction
2014-07-14 03:21:10,372 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:21:10,372 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=70.3m
2014-07-14 03:21:10,372 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/20e7ef6b67c14fbdb58e6485e1687e4e, keycount=41890, bloomtype=ROW, size=29.8m, encoding=NONE, seqNum=17476
2014-07-14 03:21:10,372 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/86ce30f6e8ae4edd9fa0a298b5f59254, keycount=30936, bloomtype=ROW, size=22.0m, encoding=NONE, seqNum=17678
2014-07-14 03:21:10,372 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8c705e2b149e4badaaac755915b7c473, keycount=25928, bloomtype=ROW, size=18.5m, encoding=NONE, seqNum=17848
2014-07-14 03:21:10,437 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:10,651 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:10,652 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,655 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:10,656 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,656 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:10,657 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,660 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,691 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,691 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,783 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,784 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,785 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:21:10,787 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,788 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,901 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,902 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,902 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,903 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:10,903 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,905 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-14 03:21:10,906 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:10,906 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,997 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:10,997 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,997 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:10,997 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,001 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,001 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,001 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,001 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,002 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,002 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,002 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,005 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,005 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 03:21:11,006 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-14 03:21:11,006 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,006 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,007 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,008 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,009 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,009 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,010 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:11,010 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,010 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 03:21:11,010 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-14 03:21:11,011 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,011 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:11,011 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5010ms
2014-07-14 03:21:11,012 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:14,962 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19194, memsize=890.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/11c051d54cd44515a850c1bfa898b109
2014-07-14 03:21:14,981 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/11c051d54cd44515a850c1bfa898b109 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/11c051d54cd44515a850c1bfa898b109
2014-07-14 03:21:14,996 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/11c051d54cd44515a850c1bfa898b109, entries=3242530, sequenceid=19194, filesize=230.8m
2014-07-14 03:21:14,996 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.2g/1244830320, currentsize=397.9m/417205440 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 39728ms, sequenceid=19194, compaction requested=true
2014-07-14 03:21:14,997 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:172), split_queue=0, merge_queue=0
2014-07-14 03:21:14,997 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8986ms
2014-07-14 03:21:14,997 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:14,998 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8996ms
2014-07-14 03:21:14,998 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:14,998 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8988ms
2014-07-14 03:21:14,998 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,007 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8998ms
2014-07-14 03:21:15,007 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,007 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9002ms
2014-07-14 03:21:15,007 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,008 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9002ms
2014-07-14 03:21:15,008 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,013 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9004ms
2014-07-14 03:21:15,013 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,013 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9004ms
2014-07-14 03:21:15,013 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,014 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9004ms
2014-07-14 03:21:15,014 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,014 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9006ms
2014-07-14 03:21:15,014 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,015 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9007ms
2014-07-14 03:21:15,015 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,015 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9008ms
2014-07-14 03:21:15,015 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,029 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9024ms
2014-07-14 03:21:15,029 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,029 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9024ms
2014-07-14 03:21:15,029 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,030 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9025ms
2014-07-14 03:21:15,030 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,031 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9031ms
2014-07-14 03:21:15,031 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,041 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9037ms
2014-07-14 03:21:15,041 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,041 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9039ms
2014-07-14 03:21:15,041 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,042 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9039ms
2014-07-14 03:21:15,042 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,043 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9041ms
2014-07-14 03:21:15,043 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,044 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9042ms
2014-07-14 03:21:15,044 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,053 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9052ms
2014-07-14 03:21:15,054 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,054 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9053ms
2014-07-14 03:21:15,054 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,055 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9054ms
2014-07-14 03:21:15,055 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,065 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9068ms
2014-07-14 03:21:15,065 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,068 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9071ms
2014-07-14 03:21:15,068 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,069 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9071ms
2014-07-14 03:21:15,069 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,069 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9073ms
2014-07-14 03:21:15,069 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,077 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9171ms
2014-07-14 03:21:15,077 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,078 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9173ms
2014-07-14 03:21:15,078 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,089 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9187ms
2014-07-14 03:21:15,090 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,090 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9187ms
2014-07-14 03:21:15,091 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,097 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9195ms
2014-07-14 03:21:15,097 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,097 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9195ms
2014-07-14 03:21:15,097 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,098 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9195ms
2014-07-14 03:21:15,098 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,105 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9204ms
2014-07-14 03:21:15,105 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,105 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9317ms
2014-07-14 03:21:15,105 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,108 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9322ms
2014-07-14 03:21:15,108 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,117 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9334ms
2014-07-14 03:21:15,117 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,117 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9333ms
2014-07-14 03:21:15,117 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,118 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9334ms
2014-07-14 03:21:15,118 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,123 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9431ms
2014-07-14 03:21:15,123 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,124 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9432ms
2014-07-14 03:21:15,124 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,125 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9464ms
2014-07-14 03:21:15,125 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,126 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9468ms
2014-07-14 03:21:15,126 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,127 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9471ms
2014-07-14 03:21:15,127 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,128 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9473ms
2014-07-14 03:21:15,128 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,134 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9480ms
2014-07-14 03:21:15,134 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,134 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9483ms
2014-07-14 03:21:15,134 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,145 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9495ms
2014-07-14 03:21:15,145 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:21:15,148 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11453,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263694,"queuetimems":22765,"class":"HRegionServer","responsesize":15463,"method":"Multi"}
2014-07-14 03:21:15,226 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11540,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263685,"queuetimems":22832,"class":"HRegionServer","responsesize":15774,"method":"Multi"}
2014-07-14 03:21:15,465 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:15,467 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11795,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263672,"queuetimems":23954,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-14 03:21:15,467 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11762,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263705,"queuetimems":21733,"class":"HRegionServer","responsesize":16094,"method":"Multi"}
2014-07-14 03:21:15,473 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11787,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263685,"queuetimems":22866,"class":"HRegionServer","responsesize":16061,"method":"Multi"}
2014-07-14 03:21:15,473 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11768,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263704,"queuetimems":21789,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:21:15,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77629 synced till here 77584
2014-07-14 03:21:15,672 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:21:15,672 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 399.1m
2014-07-14 03:21:15,676 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11980,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263695,"queuetimems":22689,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:21:15,676 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11971,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263705,"queuetimems":21762,"class":"HRegionServer","responsesize":15719,"method":"Multi"}
2014-07-14 03:21:15,677 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11981,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263695,"queuetimems":22604,"class":"HRegionServer","responsesize":16124,"method":"Multi"}
2014-07-14 03:21:15,685 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11990,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263695,"queuetimems":22652,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 03:21:15,686 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263681,"queuetimems":22902,"class":"HRegionServer","responsesize":15640,"method":"Multi"}
2014-07-14 03:21:15,686 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12011,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263675,"queuetimems":23924,"class":"HRegionServer","responsesize":15877,"method":"Multi"}
2014-07-14 03:21:15,844 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263704,"queuetimems":21798,"class":"HRegionServer","responsesize":15513,"method":"Multi"}
2014-07-14 03:21:15,850 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12155,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263694,"queuetimems":22800,"class":"HRegionServer","responsesize":15854,"method":"Multi"}
2014-07-14 03:21:15,861 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263695,"queuetimems":22729,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:21:15,924 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12252,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333263672,"queuetimems":23993,"class":"HRegionServer","responsesize":16070,"method":"Multi"}
2014-07-14 03:21:15,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333264564 with entries=118, filesize=100.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333275466
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333140322
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333141716
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333143986
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333145853
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333147914
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333151522
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333153407
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333161932
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333168147
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333169379
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333170648
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333172428
2014-07-14 03:21:16,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333174027
2014-07-14 03:21:16,870 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264402,"queuetimems":12805,"class":"HRegionServer","responsesize":15912,"method":"Multi"}
2014-07-14 03:21:16,877 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264402,"queuetimems":14583,"class":"HRegionServer","responsesize":15381,"method":"Multi"}
2014-07-14 03:21:16,885 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12491,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264394,"queuetimems":14617,"class":"HRegionServer","responsesize":15715,"method":"Multi"}
2014-07-14 03:21:17,110 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:17,134 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12739,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264394,"queuetimems":14653,"class":"HRegionServer","responsesize":15950,"method":"Multi"}
2014-07-14 03:21:17,134 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12907,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264227,"queuetimems":20541,"class":"HRegionServer","responsesize":15605,"method":"Multi"}
2014-07-14 03:21:17,134 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264234,"queuetimems":14581,"class":"HRegionServer","responsesize":15988,"method":"Multi"}
2014-07-14 03:21:17,363 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13165,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264197,"queuetimems":22195,"class":"HRegionServer","responsesize":16327,"method":"Multi"}
2014-07-14 03:21:17,363 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12960,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264402,"queuetimems":12849,"class":"HRegionServer","responsesize":15647,"method":"Multi"}
2014-07-14 03:21:17,377 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12975,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264402,"queuetimems":14540,"class":"HRegionServer","responsesize":15455,"method":"Multi"}
2014-07-14 03:21:17,378 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13157,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264221,"queuetimems":22158,"class":"HRegionServer","responsesize":15996,"method":"Multi"}
2014-07-14 03:21:17,385 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13162,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264223,"queuetimems":22130,"class":"HRegionServer","responsesize":15910,"method":"Multi"}
2014-07-14 03:21:17,377 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13144,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264233,"queuetimems":14625,"class":"HRegionServer","responsesize":15830,"method":"Multi"}
2014-07-14 03:21:17,389 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264223,"queuetimems":20646,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 03:21:17,397 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13010,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264387,"queuetimems":14689,"class":"HRegionServer","responsesize":16052,"method":"Multi"}
2014-07-14 03:21:17,403 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13178,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264224,"queuetimems":20605,"class":"HRegionServer","responsesize":15643,"method":"Multi"}
2014-07-14 03:21:17,403 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264233,"queuetimems":20513,"class":"HRegionServer","responsesize":15614,"method":"Multi"}
2014-07-14 03:21:17,403 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264233,"queuetimems":14669,"class":"HRegionServer","responsesize":15843,"method":"Multi"}
2014-07-14 03:21:17,409 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13205,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264204,"queuetimems":22172,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:21:17,403 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13178,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333264225,"queuetimems":20573,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:21:17,409 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11869,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265540,"queuetimems":13820,"class":"HRegionServer","responsesize":14937,"method":"Multi"}
2014-07-14 03:21:17,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:17,709 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11711,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265998,"queuetimems":13316,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:21:17,709 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265551,"queuetimems":13752,"class":"HRegionServer","responsesize":15930,"method":"Multi"}
2014-07-14 03:21:17,709 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12158,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265551,"queuetimems":13790,"class":"HRegionServer","responsesize":15598,"method":"Multi"}
2014-07-14 03:21:17,713 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11715,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265998,"queuetimems":13351,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-14 03:21:17,719 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11724,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265994,"queuetimems":13471,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 03:21:17,721 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11822,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265899,"queuetimems":13520,"class":"HRegionServer","responsesize":16070,"method":"Multi"}
2014-07-14 03:21:17,920 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265514,"queuetimems":13878,"class":"HRegionServer","responsesize":15877,"method":"Multi"}
2014-07-14 03:21:17,921 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12021,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265899,"queuetimems":13988,"class":"HRegionServer","responsesize":16054,"method":"Multi"}
2014-07-14 03:21:17,922 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12405,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265516,"queuetimems":13839,"class":"HRegionServer","responsesize":16416,"method":"Multi"}
2014-07-14 03:21:17,922 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11927,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265995,"queuetimems":13419,"class":"HRegionServer","responsesize":15549,"method":"Multi"}
2014-07-14 03:21:17,929 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12031,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265898,"queuetimems":14061,"class":"HRegionServer","responsesize":15789,"method":"Multi"}
2014-07-14 03:21:17,931 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11937,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265994,"queuetimems":13534,"class":"HRegionServer","responsesize":15923,"method":"Multi"}
2014-07-14 03:21:17,945 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12046,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265899,"queuetimems":13616,"class":"HRegionServer","responsesize":15180,"method":"Multi"}
2014-07-14 03:21:17,945 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11948,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333265997,"queuetimems":13387,"class":"HRegionServer","responsesize":15270,"method":"Multi"}
2014-07-14 03:21:18,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77775 synced till here 77741
2014-07-14 03:21:18,802 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333275466 with entries=146, filesize=124.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333277694
2014-07-14 03:21:20,574 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:20,634 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77876 synced till here 77849
2014-07-14 03:21:20,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333277694 with entries=101, filesize=86.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333280574
2014-07-14 03:21:21,317 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/a25d5d6c3a5c4b2b8d21014308e12d4f as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/a25d5d6c3a5c4b2b8d21014308e12d4f
2014-07-14 03:21:21,593 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:21:22,606 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/20e7ef6b67c14fbdb58e6485e1687e4e, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/20e7ef6b67c14fbdb58e6485e1687e4e
2014-07-14 03:21:22,609 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/86ce30f6e8ae4edd9fa0a298b5f59254, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/86ce30f6e8ae4edd9fa0a298b5f59254
2014-07-14 03:21:22,614 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8c705e2b149e4badaaac755915b7c473, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/8c705e2b149e4badaaac755915b7c473
2014-07-14 03:21:22,614 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into a25d5d6c3a5c4b2b8d21014308e12d4f(size=46.7m), total size for store is 3.9g. This selection was in queue for 0sec, and took 12sec to execute.
2014-07-14 03:21:22,614 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=3, fileSize=70.3m, priority=-2, time=287177798797936; duration=12sec
2014-07-14 03:21:22,614 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:173), split_queue=0, merge_queue=0
2014-07-14 03:21:22,614 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:173), split_queue=0, merge_queue=0
2014-07-14 03:21:22,615 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:21:22,626 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 232395819 starting at candidate #16 after considering 124 permutations with 98 in ratio
2014-07-14 03:21:22,626 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: fd2af1df8ba9259ec0c538eeceae443e - family: Initiating minor compaction
2014-07-14 03:21:22,627 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:21:22,627 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp, totalSize=221.6m
2014-07-14 03:21:22,627 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8c7b149ed0504198a7cb60e3ecb4deda, keycount=91572, bloomtype=ROW, size=65.2m, encoding=NONE, seqNum=16662
2014-07-14 03:21:22,628 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9343683a1f0945eea8f8b9786fe545e4, keycount=182243, bloomtype=ROW, size=129.9m, encoding=NONE, seqNum=17469
2014-07-14 03:21:22,628 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/40f6a449b48b4a5f93f9f3b89ae85993, keycount=37277, bloomtype=ROW, size=26.6m, encoding=NONE, seqNum=17848
2014-07-14 03:21:22,718 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:22,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:22,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 77994 synced till here 77973
2014-07-14 03:21:23,141 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333280574 with entries=118, filesize=100.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333282895
2014-07-14 03:21:23,581 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19470, memsize=72.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f9853f4df82e401981adeb907dd6b696
2014-07-14 03:21:23,601 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f9853f4df82e401981adeb907dd6b696 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9853f4df82e401981adeb907dd6b696
2014-07-14 03:21:23,613 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9853f4df82e401981adeb907dd6b696, entries=263930, sequenceid=19470, filesize=18.8m
2014-07-14 03:21:23,614 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~422.4m/442955040, currentsize=148.2m/155444960 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 7942ms, sequenceid=19470, compaction requested=true
2014-07-14 03:21:23,614 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:173), split_queue=0, merge_queue=0
2014-07-14 03:21:23,614 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 93259ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:21:23,614 DEBUG [MemStoreFlusher.1] regionserver.HRegion: NOT flushing memstore for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., flushing=true, writesEnabled=true
2014-07-14 03:21:24,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:24,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78096 synced till here 78073
2014-07-14 03:21:25,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333282895 with entries=102, filesize=86.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333284724
2014-07-14 03:21:27,683 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:27,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333284724 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333287683
2014-07-14 03:21:30,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:30,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78242 synced till here 78240
2014-07-14 03:21:30,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333287683 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333290120
2014-07-14 03:21:32,136 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:32,173 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78319 synced till here 78316
2014-07-14 03:21:32,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333290120 with entries=77, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333292136
2014-07-14 03:21:32,433 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:21:32,433 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 259.3m
2014-07-14 03:21:32,779 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:33,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:33,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78406 synced till here 78394
2014-07-14 03:21:33,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333292136 with entries=87, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333293740
2014-07-14 03:21:35,612 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:35,635 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78487 synced till here 78479
2014-07-14 03:21:35,700 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333293740 with entries=81, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333295612
2014-07-14 03:21:35,838 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19420, memsize=619.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f3d6525daaa549a68b37582ca7b7e315
2014-07-14 03:21:35,855 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/f3d6525daaa549a68b37582ca7b7e315 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f3d6525daaa549a68b37582ca7b7e315
2014-07-14 03:21:35,882 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/f3d6525daaa549a68b37582ca7b7e315, entries=2254760, sequenceid=19420, filesize=160.5m
2014-07-14 03:21:35,883 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1141076880, currentsize=413.0m/433072960 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 32231ms, sequenceid=19420, compaction requested=true
2014-07-14 03:21:35,883 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:174), split_queue=0, merge_queue=0
2014-07-14 03:21:35,918 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:21:35,918 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:21:35,919 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:175), split_queue=0, merge_queue=0
2014-07-14 03:21:37,559 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:37,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78575 synced till here 78561
2014-07-14 03:21:37,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333295612 with entries=88, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333297560
2014-07-14 03:21:37,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333175864
2014-07-14 03:21:37,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333178277
2014-07-14 03:21:37,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333179848
2014-07-14 03:21:37,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333182008
2014-07-14 03:21:37,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333183555
2014-07-14 03:21:37,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333184879
2014-07-14 03:21:37,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333186480
2014-07-14 03:21:37,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333188490
2014-07-14 03:21:37,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333189848
2014-07-14 03:21:37,716 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333191348
2014-07-14 03:21:38,392 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:38,561 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78658 synced till here 78655
2014-07-14 03:21:38,583 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333297560 with entries=83, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333298392
2014-07-14 03:21:38,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:40,270 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:40,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 78732 synced till here 78731
2014-07-14 03:21:40,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333298392 with entries=74, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333300270
2014-07-14 03:21:40,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:41,037 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19643, memsize=121.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/5366c693367d40d3b090d651123e42ea
2014-07-14 03:21:41,053 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/5366c693367d40d3b090d651123e42ea as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5366c693367d40d3b090d651123e42ea
2014-07-14 03:21:41,066 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5366c693367d40d3b090d651123e42ea, entries=443330, sequenceid=19643, filesize=31.5m
2014-07-14 03:21:41,066 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.3m/278201760, currentsize=153.4m/160809440 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 8633ms, sequenceid=19643, compaction requested=true
2014-07-14 03:21:41,066 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:176), split_queue=0, merge_queue=0
2014-07-14 03:21:41,817 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:41,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333300270 with entries=73, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333301817
2014-07-14 03:21:41,843 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:43,412 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:43,458 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333301817 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333303413
2014-07-14 03:21:43,459 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:44,937 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:44,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333303413 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333304937
2014-07-14 03:21:44,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:46,292 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:46,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79027 synced till here 79023
2014-07-14 03:21:46,342 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:21:46,342 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files; delaying flush up to 90000ms
2014-07-14 03:21:46,343 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:177), split_queue=0, merge_queue=0
2014-07-14 03:21:46,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333304937 with entries=78, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333306292
2014-07-14 03:21:46,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:47,368 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:47,391 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79100 synced till here 79099
2014-07-14 03:21:47,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333306292 with entries=73, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333307369
2014-07-14 03:21:47,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:48,876 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:48,891 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79173 synced till here 79172
2014-07-14 03:21:48,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333307369 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333308877
2014-07-14 03:21:48,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:50,475 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:50,508 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79247 synced till here 79245
2014-07-14 03:21:50,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333308877 with entries=74, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333310476
2014-07-14 03:21:50,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:52,420 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1177ms
GC pool 'ParNew' had collection(s): count=1 time=1279ms
2014-07-14 03:21:52,618 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:21:52,618 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. due to global heap pressure
2014-07-14 03:21:52,619 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 1.3g
2014-07-14 03:21:52,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:52,939 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79325 synced till here 79321
2014-07-14 03:21:52,973 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333310476 with entries=78, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333312887
2014-07-14 03:21:52,974 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): f874ab9cace3c84c3e27af574e5b4d27
2014-07-14 03:21:53,336 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:21:53,336 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files, but is 1.5g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:21:53,336 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. due to global heap pressure
2014-07-14 03:21:53,337 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 1.5g
2014-07-14 03:21:54,657 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:21:54,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79404 synced till here 79399
2014-07-14 03:21:54,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333312887 with entries=79, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333314658
2014-07-14 03:21:54,809 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:54,912 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,913 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,962 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,962 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,962 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,968 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,968 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,968 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:54,980 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,011 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,042 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,072 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,102 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,130 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,160 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,212 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,247 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,281 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,329 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,359 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,388 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,417 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,449 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,477 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,508 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:55,536 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:56,554 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:56,597 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:21:57,173 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,203 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,257 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,268 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,297 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,327 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,357 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,387 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,417 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,447 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,477 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,506 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,540 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,570 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,599 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,660 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,744 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,787 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,832 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:57,870 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:59,180 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:59,218 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:59,258 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:21:59,913 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:59,913 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:59,962 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:59,962 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:59,963 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:21:59,968 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:59,968 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:59,968 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:21:59,980 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,012 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,043 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,073 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,103 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,131 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,160 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,212 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,247 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,281 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,330 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,359 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,388 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,418 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,449 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:00,478 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,509 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:00,537 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:01,555 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,173 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,257 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5054ms
2014-07-14 03:22:02,258 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5024ms
2014-07-14 03:22:02,268 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,298 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,328 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,357 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,387 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,417 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,447 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,477 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,506 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,540 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,570 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,600 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,661 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,745 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,788 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:02,832 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:02,870 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:04,180 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:04,219 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:22:04,259 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:22:04,913 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:04,914 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:04,963 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:04,964 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:04,964 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:22:04,969 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:04,969 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:04,969 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:04,980 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,012 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,043 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,073 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,103 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,131 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,160 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,213 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,248 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,281 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:05,330 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,360 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:05,388 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:05,418 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,450 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:05,467 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/2c2d8417e6404818b975445fd90e3ac1 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/2c2d8417e6404818b975445fd90e3ac1
2014-07-14 03:22:05,479 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,483 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:22:05,495 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8c7b149ed0504198a7cb60e3ecb4deda, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/8c7b149ed0504198a7cb60e3ecb4deda
2014-07-14 03:22:05,497 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9343683a1f0945eea8f8b9786fe545e4, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/9343683a1f0945eea8f8b9786fe545e4
2014-07-14 03:22:05,500 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/40f6a449b48b4a5f93f9f3b89ae85993, to hdfs://master:54310/hbase/archive/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/40f6a449b48b4a5f93f9f3b89ae85993
2014-07-14 03:22:05,500 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. into 2c2d8417e6404818b975445fd90e3ac1(size=211.6m), total size for store is 3.9g. This selection was in queue for 0sec, and took 42sec to execute.
2014-07-14 03:22:05,500 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., storeName=family, fileCount=3, fileSize=221.6m, priority=-1, time=287190053563624; duration=42sec
2014-07-14 03:22:05,500 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:178), split_queue=0, merge_queue=0
2014-07-14 03:22:05,500 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:178), split_queue=0, merge_queue=0
2014-07-14 03:22:05,501 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:22:05,501 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 480695201 starting at candidate #16 after considering 124 permutations with 110 in ratio
2014-07-14 03:22:05,501 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 5cdea4a8c4f1b79cac96dfb3d518efe1 - family: Initiating minor compaction
2014-07-14 03:22:05,502 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:22:05,502 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp, totalSize=458.4m
2014-07-14 03:22:05,502 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d62908ac3bb64e938b565c5d710f8b53, keycount=178148, bloomtype=ROW, size=126.9m, encoding=NONE, seqNum=18257
2014-07-14 03:22:05,502 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c301d9e638dc45eda465285e3afe6e7b, keycount=70786, bloomtype=ROW, size=50.4m, encoding=NONE, seqNum=18427
2014-07-14 03:22:05,502 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/11c051d54cd44515a850c1bfa898b109, keycount=324253, bloomtype=ROW, size=230.8m, encoding=NONE, seqNum=19194
2014-07-14 03:22:05,502 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9853f4df82e401981adeb907dd6b696, keycount=26393, bloomtype=ROW, size=18.8m, encoding=NONE, seqNum=19470
2014-07-14 03:22:05,502 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5366c693367d40d3b090d651123e42ea, keycount=44333, bloomtype=ROW, size=31.5m, encoding=NONE, seqNum=19643
2014-07-14 03:22:05,509 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,537 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:05,623 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:22:06,555 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,174 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,259 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10025ms
2014-07-14 03:22:07,260 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10057ms
2014-07-14 03:22:07,268 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:07,298 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,329 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:22:07,357 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:07,387 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,417 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:07,447 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,477 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:07,507 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,540 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,570 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:07,600 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,661 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,745 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,788 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:07,832 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:07,871 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:22:09,180 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:09,219 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:09,259 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:22:09,914 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:09,914 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:09,963 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:09,964 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:09,964 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:09,969 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:09,969 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:09,970 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:09,981 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:10,012 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,043 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,073 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,103 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,131 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,160 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,213 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:10,248 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,282 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,331 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,360 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,389 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,419 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:10,450 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,479 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:10,509 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:10,538 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:11,555 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,174 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,260 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15026ms
2014-07-14 03:22:12,260 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15057ms
2014-07-14 03:22:12,269 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:22:12,299 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,329 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:12,357 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:22:12,387 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,418 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,447 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,477 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:22:12,507 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,540 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,570 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:22:12,600 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,662 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,745 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,788 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,833 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:12,871 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:22:14,124 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19878, memsize=444.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/cf4c5e74e60e4031904ec99b9ba76440
2014-07-14 03:22:14,139 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/cf4c5e74e60e4031904ec99b9ba76440 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/cf4c5e74e60e4031904ec99b9ba76440
2014-07-14 03:22:14,152 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/cf4c5e74e60e4031904ec99b9ba76440, entries=1617640, sequenceid=19878, filesize=115.2m
2014-07-14 03:22:14,153 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1358087600, currentsize=49.7m/52095200 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 21534ms, sequenceid=19878, compaction requested=true
2014-07-14 03:22:14,153 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:178), split_queue=0, merge_queue=0
2014-07-14 03:22:14,153 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16283ms
2014-07-14 03:22:14,153 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 105014ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:22:14,153 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,153 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16321ms
2014-07-14 03:22:14,154 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,154 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., flushing=true, writesEnabled=true
2014-07-14 03:22:14,154 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16367ms
2014-07-14 03:22:14,154 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,154 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16410ms
2014-07-14 03:22:14,154 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,154 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16494ms
2014-07-14 03:22:14,154 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,159 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16560ms
2014-07-14 03:22:14,159 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,159 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16589ms
2014-07-14 03:22:14,159 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,160 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16621ms
2014-07-14 03:22:14,160 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,160 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16654ms
2014-07-14 03:22:14,160 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,166 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16689ms
2014-07-14 03:22:14,166 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,166 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16720ms
2014-07-14 03:22:14,167 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,173 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16756ms
2014-07-14 03:22:14,173 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,173 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16787ms
2014-07-14 03:22:14,173 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,181 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:14,181 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,181 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16824ms
2014-07-14 03:22:14,182 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,182 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16855ms
2014-07-14 03:22:14,182 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,182 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16885ms
2014-07-14 03:22:14,182 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,182 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16914ms
2014-07-14 03:22:14,182 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,187 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16984ms
2014-07-14 03:22:14,187 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,188 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16953ms
2014-07-14 03:22:14,188 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,188 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17015ms
2014-07-14 03:22:14,188 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,190 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17636ms
2014-07-14 03:22:14,190 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,197 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18661ms
2014-07-14 03:22:14,197 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,197 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18689ms
2014-07-14 03:22:14,197 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,205 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18728ms
2014-07-14 03:22:14,205 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,207 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18758ms
2014-07-14 03:22:14,207 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,210 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18793ms
2014-07-14 03:22:14,210 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,212 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18824ms
2014-07-14 03:22:14,212 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,212 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18853ms
2014-07-14 03:22:14,213 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,213 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18884ms
2014-07-14 03:22:14,213 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,213 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18932ms
2014-07-14 03:22:14,213 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,213 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18966ms
2014-07-14 03:22:14,213 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,214 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19003ms
2014-07-14 03:22:14,215 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,216 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19057ms
2014-07-14 03:22:14,216 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,216 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19086ms
2014-07-14 03:22:14,216 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,220 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:22:14,220 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,221 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19119ms
2014-07-14 03:22:14,221 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,221 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19149ms
2014-07-14 03:22:14,221 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,221 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19179ms
2014-07-14 03:22:14,221 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,221 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19210ms
2014-07-14 03:22:14,222 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,222 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19243ms
2014-07-14 03:22:14,222 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,222 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19254ms
2014-07-14 03:22:14,222 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,222 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19254ms
2014-07-14 03:22:14,222 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,229 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19261ms
2014-07-14 03:22:14,229 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,229 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19267ms
2014-07-14 03:22:14,229 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,229 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19267ms
2014-07-14 03:22:14,229 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,229 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19267ms
2014-07-14 03:22:14,229 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,230 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19316ms
2014-07-14 03:22:14,230 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,230 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19318ms
2014-07-14 03:22:14,230 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,236 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14978ms
2014-07-14 03:22:14,236 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:22:14,237 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 773.3m
2014-07-14 03:22:14,759 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:14,766 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314721,"queuetimems":0,"class":"HRegionServer","responsesize":15669,"method":"Multi"}
2014-07-14 03:22:14,770 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314659,"queuetimems":0,"class":"HRegionServer","responsesize":15800,"method":"Multi"}
2014-07-14 03:22:15,434 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20741,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314692,"queuetimems":4,"class":"HRegionServer","responsesize":15795,"method":"Multi"}
2014-07-14 03:22:15,437 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314752,"queuetimems":0,"class":"HRegionServer","responsesize":15803,"method":"Multi"}
2014-07-14 03:22:15,449 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20817,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314632,"queuetimems":0,"class":"HRegionServer","responsesize":16226,"method":"Multi"}
2014-07-14 03:22:15,450 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314782,"queuetimems":0,"class":"HRegionServer","responsesize":15441,"method":"Multi"}
2014-07-14 03:22:15,517 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79499 synced till here 79483
2014-07-14 03:22:15,714 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333314658 with entries=95, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333334760
2014-07-14 03:22:16,137 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21236,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314901,"queuetimems":0,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:22:16,141 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314811,"queuetimems":0,"class":"HRegionServer","responsesize":15854,"method":"Multi"}
2014-07-14 03:22:16,141 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333314841,"queuetimems":1,"class":"HRegionServer","responsesize":15542,"method":"Multi"}
2014-07-14 03:22:16,152 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18409,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317742,"queuetimems":0,"class":"HRegionServer","responsesize":15643,"method":"Multi"}
2014-07-14 03:22:16,153 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18285,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317867,"queuetimems":1,"class":"HRegionServer","responsesize":15746,"method":"Multi"}
2014-07-14 03:22:16,152 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18368,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317783,"queuetimems":1,"class":"HRegionServer","responsesize":15614,"method":"Multi"}
2014-07-14 03:22:16,161 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:22:16,525 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:16,526 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317828,"queuetimems":0,"class":"HRegionServer","responsesize":15605,"method":"Multi"}
2014-07-14 03:22:16,559 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79603 synced till here 79577
2014-07-14 03:22:17,237 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333334760 with entries=104, filesize=87.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333336525
2014-07-14 03:22:17,500 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20086,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317414,"queuetimems":0,"class":"HRegionServer","responsesize":15953,"method":"Multi"}
2014-07-14 03:22:17,500 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20026,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317474,"queuetimems":0,"class":"HRegionServer","responsesize":15732,"method":"Multi"}
2014-07-14 03:22:17,500 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19996,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317504,"queuetimems":1,"class":"HRegionServer","responsesize":15648,"method":"Multi"}
2014-07-14 03:22:17,707 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20140,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317567,"queuetimems":1,"class":"HRegionServer","responsesize":15813,"method":"Multi"}
2014-07-14 03:22:17,713 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22613,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315100,"queuetimems":1,"class":"HRegionServer","responsesize":16024,"method":"Multi"}
2014-07-14 03:22:17,713 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22237,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315476,"queuetimems":0,"class":"HRegionServer","responsesize":15774,"method":"Multi"}
2014-07-14 03:22:17,713 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315070,"queuetimems":0,"class":"HRegionServer","responsesize":15953,"method":"Multi"}
2014-07-14 03:22:17,713 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317597,"queuetimems":1,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:22:17,714 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315040,"queuetimems":0,"class":"HRegionServer","responsesize":15732,"method":"Multi"}
2014-07-14 03:22:17,714 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22586,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315128,"queuetimems":0,"class":"HRegionServer","responsesize":15664,"method":"Multi"}
2014-07-14 03:22:17,717 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21165,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333316552,"queuetimems":0,"class":"HRegionServer","responsesize":15860,"method":"Multi"}
2014-07-14 03:22:17,718 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315386,"queuetimems":1,"class":"HRegionServer","responsesize":15910,"method":"Multi"}
2014-07-14 03:22:17,718 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20060,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317658,"queuetimems":0,"class":"HRegionServer","responsesize":15771,"method":"Multi"}
2014-07-14 03:22:17,717 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20422,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317295,"queuetimems":0,"class":"HRegionServer","responsesize":15800,"method":"Multi"}
2014-07-14 03:22:17,722 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18507,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333319215,"queuetimems":0,"class":"HRegionServer","responsesize":16214,"method":"Multi"}
2014-07-14 03:22:17,730 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22485,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315245,"queuetimems":0,"class":"HRegionServer","responsesize":15813,"method":"Multi"}
2014-07-14 03:22:17,731 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317385,"queuetimems":1,"class":"HRegionServer","responsesize":16024,"method":"Multi"}
2014-07-14 03:22:17,736 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317265,"queuetimems":0,"class":"HRegionServer","responsesize":15669,"method":"Multi"}
2014-07-14 03:22:17,736 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20411,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317325,"queuetimems":0,"class":"HRegionServer","responsesize":15803,"method":"Multi"}
2014-07-14 03:22:17,736 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22579,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315157,"queuetimems":0,"class":"HRegionServer","responsesize":15921,"method":"Multi"}
2014-07-14 03:22:17,731 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20529,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317201,"queuetimems":0,"class":"HRegionServer","responsesize":15795,"method":"Multi"}
2014-07-14 03:22:17,736 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315447,"queuetimems":0,"class":"HRegionServer","responsesize":15996,"method":"Multi"}
2014-07-14 03:22:17,736 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20382,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317354,"queuetimems":0,"class":"HRegionServer","responsesize":15441,"method":"Multi"}
2014-07-14 03:22:17,736 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22321,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315415,"queuetimems":0,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:22:17,747 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20209,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317537,"queuetimems":1,"class":"HRegionServer","responsesize":15542,"method":"Multi"}
2014-07-14 03:22:17,750 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22422,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315327,"queuetimems":0,"class":"HRegionServer","responsesize":15463,"method":"Multi"}
2014-07-14 03:22:17,750 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333319254,"queuetimems":0,"class":"HRegionServer","responsesize":15860,"method":"Multi"}
2014-07-14 03:22:17,750 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18575,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333319175,"queuetimems":0,"class":"HRegionServer","responsesize":14903,"method":"Multi"}
2014-07-14 03:22:17,751 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20306,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317444,"queuetimems":0,"class":"HRegionServer","responsesize":15584,"method":"Multi"}
2014-07-14 03:22:17,753 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20521,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317232,"queuetimems":0,"class":"HRegionServer","responsesize":16226,"method":"Multi"}
2014-07-14 03:22:17,754 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22246,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315507,"queuetimems":0,"class":"HRegionServer","responsesize":16214,"method":"Multi"}
2014-07-14 03:22:17,757 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315278,"queuetimems":0,"class":"HRegionServer","responsesize":15584,"method":"Multi"}
2014-07-14 03:22:17,750 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20578,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333317171,"queuetimems":0,"class":"HRegionServer","responsesize":16032,"method":"Multi"}
2014-07-14 03:22:17,753 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22544,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315209,"queuetimems":0,"class":"HRegionServer","responsesize":15580,"method":"Multi"}
2014-07-14 03:22:17,825 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:17,846 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315534,"queuetimems":0,"class":"HRegionServer","responsesize":14903,"method":"Multi"}
2014-07-14 03:22:18,013 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315009,"queuetimems":0,"class":"HRegionServer","responsesize":15648,"method":"Multi"}
2014-07-14 03:22:18,014 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22657,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333315357,"queuetimems":1,"class":"HRegionServer","responsesize":16032,"method":"Multi"}
2014-07-14 03:22:18,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79723 synced till here 79683
2014-07-14 03:22:18,809 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333336525 with entries=120, filesize=99.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333337826
2014-07-14 03:22:19,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:20,291 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79837 synced till here 79835
2014-07-14 03:22:20,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333337826 with entries=114, filesize=89.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333339622
2014-07-14 03:22:21,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:21,184 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 79927 synced till here 79919
2014-07-14 03:22:21,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333339622 with entries=90, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333341131
2014-07-14 03:22:22,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:22,601 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80018 synced till here 80011
2014-07-14 03:22:22,702 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333341131 with entries=91, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333342556
2014-07-14 03:22:23,443 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:22:24,387 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:24,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333342556 with entries=89, filesize=75.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333344388
2014-07-14 03:22:25,770 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:25,777 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19882, memsize=645.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/cadb4eca65514b03b986228873287046
2014-07-14 03:22:25,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80183 synced till here 80179
2014-07-14 03:22:25,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333344388 with entries=76, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333345770
2014-07-14 03:22:25,889 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/cadb4eca65514b03b986228873287046 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cadb4eca65514b03b986228873287046
2014-07-14 03:22:25,900 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/cadb4eca65514b03b986228873287046, entries=2348950, sequenceid=19882, filesize=167.3m
2014-07-14 03:22:25,900 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.5g/1578791920, currentsize=315.4m/330680800 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 32563ms, sequenceid=19882, compaction requested=true
2014-07-14 03:22:25,900 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:179), split_queue=0, merge_queue=0
2014-07-14 03:22:25,900 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files; delaying flush up to 90000ms
2014-07-14 03:22:25,900 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:180), split_queue=0, merge_queue=0
2014-07-14 03:22:25,970 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:22:25,970 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:22:25,970 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:181), split_queue=0, merge_queue=0
2014-07-14 03:22:27,401 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:27,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80282 synced till here 80281
2014-07-14 03:22:27,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333345770 with entries=99, filesize=84.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333347402
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333194847
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333196745
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333198517
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333199486
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333201017
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333203231
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333204636
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333206364
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333208289
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333227140
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333228800
2014-07-14 03:22:27,766 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333230794
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333232800
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333235091
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333237196
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333253074
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333255205
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333257190
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333259129
2014-07-14 03:22:27,767 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333261196
2014-07-14 03:22:29,228 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:29,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80364 synced till here 80356
2014-07-14 03:22:29,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333347402 with entries=82, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333349228
2014-07-14 03:22:30,527 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:30,555 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333349228 with entries=76, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333350527
2014-07-14 03:22:32,075 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:32,368 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80528 synced till here 80519
2014-07-14 03:22:32,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333350527 with entries=88, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333352076
2014-07-14 03:22:34,075 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:34,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333352076 with entries=80, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333354076
2014-07-14 03:22:35,587 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:35,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80683 synced till here 80681
2014-07-14 03:22:35,630 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333354076 with entries=75, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333355587
2014-07-14 03:22:37,647 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:37,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333355587 with entries=76, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333357647
2014-07-14 03:22:38,434 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=19951, memsize=456.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/3af780c5311a47818d06bd2ba0deee80
2014-07-14 03:22:38,444 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/.tmp/3af780c5311a47818d06bd2ba0deee80 as hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/3af780c5311a47818d06bd2ba0deee80
2014-07-14 03:22:38,456 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/fd2af1df8ba9259ec0c538eeceae443e/family/3af780c5311a47818d06bd2ba0deee80, entries=1662880, sequenceid=19951, filesize=118.4m
2014-07-14 03:22:38,456 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~821.9m/861829760, currentsize=469.6m/492440480 for region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. in 24219ms, sequenceid=19951, compaction requested=true
2014-07-14 03:22:38,456 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-14 03:22:38,969 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e. has too many store files; delaying flush up to 90000ms
2014-07-14 03:22:38,969 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-14 03:22:38,969 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:22:39,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:39,633 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80873 synced till here 80868
2014-07-14 03:22:39,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333357647 with entries=114, filesize=95.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333359167
2014-07-14 03:22:39,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333262714
2014-07-14 03:22:39,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333264564
2014-07-14 03:22:39,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333275466
2014-07-14 03:22:39,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333277694
2014-07-14 03:22:39,770 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333280574
2014-07-14 03:22:39,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333282895
2014-07-14 03:22:39,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333284724
2014-07-14 03:22:39,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333287683
2014-07-14 03:22:39,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333290120
2014-07-14 03:22:41,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:41,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 80958 synced till here 80957
2014-07-14 03:22:41,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333359167 with entries=85, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333361567
2014-07-14 03:22:43,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:43,956 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81043 synced till here 81031
2014-07-14 03:22:44,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333361567 with entries=85, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333363806
2014-07-14 03:22:46,387 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:46,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81122 synced till here 81116
2014-07-14 03:22:46,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333363806 with entries=79, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333366388
2014-07-14 03:22:46,480 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:47,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:47,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81197 synced till here 81196
2014-07-14 03:22:47,990 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333366388 with entries=75, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333367959
2014-07-14 03:22:47,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:49,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:49,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81281 synced till here 81271
2014-07-14 03:22:49,711 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333367959 with entries=84, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333369478
2014-07-14 03:22:49,712 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:51,441 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:51,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81358 synced till here 81352
2014-07-14 03:22:51,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333369478 with entries=77, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333371442
2014-07-14 03:22:51,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:52,450 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:52,483 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81435 synced till here 81432
2014-07-14 03:22:52,554 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333371442 with entries=77, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333372451
2014-07-14 03:22:52,554 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:54,015 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:54,054 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81514 synced till here 81512
2014-07-14 03:22:54,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333372451 with entries=79, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333374015
2014-07-14 03:22:54,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:55,597 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:56,029 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81613 synced till here 81611
2014-07-14 03:22:56,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333374015 with entries=99, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333375597
2014-07-14 03:22:56,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 5cdea4a8c4f1b79cac96dfb3d518efe1
2014-07-14 03:22:57,180 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:22:57,180 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. has too many store files, but is 1.2g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:22:57,180 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. due to global heap pressure
2014-07-14 03:22:57,180 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 1.2g
2014-07-14 03:22:57,344 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:57,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81687 synced till here 81686
2014-07-14 03:22:57,382 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333375597 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333377344
2014-07-14 03:22:57,693 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:22:57,693 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files, but is 919.0m vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:22:57,693 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. due to global heap pressure
2014-07-14 03:22:57,693 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 919.0m
2014-07-14 03:22:58,603 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:22:58,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:22:58,778 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:22:58,782 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333377344 with entries=73, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333378752
2014-07-14 03:22:59,667 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,675 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,678 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,681 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,706 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,715 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,723 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,743 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,756 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:22:59,940 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,021 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,070 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,125 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,171 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,295 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,362 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,436 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,492 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,570 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,767 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:00,834 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,152 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,444 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,492 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,536 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,571 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,626 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,669 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:01,706 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:03,821 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:03,849 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:03,879 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:03,908 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:03,938 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:03,974 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,011 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,058 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,101 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,141 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,185 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,234 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,275 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,285 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,327 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,370 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:04,668 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:04,675 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:04,678 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:04,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:04,707 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:04,716 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:04,723 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:04,743 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:04,757 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:04,941 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:05,021 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,070 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,125 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,171 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,296 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,363 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:05,437 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:05,456 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:05,492 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,546 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:05,571 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:05,586 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:05,624 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:05,664 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:05,768 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:05,834 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,153 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,445 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:06,492 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,536 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,571 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,626 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,669 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:06,707 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:08,822 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:08,849 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:08,880 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:08,908 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:08,939 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:08,974 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:09,011 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:09,058 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:09,102 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:09,141 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:09,186 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:09,234 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:09,275 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:09,285 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:09,327 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:09,371 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:09,668 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:09,675 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:09,679 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:09,681 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:09,707 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:09,716 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:09,723 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:09,743 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:09,757 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:09,942 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,022 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:10,070 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:10,126 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,171 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:10,296 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,363 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,437 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,457 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:10,492 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:10,547 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-14 03:23:10,571 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,586 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:10,624 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:10,664 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-14 03:23:10,768 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:10,835 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:11,153 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:11,446 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:23:11,492 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:11,536 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:11,572 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:11,627 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:11,670 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:11,707 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:13,823 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-14 03:23:13,850 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:13,880 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:13,908 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:13,939 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:13,975 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,011 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,058 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:14,102 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,141 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,186 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,234 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:14,276 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:14,286 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,327 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,371 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:14,668 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:14,676 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:23:14,679 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:14,682 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:23:14,707 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:14,716 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:14,723 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:23:14,744 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:14,758 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:14,942 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:23:15,022 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,070 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:23:15,126 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,172 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,296 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,363 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,437 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,457 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:15,493 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,547 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-14 03:23:15,571 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,586 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:15,625 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:15,664 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-14 03:23:15,768 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:15,835 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:16,153 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:16,446 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:23:16,493 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:16,537 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:16,572 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:17,054 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15348ms
2014-07-14 03:23:17,055 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15429ms
2014-07-14 03:23:17,055 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15386ms
2014-07-14 03:23:18,823 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:23:18,850 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:18,881 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:23:18,909 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:18,940 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:23:18,975 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,011 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,059 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,102 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,142 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-14 03:23:19,186 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,234 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:23:19,276 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,286 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,327 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,371 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:19,669 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:23:19,676 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:19,679 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:19,682 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:19,707 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:19,717 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:23:19,724 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:19,744 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:19,758 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:23:19,942 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:23:20,022 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,071 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,126 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,172 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,296 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,363 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,437 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,458 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:20,493 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,547 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:20,571 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,586 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-14 03:23:20,625 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:20,665 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-14 03:23:20,768 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:20,835 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-14 03:23:21,154 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-14 03:23:21,646 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20074ms
2014-07-14 03:23:21,646 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20202ms
2014-07-14 03:23:21,647 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20155ms
2014-07-14 03:23:21,647 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20111ms
2014-07-14 03:23:22,055 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20349ms
2014-07-14 03:23:22,055 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20386ms
2014-07-14 03:23:22,055 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20429ms
2014-07-14 03:23:22,253 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20481, memsize=663.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/0ada75bc29ec4759b30f16359097935a
2014-07-14 03:23:22,269 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/0ada75bc29ec4759b30f16359097935a as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0ada75bc29ec4759b30f16359097935a
2014-07-14 03:23:22,282 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/0ada75bc29ec4759b30f16359097935a, entries=2416350, sequenceid=20481, filesize=171.9m
2014-07-14 03:23:22,282 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~920.6m/965357600, currentsize=34.1m/35757440 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 24589ms, sequenceid=20481, compaction requested=true
2014-07-14 03:23:22,283 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:184), split_queue=0, merge_queue=0
2014-07-14 03:23:22,283 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20657ms
2014-07-14 03:23:22,283 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,283 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20614ms
2014-07-14 03:23:22,283 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,283 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20577ms
2014-07-14 03:23:22,283 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,283 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20747ms
2014-07-14 03:23:22,283 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,283 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20791ms
2014-07-14 03:23:22,284 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,284 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20840ms
2014-07-14 03:23:22,284 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,284 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20713ms
2014-07-14 03:23:22,284 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,285 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21132ms
2014-07-14 03:23:22,285 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,289 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21455ms
2014-07-14 03:23:22,289 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,290 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21523ms
2014-07-14 03:23:22,290 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,293 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16629ms
2014-07-14 03:23:22,293 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,293 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16669ms
2014-07-14 03:23:22,293 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,293 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16707ms
2014-07-14 03:23:22,293 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,294 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21724ms
2014-07-14 03:23:22,294 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,294 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16748ms
2014-07-14 03:23:22,294 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,294 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21802ms
2014-07-14 03:23:22,294 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,297 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16841ms
2014-07-14 03:23:22,297 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,297 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21861ms
2014-07-14 03:23:22,297 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,303 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21941ms
2014-07-14 03:23:22,303 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,303 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22008ms
2014-07-14 03:23:22,303 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,303 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22132ms
2014-07-14 03:23:22,303 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,305 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22180ms
2014-07-14 03:23:22,305 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,305 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22235ms
2014-07-14 03:23:22,305 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,305 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22284ms
2014-07-14 03:23:22,305 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,309 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22369ms
2014-07-14 03:23:22,309 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,310 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22554ms
2014-07-14 03:23:22,310 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,311 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22568ms
2014-07-14 03:23:22,311 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,317 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22594ms
2014-07-14 03:23:22,317 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,317 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22602ms
2014-07-14 03:23:22,317 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,318 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22612ms
2014-07-14 03:23:22,318 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,319 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22638ms
2014-07-14 03:23:22,320 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,320 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22642ms
2014-07-14 03:23:22,320 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,320 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22645ms
2014-07-14 03:23:22,320 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,327 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22660ms
2014-07-14 03:23:22,327 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,333 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17963ms
2014-07-14 03:23:22,333 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,333 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18007ms
2014-07-14 03:23:22,333 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,333 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18048ms
2014-07-14 03:23:22,333 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,333 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18058ms
2014-07-14 03:23:22,334 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,334 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18100ms
2014-07-14 03:23:22,334 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,334 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18149ms
2014-07-14 03:23:22,334 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,334 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18194ms
2014-07-14 03:23:22,334 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,334 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18233ms
2014-07-14 03:23:22,334 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,334 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18276ms
2014-07-14 03:23:22,334 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,335 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18325ms
2014-07-14 03:23:22,335 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,335 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18361ms
2014-07-14 03:23:22,335 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,335 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18397ms
2014-07-14 03:23:22,335 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,335 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18427ms
2014-07-14 03:23:22,335 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,335 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18456ms
2014-07-14 03:23:22,335 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,335 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18486ms
2014-07-14 03:23:22,335 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,336 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18515ms
2014-07-14 03:23:22,336 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:22,468 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23377,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379090,"queuetimems":0,"class":"HRegionServer","responsesize":16029,"method":"Multi"}
2014-07-14 03:23:22,469 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379137,"queuetimems":1,"class":"HRegionServer","responsesize":15745,"method":"Multi"}
2014-07-14 03:23:22,663 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379184,"queuetimems":0,"class":"HRegionServer","responsesize":15436,"method":"Multi"}
2014-07-14 03:23:22,959 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:22,960 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379662,"queuetimems":1,"class":"HRegionServer","responsesize":15767,"method":"Multi"}
2014-07-14 03:23:22,960 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379647,"queuetimems":361,"class":"HRegionServer","responsesize":16258,"method":"Multi"}
2014-07-14 03:23:23,043 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379228,"queuetimems":0,"class":"HRegionServer","responsesize":15591,"method":"Multi"}
2014-07-14 03:23:23,230 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21564,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381666,"queuetimems":0,"class":"HRegionServer","responsesize":15436,"method":"Multi"}
2014-07-14 03:23:23,278 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 81920 synced till here 81893
2014-07-14 03:23:23,456 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21833,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381622,"queuetimems":1,"class":"HRegionServer","responsesize":15745,"method":"Multi"}
2014-07-14 03:23:23,456 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21923,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381532,"queuetimems":0,"class":"HRegionServer","responsesize":16029,"method":"Multi"}
2014-07-14 03:23:23,456 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21752,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381703,"queuetimems":0,"class":"HRegionServer","responsesize":15865,"method":"Multi"}
2014-07-14 03:23:23,959 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333378752 with entries=160, filesize=131.2m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333402959
2014-07-14 03:23:24,231 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22790,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381441,"queuetimems":0,"class":"HRegionServer","responsesize":15591,"method":"Multi"}
2014-07-14 03:23:24,626 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20779,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333383847,"queuetimems":0,"class":"HRegionServer","responsesize":15667,"method":"Multi"}
2014-07-14 03:23:24,686 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:24,698 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/ee72d6f2ec3d4c5dac3b902040f8fc67 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/ee72d6f2ec3d4c5dac3b902040f8fc67
2014-07-14 03:23:24,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82013 synced till here 81997
2014-07-14 03:23:24,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333402959 with entries=93, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333404687
2014-07-14 03:23:25,592 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333385543,"queuetimems":0,"class":"HRegionServer","responsesize":16258,"method":"Multi"}
2014-07-14 03:23:25,699 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:23:25,700 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21730,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333383969,"queuetimems":1,"class":"HRegionServer","responsesize":15652,"method":"Multi"}
2014-07-14 03:23:25,702 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384230,"queuetimems":0,"class":"HRegionServer","responsesize":15866,"method":"Multi"}
2014-07-14 03:23:25,702 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21823,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333383878,"queuetimems":1,"class":"HRegionServer","responsesize":15572,"method":"Multi"}
2014-07-14 03:23:25,702 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24553,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381149,"queuetimems":1,"class":"HRegionServer","responsesize":15758,"method":"Multi"}
2014-07-14 03:23:25,702 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25636,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380066,"queuetimems":1,"class":"HRegionServer","responsesize":16006,"method":"Multi"}
2014-07-14 03:23:25,707 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24138,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381568,"queuetimems":0,"class":"HRegionServer","responsesize":16258,"method":"Multi"}
2014-07-14 03:23:25,709 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26033,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379676,"queuetimems":1,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:23:25,721 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379754,"queuetimems":1,"class":"HRegionServer","responsesize":15389,"method":"Multi"}
2014-07-14 03:23:25,702 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21767,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333383935,"queuetimems":0,"class":"HRegionServer","responsesize":15849,"method":"Multi"}
2014-07-14 03:23:25,724 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21629,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384094,"queuetimems":0,"class":"HRegionServer","responsesize":16207,"method":"Multi"}
2014-07-14 03:23:25,721 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25599,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380122,"queuetimems":0,"class":"HRegionServer","responsesize":15667,"method":"Multi"}
2014-07-14 03:23:25,729 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21458,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384271,"queuetimems":0,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:23:25,730 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384284,"queuetimems":1,"class":"HRegionServer","responsesize":5841,"method":"Multi"}
2014-07-14 03:23:25,730 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21593,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384137,"queuetimems":0,"class":"HRegionServer","responsesize":15505,"method":"Multi"}
2014-07-14 03:23:25,730 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25298,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380432,"queuetimems":0,"class":"HRegionServer","responsesize":15572,"method":"Multi"}
2014-07-14 03:23:25,731 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25721,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380010,"queuetimems":0,"class":"HRegionServer","responsesize":15027,"method":"Multi"}
2014-07-14 03:23:25,737 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25168,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380569,"queuetimems":1,"class":"HRegionServer","responsesize":5841,"method":"Multi"}
2014-07-14 03:23:25,737 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333385619,"queuetimems":0,"class":"HRegionServer","responsesize":15436,"method":"Multi"}
2014-07-14 03:23:25,737 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21684,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384053,"queuetimems":0,"class":"HRegionServer","responsesize":16105,"method":"Multi"}
2014-07-14 03:23:25,738 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25801,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379936,"queuetimems":0,"class":"HRegionServer","responsesize":16207,"method":"Multi"}
2014-07-14 03:23:25,738 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384363,"queuetimems":1,"class":"HRegionServer","responsesize":16006,"method":"Multi"}
2014-07-14 03:23:25,738 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24249,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333381488,"queuetimems":1,"class":"HRegionServer","responsesize":15767,"method":"Multi"}
2014-07-14 03:23:25,742 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21421,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384320,"queuetimems":1,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-14 03:23:25,729 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25561,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380168,"queuetimems":0,"class":"HRegionServer","responsesize":16105,"method":"Multi"}
2014-07-14 03:23:25,737 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380291,"queuetimems":0,"class":"HRegionServer","responsesize":15505,"method":"Multi"}
2014-07-14 03:23:25,743 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25383,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380359,"queuetimems":0,"class":"HRegionServer","responsesize":15866,"method":"Multi"}
2014-07-14 03:23:25,743 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21924,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333383819,"queuetimems":1,"class":"HRegionServer","responsesize":15027,"method":"Multi"}
2014-07-14 03:23:25,744 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333385454,"queuetimems":1,"class":"HRegionServer","responsesize":15865,"method":"Multi"}
2014-07-14 03:23:25,745 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21839,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333383906,"queuetimems":0,"class":"HRegionServer","responsesize":15389,"method":"Multi"}
2014-07-14 03:23:25,748 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26044,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333379704,"queuetimems":0,"class":"HRegionServer","responsesize":15660,"method":"Multi"}
2014-07-14 03:23:25,748 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21741,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384007,"queuetimems":1,"class":"HRegionServer","responsesize":15758,"method":"Multi"}
2014-07-14 03:23:25,749 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333385582,"queuetimems":1,"class":"HRegionServer","responsesize":16029,"method":"Multi"}
2014-07-14 03:23:25,750 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20088,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333385661,"queuetimems":1,"class":"HRegionServer","responsesize":15767,"method":"Multi"}
2014-07-14 03:23:25,730 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24900,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380830,"queuetimems":1,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:23:25,806 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380487,"queuetimems":0,"class":"HRegionServer","responsesize":15849,"method":"Multi"}
2014-07-14 03:23:25,819 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25057,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333380762,"queuetimems":1,"class":"HRegionServer","responsesize":15652,"method":"Multi"}
2014-07-14 03:23:25,872 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21689,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:47241","starttimems":1405333384182,"queuetimems":1,"class":"HRegionServer","responsesize":16155,"method":"Multi"}
2014-07-14 03:23:25,887 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d62908ac3bb64e938b565c5d710f8b53, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/d62908ac3bb64e938b565c5d710f8b53
2014-07-14 03:23:25,891 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c301d9e638dc45eda465285e3afe6e7b, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/c301d9e638dc45eda465285e3afe6e7b
2014-07-14 03:23:25,895 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/11c051d54cd44515a850c1bfa898b109, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/11c051d54cd44515a850c1bfa898b109
2014-07-14 03:23:25,899 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9853f4df82e401981adeb907dd6b696, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9853f4df82e401981adeb907dd6b696
2014-07-14 03:23:25,902 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5366c693367d40d3b090d651123e42ea, to hdfs://master:54310/hbase/archive/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/5366c693367d40d3b090d651123e42ea
2014-07-14 03:23:25,902 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 5 file(s) in family of usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. into ee72d6f2ec3d4c5dac3b902040f8fc67(size=399.7m), total size for store is 3.9g. This selection was in queue for 0sec, and took 1mins, 20sec to execute.
2014-07-14 03:23:25,903 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., storeName=family, fileCount=5, fileSize=458.4m, priority=-1, time=287232928824797; duration=1mins, 20sec
2014-07-14 03:23:25,903 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:184), split_queue=0, merge_queue=0
2014-07-14 03:23:25,903 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 03:23:25,904 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 292178974 starting at candidate #3 after considering 132 permutations with 126 in ratio
2014-07-14 03:23:25,904 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating minor compaction
2014-07-14 03:23:25,904 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:23:25,904 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=278.6m
2014-07-14 03:23:25,904 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/d6bdce3401484d1185c66bb5e803b5f8, keycount=167613, bloomtype=ROW, size=119.3m, encoding=NONE, seqNum=8445
2014-07-14 03:23:25,904 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e3f79e7605bb4271b19d32165a8d53f9, keycount=84437, bloomtype=ROW, size=60.1m, encoding=NONE, seqNum=8992
2014-07-14 03:23:25,905 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/aa0fdeb77f7a4cdcbb162f76e78590e5, keycount=139269, bloomtype=ROW, size=99.2m, encoding=NONE, seqNum=9468
2014-07-14 03:23:26,123 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:23:26,393 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:26,558 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82130 synced till here 82120
2014-07-14 03:23:26,655 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333404687 with entries=117, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333406393
2014-07-14 03:23:27,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:27,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82234 synced till here 82205
2014-07-14 03:23:28,186 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333406393 with entries=104, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333407888
2014-07-14 03:23:29,347 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:29,351 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-14 03:23:29,351 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files, but is 1.1g vs best flushable region's 0.0. Choosing the bigger.
2014-07-14 03:23:29,351 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. due to global heap pressure
2014-07-14 03:23:29,351 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., current region memstore size 1.1g
2014-07-14 03:23:29,367 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82347 synced till here 82317
2014-07-14 03:23:29,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333407888 with entries=113, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333409347
2014-07-14 03:23:31,060 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:31,116 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82458 synced till here 82432
2014-07-14 03:23:31,317 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,317 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,317 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,321 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,322 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,322 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,322 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,323 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,323 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,325 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,325 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,325 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,327 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,334 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,335 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,335 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,335 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333409347 with entries=111, filesize=92.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333411061
2014-07-14 03:23:31,562 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:23:31,598 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,632 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,652 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,653 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,653 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,653 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,653 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,653 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:23:31,654 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,656 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,656 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,661 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,687 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,717 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,747 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,776 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,807 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,838 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,867 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,876 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,909 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,939 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,967 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:31,997 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:32,026 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:33,416 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405330807068: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-14 03:23:35,469 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20473, memsize=942.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/3ea214aca1df4285b7c0c269926b8960
2014-07-14 03:23:35,484 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/3ea214aca1df4285b7c0c269926b8960 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/3ea214aca1df4285b7c0c269926b8960
2014-07-14 03:23:35,495 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/3ea214aca1df4285b7c0c269926b8960, entries=3431090, sequenceid=20473, filesize=244.1m
2014-07-14 03:23:35,495 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1330735920, currentsize=307.0m/321928320 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 38315ms, sequenceid=20473, compaction requested=true
2014-07-14 03:23:35,496 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:184), split_queue=0, merge_queue=0
2014-07-14 03:23:35,496 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2080ms
2014-07-14 03:23:35,496 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. has too many store files; delaying flush up to 90000ms
2014-07-14 03:23:35,496 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,496 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:185), split_queue=0, merge_queue=0
2014-07-14 03:23:35,496 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3470ms
2014-07-14 03:23:35,496 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,496 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3499ms
2014-07-14 03:23:35,496 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,496 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3529ms
2014-07-14 03:23:35,496 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,497 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3557ms
2014-07-14 03:23:35,497 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,501 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3592ms
2014-07-14 03:23:35,501 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,502 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3626ms
2014-07-14 03:23:35,502 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,502 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3635ms
2014-07-14 03:23:35,502 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,502 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3664ms
2014-07-14 03:23:35,502 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,502 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3695ms
2014-07-14 03:23:35,503 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,509 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3733ms
2014-07-14 03:23:35,509 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,512 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3765ms
2014-07-14 03:23:35,512 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,513 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3796ms
2014-07-14 03:23:35,513 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,514 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3827ms
2014-07-14 03:23:35,514 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,514 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3853ms
2014-07-14 03:23:35,514 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,515 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3859ms
2014-07-14 03:23:35,515 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,515 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3859ms
2014-07-14 03:23:35,515 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,518 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3864ms
2014-07-14 03:23:35,518 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,518 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3865ms
2014-07-14 03:23:35,518 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,518 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3866ms
2014-07-14 03:23:35,518 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,518 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3865ms
2014-07-14 03:23:35,518 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,519 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3865ms
2014-07-14 03:23:35,519 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,521 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3869ms
2014-07-14 03:23:35,521 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,528 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3896ms
2014-07-14 03:23:35,528 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,528 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3930ms
2014-07-14 03:23:35,528 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,528 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4193ms
2014-07-14 03:23:35,528 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,537 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4202ms
2014-07-14 03:23:35,537 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,537 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4202ms
2014-07-14 03:23:35,537 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,537 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4203ms
2014-07-14 03:23:35,537 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,541 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4214ms
2014-07-14 03:23:35,541 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,541 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4216ms
2014-07-14 03:23:35,541 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,549 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4224ms
2014-07-14 03:23:35,549 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,549 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4224ms
2014-07-14 03:23:35,549 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,549 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4226ms
2014-07-14 03:23:35,549 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,549 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4226ms
2014-07-14 03:23:35,549 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,549 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4227ms
2014-07-14 03:23:35,549 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,550 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4228ms
2014-07-14 03:23:35,550 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,550 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4228ms
2014-07-14 03:23:35,550 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,553 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4232ms
2014-07-14 03:23:35,553 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,557 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4240ms
2014-07-14 03:23:35,557 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,561 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4244ms
2014-07-14 03:23:35,561 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:35,565 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4248ms
2014-07-14 03:23:35,565 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405330807068
2014-07-14 03:23:36,439 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 308.6m
2014-07-14 03:23:36,439 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:23:36,445 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:36,479 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82538 synced till here 82534
2014-07-14 03:23:36,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333411061 with entries=80, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333416446
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333292136
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333293740
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333295612
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333297560
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333298392
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333300270
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333301817
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333303413
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333304937
2014-07-14 03:23:36,684 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333306292
2014-07-14 03:23:36,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333307369
2014-07-14 03:23:36,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333308877
2014-07-14 03:23:36,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333310476
2014-07-14 03:23:37,191 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:23:40,154 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20702, memsize=83.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f9d31adf23a743a0b9e58111f0d5fe83
2014-07-14 03:23:40,167 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/f9d31adf23a743a0b9e58111f0d5fe83 as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9d31adf23a743a0b9e58111f0d5fe83
2014-07-14 03:23:40,180 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/f9d31adf23a743a0b9e58111f0d5fe83, entries=302430, sequenceid=20702, filesize=21.6m
2014-07-14 03:23:40,181 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~332.6m/348706000, currentsize=0.0/0 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 3742ms, sequenceid=20702, compaction requested=true
2014-07-14 03:23:40,181 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:186), split_queue=0, merge_queue=0
2014-07-14 03:23:42,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:42,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82613 synced till here 82612
2014-07-14 03:23:42,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333416446 with entries=75, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333422869
2014-07-14 03:23:44,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:44,753 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82690 synced till here 82688
2014-07-14 03:23:44,778 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333422869 with entries=77, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333424728
2014-07-14 03:23:45,946 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:45,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333424728 with entries=72, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333425946
2014-07-14 03:23:47,374 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:47,402 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333425946 with entries=72, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333427374
2014-07-14 03:23:48,388 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:48,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333427374 with entries=75, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333428389
2014-07-14 03:23:49,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:49,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 82983 synced till here 82982
2014-07-14 03:23:49,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333428389 with entries=74, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333429715
2014-07-14 03:23:51,120 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:51,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83076 synced till here 83075
2014-07-14 03:23:51,428 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333429715 with entries=93, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333431121
2014-07-14 03:23:53,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:53,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333431121 with entries=95, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333433077
2014-07-14 03:23:54,913 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:54,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333433077 with entries=71, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333434913
2014-07-14 03:23:54,972 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1.
2014-07-14 03:23:54,972 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1., current region memstore size 256.0m
2014-07-14 03:23:55,139 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:23:56,269 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:56,286 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83315 synced till here 83314
2014-07-14 03:23:56,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333434913 with entries=73, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333436270
2014-07-14 03:23:57,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:57,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83390 synced till here 83389
2014-07-14 03:23:57,912 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333436270 with entries=75, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333437872
2014-07-14 03:23:58,178 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20625, memsize=709.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/6f0d8cc2309d408a812b0764c8c4bda5
2014-07-14 03:23:58,188 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/6f0d8cc2309d408a812b0764c8c4bda5 as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6f0d8cc2309d408a812b0764c8c4bda5
2014-07-14 03:23:58,198 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/6f0d8cc2309d408a812b0764c8c4bda5, entries=2581370, sequenceid=20625, filesize=183.6m
2014-07-14 03:23:58,198 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1175453360, currentsize=412.8m/432827200 for region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. in 28847ms, sequenceid=20625, compaction requested=true
2014-07-14 03:23:58,198 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:187), split_queue=0, merge_queue=0
2014-07-14 03:23:58,537 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:23:58,537 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. has too many store files; delaying flush up to 90000ms
2014-07-14 03:23:58,537 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:188), split_queue=0, merge_queue=0
2014-07-14 03:23:59,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:23:59,538 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83463 synced till here 83461
2014-07-14 03:23:59,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333437872 with entries=73, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333439438
2014-07-14 03:23:59,687 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333312887
2014-07-14 03:23:59,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:24:01,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:24:01,895 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333439438 with entries=75, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333441854
2014-07-14 03:24:01,896 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:24:04,024 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=20870, memsize=256.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/097d8652b5f5413e97858f82dab4c36a
2014-07-14 03:24:04,037 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/.tmp/097d8652b5f5413e97858f82dab4c36a as hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/097d8652b5f5413e97858f82dab4c36a
2014-07-14 03:24:04,082 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/5cdea4a8c4f1b79cac96dfb3d518efe1/family/097d8652b5f5413e97858f82dab4c36a, entries=932190, sequenceid=20870, filesize=66.4m
2014-07-14 03:24:04,082 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.0m/268463120, currentsize=137.6m/144241280 for region usertable,user3,1405331185400.5cdea4a8c4f1b79cac96dfb3d518efe1. in 9110ms, sequenceid=20870, compaction requested=true
2014-07-14 03:24:04,083 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:189), split_queue=0, merge_queue=0
2014-07-14 03:24:04,354 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:24:04,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83615 synced till here 83614
2014-07-14 03:24:04,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333441854 with entries=77, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333444354
2014-07-14 03:24:04,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:24:08,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:24:08,350 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 83691 synced till here 83689
2014-07-14 03:24:08,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333444354 with entries=76, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333448085
2014-07-14 03:24:08,427 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): fd2af1df8ba9259ec0c538eeceae443e
2014-07-14 03:24:09,186 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90218ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e.
2014-07-14 03:24:09,187 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user2,1405331185400.fd2af1df8ba9259ec0c538eeceae443e., current region memstore size 1.5g
2014-07-14 03:24:09,276 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp/28a71a409299425892e95273033d7bcb as hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/28a71a409299425892e95273033d7bcb
2014-07-14 03:24:09,295 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:24:09,306 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/d6bdce3401484d1185c66bb5e803b5f8, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/d6bdce3401484d1185c66bb5e803b5f8
2014-07-14 03:24:09,309 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e3f79e7605bb4271b19d32165a8d53f9, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/e3f79e7605bb4271b19d32165a8d53f9
2014-07-14 03:24:09,312 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/aa0fdeb77f7a4cdcbb162f76e78590e5, to hdfs://master:54310/hbase/archive/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/aa0fdeb77f7a4cdcbb162f76e78590e5
2014-07-14 03:24:09,312 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into 28a71a409299425892e95273033d7bcb(size=243.3m), total size for store is 4.2g. This selection was in queue for 0sec, and took 43sec to execute.
2014-07-14 03:24:09,312 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27., storeName=family, fileCount=3, fileSize=278.6m, priority=-2, time=287313331204186; duration=43sec
2014-07-14 03:24:09,312 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 03:24:09,312 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 03:24:09,313 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-14 03:24:09,313 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 120298506 starting at candidate #13 after considering 132 permutations with 75 in ratio
2014-07-14 03:24:09,314 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: 7f4e87d2eea7a637326e2204c730bf5a - family: Initiating minor compaction
2014-07-14 03:24:09,314 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a.
2014-07-14 03:24:09,314 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp, totalSize=114.7m
2014-07-14 03:24:09,314 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c96483177344d64b0078a33d5f6d5f4, keycount=19226, bloomtype=ROW, size=13.7m, encoding=NONE, seqNum=16940
2014-07-14 03:24:09,314 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/632cd2d88f7e487992d626c88c78701b, keycount=60470, bloomtype=ROW, size=43.1m, encoding=NONE, seqNum=17108
2014-07-14 03:24:09,314 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/27ffbfdb1baa4ea7aa0dd1c9517a2458, keycount=81293, bloomtype=ROW, size=57.9m, encoding=NONE, seqNum=17307
2014-07-14 03:24:09,504 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:24:10,532 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:24:11,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:24:11,268 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333448085 with entries=73, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333451243
2014-07-14 03:24:14,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-14 03:24:14,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333451243 with entries=75, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405330807068/slave1%2C60020%2C1405330807068.1405333454798
2014-07-14 03:24:24,226 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/5d475845739d43e1b8ab42085cd41e57 as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/5d475845739d43e1b8ab42085cd41e57
2014-07-14 03:24:24,250 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Removing store files after compaction...
2014-07-14 03:24:24,263 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c96483177344d64b0078a33d5f6d5f4, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/2c96483177344d64b0078a33d5f6d5f4
2014-07-14 03:24:24,267 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/632cd2d88f7e487992d626c88c78701b, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/632cd2d88f7e487992d626c88c78701b
2014-07-14 03:24:24,269 DEBUG [regionserver60020-smallCompactions-1405330847103] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/27ffbfdb1baa4ea7aa0dd1c9517a2458, to hdfs://master:54310/hbase/archive/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/27ffbfdb1baa4ea7aa0dd1c9517a2458
2014-07-14 03:24:24,269 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. into 5d475845739d43e1b8ab42085cd41e57(size=96.5m), total size for store is 4.1g. This selection was in queue for 0sec, and took 14sec to execute.
2014-07-14 03:24:24,269 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., storeName=family, fileCount=3, fileSize=114.7m, priority=-2, time=287356740946198; duration=14sec
2014-07-14 03:24:24,269 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 03:24:24,269 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-14 03:24:24,269 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-14 03:24:24,270 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 293457531 starting at candidate #9 after considering 124 permutations with 122 in ratio
2014-07-14 03:24:24,270 DEBUG [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: f874ab9cace3c84c3e27af574e5b4d27 - family: Initiating minor compaction
2014-07-14 03:24:24,270 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27.
2014-07-14 03:24:24,271 INFO  [regionserver60020-smallCompactions-1405330847103] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405331185400.f874ab9cace3c84c3e27af574e5b4d27. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/.tmp, totalSize=279.9m
2014-07-14 03:24:24,271 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/2e40f34af51b450aa2cad025ade6dd25, keycount=111168, bloomtype=ROW, size=79.1m, encoding=NONE, seqNum=12814
2014-07-14 03:24:24,271 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/ba449af0a5ee408f906ddfa55c4d3a52, keycount=157301, bloomtype=ROW, size=112.0m, encoding=NONE, seqNum=13389
2014-07-14 03:24:24,271 DEBUG [regionserver60020-smallCompactions-1405330847103] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/f874ab9cace3c84c3e27af574e5b4d27/family/db087f6d8de34bd4b87c1ccebb04e49e, keycount=124545, bloomtype=ROW, size=88.7m, encoding=NONE, seqNum=13884
2014-07-14 03:24:24,371 DEBUG [regionserver60020-smallCompactions-1405330847103] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:24:24,488 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a., current region memstore size 813.7m
2014-07-14 03:24:25,049 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-14 03:24:41,799 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=21022, memsize=526.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/652ef9e9c1bb4ba6855ac12f35d985dc
2014-07-14 03:24:41,823 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/.tmp/652ef9e9c1bb4ba6855ac12f35d985dc as hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/652ef9e9c1bb4ba6855ac12f35d985dc
2014-07-14 03:24:41,943 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/7f4e87d2eea7a637326e2204c730bf5a/family/652ef9e9c1bb4ba6855ac12f35d985dc, entries=1915010, sequenceid=21022, filesize=136.4m
2014-07-14 03:24:41,944 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~813.7m/853240000, currentsize=0.0/0 for region usertable,user8,1405331185400.7f4e87d2eea7a637326e2204c730bf5a. in 17456ms, sequenceid=21022, compaction requested=true
2014-07-14 03:24:41,944 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:190), split_queue=0, merge_queue=0
