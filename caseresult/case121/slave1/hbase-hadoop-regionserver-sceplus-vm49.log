Sun Jul 13 17:48:08 PDT 2014 Starting regionserver on sceplus-vm49
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-13 17:48:09,073 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-13 17:48:09,073 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-13 17:48:09,073 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-13 17:48:09,300 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-13 17:48:09,300 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-13 17:48:09,300 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-13 17:48:09,300 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 36341 22
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-13 17:48:09,301 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 36341 9.1.143.59 22
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-13 17:48:09,302 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-13 17:48:09,305 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=839
2014-07-13 17:48:09,306 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm49.log
2014-07-13 17:48:09,306 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-13 17:48:09,306 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-13 17:48:09,306 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm49
2014-07-13 17:48:09,306 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-13 17:48:09,308 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-13 17:48:09,309 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm49.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-13 17:48:09,527 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020 HConnection server-to-server retries=350
2014-07-13 17:48:09,883 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm49.almaden.ibm.com/9.1.143.59:60020: started 10 reader(s).
2014-07-13 17:48:09,964 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-13 17:48:09,976 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-13 17:48:10,043 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-13 17:48:10,045 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-13 17:48:10,045 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-13 17:48:10,050 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-13 17:48:10,055 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-13 17:48:10,137 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-13 17:48:10,137 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-13 17:48:10,141 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-13 17:48:10,143 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-13 17:48:10,210 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-13 17:48:10,267 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-13 17:48:10,276 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-13 17:48:10,278 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-13 17:48:10,278 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-13 17:48:10,278 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-13 17:48:10,579 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm49.almaden.ibm.com
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/bin/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-13 17:48:10,623 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-13 17:48:10,624 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-13 17:48:10,624 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-13 17:48:10,624 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-13 17:48:10,626 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-13 17:48:10,626 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-13 17:48:10,648 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-13 17:48:10,651 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-13 17:48:10,656 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-13 17:48:10,666 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x47325750590002, negotiated timeout = 90000
2014-07-13 17:48:39,801 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x53c01def, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-13 17:48:39,802 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x53c01def connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-13 17:48:39,802 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-13 17:48:39,803 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, initiating session
2014-07-13 17:48:39,806 INFO  [regionserver60020-SendThread(sceplus-vm49.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm49.almaden.ibm.com/9.1.143.59:2181, sessionid = 0x14732574f250001, negotiated timeout = 90000
2014-07-13 17:48:40,054 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@38a83930
2014-07-13 17:48:40,059 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-13 17:48:40,064 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-13 17:48:40,080 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-13 17:48:40,110 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-13 17:48:40,115 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-13 17:48:40,119 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-13 17:48:40,140 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1405298888448 with port=60020, startcode=1405298890065
2014-07-13 17:48:40,516 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-13 17:48:40,516 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-13 17:48:40,517 INFO  [regionserver60020] regionserver.HRegionServer: Master passed us a different hostname to use; was=sceplus-vm49.almaden.ibm.com, but now=slave1
2014-07-13 17:48:40,548 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-13 17:48:40,556 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065
2014-07-13 17:48:40,591 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-13 17:48:40,603 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-13 17:48:40,703 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405298920609
2014-07-13 17:48:40,715 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-13 17:48:40,720 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-13 17:48:40,724 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-13 17:48:40,728 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-13 17:48:40,731 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-13 17:48:40,731 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-13 17:48:40,731 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-slave1:60020, corePoolSize=3, maxPoolSize=3
2014-07-13 17:48:40,732 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-slave1:60020, corePoolSize=1, maxPoolSize=1
2014-07-13 17:48:40,732 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-slave1:60020, corePoolSize=2, maxPoolSize=2
2014-07-13 17:48:40,740 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1405298890065, sceplus-vm48.almaden.ibm.com,60020,1405298890327] other RSs: [slave1,60020,1405298890065, sceplus-vm48.almaden.ibm.com,60020,1405298890327]
2014-07-13 17:48:40,763 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-13 17:48:40,767 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x6eca6aba, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-13 17:48:40,768 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6eca6aba connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-13 17:48:40,769 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Opening socket connection to server master/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-13 17:48:40,770 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Socket connection established to master/9.1.143.58:2181, initiating session
2014-07-13 17:48:40,775 INFO  [regionserver60020-SendThread(master:2181)] zookeeper.ClientCnxn: Session establishment complete on server master/9.1.143.58:2181, sessionid = 0x47325750590003, negotiated timeout = 90000
2014-07-13 17:48:40,785 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-13 17:48:40,785 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-13 17:48:40,834 INFO  [regionserver60020] regionserver.HRegionServer: Serving as slave1,60020,1405298890065, RpcServer on sceplus-vm49.almaden.ibm.com/9.1.143.59:60020, sessionid=0x47325750590002
2014-07-13 17:48:40,834 INFO  [SplitLogWorker-slave1,60020,1405298890065] regionserver.SplitLogWorker: SplitLogWorker slave1,60020,1405298890065 starting
2014-07-13 17:48:40,834 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-13 17:48:40,835 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager slave1,60020,1405298890065
2014-07-13 17:48:40,835 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'slave1,60020,1405298890065'
2014-07-13 17:48:40,835 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-13 17:48:40,837 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-13 17:48:40,838 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-13 17:48:45,528 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:48:45,660 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:48:45,662 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:48:45,662 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2bc32b824633798283ec8f635ffac705 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:45,662 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fbd7f9af67794724bf44ada59fc184e3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:45,664 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 17:48:45,664 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 444708cfc43de9303cdc184e6f0e32c8 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:45,672 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:48:45,672 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Open usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:48:45,687 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fbd7f9af67794724bf44ada59fc184e3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:45,687 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 444708cfc43de9303cdc184e6f0e32c8 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:45,687 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2bc32b824633798283ec8f635ffac705 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:45,703 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => fbd7f9af67794724bf44ada59fc184e3, NAME => 'usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-13 17:48:45,703 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 2bc32b824633798283ec8f635ffac705, NAME => 'usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-13 17:48:45,704 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => 444708cfc43de9303cdc184e6f0e32c8, NAME => 'usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.', STARTKEY => 'user2', ENDKEY => 'user3'}
2014-07-13 17:48:45,735 INFO  [RS_OPEN_REGION-slave1:60020-2] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-13 17:48:45,735 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 444708cfc43de9303cdc184e6f0e32c8
2014-07-13 17:48:45,735 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable fbd7f9af67794724bf44ada59fc184e3
2014-07-13 17:48:45,735 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2bc32b824633798283ec8f635ffac705
2014-07-13 17:48:45,736 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:48:45,736 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:48:45,736 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:48:45,745 INFO  [RS_OPEN_REGION-slave1:60020-2] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-13 17:48:45,747 INFO  [RS_OPEN_REGION-slave1:60020-2] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-13 17:48:45,750 INFO  [RS_OPEN_REGION-slave1:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-13 17:48:45,750 INFO  [RS_OPEN_REGION-slave1:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-13 17:48:45,750 INFO  [RS_OPEN_REGION-slave1:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-13 17:48:45,824 INFO  [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 17:48:45,824 INFO  [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 17:48:45,831 INFO  [StoreOpener-2bc32b824633798283ec8f635ffac705-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 17:48:45,858 INFO  [StoreOpener-2bc32b824633798283ec8f635ffac705-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-13 17:48:45,869 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2bc32b824633798283ec8f635ffac705
2014-07-13 17:48:45,873 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 2bc32b824633798283ec8f635ffac705; next sequenceid=1
2014-07-13 17:48:45,873 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2bc32b824633798283ec8f635ffac705
2014-07-13 17:48:45,878 INFO  [PostOpenDeployTasks:2bc32b824633798283ec8f635ffac705] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:48:45,955 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-13 17:48:45,955 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-13 17:48:45,974 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/06cc97b622f54114a13d85be2995aa83, isReference=false, isBulkLoadResult=false, seqid=9634, majorCompaction=false
2014-07-13 17:48:45,974 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/0a3b4aa028644cb59f1cf002c6c70488, isReference=false, isBulkLoadResult=false, seqid=2660, majorCompaction=false
2014-07-13 17:48:45,994 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/105ddbecdf504b2f90cc02be8e346f2f, isReference=false, isBulkLoadResult=false, seqid=1500, majorCompaction=false
2014-07-13 17:48:45,995 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/0b41261d06f74b96af2dffc40af569ea, isReference=false, isBulkLoadResult=false, seqid=9634, majorCompaction=false
2014-07-13 17:48:46,010 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/169917456fd749cb9f9d8481a612600b, isReference=false, isBulkLoadResult=false, seqid=8132, majorCompaction=false
2014-07-13 17:48:46,011 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/0cac5579eef646a69d84bda7a9c5969d, isReference=false, isBulkLoadResult=false, seqid=8922, majorCompaction=false
2014-07-13 17:48:46,040 INFO  [PostOpenDeployTasks:2bc32b824633798283ec8f635ffac705] catalog.MetaEditor: Updated row usertable,,1405265098509.2bc32b824633798283ec8f635ffac705. with server=slave1,60020,1405298890065
2014-07-13 17:48:46,040 INFO  [PostOpenDeployTasks:2bc32b824633798283ec8f635ffac705] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:48:46,040 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2bc32b824633798283ec8f635ffac705 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,046 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2bc32b824633798283ec8f635ffac705 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,046 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 2bc32b824633798283ec8f635ffac705 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:48:46,047 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,,1405265098509.2bc32b824633798283ec8f635ffac705. on slave1,60020,1405298890065
2014-07-13 17:48:46,047 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:46,048 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/1b23caaffe0b49f98affcc77df8b0777, isReference=false, isBulkLoadResult=false, seqid=2499, majorCompaction=false
2014-07-13 17:48:46,051 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/0d97f97b0b3c43348a9f4143808a9b42, isReference=false, isBulkLoadResult=false, seqid=1164, majorCompaction=false
2014-07-13 17:48:46,054 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:46,054 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => e5ee55a21ff19d69490518939b0887e0, NAME => 'hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.', STARTKEY => '', ENDKEY => ''}
2014-07-13 17:48:46,055 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace e5ee55a21ff19d69490518939b0887e0
2014-07-13 17:48:46,055 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 17:48:46,063 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/36a79609e1ea4235b930ab3d58757e92, isReference=false, isBulkLoadResult=false, seqid=1667, majorCompaction=false
2014-07-13 17:48:46,064 INFO  [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 17:48:46,065 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/215934800f0744949a2c080e51e9db3e, isReference=false, isBulkLoadResult=false, seqid=6280, majorCompaction=false
2014-07-13 17:48:46,074 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/39a060d6cf284b28bdcc5d94ebf7eaa9, isReference=false, isBulkLoadResult=false, seqid=502, majorCompaction=false
2014-07-13 17:48:46,080 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/2492a8fa03534e63a06fde861f04a39d, isReference=false, isBulkLoadResult=false, seqid=1496, majorCompaction=false
2014-07-13 17:48:46,082 DEBUG [StoreOpener-e5ee55a21ff19d69490518939b0887e0-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0/info/5b0102065d284f308d4c0a8d64d9fab5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-07-13 17:48:46,085 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/hbase/namespace/e5ee55a21ff19d69490518939b0887e0
2014-07-13 17:48:46,088 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/5076dcd7c95e480c88a0169f9ce9ca5c, isReference=false, isBulkLoadResult=false, seqid=2333, majorCompaction=false
2014-07-13 17:48:46,089 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined e5ee55a21ff19d69490518939b0887e0; next sequenceid=5
2014-07-13 17:48:46,089 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node e5ee55a21ff19d69490518939b0887e0
2014-07-13 17:48:46,092 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 17:48:46,096 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/31e38ca7ebf84014893757d39d7a28ca, isReference=false, isBulkLoadResult=false, seqid=7653, majorCompaction=false
2014-07-13 17:48:46,104 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] catalog.MetaEditor: Updated row hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. with server=slave1,60020,1405298890065
2014-07-13 17:48:46,104 INFO  [PostOpenDeployTasks:e5ee55a21ff19d69490518939b0887e0] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0.
2014-07-13 17:48:46,104 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,105 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/52c4b7dd47574a65a875e616370f8bbd, isReference=false, isBulkLoadResult=false, seqid=5880, majorCompaction=false
2014-07-13 17:48:46,111 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node e5ee55a21ff19d69490518939b0887e0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,111 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned e5ee55a21ff19d69490518939b0887e0 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:48:46,111 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. on slave1,60020,1405298890065
2014-07-13 17:48:46,112 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5333598b8a016f79da464f68b5b4a9d7 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:46,115 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/33e6e21fce684ab3835220637938eabb, isReference=false, isBulkLoadResult=false, seqid=5863, majorCompaction=false
2014-07-13 17:48:46,118 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5333598b8a016f79da464f68b5b4a9d7 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:46,118 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 5333598b8a016f79da464f68b5b4a9d7, NAME => 'usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-13 17:48:46,119 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 5333598b8a016f79da464f68b5b4a9d7
2014-07-13 17:48:46,119 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:48:46,123 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/53c0f8168e454112a87398cf25a21dc0, isReference=false, isBulkLoadResult=false, seqid=3164, majorCompaction=false
2014-07-13 17:48:46,131 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/4264685097d44ab9864b1665b2a2272d, isReference=false, isBulkLoadResult=false, seqid=8109, majorCompaction=false
2014-07-13 17:48:46,133 INFO  [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 17:48:46,136 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/53cd60f8eea0418d8b357e4ad228b79c, isReference=false, isBulkLoadResult=false, seqid=1834, majorCompaction=false
2014-07-13 17:48:46,146 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/5763c973e81947d0807ed3029d06c5ab, isReference=false, isBulkLoadResult=false, seqid=1662, majorCompaction=false
2014-07-13 17:48:46,149 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/5414deb038824c389576aea4ecf29424, isReference=false, isBulkLoadResult=false, seqid=9359, majorCompaction=false
2014-07-13 17:48:46,156 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/05ed562582044556ba8ca85084266e18, isReference=false, isBulkLoadResult=false, seqid=1560, majorCompaction=false
2014-07-13 17:48:46,161 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/6db64feb27b949a2a4fc5aacd8104cf6, isReference=false, isBulkLoadResult=false, seqid=2161, majorCompaction=false
2014-07-13 17:48:46,163 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/55753925694f4932a127bb694c0d1d25, isReference=false, isBulkLoadResult=false, seqid=6295, majorCompaction=false
2014-07-13 17:48:46,170 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/0fb3c0637da04af6bf79cda0a2d4fba6, isReference=false, isBulkLoadResult=false, seqid=395, majorCompaction=false
2014-07-13 17:48:46,173 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/7d7bf284c929489cbb1068a10b1f5222, isReference=false, isBulkLoadResult=false, seqid=167, majorCompaction=false
2014-07-13 17:48:46,176 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/611317b534c64dd1855f76a43a06d784, isReference=false, isBulkLoadResult=false, seqid=4934, majorCompaction=false
2014-07-13 17:48:46,183 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/13b7b5e1ee2b4f07a967377fea5fa9c1, isReference=false, isBulkLoadResult=false, seqid=7900, majorCompaction=false
2014-07-13 17:48:46,187 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/7f290b08a8fc4d32908b816d17421431, isReference=false, isBulkLoadResult=false, seqid=1330, majorCompaction=false
2014-07-13 17:48:46,190 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/64479cd68e2f464590bce0660ac70462, isReference=false, isBulkLoadResult=false, seqid=835, majorCompaction=false
2014-07-13 17:48:46,196 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/19d01a4b563140f1a9820325b66b9ffb, isReference=false, isBulkLoadResult=false, seqid=2724, majorCompaction=false
2014-07-13 17:48:46,199 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/7fd1cfa0fc024f74aba1a565aa5ca394, isReference=false, isBulkLoadResult=false, seqid=3976, majorCompaction=false
2014-07-13 17:48:46,202 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/663133a0d65a48a888611d0b0d22d105, isReference=false, isBulkLoadResult=false, seqid=6761, majorCompaction=false
2014-07-13 17:48:46,208 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/1bc8aaf378ba42688da482b4bb8e8925, isReference=false, isBulkLoadResult=false, seqid=1228, majorCompaction=false
2014-07-13 17:48:46,212 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/87006b750de24793b3106cae61177e98, isReference=false, isBulkLoadResult=false, seqid=3158, majorCompaction=false
2014-07-13 17:48:46,216 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/710288cd174b4ccdb103f2c0f76f0d8b, isReference=false, isBulkLoadResult=false, seqid=7227, majorCompaction=false
2014-07-13 17:48:46,220 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/259885342b6d4892a1e3fda1b7023a07, isReference=false, isBulkLoadResult=false, seqid=2392, majorCompaction=false
2014-07-13 17:48:46,223 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/8a68129e8d1840bfa64aac6402c3ffbf, isReference=false, isBulkLoadResult=false, seqid=4924, majorCompaction=false
2014-07-13 17:48:46,229 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/75343a84f638455e881f3ee2616fb960, isReference=false, isBulkLoadResult=false, seqid=3496, majorCompaction=false
2014-07-13 17:48:46,235 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/25b72a946c00460793452872d00d4789, isReference=false, isBulkLoadResult=false, seqid=6515, majorCompaction=false
2014-07-13 17:48:46,240 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/8b7c5e7ba67a481fa6cad79b3d60c554, isReference=false, isBulkLoadResult=false, seqid=998, majorCompaction=false
2014-07-13 17:48:46,247 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/8b28c63725ee4f3384783edf30035571, isReference=false, isBulkLoadResult=false, seqid=7677, majorCompaction=false
2014-07-13 17:48:46,250 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/3acd007bb43d402886b832cb3cb05881, isReference=false, isBulkLoadResult=false, seqid=229, majorCompaction=false
2014-07-13 17:48:46,252 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/9544598400564890805e9f7b18178417, isReference=false, isBulkLoadResult=false, seqid=2992, majorCompaction=false
2014-07-13 17:48:46,259 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/8db0a8a1a459401aa5b69ad2508559fe, isReference=false, isBulkLoadResult=false, seqid=4498, majorCompaction=false
2014-07-13 17:48:46,260 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/4749fb28107a45d7acd681a3fb72e911, isReference=false, isBulkLoadResult=false, seqid=2891, majorCompaction=false
2014-07-13 17:48:46,264 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/a830c9226f634316af56e71ce65b837e, isReference=false, isBulkLoadResult=false, seqid=665, majorCompaction=false
2014-07-13 17:48:46,271 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/90dc9168af474fdbbbed708a0e7e1bc1, isReference=false, isBulkLoadResult=false, seqid=5406, majorCompaction=false
2014-07-13 17:48:46,273 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/4f4ab3470bd645899f4e53a6d8f37d4a, isReference=false, isBulkLoadResult=false, seqid=8350, majorCompaction=false
2014-07-13 17:48:46,274 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/af932cb9fbdc418dbf88d672f1d5cba4, isReference=false, isBulkLoadResult=false, seqid=4493, majorCompaction=false
2014-07-13 17:48:46,283 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/95ceee78566648cfa59e1426a279c579, isReference=false, isBulkLoadResult=false, seqid=3330, majorCompaction=false
2014-07-13 17:48:46,284 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/5aaf99fe0eff425892b7049c10bfe3be, isReference=false, isBulkLoadResult=false, seqid=728, majorCompaction=false
2014-07-13 17:48:46,287 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/b0d892e7916d42f3956b1b3a8479da1e, isReference=false, isBulkLoadResult=false, seqid=6746, majorCompaction=false
2014-07-13 17:48:46,293 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/991162030ac44062b2fb26ea85ea5ebd, isReference=false, isBulkLoadResult=false, seqid=668, majorCompaction=false
2014-07-13 17:48:46,293 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/62e973d369d245b388c87954caa34b1b, isReference=false, isBulkLoadResult=false, seqid=7444, majorCompaction=false
2014-07-13 17:48:46,301 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/b5bada7f9e6245a981386bff2c7dadc3, isReference=false, isBulkLoadResult=false, seqid=1829, majorCompaction=false
2014-07-13 17:48:46,307 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/9d05931b116047eead9afbd050ac50d3, isReference=false, isBulkLoadResult=false, seqid=1334, majorCompaction=false
2014-07-13 17:48:46,307 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/62f350ae3f62460cb8087779fdb5bef2, isReference=false, isBulkLoadResult=false, seqid=5081, majorCompaction=false
2014-07-13 17:48:46,312 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/be2d140fc4c94f20b0de17c28a963d5a, isReference=false, isBulkLoadResult=false, seqid=2826, majorCompaction=false
2014-07-13 17:48:46,317 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/9e6cf2e562e042bd899184f81e9a4034, isReference=false, isBulkLoadResult=false, seqid=1001, majorCompaction=false
2014-07-13 17:48:46,321 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/651c3ef774144db182e829b73c89005b, isReference=false, isBulkLoadResult=false, seqid=2558, majorCompaction=false
2014-07-13 17:48:46,325 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/bf1117e7e7c04d6aa06e7c6584de451d, isReference=false, isBulkLoadResult=false, seqid=9336, majorCompaction=false
2014-07-13 17:48:46,328 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/a11992e9e78d40ebb50bdffe7f832fdb, isReference=false, isBulkLoadResult=false, seqid=2000, majorCompaction=false
2014-07-13 17:48:46,334 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/6bbbe92abde24e24b72083d6110d7abe, isReference=false, isBulkLoadResult=false, seqid=2059, majorCompaction=false
2014-07-13 17:48:46,337 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/bfc20dd5344e4f9091e44acb759e0e5e, isReference=false, isBulkLoadResult=false, seqid=333, majorCompaction=false
2014-07-13 17:48:46,338 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/b0f119a329224cc1a0a6d20f2d673f1b, isReference=false, isBulkLoadResult=false, seqid=2997, majorCompaction=false
2014-07-13 17:48:46,347 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/81b133ce39424265be7b03179f46bb9b, isReference=false, isBulkLoadResult=false, seqid=6984, majorCompaction=false
2014-07-13 17:48:46,349 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/ce1e1c6478594c1f90d8fcce40304e59, isReference=false, isBulkLoadResult=false, seqid=1995, majorCompaction=false
2014-07-13 17:48:46,350 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/b28ee7c15eff4a3b805d3eb8c13ed193, isReference=false, isBulkLoadResult=false, seqid=2166, majorCompaction=false
2014-07-13 17:48:46,358 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/98bfb9cef8d74138a83a66ca296285fa, isReference=false, isBulkLoadResult=false, seqid=894, majorCompaction=false
2014-07-13 17:48:46,359 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/dc78b3a439ba48f6abe0f230294a1fd1, isReference=false, isBulkLoadResult=false, seqid=499, majorCompaction=false
2014-07-13 17:48:46,361 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/b55fe0e17efe4566ae4d57b54d60eea4, isReference=false, isBulkLoadResult=false, seqid=2831, majorCompaction=false
2014-07-13 17:48:46,369 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/a8563193e3c54a03bf6dec6052eca0c6, isReference=false, isBulkLoadResult=false, seqid=9633, majorCompaction=false
2014-07-13 17:48:46,370 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/e679f4ffffcb40e9a5cd7f5ed7163fd8, isReference=false, isBulkLoadResult=false, seqid=2327, majorCompaction=false
2014-07-13 17:48:46,372 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/c2c852cbb01a49b6966dcabc6e71c6cd, isReference=false, isBulkLoadResult=false, seqid=335, majorCompaction=false
2014-07-13 17:48:46,379 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/ac58efd4e8ff42f781ef265573d72a48, isReference=false, isBulkLoadResult=false, seqid=1062, majorCompaction=false
2014-07-13 17:48:46,382 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/e8294e5d7c5646e5ae524f8fae3beee1, isReference=false, isBulkLoadResult=false, seqid=3490, majorCompaction=false
2014-07-13 17:48:46,384 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/cd09d1d75cfd490b8a1e5febb93ded0c, isReference=false, isBulkLoadResult=false, seqid=168, majorCompaction=false
2014-07-13 17:48:46,391 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/aca5492a63034df59ce2b508e15f4984, isReference=false, isBulkLoadResult=false, seqid=5564, majorCompaction=false
2014-07-13 17:48:46,394 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/e98c20f6bb7945a192301cfc33eaf31d, isReference=false, isBulkLoadResult=false, seqid=2493, majorCompaction=false
2014-07-13 17:48:46,396 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/cf7e6e61b52342f4a62b34f41ae5c9b0, isReference=false, isBulkLoadResult=false, seqid=2665, majorCompaction=false
2014-07-13 17:48:46,403 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/b5b8d7e0de97469c914afa8b3e828231, isReference=false, isBulkLoadResult=false, seqid=3555, majorCompaction=false
2014-07-13 17:48:46,406 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/e98ff169c56749d4b820bd071a888ebd, isReference=false, isBulkLoadResult=false, seqid=3324, majorCompaction=false
2014-07-13 17:48:46,410 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/deb41355e4804b98a8dc066f720e03ad, isReference=false, isBulkLoadResult=false, seqid=3984, majorCompaction=false
2014-07-13 17:48:46,414 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/b6b47f3296ac40d49666ab3257c5d942, isReference=false, isBulkLoadResult=false, seqid=2226, majorCompaction=false
2014-07-13 17:48:46,417 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/ea7c916e8dfd46bb9ad822a8d99b0740, isReference=false, isBulkLoadResult=false, seqid=5393, majorCompaction=false
2014-07-13 17:48:46,420 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/eebb932a15fd41c380ee5c86431006bf, isReference=false, isBulkLoadResult=false, seqid=1167, majorCompaction=false
2014-07-13 17:48:46,425 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/b8d204c0624e48538846a0cce4969e31, isReference=false, isBulkLoadResult=false, seqid=8805, majorCompaction=false
2014-07-13 17:48:46,432 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/f36f7b4ac2b643b8bab172100555aafb, isReference=false, isBulkLoadResult=false, seqid=8941, majorCompaction=false
2014-07-13 17:48:46,436 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/ee5fa515af124adf984229ea3c72de7c, isReference=false, isBulkLoadResult=false, seqid=7208, majorCompaction=false
2014-07-13 17:48:46,438 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/bfa4bae89c9248a7b49df7501d180ac8, isReference=false, isBulkLoadResult=false, seqid=3057, majorCompaction=false
2014-07-13 17:48:46,443 DEBUG [StoreOpener-fbd7f9af67794724bf44ada59fc184e3-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3/family/f50341d994a14e719841ca291ee59a19, isReference=false, isBulkLoadResult=false, seqid=8499, majorCompaction=false
2014-07-13 17:48:46,448 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/fbd7f9af67794724bf44ada59fc184e3
2014-07-13 17:48:46,449 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/f2e06833f1754e168beddca87143076a, isReference=false, isBulkLoadResult=false, seqid=8477, majorCompaction=false
2014-07-13 17:48:46,451 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/c2e766c7d70e49b7a1e5ca7d8d917ac5, isReference=false, isBulkLoadResult=false, seqid=1394, majorCompaction=false
2014-07-13 17:48:46,452 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined fbd7f9af67794724bf44ada59fc184e3; next sequenceid=9635
2014-07-13 17:48:46,452 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node fbd7f9af67794724bf44ada59fc184e3
2014-07-13 17:48:46,455 INFO  [PostOpenDeployTasks:fbd7f9af67794724bf44ada59fc184e3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:48:46,458 DEBUG [PostOpenDeployTasks:fbd7f9af67794724bf44ada59fc184e3] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 17:48:46,459 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-13 17:48:46,459 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-13 17:48:46,460 DEBUG [StoreOpener-444708cfc43de9303cdc184e6f0e32c8-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8/family/fcfd6944de6b4157acc3336025d7802c, isReference=false, isBulkLoadResult=false, seqid=832, majorCompaction=false
2014-07-13 17:48:46,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:46,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:46,464 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3. because compaction request was cancelled
2014-07-13 17:48:46,471 INFO  [PostOpenDeployTasks:fbd7f9af67794724bf44ada59fc184e3] catalog.MetaEditor: Updated row usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3. with server=slave1,60020,1405298890065
2014-07-13 17:48:46,472 INFO  [PostOpenDeployTasks:fbd7f9af67794724bf44ada59fc184e3] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:48:46,472 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/d2414ac00a2f4ad89fd937747b325d4e, isReference=false, isBulkLoadResult=false, seqid=1892, majorCompaction=false
2014-07-13 17:48:46,473 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fbd7f9af67794724bf44ada59fc184e3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,473 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/444708cfc43de9303cdc184e6f0e32c8
2014-07-13 17:48:46,477 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined 444708cfc43de9303cdc184e6f0e32c8; next sequenceid=9635
2014-07-13 17:48:46,478 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 444708cfc43de9303cdc184e6f0e32c8
2014-07-13 17:48:46,478 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fbd7f9af67794724bf44ada59fc184e3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,479 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned fbd7f9af67794724bf44ada59fc184e3 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:48:46,479 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3. on slave1,60020,1405298890065
2014-07-13 17:48:46,480 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 679f284b918041b7a8319c93fa551b82 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:46,480 INFO  [PostOpenDeployTasks:444708cfc43de9303cdc184e6f0e32c8] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:48:46,481 DEBUG [PostOpenDeployTasks:444708cfc43de9303cdc184e6f0e32c8] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 17:48:46,482 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-13 17:48:46,482 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-13 17:48:46,482 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:46,483 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:46,483 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8. because compaction request was cancelled
2014-07-13 17:48:46,484 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/d30d1f40a7f6403b900e43544f57d044, isReference=false, isBulkLoadResult=false, seqid=4596, majorCompaction=false
2014-07-13 17:48:46,485 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 679f284b918041b7a8319c93fa551b82 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:48:46,486 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => 679f284b918041b7a8319c93fa551b82, NAME => 'usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-13 17:48:46,487 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 679f284b918041b7a8319c93fa551b82
2014-07-13 17:48:46,487 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:48:46,493 INFO  [PostOpenDeployTasks:444708cfc43de9303cdc184e6f0e32c8] catalog.MetaEditor: Updated row usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8. with server=slave1,60020,1405298890065
2014-07-13 17:48:46,493 INFO  [PostOpenDeployTasks:444708cfc43de9303cdc184e6f0e32c8] regionserver.HRegionServer: Finished post open deploy task for usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:48:46,494 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 444708cfc43de9303cdc184e6f0e32c8 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,494 INFO  [StoreOpener-679f284b918041b7a8319c93fa551b82-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-13 17:48:46,495 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/d7b400bc1a54448383ab6214f926bda1, isReference=false, isBulkLoadResult=false, seqid=1726, majorCompaction=false
2014-07-13 17:48:46,498 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 444708cfc43de9303cdc184e6f0e32c8 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,498 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned 444708cfc43de9303cdc184e6f0e32c8 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:48:46,498 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8. on slave1,60020,1405298890065
2014-07-13 17:48:46,503 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/d8b538ac21c34909a0623d2cef6d7299, isReference=false, isBulkLoadResult=false, seqid=4072, majorCompaction=false
2014-07-13 17:48:46,513 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/07d32374e912441b8e5d0ec1fa0941cd, isReference=false, isBulkLoadResult=false, seqid=1559, majorCompaction=false
2014-07-13 17:48:46,514 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/d956eff4147c4298ab7b4f68baf36223, isReference=false, isBulkLoadResult=false, seqid=3389, majorCompaction=false
2014-07-13 17:48:46,522 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/0e6bc1ca903e470391559f0763b2817c, isReference=false, isBulkLoadResult=false, seqid=9633, majorCompaction=false
2014-07-13 17:48:46,523 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/da493157ec374d159b1be7ffb03c1c2c, isReference=false, isBulkLoadResult=false, seqid=6040, majorCompaction=false
2014-07-13 17:48:46,531 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/12eaa205e1444b8e99c0b5344e654e2f, isReference=false, isBulkLoadResult=false, seqid=2555, majorCompaction=false
2014-07-13 17:48:46,535 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/e072d8be5b554c4d92c7d618e6212776, isReference=false, isBulkLoadResult=false, seqid=561, majorCompaction=false
2014-07-13 17:48:46,540 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/1dbb0e9e42c74c4fa45d1abae8917efa, isReference=false, isBulkLoadResult=false, seqid=8348, majorCompaction=false
2014-07-13 17:48:46,549 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/e36baf6f1ef34af292864b8e6eb90aab, isReference=false, isBulkLoadResult=false, seqid=9239, majorCompaction=false
2014-07-13 17:48:46,554 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/21ed088dd7704403a3aeac6e4df0ab04, isReference=false, isBulkLoadResult=false, seqid=561, majorCompaction=false
2014-07-13 17:48:46,559 DEBUG [StoreOpener-5333598b8a016f79da464f68b5b4a9d7-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7/family/ee688e9ccae14d2fb8621317ff3a767b, isReference=false, isBulkLoadResult=false, seqid=3223, majorCompaction=false
2014-07-13 17:48:46,563 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/5333598b8a016f79da464f68b5b4a9d7
2014-07-13 17:48:46,565 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/2a2bd26186294e1b9cdd67ba65479e44, isReference=false, isBulkLoadResult=false, seqid=5559, majorCompaction=false
2014-07-13 17:48:46,565 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 5333598b8a016f79da464f68b5b4a9d7; next sequenceid=9634
2014-07-13 17:48:46,566 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 5333598b8a016f79da464f68b5b4a9d7
2014-07-13 17:48:46,568 INFO  [PostOpenDeployTasks:5333598b8a016f79da464f68b5b4a9d7] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:48:46,569 DEBUG [PostOpenDeployTasks:5333598b8a016f79da464f68b5b4a9d7] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 17:48:46,570 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 17:48:46,570 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 17:48:46,570 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:46,570 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:46,571 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7. because compaction request was cancelled
2014-07-13 17:48:46,576 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/437b4a899dcf4636bec41f58f2f2858c, isReference=false, isBulkLoadResult=false, seqid=1891, majorCompaction=false
2014-07-13 17:48:46,580 INFO  [PostOpenDeployTasks:5333598b8a016f79da464f68b5b4a9d7] catalog.MetaEditor: Updated row usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7. with server=slave1,60020,1405298890065
2014-07-13 17:48:46,580 INFO  [PostOpenDeployTasks:5333598b8a016f79da464f68b5b4a9d7] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:48:46,581 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5333598b8a016f79da464f68b5b4a9d7 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,588 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5333598b8a016f79da464f68b5b4a9d7 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,588 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 5333598b8a016f79da464f68b5b4a9d7 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:48:46,588 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7. on slave1,60020,1405298890065
2014-07-13 17:48:46,590 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/47ceb95255424cbc904098a0f7f836b0, isReference=false, isBulkLoadResult=false, seqid=2223, majorCompaction=false
2014-07-13 17:48:46,598 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/4cfe2ed4bef74dda9bb19bdf9322476b, isReference=false, isBulkLoadResult=false, seqid=228, majorCompaction=false
2014-07-13 17:48:46,606 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/4e07452335db47238f713adccd0ebd57, isReference=false, isBulkLoadResult=false, seqid=1392, majorCompaction=false
2014-07-13 17:48:46,618 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/55bef0c73aa0413bbe9e48dbdbc2fd09, isReference=false, isBulkLoadResult=false, seqid=4071, majorCompaction=false
2014-07-13 17:48:46,631 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/56390d82666b4a98aec00b949690e752, isReference=false, isBulkLoadResult=false, seqid=8803, majorCompaction=false
2014-07-13 17:48:46,642 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/6a7cc5edb59c42a7a41e3602e6bf394c, isReference=false, isBulkLoadResult=false, seqid=3387, majorCompaction=false
2014-07-13 17:48:46,655 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/71c7d7149110431c8fbd10e9ab861100, isReference=false, isBulkLoadResult=false, seqid=2888, majorCompaction=false
2014-07-13 17:48:46,670 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/72f20c71cac3414891474c81844623e6, isReference=false, isBulkLoadResult=false, seqid=5076, majorCompaction=false
2014-07-13 17:48:46,685 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/73cc4c2cc84f4ae28e4aab690da0969c, isReference=false, isBulkLoadResult=false, seqid=6507, majorCompaction=false
2014-07-13 17:48:46,694 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/7a75d34070c14aff81b9621220d413db, isReference=false, isBulkLoadResult=false, seqid=3221, majorCompaction=false
2014-07-13 17:48:46,703 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/86f591e7324f43a280af8ddcd4298b06, isReference=false, isBulkLoadResult=false, seqid=2389, majorCompaction=false
2014-07-13 17:48:46,715 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/8954fddfbf7d40c794b6b43f02a3e137, isReference=false, isBulkLoadResult=false, seqid=727, majorCompaction=false
2014-07-13 17:48:46,726 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/8f21988b6d5b43f5b41ae6a9742e4656, isReference=false, isBulkLoadResult=false, seqid=1060, majorCompaction=false
2014-07-13 17:48:46,739 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/8f2e00b840804a838f5fc70f16315b0a, isReference=false, isBulkLoadResult=false, seqid=1226, majorCompaction=false
2014-07-13 17:48:46,753 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/9dab33cf196f486a8b0969370f6b923d, isReference=false, isBulkLoadResult=false, seqid=394, majorCompaction=false
2014-07-13 17:48:46,767 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/9e3dc99526594cdea9934893f8c7a259, isReference=false, isBulkLoadResult=false, seqid=3055, majorCompaction=false
2014-07-13 17:48:46,782 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/9e7b5e1b33db431b8b2c81bf04d11ab3, isReference=false, isBulkLoadResult=false, seqid=2721, majorCompaction=false
2014-07-13 17:48:46,795 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/b6390050baf348fdbaa0355d9f7845fb, isReference=false, isBulkLoadResult=false, seqid=9235, majorCompaction=false
2014-07-13 17:48:46,804 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/bb7500cbe7134b0bbb4b735cd7d4c3f7, isReference=false, isBulkLoadResult=false, seqid=7436, majorCompaction=false
2014-07-13 17:48:46,817 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/be20b80216714a12a2e0a8bbae0463cd, isReference=false, isBulkLoadResult=false, seqid=7896, majorCompaction=false
2014-07-13 17:48:46,831 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/c4d603b9d18e42cda59e10247bc70872, isReference=false, isBulkLoadResult=false, seqid=6037, majorCompaction=false
2014-07-13 17:48:46,844 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/cdf4a229d7a1420d8925e9a93249f19b, isReference=false, isBulkLoadResult=false, seqid=893, majorCompaction=false
2014-07-13 17:48:46,860 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/da664748a90f411c8dc8f8114540b36e, isReference=false, isBulkLoadResult=false, seqid=3553, majorCompaction=false
2014-07-13 17:48:46,884 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/e4a9e767cb92496a804afa0939fc9db9, isReference=false, isBulkLoadResult=false, seqid=1725, majorCompaction=false
2014-07-13 17:48:46,895 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/e7d4ce620a9247eeb89de1ea7417a8a1, isReference=false, isBulkLoadResult=false, seqid=4588, majorCompaction=false
2014-07-13 17:48:46,904 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/f004993f3b9448858875b6e84dfe199c, isReference=false, isBulkLoadResult=false, seqid=6975, majorCompaction=false
2014-07-13 17:48:46,916 DEBUG [StoreOpener-679f284b918041b7a8319c93fa551b82-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82/family/f5a89f3d4a1f423a8468424b90a83f8b, isReference=false, isBulkLoadResult=false, seqid=2057, majorCompaction=false
2014-07-13 17:48:46,924 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/679f284b918041b7a8319c93fa551b82
2014-07-13 17:48:46,928 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined 679f284b918041b7a8319c93fa551b82; next sequenceid=9634
2014-07-13 17:48:46,928 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 679f284b918041b7a8319c93fa551b82
2014-07-13 17:48:46,933 INFO  [PostOpenDeployTasks:679f284b918041b7a8319c93fa551b82] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:48:46,933 DEBUG [PostOpenDeployTasks:679f284b918041b7a8319c93fa551b82] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 17:48:46,934 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 17:48:46,934 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 17:48:46,934 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:46,934 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:46,935 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82. because compaction request was cancelled
2014-07-13 17:48:46,947 INFO  [PostOpenDeployTasks:679f284b918041b7a8319c93fa551b82] catalog.MetaEditor: Updated row usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82. with server=slave1,60020,1405298890065
2014-07-13 17:48:46,947 INFO  [PostOpenDeployTasks:679f284b918041b7a8319c93fa551b82] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:48:46,948 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 679f284b918041b7a8319c93fa551b82 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,956 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 679f284b918041b7a8319c93fa551b82 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:48:46,956 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned 679f284b918041b7a8319c93fa551b82 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:48:46,956 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82. on slave1,60020,1405298890065
2014-07-13 17:48:50,735 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 17:48:50,735 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-13 17:48:50,736 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-13 17:48:50,736 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:50,736 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:50,736 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-13 17:48:50,736 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3. because compaction request was cancelled
2014-07-13 17:48:50,736 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-13 17:48:50,737 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 35 store files, 0 compacting, 35 eligible, 20 blocking
2014-07-13 17:48:50,737 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 35 files from compaction candidates
2014-07-13 17:48:50,737 DEBUG [regionserver60020.compactionChecker] regionserver.CompactSplitThread: Small Compaction requested: system; Because: regionserver60020.compactionChecker requests compaction; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 17:48:50,737 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:50,737 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:50,737 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8. because compaction request was cancelled
2014-07-13 17:48:50,738 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 17:48:50,738 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 17:48:50,738 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:50,738 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:50,738 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82. because compaction request was cancelled
2014-07-13 17:48:50,738 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 34 store files, 0 compacting, 34 eligible, 20 blocking
2014-07-13 17:48:50,739 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 34 files from compaction candidates
2014-07-13 17:48:50,739 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 9223372036854775807 because the store might be stuck
2014-07-13 17:48:50,739 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-13 17:48:50,739 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Not compacting usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7. because compaction request was cancelled
2014-07-13 17:49:17,220 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close 5333598b8a016f79da464f68b5b4a9d7, via zk=yes, znode version=0, on null
2014-07-13 17:49:17,222 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close 679f284b918041b7a8319c93fa551b82, via zk=yes, znode version=0, on null
2014-07-13 17:49:17,222 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close 444708cfc43de9303cdc184e6f0e32c8, via zk=yes, znode version=0, on null
2014-07-13 17:49:17,223 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close 2bc32b824633798283ec8f635ffac705, via zk=yes, znode version=0, on null
2014-07-13 17:49:17,223 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Close fbd7f9af67794724bf44ada59fc184e3, via zk=yes, znode version=0, on null
2014-07-13 17:49:17,228 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:49:17,229 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Processing close of usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:49:17,228 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:49:17,231 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.: disabling compactions & flushes
2014-07-13 17:49:17,233 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closing usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.: disabling compactions & flushes
2014-07-13 17:49:17,233 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.: disabling compactions & flushes
2014-07-13 17:49:17,234 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:49:17,234 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:49:17,234 DEBUG [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Updates disabled for region usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:49:17,278 INFO  [StoreCloserThread-usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.-1] regionserver.HStore: Closed family
2014-07-13 17:49:17,278 INFO  [StoreCloserThread-usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.-1] regionserver.HStore: Closed family
2014-07-13 17:49:17,278 INFO  [StoreCloserThread-usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.-1] regionserver.HStore: Closed family
2014-07-13 17:49:17,282 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:49:17,282 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:49:17,282 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 679f284b918041b7a8319c93fa551b82 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,282 INFO  [RS_CLOSE_REGION-slave1:60020-1] regionserver.HRegion: Closed usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:49:17,282 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 444708cfc43de9303cdc184e6f0e32c8 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,282 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 5333598b8a016f79da464f68b5b4a9d7 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 679f284b918041b7a8319c93fa551b82 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82. on slave1,60020,1405298890065
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,user8,1405265098510.679f284b918041b7a8319c93fa551b82.
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Processing close of usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 444708cfc43de9303cdc184e6f0e32c8 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8. on slave1,60020,1405298890065
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user2,1405265098509.444708cfc43de9303cdc184e6f0e32c8.
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Processing close of usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:49:17,289 DEBUG [RS_CLOSE_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 5333598b8a016f79da464f68b5b4a9d7 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,290 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7. on slave1,60020,1405298890065
2014-07-13 17:49:17,290 DEBUG [RS_CLOSE_REGION-slave1:60020-1] handler.CloseRegionHandler: Closed usertable,user6,1405265098509.5333598b8a016f79da464f68b5b4a9d7.
2014-07-13 17:49:17,292 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closing usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.: disabling compactions & flushes
2014-07-13 17:49:17,292 DEBUG [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Updates disabled for region usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:49:17,292 INFO  [StoreCloserThread-usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.-1] regionserver.HStore: Closed family
2014-07-13 17:49:17,293 INFO  [RS_CLOSE_REGION-slave1:60020-0] regionserver.HRegion: Closed usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:49:17,293 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2bc32b824633798283ec8f635ffac705 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,296 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closing usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.: disabling compactions & flushes
2014-07-13 17:49:17,296 DEBUG [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Updates disabled for region usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:49:17,301 DEBUG [RS_CLOSE_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2bc32b824633798283ec8f635ffac705 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,301 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,,1405265098509.2bc32b824633798283ec8f635ffac705. on slave1,60020,1405298890065
2014-07-13 17:49:17,301 DEBUG [RS_CLOSE_REGION-slave1:60020-0] handler.CloseRegionHandler: Closed usertable,,1405265098509.2bc32b824633798283ec8f635ffac705.
2014-07-13 17:49:17,306 INFO  [StoreCloserThread-usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.-1] regionserver.HStore: Closed family
2014-07-13 17:49:17,307 INFO  [RS_CLOSE_REGION-slave1:60020-2] regionserver.HRegion: Closed usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:49:17,307 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning fbd7f9af67794724bf44ada59fc184e3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,313 DEBUG [RS_CLOSE_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node fbd7f9af67794724bf44ada59fc184e3 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-13 17:49:17,313 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3. on slave1,60020,1405298890065
2014-07-13 17:49:17,313 DEBUG [RS_CLOSE_REGION-slave1:60020-2] handler.CloseRegionHandler: Closed usertable,user3,1405265098509.fbd7f9af67794724bf44ada59fc184e3.
2014-07-13 17:53:10,153 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=5, hits=3, hitRatio=60.00%, , cachingAccesses=5, cachingHits=3, cachingHitsRatio=60.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-13 17:54:28,846 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:54:28,858 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:54:28,858 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8c427e222de992c0f6302092c0a1292 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,858 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:54:28,859 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:54:28,859 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning df2b912714c1f15f547c828466aaf923 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,859 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ecd2c8d6e263c2e3db5b8717fb22b6df from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,859 INFO  [Priority.RpcServer.handler=7,port=60020] regionserver.HRegionServer: Open usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af.
2014-07-13 17:54:28,864 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8c427e222de992c0f6302092c0a1292 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,864 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => c8c427e222de992c0f6302092c0a1292, NAME => 'usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.', STARTKEY => 'user7', ENDKEY => 'user8'}
2014-07-13 17:54:28,865 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node df2b912714c1f15f547c828466aaf923 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,865 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable c8c427e222de992c0f6302092c0a1292
2014-07-13 17:54:28,865 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => df2b912714c1f15f547c828466aaf923, NAME => 'usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-13 17:54:28,865 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:54:28,866 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ecd2c8d6e263c2e3db5b8717fb22b6df from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,866 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable df2b912714c1f15f547c828466aaf923
2014-07-13 17:54:28,867 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:54:28,868 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Opening region: {ENCODED => ecd2c8d6e263c2e3db5b8717fb22b6df, NAME => 'usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-13 17:54:28,869 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 17:54:28,869 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Instantiated usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:54:28,877 INFO  [StoreOpener-c8c427e222de992c0f6302092c0a1292-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 17:54:28,879 INFO  [StoreOpener-df2b912714c1f15f547c828466aaf923-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 17:54:28,880 INFO  [StoreOpener-ecd2c8d6e263c2e3db5b8717fb22b6df-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 17:54:28,882 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292
2014-07-13 17:54:28,883 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923
2014-07-13 17:54:28,886 DEBUG [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 17:54:28,886 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined c8c427e222de992c0f6302092c0a1292; next sequenceid=1
2014-07-13 17:54:28,886 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node c8c427e222de992c0f6302092c0a1292
2014-07-13 17:54:28,887 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined df2b912714c1f15f547c828466aaf923; next sequenceid=1
2014-07-13 17:54:28,887 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node df2b912714c1f15f547c828466aaf923
2014-07-13 17:54:28,889 INFO  [PostOpenDeployTasks:c8c427e222de992c0f6302092c0a1292] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:54:28,891 INFO  [PostOpenDeployTasks:df2b912714c1f15f547c828466aaf923] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:54:28,927 INFO  [RS_OPEN_REGION-slave1:60020-1] regionserver.HRegion: Onlined ecd2c8d6e263c2e3db5b8717fb22b6df; next sequenceid=1
2014-07-13 17:54:28,928 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 17:54:28,932 INFO  [PostOpenDeployTasks:ecd2c8d6e263c2e3db5b8717fb22b6df] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:54:28,935 INFO  [PostOpenDeployTasks:df2b912714c1f15f547c828466aaf923] catalog.MetaEditor: Updated row usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. with server=slave1,60020,1405298890065
2014-07-13 17:54:28,935 INFO  [PostOpenDeployTasks:df2b912714c1f15f547c828466aaf923] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:54:28,937 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning df2b912714c1f15f547c828466aaf923 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,939 INFO  [PostOpenDeployTasks:c8c427e222de992c0f6302092c0a1292] catalog.MetaEditor: Updated row usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. with server=slave1,60020,1405298890065
2014-07-13 17:54:28,939 INFO  [PostOpenDeployTasks:c8c427e222de992c0f6302092c0a1292] regionserver.HRegionServer: Finished post open deploy task for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:54:28,941 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning c8c427e222de992c0f6302092c0a1292 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node df2b912714c1f15f547c828466aaf923 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned df2b912714c1f15f547c828466aaf923 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:54:28,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. on slave1,60020,1405298890065
2014-07-13 17:54:28,946 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 60bba508114b247927d755fe2fd7c8ea from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,947 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node c8c427e222de992c0f6302092c0a1292 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,947 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned c8c427e222de992c0f6302092c0a1292 to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:54:28,948 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. on slave1,60020,1405298890065
2014-07-13 17:54:28,948 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ad1657eb75759c7e1a278575c69aa5af from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,952 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 60bba508114b247927d755fe2fd7c8ea from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,953 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Opening region: {ENCODED => 60bba508114b247927d755fe2fd7c8ea, NAME => 'usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-13 17:54:28,954 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 60bba508114b247927d755fe2fd7c8ea
2014-07-13 17:54:28,954 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Instantiated usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:54:28,954 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ad1657eb75759c7e1a278575c69aa5af from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-13 17:54:28,955 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Opening region: {ENCODED => ad1657eb75759c7e1a278575c69aa5af, NAME => 'usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af.', STARTKEY => '', ENDKEY => 'user1'}
2014-07-13 17:54:28,955 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable ad1657eb75759c7e1a278575c69aa5af
2014-07-13 17:54:28,955 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Instantiated usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af.
2014-07-13 17:54:28,961 INFO  [StoreOpener-60bba508114b247927d755fe2fd7c8ea-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 17:54:28,963 INFO  [StoreOpener-ad1657eb75759c7e1a278575c69aa5af-1] compactions.CompactionConfiguration: size [268435456, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 604800000, major jitter 0.500000
2014-07-13 17:54:28,964 DEBUG [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea
2014-07-13 17:54:28,967 INFO  [RS_OPEN_REGION-slave1:60020-0] regionserver.HRegion: Onlined 60bba508114b247927d755fe2fd7c8ea; next sequenceid=1
2014-07-13 17:54:28,967 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 60bba508114b247927d755fe2fd7c8ea
2014-07-13 17:54:28,967 DEBUG [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/ad1657eb75759c7e1a278575c69aa5af
2014-07-13 17:54:28,969 INFO  [RS_OPEN_REGION-slave1:60020-2] regionserver.HRegion: Onlined ad1657eb75759c7e1a278575c69aa5af; next sequenceid=1
2014-07-13 17:54:28,970 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node ad1657eb75759c7e1a278575c69aa5af
2014-07-13 17:54:28,970 INFO  [PostOpenDeployTasks:60bba508114b247927d755fe2fd7c8ea] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:54:28,972 INFO  [PostOpenDeployTasks:ad1657eb75759c7e1a278575c69aa5af] regionserver.HRegionServer: Post open deploy tasks for region=usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af.
2014-07-13 17:54:28,974 INFO  [PostOpenDeployTasks:ecd2c8d6e263c2e3db5b8717fb22b6df] catalog.MetaEditor: Updated row usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. with server=slave1,60020,1405298890065
2014-07-13 17:54:28,974 INFO  [PostOpenDeployTasks:ecd2c8d6e263c2e3db5b8717fb22b6df] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:54:28,976 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ecd2c8d6e263c2e3db5b8717fb22b6df from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,978 INFO  [PostOpenDeployTasks:60bba508114b247927d755fe2fd7c8ea] catalog.MetaEditor: Updated row usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. with server=slave1,60020,1405298890065
2014-07-13 17:54:28,978 INFO  [PostOpenDeployTasks:60bba508114b247927d755fe2fd7c8ea] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:54:28,978 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 60bba508114b247927d755fe2fd7c8ea from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,984 DEBUG [RS_OPEN_REGION-slave1:60020-1] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ecd2c8d6e263c2e3db5b8717fb22b6df from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,984 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Transitioned ecd2c8d6e263c2e3db5b8717fb22b6df to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:54:28,984 DEBUG [RS_OPEN_REGION-slave1:60020-1] handler.OpenRegionHandler: Opened usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. on slave1,60020,1405298890065
2014-07-13 17:54:28,987 DEBUG [RS_OPEN_REGION-slave1:60020-0] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 60bba508114b247927d755fe2fd7c8ea from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:28,987 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Transitioned 60bba508114b247927d755fe2fd7c8ea to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:54:28,987 DEBUG [RS_OPEN_REGION-slave1:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. on slave1,60020,1405298890065
2014-07-13 17:54:29,018 INFO  [PostOpenDeployTasks:ad1657eb75759c7e1a278575c69aa5af] catalog.MetaEditor: Updated row usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af. with server=slave1,60020,1405298890065
2014-07-13 17:54:29,018 INFO  [PostOpenDeployTasks:ad1657eb75759c7e1a278575c69aa5af] regionserver.HRegionServer: Finished post open deploy task for usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af.
2014-07-13 17:54:29,019 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning ad1657eb75759c7e1a278575c69aa5af from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:29,027 DEBUG [RS_OPEN_REGION-slave1:60020-2] zookeeper.ZKAssign: regionserver:60020-0x47325750590002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node ad1657eb75759c7e1a278575c69aa5af from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-13 17:54:29,027 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Transitioned ad1657eb75759c7e1a278575c69aa5af to OPENED in zk on slave1,60020,1405298890065
2014-07-13 17:54:29,028 DEBUG [RS_OPEN_REGION-slave1:60020-2] handler.OpenRegionHandler: Opened usertable,,1405299268767.ad1657eb75759c7e1a278575c69aa5af. on slave1,60020,1405298890065
2014-07-13 17:54:48,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:54:48,638 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 110 synced till here 91
2014-07-13 17:54:48,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405298920609 with entries=110, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299288454
2014-07-13 17:54:51,007 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:54:51,155 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 213 synced till here 194
2014-07-13 17:54:51,558 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299288454 with entries=103, filesize=86.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299291007
2014-07-13 17:54:53,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:54:54,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 346 synced till here 328
2014-07-13 17:54:54,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299291007 with entries=133, filesize=97.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299293806
2014-07-13 17:54:56,768 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:54:56,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 458 synced till here 435
2014-07-13 17:54:57,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299293806 with entries=112, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299296768
2014-07-13 17:54:58,569 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:54:58,573 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 259.7m
2014-07-13 17:54:59,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:54:59,552 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 566 synced till here 549
2014-07-13 17:54:59,761 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:54:59,761 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 259.0m
2014-07-13 17:54:59,889 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299296768 with entries=108, filesize=83.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299299420
2014-07-13 17:55:00,042 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:01,349 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:01,355 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-13 17:55:01,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:01,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 668 synced till here 667
2014-07-13 17:55:01,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299299420 with entries=102, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299301487
2014-07-13 17:55:03,662 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:03,777 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 784 synced till here 773
2014-07-13 17:55:04,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299301487 with entries=116, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299303663
2014-07-13 17:55:05,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:05,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 898 synced till here 875
2014-07-13 17:55:05,837 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299303663 with entries=114, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299305474
2014-07-13 17:55:07,153 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=198, memsize=64.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/525b916d677646caa006b016253e72e2
2014-07-13 17:55:07,172 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/525b916d677646caa006b016253e72e2 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/525b916d677646caa006b016253e72e2
2014-07-13 17:55:07,339 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=202, memsize=63.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/7172737864fd47c9b066b21ad9ea8249
2014-07-13 17:55:07,355 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/7172737864fd47c9b066b21ad9ea8249 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7172737864fd47c9b066b21ad9ea8249
2014-07-13 17:55:07,386 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:07,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 985 synced till here 984
2014-07-13 17:55:07,635 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/525b916d677646caa006b016253e72e2, entries=233390, sequenceid=198, filesize=16.6m
2014-07-13 17:55:07,636 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~268.3m/281313440, currentsize=169.6m/177840880 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 9063ms, sequenceid=198, compaction requested=false
2014-07-13 17:55:07,653 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7172737864fd47c9b066b21ad9ea8249, entries=232220, sequenceid=202, filesize=16.5m
2014-07-13 17:55:07,653 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~268.7m/281751600, currentsize=165.6m/173641680 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 7892ms, sequenceid=202, compaction requested=false
2014-07-13 17:55:07,693 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299305474 with entries=87, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299307387
2014-07-13 17:55:09,346 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:55:09,346 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 257.7m
2014-07-13 17:55:09,699 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:55:09,699 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.8m
2014-07-13 17:55:09,951 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:10,108 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:10,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:10,276 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1059 synced till here 1054
2014-07-13 17:55:10,325 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299307387 with entries=74, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299310149
2014-07-13 17:55:12,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:12,567 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1166 synced till here 1143
2014-07-13 17:55:12,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299310149 with entries=107, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299312464
2014-07-13 17:55:14,129 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:55:14,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:14,732 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1253 synced till here 1245
2014-07-13 17:55:14,932 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:55:14,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299312464 with entries=87, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299314706
2014-07-13 17:55:15,364 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=166, memsize=50.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c161865a87ce4b4fb087f92f5b064913
2014-07-13 17:55:15,485 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c161865a87ce4b4fb087f92f5b064913 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c161865a87ce4b4fb087f92f5b064913
2014-07-13 17:55:15,503 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c161865a87ce4b4fb087f92f5b064913, entries=183960, sequenceid=166, filesize=13.1m
2014-07-13 17:55:15,503 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.8m/271350320, currentsize=100.9m/105809040 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 5804ms, sequenceid=166, compaction requested=false
2014-07-13 17:55:15,504 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 270.6m
2014-07-13 17:55:15,908 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=167, memsize=50.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/a86309e568a34093a057f0125b290b83
2014-07-13 17:55:15,924 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/a86309e568a34093a057f0125b290b83 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a86309e568a34093a057f0125b290b83
2014-07-13 17:55:16,079 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a86309e568a34093a057f0125b290b83, entries=182800, sequenceid=167, filesize=13.0m
2014-07-13 17:55:16,079 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.3m/271853440, currentsize=117.3m/123042480 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 6733ms, sequenceid=167, compaction requested=false
2014-07-13 17:55:16,080 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 270.8m
2014-07-13 17:55:16,209 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:16,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:16,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1326 synced till here 1314
2014-07-13 17:55:17,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299314706 with entries=73, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299316637
2014-07-13 17:55:17,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405298920609
2014-07-13 17:55:17,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299288454
2014-07-13 17:55:17,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299291007
2014-07-13 17:55:17,001 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299293806
2014-07-13 17:55:17,160 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:18,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:18,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1403 synced till here 1401
2014-07-13 17:55:18,686 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299316637 with entries=77, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299318582
2014-07-13 17:55:20,415 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:20,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1478 synced till here 1468
2014-07-13 17:55:20,650 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299318582 with entries=75, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299320415
2014-07-13 17:55:23,614 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:23,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1573 synced till here 1552
2014-07-13 17:55:24,226 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299320415 with entries=95, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299323615
2014-07-13 17:55:26,122 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=416, memsize=117.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/efb59d8a181a45ac861c08d862a9ffbf
2014-07-13 17:55:26,130 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:26,133 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:55:26,277 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/efb59d8a181a45ac861c08d862a9ffbf as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/efb59d8a181a45ac861c08d862a9ffbf
2014-07-13 17:55:26,408 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/efb59d8a181a45ac861c08d862a9ffbf, entries=426720, sequenceid=416, filesize=30.4m
2014-07-13 17:55:26,411 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1699 synced till here 1681
2014-07-13 17:55:26,425 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~272.2m/285432080, currentsize=156.9m/164539680 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 10921ms, sequenceid=416, compaction requested=false
2014-07-13 17:55:26,426 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 268.5m
2014-07-13 17:55:26,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299323615 with entries=126, filesize=86.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299326130
2014-07-13 17:55:26,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299296768
2014-07-13 17:55:27,236 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:27,672 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=418, memsize=120.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/0b18571d51ce42fbb4844135f6e064a0
2014-07-13 17:55:27,768 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/0b18571d51ce42fbb4844135f6e064a0 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/0b18571d51ce42fbb4844135f6e064a0
2014-07-13 17:55:27,851 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/0b18571d51ce42fbb4844135f6e064a0, entries=440000, sequenceid=418, filesize=31.4m
2014-07-13 17:55:27,851 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~274.0m/287348720, currentsize=146.7m/153853680 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 11771ms, sequenceid=418, compaction requested=false
2014-07-13 17:55:28,089 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:55:28,090 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.3m
2014-07-13 17:55:28,679 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:29,220 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:31,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1880 synced till here 1851
2014-07-13 17:55:32,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299326130 with entries=181, filesize=146.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299329220
2014-07-13 17:55:32,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299299420
2014-07-13 17:55:32,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299301487
2014-07-13 17:55:32,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299303663
2014-07-13 17:55:32,044 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299305474
2014-07-13 17:55:33,829 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:55:34,401 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:55:34,725 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:34,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1977 synced till here 1961
2014-07-13 17:55:35,096 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299329220 with entries=97, filesize=81.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299334725
2014-07-13 17:55:37,341 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=332, memsize=172.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ab73ce53d8384e8188a2cc3db929181e
2014-07-13 17:55:37,358 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ab73ce53d8384e8188a2cc3db929181e as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ab73ce53d8384e8188a2cc3db929181e
2014-07-13 17:55:37,429 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ab73ce53d8384e8188a2cc3db929181e, entries=626340, sequenceid=332, filesize=44.7m
2014-07-13 17:55:37,429 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~277.5m/291029760, currentsize=106.2m/111348160 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 11003ms, sequenceid=332, compaction requested=false
2014-07-13 17:55:37,430 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 301.4m
2014-07-13 17:55:37,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:37,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2058 synced till here 2047
2014-07-13 17:55:37,833 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299334725 with entries=81, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299337482
2014-07-13 17:55:38,024 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:38,971 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=335, memsize=173.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/cad4e31403da47b689269be4e67a5f94
2014-07-13 17:55:39,156 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/cad4e31403da47b689269be4e67a5f94 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/cad4e31403da47b689269be4e67a5f94
2014-07-13 17:55:39,189 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/cad4e31403da47b689269be4e67a5f94, entries=631110, sequenceid=335, filesize=45.0m
2014-07-13 17:55:39,189 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~278.8m/292337520, currentsize=113.4m/118919200 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 11099ms, sequenceid=335, compaction requested=false
2014-07-13 17:55:39,189 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 305.2m
2014-07-13 17:55:40,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:40,174 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:40,176 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2138 synced till here 2134
2014-07-13 17:55:40,344 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299337482 with entries=80, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299340038
2014-07-13 17:55:40,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299307387
2014-07-13 17:55:40,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299310149
2014-07-13 17:55:40,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299312464
2014-07-13 17:55:43,135 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:43,154 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2203 synced till here 2197
2014-07-13 17:55:43,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299340038 with entries=65, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299343135
2014-07-13 17:55:46,662 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:46,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2318 synced till here 2298
2014-07-13 17:55:47,025 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299343135 with entries=115, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299346663
2014-07-13 17:55:48,827 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=634, memsize=129.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/8d8ba87e21194fbda98122803baa4622
2014-07-13 17:55:48,843 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/8d8ba87e21194fbda98122803baa4622 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8d8ba87e21194fbda98122803baa4622
2014-07-13 17:55:48,852 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8d8ba87e21194fbda98122803baa4622, entries=469510, sequenceid=634, filesize=33.5m
2014-07-13 17:55:48,853 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~303.7m/318489040, currentsize=133.2m/139690880 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 11423ms, sequenceid=634, compaction requested=true
2014-07-13 17:55:48,854 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-13 17:55:48,854 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-13 17:55:48,855 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 84428181 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-13 17:55:48,855 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating major compaction
2014-07-13 17:55:48,855 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:55:48,856 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=80.5m
2014-07-13 17:55:48,858 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/525b916d677646caa006b016253e72e2, keycount=23339, bloomtype=ROW, size=16.6m, encoding=NONE, seqNum=198, earliestPutTs=1405299288017
2014-07-13 17:55:48,858 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/efb59d8a181a45ac861c08d862a9ffbf, keycount=42672, bloomtype=ROW, size=30.4m, encoding=NONE, seqNum=416, earliestPutTs=1405299303246
2014-07-13 17:55:48,858 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8d8ba87e21194fbda98122803baa4622, keycount=46951, bloomtype=ROW, size=33.5m, encoding=NONE, seqNum=634, earliestPutTs=1405299315503
2014-07-13 17:55:48,953 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:49,170 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=643, memsize=126.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/b2ed1dbe01484ce4bea7d65a6042eda1
2014-07-13 17:55:49,181 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/b2ed1dbe01484ce4bea7d65a6042eda1 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/b2ed1dbe01484ce4bea7d65a6042eda1
2014-07-13 17:55:49,295 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/b2ed1dbe01484ce4bea7d65a6042eda1, entries=458990, sequenceid=643, filesize=32.7m
2014-07-13 17:55:49,295 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~313.9m/329100720, currentsize=125.2m/131257920 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 10106ms, sequenceid=643, compaction requested=true
2014-07-13 17:55:49,296 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-13 17:55:49,660 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:49,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2395 synced till here 2391
2014-07-13 17:55:49,735 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299346663 with entries=77, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299349660
2014-07-13 17:55:49,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299314706
2014-07-13 17:55:49,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299316637
2014-07-13 17:55:49,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299318582
2014-07-13 17:55:49,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299320415
2014-07-13 17:55:49,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299323615
2014-07-13 17:55:52,473 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:55:52,473 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 257.0m
2014-07-13 17:55:52,601 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:52,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2474 synced till here 2465
2014-07-13 17:55:52,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299349660 with entries=79, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299352602
2014-07-13 17:55:52,830 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:52,836 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:55:52,836 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 257.2m
2014-07-13 17:55:53,229 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:55:53,318 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-13 17:55:53,319 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-13 17:55:55,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:55:56,152 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2564 synced till here 2556
2014-07-13 17:55:56,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299352602 with entries=90, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299355849
2014-07-13 17:56:00,158 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:01,528 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:56:01,655 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=509, memsize=112.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c22ee49a23054f56985f65cc1f2dd3e5
2014-07-13 17:56:01,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2722 synced till here 2684
2014-07-13 17:56:01,663 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=500, memsize=108.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/87b7b877b0e64331b9ea213723219d69
2014-07-13 17:56:01,687 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c22ee49a23054f56985f65cc1f2dd3e5 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c22ee49a23054f56985f65cc1f2dd3e5
2014-07-13 17:56:01,694 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/87b7b877b0e64331b9ea213723219d69 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/87b7b877b0e64331b9ea213723219d69
2014-07-13 17:56:01,701 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c22ee49a23054f56985f65cc1f2dd3e5, entries=408770, sequenceid=509, filesize=29.1m
2014-07-13 17:56:01,701 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.3m/272935920, currentsize=76.5m/80258720 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 8865ms, sequenceid=509, compaction requested=true
2014-07-13 17:56:01,703 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 17:56:01,703 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 257.3m
2014-07-13 17:56:01,706 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/87b7b877b0e64331b9ea213723219d69, entries=393810, sequenceid=500, filesize=28.1m
2014-07-13 17:56:01,706 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.6m/270154800, currentsize=89.0m/93315120 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 9233ms, sequenceid=500, compaction requested=true
2014-07-13 17:56:01,706 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-13 17:56:02,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299355849 with entries=158, filesize=122.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299360158
2014-07-13 17:56:02,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299326130
2014-07-13 17:56:02,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299329220
2014-07-13 17:56:04,171 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:04,519 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:04,520 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:56:04,522 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 260.5m
2014-07-13 17:56:04,616 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2812 synced till here 2801
2014-07-13 17:56:04,764 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299360158 with entries=90, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299364519
2014-07-13 17:56:05,243 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:06,164 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/0aabb33c579f4454a537f68487f49da9 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0aabb33c579f4454a537f68487f49da9
2014-07-13 17:56:06,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:06,322 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2882 synced till here 2874
2014-07-13 17:56:06,440 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 17:56:06,458 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/525b916d677646caa006b016253e72e2, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/525b916d677646caa006b016253e72e2
2014-07-13 17:56:06,461 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/efb59d8a181a45ac861c08d862a9ffbf, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/efb59d8a181a45ac861c08d862a9ffbf
2014-07-13 17:56:06,464 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8d8ba87e21194fbda98122803baa4622, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8d8ba87e21194fbda98122803baa4622
2014-07-13 17:56:06,464 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into 0aabb33c579f4454a537f68487f49da9(size=60.0m), total size for store is 60.0m. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-13 17:56:06,473 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=3, fileSize=80.5m, priority=17, time=253256282090757; duration=17sec
2014-07-13 17:56:06,473 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-13 17:56:06,474 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-13 17:56:06,474 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 84536057 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-13 17:56:06,474 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating major compaction
2014-07-13 17:56:06,474 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:56:06,474 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=80.6m
2014-07-13 17:56:06,475 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7172737864fd47c9b066b21ad9ea8249, keycount=23222, bloomtype=ROW, size=16.5m, encoding=NONE, seqNum=202, earliestPutTs=1405299288490
2014-07-13 17:56:06,475 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/0b18571d51ce42fbb4844135f6e064a0, keycount=44000, bloomtype=ROW, size=31.4m, encoding=NONE, seqNum=418, earliestPutTs=1405299303993
2014-07-13 17:56:06,475 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/b2ed1dbe01484ce4bea7d65a6042eda1, keycount=45899, bloomtype=ROW, size=32.7m, encoding=NONE, seqNum=643, earliestPutTs=1405299316114
2014-07-13 17:56:06,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299364519 with entries=70, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299366297
2014-07-13 17:56:06,501 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:08,155 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:08,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2958 synced till here 2946
2014-07-13 17:56:08,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299366297 with entries=76, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299368156
2014-07-13 17:56:09,806 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:56:10,285 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:56:10,426 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:10,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3025 synced till here 3020
2014-07-13 17:56:10,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299368156 with entries=67, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299370426
2014-07-13 17:56:12,534 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:12,552 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3089 synced till here 3086
2014-07-13 17:56:12,669 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299370426 with entries=64, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299372535
2014-07-13 17:56:14,608 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:14,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3164 synced till here 3152
2014-07-13 17:56:15,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299372535 with entries=75, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299374608
2014-07-13 17:56:16,183 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=824, memsize=150.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/88386aa496ec40709f65381fd139233c
2014-07-13 17:56:16,370 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/88386aa496ec40709f65381fd139233c as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/88386aa496ec40709f65381fd139233c
2014-07-13 17:56:16,390 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/88386aa496ec40709f65381fd139233c, entries=548600, sequenceid=824, filesize=39.1m
2014-07-13 17:56:16,391 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.2m/276992960, currentsize=169.5m/177768960 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 14688ms, sequenceid=824, compaction requested=false
2014-07-13 17:56:16,391 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 351.2m
2014-07-13 17:56:16,701 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=840, memsize=143.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/33cd95040426474c9f081d83377a61fa
2014-07-13 17:56:16,725 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/33cd95040426474c9f081d83377a61fa as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/33cd95040426474c9f081d83377a61fa
2014-07-13 17:56:16,820 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/33cd95040426474c9f081d83377a61fa, entries=522490, sequenceid=840, filesize=37.2m
2014-07-13 17:56:16,821 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~263.1m/275887040, currentsize=157.5m/165100240 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 12299ms, sequenceid=840, compaction requested=false
2014-07-13 17:56:16,822 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 346.9m
2014-07-13 17:56:17,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:17,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3243 synced till here 3234
2014-07-13 17:56:17,391 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:17,873 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:18,445 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299374608 with entries=79, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299377017
2014-07-13 17:56:18,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299334725
2014-07-13 17:56:18,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299337482
2014-07-13 17:56:18,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299340038
2014-07-13 17:56:18,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299343135
2014-07-13 17:56:18,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299346663
2014-07-13 17:56:21,693 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:21,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3395 synced till here 3360
2014-07-13 17:56:22,248 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:56:22,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299377017 with entries=152, filesize=123.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299381694
2014-07-13 17:56:24,086 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:24,128 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:56:24,304 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3508 synced till here 3477
2014-07-13 17:56:24,823 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299381694 with entries=113, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299384086
2014-07-13 17:56:26,510 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:26,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3624 synced till here 3600
2014-07-13 17:56:27,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299384086 with entries=116, filesize=87.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299386510
2014-07-13 17:56:28,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:28,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3727 synced till here 3699
2014-07-13 17:56:29,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299386510 with entries=103, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299388717
2014-07-13 17:56:30,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:30,958 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/f3d343b4305e45988041e90352f3d91e as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f3d343b4305e45988041e90352f3d91e
2014-07-13 17:56:30,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3844 synced till here 3816
2014-07-13 17:56:31,544 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299388717 with entries=117, filesize=84.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299390920
2014-07-13 17:56:32,336 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 17:56:32,348 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7172737864fd47c9b066b21ad9ea8249, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7172737864fd47c9b066b21ad9ea8249
2014-07-13 17:56:32,353 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/0b18571d51ce42fbb4844135f6e064a0, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/0b18571d51ce42fbb4844135f6e064a0
2014-07-13 17:56:32,469 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/b2ed1dbe01484ce4bea7d65a6042eda1, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/b2ed1dbe01484ce4bea7d65a6042eda1
2014-07-13 17:56:32,469 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into f3d343b4305e45988041e90352f3d91e(size=60.1m), total size for store is 97.4m. This selection was in queue for 0sec, and took 25sec to execute.
2014-07-13 17:56:32,469 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=3, fileSize=80.6m, priority=17, time=253273901205688; duration=25sec
2014-07-13 17:56:32,470 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 17:56:32,470 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-13 17:56:32,470 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 89913541 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-13 17:56:32,470 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating major compaction
2014-07-13 17:56:32,471 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:56:32,471 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=85.7m
2014-07-13 17:56:32,471 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a86309e568a34093a057f0125b290b83, keycount=18280, bloomtype=ROW, size=13.0m, encoding=NONE, seqNum=167, earliestPutTs=1405299304997
2014-07-13 17:56:32,472 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ab73ce53d8384e8188a2cc3db929181e, keycount=62634, bloomtype=ROW, size=44.7m, encoding=NONE, seqNum=332, earliestPutTs=1405299309365
2014-07-13 17:56:32,472 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/87b7b877b0e64331b9ea213723219d69, keycount=39381, bloomtype=ROW, size=28.1m, encoding=NONE, seqNum=500, earliestPutTs=1405299326579
2014-07-13 17:56:32,502 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:33,026 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:33,046 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3928 synced till here 3918
2014-07-13 17:56:33,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299390920 with entries=84, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299393026
2014-07-13 17:56:35,627 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:35,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4052 synced till here 4043
2014-07-13 17:56:35,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299393026 with entries=124, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299395627
2014-07-13 17:56:37,493 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:37,620 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4138 synced till here 4127
2014-07-13 17:56:37,883 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299395627 with entries=86, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299397494
2014-07-13 17:56:39,360 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:40,148 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4229 synced till here 4223
2014-07-13 17:56:40,148 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=693, memsize=242.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/bd985e6755464912a6502d2e1081ca3b
2014-07-13 17:56:40,173 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/bd985e6755464912a6502d2e1081ca3b as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd985e6755464912a6502d2e1081ca3b
2014-07-13 17:56:40,245 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd985e6755464912a6502d2e1081ca3b, entries=881690, sequenceid=693, filesize=62.8m
2014-07-13 17:56:40,246 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~358.3m/375736720, currentsize=300.7m/315261360 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 23424ms, sequenceid=693, compaction requested=true
2014-07-13 17:56:40,246 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 17:56:40,247 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 584.2m
2014-07-13 17:56:40,250 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:56:40,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299397494 with entries=91, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299399360
2014-07-13 17:56:40,727 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=689, memsize=246.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/f9ce0fc7bf094da6b6419fc54498967d
2014-07-13 17:56:40,771 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/f9ce0fc7bf094da6b6419fc54498967d as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f9ce0fc7bf094da6b6419fc54498967d
2014-07-13 17:56:40,790 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f9ce0fc7bf094da6b6419fc54498967d, entries=898290, sequenceid=689, filesize=64.0m
2014-07-13 17:56:40,791 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~362.6m/380230560, currentsize=309.8m/324890880 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 24400ms, sequenceid=689, compaction requested=false
2014-07-13 17:56:40,791 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 577.2m
2014-07-13 17:56:40,888 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:56:41,766 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:41,939 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:42,249 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:56:43,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4331 synced till here 4328
2014-07-13 17:56:43,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299399360 with entries=102, filesize=104.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299401939
2014-07-13 17:56:43,179 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299349660
2014-07-13 17:56:43,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299352602
2014-07-13 17:56:43,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299355849
2014-07-13 17:56:44,626 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:44,650 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299401939 with entries=66, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299404627
2014-07-13 17:56:47,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:47,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4479 synced till here 4466
2014-07-13 17:56:47,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299404627 with entries=82, filesize=78.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299407142
2014-07-13 17:56:49,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:49,193 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4561 synced till here 4559
2014-07-13 17:56:49,251 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299407142 with entries=82, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299409168
2014-07-13 17:56:52,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:52,215 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4655 synced till here 4644
2014-07-13 17:56:52,669 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299409168 with entries=94, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299412022
2014-07-13 17:56:55,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:56:56,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4797 synced till here 4775
2014-07-13 17:56:57,805 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299412022 with entries=142, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299415773
2014-07-13 17:57:00,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:01,247 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/9fdf8e45c34b4b469e8ac58fcee352cf as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9fdf8e45c34b4b469e8ac58fcee352cf
2014-07-13 17:57:01,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4928 synced till here 4904
2014-07-13 17:57:01,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299415773 with entries=131, filesize=93.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299420728
2014-07-13 17:57:02,104 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 17:57:02,231 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a86309e568a34093a057f0125b290b83, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a86309e568a34093a057f0125b290b83
2014-07-13 17:57:02,238 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ab73ce53d8384e8188a2cc3db929181e, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ab73ce53d8384e8188a2cc3db929181e
2014-07-13 17:57:02,241 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/87b7b877b0e64331b9ea213723219d69, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/87b7b877b0e64331b9ea213723219d69
2014-07-13 17:57:02,241 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into 9fdf8e45c34b4b469e8ac58fcee352cf(size=69.6m), total size for store is 133.6m. This selection was in queue for 0sec, and took 29sec to execute.
2014-07-13 17:57:02,242 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=3, fileSize=85.7m, priority=17, time=253299897749780; duration=29sec
2014-07-13 17:57:02,242 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 17:57:02,242 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-13 17:57:02,243 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 157341398 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-13 17:57:02,243 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating major compaction
2014-07-13 17:57:02,243 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:57:02,244 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=150.1m
2014-07-13 17:57:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c161865a87ce4b4fb087f92f5b064913, keycount=18396, bloomtype=ROW, size=13.1m, encoding=NONE, seqNum=166, earliestPutTs=1405299305676
2014-07-13 17:57:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/cad4e31403da47b689269be4e67a5f94, keycount=63111, bloomtype=ROW, size=45.0m, encoding=NONE, seqNum=335, earliestPutTs=1405299309705
2014-07-13 17:57:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c22ee49a23054f56985f65cc1f2dd3e5, keycount=40877, bloomtype=ROW, size=29.1m, encoding=NONE, seqNum=509, earliestPutTs=1405299328149
2014-07-13 17:57:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd985e6755464912a6502d2e1081ca3b, keycount=88169, bloomtype=ROW, size=62.8m, encoding=NONE, seqNum=693, earliestPutTs=1405299352956
2014-07-13 17:57:02,312 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:57:03,052 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:03,283 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5048 synced till here 5030
2014-07-13 17:57:03,506 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299420728 with entries=120, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299423053
2014-07-13 17:57:04,926 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:05,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5172 synced till here 5148
2014-07-13 17:57:05,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299423053 with entries=124, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299424927
2014-07-13 17:57:07,224 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:07,464 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5305 synced till here 5276
2014-07-13 17:57:07,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299424927 with entries=133, filesize=79.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299427224
2014-07-13 17:57:09,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:09,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5423 synced till here 5407
2014-07-13 17:57:09,729 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299427224 with entries=118, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299429495
2014-07-13 17:57:11,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:12,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5543 synced till here 5514
2014-07-13 17:57:12,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299429495 with entries=120, filesize=83.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299431896
2014-07-13 17:57:29,892 WARN  [regionserver60020] util.Sleeper: We slept 20046ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-13 17:57:29,934 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17047ms
GC pool 'ParNew' had collection(s): count=1 time=0ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=17430ms
2014-07-13 17:57:30,207 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18425,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431632,"queuetimems":0,"class":"HRegionServer","responsesize":7782,"method":"Multi"}
2014-07-13 17:57:30,207 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18069,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299432087,"queuetimems":0,"class":"HRegionServer","responsesize":2419,"method":"Multi"}
2014-07-13 17:57:30,208 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18235,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431924,"queuetimems":0,"class":"HRegionServer","responsesize":3777,"method":"Multi"}
2014-07-13 17:57:30,208 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18669,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431392,"queuetimems":0,"class":"HRegionServer","responsesize":7882,"method":"Multi"}
2014-07-13 17:57:30,208 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18517,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431642,"queuetimems":0,"class":"HRegionServer","responsesize":4810,"method":"Multi"}
2014-07-13 17:57:30,208 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3380 service: ClientService methodName: Multi size: 1.4m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,207 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18708,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431449,"queuetimems":0,"class":"HRegionServer","responsesize":12162,"method":"Multi"}
2014-07-13 17:57:30,207 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431038,"queuetimems":0,"class":"HRegionServer","responsesize":10965,"method":"Multi"}
2014-07-13 17:57:30,210 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3378 service: ClientService methodName: Multi size: 866.9k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,210 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,208 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431575,"queuetimems":0,"class":"HRegionServer","responsesize":3857,"method":"Multi"}
2014-07-13 17:57:30,207 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18541,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431618,"queuetimems":0,"class":"HRegionServer","responsesize":6271,"method":"Multi"}
2014-07-13 17:57:30,226 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: RpcServer.handler=16,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3389 service: ClientService methodName: Multi size: 1.4m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: RpcServer.handler=40,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3398 service: ClientService methodName: Multi size: 682.0k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: RpcServer.handler=33,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3401 service: ClientService methodName: Multi size: 437.2k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,227 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3381 service: ClientService methodName: Multi size: 1.1m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3385 service: ClientService methodName: Multi size: 695.8k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3369 service: ClientService methodName: Multi size: 1.9m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3387 service: ClientService methodName: Multi size: 2.1m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,228 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,285 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299430521,"queuetimems":0,"class":"HRegionServer","responsesize":19093,"method":"Multi"}
2014-07-13 17:57:30,285 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431642,"queuetimems":0,"class":"HRegionServer","responsesize":70,"method":"Multi"}
2014-07-13 17:57:30,285 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3377 service: ClientService methodName: Multi size: 3.3m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,285 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19019,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431265,"queuetimems":0,"class":"HRegionServer","responsesize":8897,"method":"Multi"}
2014-07-13 17:57:30,286 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3390 service: ClientService methodName: Multi size: 1.6m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,286 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: RpcServer.handler=14,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,286 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18706,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431580,"queuetimems":0,"class":"HRegionServer","responsesize":3054,"method":"Multi"}
2014-07-13 17:57:30,286 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3395 service: ClientService methodName: Multi size: 13.9k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,286 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,287 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18697,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431590,"queuetimems":0,"class":"HRegionServer","responsesize":3157,"method":"Multi"}
2014-07-13 17:57:30,287 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3382 service: ClientService methodName: Multi size: 575.8k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,287 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,287 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3384 service: ClientService methodName: Multi size: 557.1k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,287 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,285 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,286 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18643,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431643,"queuetimems":1,"class":"HRegionServer","responsesize":202,"method":"Multi"}
2014-07-13 17:57:30,288 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3394 service: ClientService methodName: Multi size: 41.3k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,288 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,288 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18714,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431573,"queuetimems":0,"class":"HRegionServer","responsesize":7649,"method":"Multi"}
2014-07-13 17:57:30,288 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3386 service: ClientService methodName: Multi size: 1.3m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,288 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: RpcServer.handler=41,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,289 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18656,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431633,"queuetimems":0,"class":"HRegionServer","responsesize":1183,"method":"Multi"}
2014-07-13 17:57:30,289 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3379 service: ClientService methodName: Multi size: 224.9k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,289 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,289 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18701,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431586,"queuetimems":1,"class":"HRegionServer","responsesize":3451,"method":"Multi"}
2014-07-13 17:57:30,290 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3383 service: ClientService methodName: Multi size: 629.5k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,290 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,350 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3426 service: ClientService methodName: Multi size: 136.2k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,358 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,358 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3423 service: ClientService methodName: Multi size: 189.9k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,358 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,358 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3424 service: ClientService methodName: Multi size: 542.1k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,359 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: RpcServer.handler=12,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,359 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19969,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299430389,"queuetimems":0,"class":"HRegionServer","responsesize":17296,"method":"Multi"}
2014-07-13 17:57:30,360 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3365 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,360 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,360 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299430731,"queuetimems":0,"class":"HRegionServer","responsesize":17331,"method":"Multi"}
2014-07-13 17:57:30,361 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3373 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,361 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,400 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19700,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299430699,"queuetimems":1,"class":"HRegionServer","responsesize":15598,"method":"Multi"}
2014-07-13 17:57:30,401 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3374 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,401 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,401 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3422 service: ClientService methodName: Multi size: 7.6k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,401 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,402 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3425 service: ClientService methodName: Multi size: 25.1k connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,402 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: RpcServer.handler=10,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,401 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3451 service: ClientService methodName: Multi size: 13.9k connection: 9.1.143.53:46710: output error
2014-07-13 17:57:30,440 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,440 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3452 service: ClientService methodName: Multi size: 41.3k connection: 9.1.143.53:46710: output error
2014-07-13 17:57:30,440 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,402 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299430907,"queuetimems":1,"class":"HRegionServer","responsesize":14454,"method":"Multi"}
2014-07-13 17:57:30,441 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3370 service: ClientService methodName: Multi size: 2.5m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,441 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: RpcServer.handler=25,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,469 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3408 service: ClientService methodName: Multi size: 1.7m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,469 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,564 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18136,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299432428,"queuetimems":0,"class":"HRegionServer","responsesize":17488,"method":"Multi"}
2014-07-13 17:57:30,565 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3406 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,565 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,657 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431427,"queuetimems":1,"class":"HRegionServer","responsesize":15790,"method":"Multi"}
2014-07-13 17:57:30,658 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3388 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,658 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: RpcServer.handler=35,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,846 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19597,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431249,"queuetimems":0,"class":"HRegionServer","responsesize":17729,"method":"Multi"}
2014-07-13 17:57:30,846 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19780,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431066,"queuetimems":0,"class":"HRegionServer","responsesize":17665,"method":"Multi"}
2014-07-13 17:57:30,846 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3409 service: ClientService methodName: Multi size: 2.8m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,847 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19636,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46709","starttimems":1405299431210,"queuetimems":0,"class":"HRegionServer","responsesize":15685,"method":"Multi"}
2014-07-13 17:57:30,847 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,847 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3391 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,847 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,847 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3368 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,847 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:30,848 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 3367 service: ClientService methodName: Multi size: 2.7m connection: 9.1.143.53:46709: output error
2014-07-13 17:57:30,848 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-13 17:57:31,676 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:31,710 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299431896 with entries=90, filesize=61.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299451677
2014-07-13 17:57:32,063 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1198, memsize=296.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/8b27f57eb1dc4e7892954eda97536242
2014-07-13 17:57:32,106 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/8b27f57eb1dc4e7892954eda97536242 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8b27f57eb1dc4e7892954eda97536242
2014-07-13 17:57:32,128 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8b27f57eb1dc4e7892954eda97536242, entries=1079200, sequenceid=1198, filesize=76.9m
2014-07-13 17:57:32,129 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~587.8m/616347360, currentsize=483.5m/506967920 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 51882ms, sequenceid=1198, compaction requested=true
2014-07-13 17:57:32,130 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:2), split_queue=0, merge_queue=0
2014-07-13 17:57:32,130 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 731.0m
2014-07-13 17:57:32,130 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:57:32,582 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1202, memsize=296.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/57a14f6ea8c84fcf83bb5f81f7a75f63
2014-07-13 17:57:32,600 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/57a14f6ea8c84fcf83bb5f81f7a75f63 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57a14f6ea8c84fcf83bb5f81f7a75f63
2014-07-13 17:57:32,621 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57a14f6ea8c84fcf83bb5f81f7a75f63, entries=1078830, sequenceid=1202, filesize=76.9m
2014-07-13 17:57:32,621 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~585.8m/614292000, currentsize=471.3m/494212240 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 51830ms, sequenceid=1202, compaction requested=true
2014-07-13 17:57:32,622 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:3), split_queue=0, merge_queue=0
2014-07-13 17:57:32,622 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 734.2m
2014-07-13 17:57:33,117 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:57:33,433 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:57:33,662 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:33,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5699 synced till here 5695
2014-07-13 17:57:33,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299451677 with entries=66, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299453662
2014-07-13 17:57:33,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299360158
2014-07-13 17:57:33,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299364519
2014-07-13 17:57:33,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299366297
2014-07-13 17:57:33,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299368156
2014-07-13 17:57:33,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299370426
2014-07-13 17:57:33,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299372535
2014-07-13 17:57:33,745 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:57:35,395 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:35,429 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5775 synced till here 5770
2014-07-13 17:57:35,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299453662 with entries=76, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299455396
2014-07-13 17:57:37,363 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:37,379 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5877 synced till here 5867
2014-07-13 17:57:37,508 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299455396 with entries=102, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299457363
2014-07-13 17:57:38,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:38,644 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5957 synced till here 5956
2014-07-13 17:57:38,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299457363 with entries=80, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299458618
2014-07-13 17:57:40,064 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:40,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6037 synced till here 6026
2014-07-13 17:57:40,213 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299458618 with entries=80, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299460065
2014-07-13 17:57:41,449 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:43,195 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6189 synced till here 6188
2014-07-13 17:57:43,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299460065 with entries=152, filesize=114.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299461450
2014-07-13 17:57:45,864 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:45,905 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299461450 with entries=77, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299465865
2014-07-13 17:57:46,687 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1257, memsize=258.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/8c353e8f601947c6abc5fcab4ee4d130
2014-07-13 17:57:46,706 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/8c353e8f601947c6abc5fcab4ee4d130 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8c353e8f601947c6abc5fcab4ee4d130
2014-07-13 17:57:46,722 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8c353e8f601947c6abc5fcab4ee4d130, entries=940330, sequenceid=1257, filesize=67.0m
2014-07-13 17:57:46,723 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~733.9m/769575840, currentsize=248.8m/260844640 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 14593ms, sequenceid=1257, compaction requested=false
2014-07-13 17:57:46,724 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 712.3m
2014-07-13 17:57:46,932 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:57:47,713 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:57:48,102 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1263, memsize=258.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/50de0376615b4ba292c61304b0661330
2014-07-13 17:57:48,116 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/50de0376615b4ba292c61304b0661330 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/50de0376615b4ba292c61304b0661330
2014-07-13 17:57:48,127 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/50de0376615b4ba292c61304b0661330, entries=941530, sequenceid=1263, filesize=67.1m
2014-07-13 17:57:48,127 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~734.2m/769906880, currentsize=271.1m/284306880 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 15505ms, sequenceid=1263, compaction requested=true
2014-07-13 17:57:48,127 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-13 17:57:48,128 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 708.9m
2014-07-13 17:57:48,638 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:57:48,773 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:57:48,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:48,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299465865 with entries=122, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299468907
2014-07-13 17:57:48,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299374608
2014-07-13 17:57:48,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299377017
2014-07-13 17:57:48,931 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299381694
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299384086
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299386510
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299388717
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299390920
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299393026
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299395627
2014-07-13 17:57:48,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299397494
2014-07-13 17:57:50,427 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:50,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6483 synced till here 6470
2014-07-13 17:57:50,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299468907 with entries=95, filesize=92.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299470427
2014-07-13 17:57:51,827 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/aae1b6e65d594cc299503648b4fb3579 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/aae1b6e65d594cc299503648b4fb3579
2014-07-13 17:57:51,856 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 17:57:51,865 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c161865a87ce4b4fb087f92f5b064913, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c161865a87ce4b4fb087f92f5b064913
2014-07-13 17:57:51,869 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/cad4e31403da47b689269be4e67a5f94, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/cad4e31403da47b689269be4e67a5f94
2014-07-13 17:57:51,875 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c22ee49a23054f56985f65cc1f2dd3e5, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c22ee49a23054f56985f65cc1f2dd3e5
2014-07-13 17:57:51,879 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd985e6755464912a6502d2e1081ca3b, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd985e6755464912a6502d2e1081ca3b
2014-07-13 17:57:51,879 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into aae1b6e65d594cc299503648b4fb3579(size=125.7m), total size for store is 192.6m. This selection was in queue for 0sec, and took 49sec to execute.
2014-07-13 17:57:51,879 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=4, fileSize=150.1m, priority=16, time=253329670018633; duration=49sec
2014-07-13 17:57:51,880 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-13 17:57:51,880 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-13 17:57:51,880 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 210429690 starting at candidate #0 after considering 1 permutations with 1 in ratio
2014-07-13 17:57:51,880 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating major compaction
2014-07-13 17:57:51,881 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:57:51,881 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=200.7m
2014-07-13 17:57:51,881 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9fdf8e45c34b4b469e8ac58fcee352cf, keycount=97704, bloomtype=ROW, size=69.6m, encoding=NONE, seqNum=500, earliestPutTs=1405299306044
2014-07-13 17:57:51,881 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f9ce0fc7bf094da6b6419fc54498967d, keycount=89829, bloomtype=ROW, size=64.0m, encoding=NONE, seqNum=689, earliestPutTs=1405299352476
2014-07-13 17:57:51,882 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/50de0376615b4ba292c61304b0661330, keycount=94153, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=1263, earliestPutTs=1405299376423
2014-07-13 17:57:51,909 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:57:53,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:53,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6556 synced till here 6555
2014-07-13 17:57:53,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299470427 with entries=73, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299473652
2014-07-13 17:57:55,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:56,776 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1191ms
GC pool 'ParNew' had collection(s): count=1 time=1489ms
2014-07-13 17:57:56,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6635 synced till here 6633
2014-07-13 17:57:56,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299473652 with entries=79, filesize=74.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299475063
2014-07-13 17:57:58,469 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:57:58,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6699 synced till here 6693
2014-07-13 17:57:58,597 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299475063 with entries=64, filesize=69.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299478469
2014-07-13 17:58:00,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:00,438 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299478469 with entries=63, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299480397
2014-07-13 17:58:01,288 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:01,735 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6831 synced till here 6821
2014-07-13 17:58:01,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299480397 with entries=69, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299481289
2014-07-13 17:58:03,304 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1711, memsize=339.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/59aa1badd82647ffb6a6176f03c26ae2
2014-07-13 17:58:03,321 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/59aa1badd82647ffb6a6176f03c26ae2 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/59aa1badd82647ffb6a6176f03c26ae2
2014-07-13 17:58:03,345 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/59aa1badd82647ffb6a6176f03c26ae2, entries=1234940, sequenceid=1711, filesize=88.0m
2014-07-13 17:58:03,345 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~714.6m/749331920, currentsize=247.4m/259406720 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 16621ms, sequenceid=1711, compaction requested=true
2014-07-13 17:58:03,346 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:4), split_queue=0, merge_queue=0
2014-07-13 17:58:03,346 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 487.6m
2014-07-13 17:58:03,806 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:03,831 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6901 synced till here 6894
2014-07-13 17:58:03,885 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:58:03,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299481289 with entries=70, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299483806
2014-07-13 17:58:03,971 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:05,134 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1716, memsize=339.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/ac093b773c4c4a7ca135c560f4086d68
2014-07-13 17:58:05,157 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/ac093b773c4c4a7ca135c560f4086d68 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ac093b773c4c4a7ca135c560f4086d68
2014-07-13 17:58:05,175 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ac093b773c4c4a7ca135c560f4086d68, entries=1237630, sequenceid=1716, filesize=88.2m
2014-07-13 17:58:05,175 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~708.9m/743376640, currentsize=267.2m/280223520 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 17047ms, sequenceid=1716, compaction requested=true
2014-07-13 17:58:05,175 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:5), split_queue=0, merge_queue=0
2014-07-13 17:58:05,176 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 522.8m
2014-07-13 17:58:05,465 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:05,773 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:05,799 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299483806 with entries=99, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299485773
2014-07-13 17:58:05,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299399360
2014-07-13 17:58:05,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299401939
2014-07-13 17:58:05,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299404627
2014-07-13 17:58:05,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299407142
2014-07-13 17:58:05,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299409168
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299412022
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299415773
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299420728
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299423053
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299424927
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299427224
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299429495
2014-07-13 17:58:05,800 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299431896
2014-07-13 17:58:06,463 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:58:09,366 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:09,388 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7071 synced till here 7069
2014-07-13 17:58:09,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299485773 with entries=71, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299489366
2014-07-13 17:58:10,409 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.28 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=17829, hits=1174, hitRatio=6.58%, , cachingAccesses=1177, cachingHits=1174, cachingHitsRatio=99.74%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-13 17:58:10,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:10,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7153 synced till here 7149
2014-07-13 17:58:10,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299489366 with entries=82, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299490705
2014-07-13 17:58:12,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:13,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299490705 with entries=116, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299492151
2014-07-13 17:58:16,465 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:16,792 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7330 synced till here 7328
2014-07-13 17:58:16,830 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299492151 with entries=61, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299496465
2014-07-13 17:58:17,592 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:18,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7414 synced till here 7410
2014-07-13 17:58:18,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299496465 with entries=84, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299497593
2014-07-13 17:58:19,308 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1610, memsize=451.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/54fca91ea29b476c922b829526bf6026
2014-07-13 17:58:19,326 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/54fca91ea29b476c922b829526bf6026 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/54fca91ea29b476c922b829526bf6026
2014-07-13 17:58:19,339 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/54fca91ea29b476c922b829526bf6026, entries=1645210, sequenceid=1610, filesize=117.2m
2014-07-13 17:58:19,339 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~487.6m/511277040, currentsize=198.1m/207705200 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 15993ms, sequenceid=1610, compaction requested=true
2014-07-13 17:58:19,339 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-13 17:58:19,339 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 451.7m
2014-07-13 17:58:19,627 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:21,369 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1655, memsize=483.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/19b433e8cd30498c99686393f2033e36
2014-07-13 17:58:21,384 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/19b433e8cd30498c99686393f2033e36 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/19b433e8cd30498c99686393f2033e36
2014-07-13 17:58:21,397 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/19b433e8cd30498c99686393f2033e36, entries=1759740, sequenceid=1655, filesize=125.3m
2014-07-13 17:58:21,397 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~522.8m/548202480, currentsize=173.1m/181547040 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 16222ms, sequenceid=1655, compaction requested=false
2014-07-13 17:58:21,398 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 448.6m
2014-07-13 17:58:21,645 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:21,876 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:22,221 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299497593 with entries=108, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299501877
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299451677
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299453662
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299455396
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299457363
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299458618
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299460065
2014-07-13 17:58:22,221 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299461450
2014-07-13 17:58:25,458 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/3400b233c20a4b45ad1debf5cd2f566a as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3400b233c20a4b45ad1debf5cd2f566a
2014-07-13 17:58:25,583 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 17:58:25,594 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9fdf8e45c34b4b469e8ac58fcee352cf, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9fdf8e45c34b4b469e8ac58fcee352cf
2014-07-13 17:58:25,597 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f9ce0fc7bf094da6b6419fc54498967d, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f9ce0fc7bf094da6b6419fc54498967d
2014-07-13 17:58:25,607 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:58:25,609 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/50de0376615b4ba292c61304b0661330, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/50de0376615b4ba292c61304b0661330
2014-07-13 17:58:25,610 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into 3400b233c20a4b45ad1debf5cd2f566a(size=188.9m), total size for store is 314.2m. This selection was in queue for 0sec, and took 33sec to execute.
2014-07-13 17:58:25,610 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=3, fileSize=200.7m, priority=17, time=253379307762353; duration=33sec
2014-07-13 17:58:25,610 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-13 17:58:25,610 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-13 17:58:25,610 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 276824986 starting at candidate #0 after considering 3 permutations with 3 in ratio
2014-07-13 17:58:25,611 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating major compaction
2014-07-13 17:58:25,611 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:58:25,611 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=264.0m
2014-07-13 17:58:25,611 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0aabb33c579f4454a537f68487f49da9, keycount=84197, bloomtype=ROW, size=60.0m, encoding=NONE, seqNum=634, earliestPutTs=1405299288017
2014-07-13 17:58:25,612 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/88386aa496ec40709f65381fd139233c, keycount=54860, bloomtype=ROW, size=39.1m, encoding=NONE, seqNum=824, earliestPutTs=1405299337829
2014-07-13 17:58:25,612 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8b27f57eb1dc4e7892954eda97536242, keycount=107920, bloomtype=ROW, size=76.9m, encoding=NONE, seqNum=1198, earliestPutTs=1405299363212
2014-07-13 17:58:25,612 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/59aa1badd82647ffb6a6176f03c26ae2, keycount=123494, bloomtype=ROW, size=88.0m, encoding=NONE, seqNum=1711, earliestPutTs=1405299400254
2014-07-13 17:58:25,636 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:25,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7599 synced till here 7593
2014-07-13 17:58:26,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299501877 with entries=77, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299505636
2014-07-13 17:58:26,660 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:27,320 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:27,350 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7669 synced till here 7666
2014-07-13 17:58:27,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299505636 with entries=70, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299507321
2014-07-13 17:58:28,482 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:58:32,386 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1450ms
GC pool 'ParNew' had collection(s): count=1 time=1680ms
2014-07-13 17:58:32,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:32,515 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7746 synced till here 7737
2014-07-13 17:58:32,600 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299507321 with entries=77, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299512471
2014-07-13 17:58:34,929 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1042ms
GC pool 'ParNew' had collection(s): count=1 time=1383ms
2014-07-13 17:58:34,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:35,011 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7818 synced till here 7811
2014-07-13 17:58:35,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299512471 with entries=72, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299514995
2014-07-13 17:58:36,765 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:36,789 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7892 synced till here 7874
2014-07-13 17:58:36,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299514995 with entries=74, filesize=73.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299516766
2014-07-13 17:58:37,674 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1955, memsize=403.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/c1ce9acdcd794d22b3f6ebecec4a602e
2014-07-13 17:58:37,694 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/c1ce9acdcd794d22b3f6ebecec4a602e as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c1ce9acdcd794d22b3f6ebecec4a602e
2014-07-13 17:58:37,710 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c1ce9acdcd794d22b3f6ebecec4a602e, entries=1469760, sequenceid=1955, filesize=104.6m
2014-07-13 17:58:37,711 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~451.7m/473641760, currentsize=192.7m/202107920 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 18371ms, sequenceid=1955, compaction requested=false
2014-07-13 17:58:37,711 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 383.4m
2014-07-13 17:58:37,943 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:39,752 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1963, memsize=400.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/894f031d3620471db381dd578cdcbe79
2014-07-13 17:58:39,771 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/894f031d3620471db381dd578cdcbe79 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/894f031d3620471db381dd578cdcbe79
2014-07-13 17:58:39,784 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/894f031d3620471db381dd578cdcbe79, entries=1459710, sequenceid=1963, filesize=103.9m
2014-07-13 17:58:39,785 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~448.6m/470396080, currentsize=186.2m/195275360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 18387ms, sequenceid=1963, compaction requested=true
2014-07-13 17:58:39,785 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:6), split_queue=0, merge_queue=0
2014-07-13 17:58:39,786 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 348.8m
2014-07-13 17:58:40,124 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:58:45,726 WARN  [RpcServer.reader=8,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: count of bytes read: 0
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:251)
	at sun.nio.ch.IOUtil.read(IOUtil.java:224)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:254)
	at org.apache.hadoop.hbase.ipc.RpcServer.channelRead(RpcServer.java:2229)
	at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1415)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener.doRead(RpcServer.java:790)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.doRunLoop(RpcServer.java:581)
	at org.apache.hadoop.hbase.ipc.RpcServer$Listener$Reader.run(RpcServer.java:556)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)
2014-07-13 17:58:48,855 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1907, memsize=359.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c37f4b732d4f4a3f866263b0cc16e918
2014-07-13 17:58:48,866 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c37f4b732d4f4a3f866263b0cc16e918 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c37f4b732d4f4a3f866263b0cc16e918
2014-07-13 17:58:48,875 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c37f4b732d4f4a3f866263b0cc16e918, entries=1308240, sequenceid=1907, filesize=93.1m
2014-07-13 17:58:48,875 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~383.4m/402032960, currentsize=0.0/0 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 11164ms, sequenceid=1907, compaction requested=true
2014-07-13 17:58:48,876 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:7), split_queue=0, merge_queue=0
2014-07-13 17:58:50,074 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1915, memsize=324.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/3c15be3a752e4888a0e031b637ac39b5
2014-07-13 17:58:50,090 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/3c15be3a752e4888a0e031b637ac39b5 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3c15be3a752e4888a0e031b637ac39b5
2014-07-13 17:58:50,098 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3c15be3a752e4888a0e031b637ac39b5, entries=1183110, sequenceid=1915, filesize=84.2m
2014-07-13 17:58:50,099 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~348.8m/365758880, currentsize=0.0/0 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10313ms, sequenceid=1915, compaction requested=true
2014-07-13 17:58:50,099 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-13 17:58:58,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:58:58,587 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7970 synced till here 7968
2014-07-13 17:58:58,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299516766 with entries=78, filesize=73.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299538449
2014-07-13 17:58:58,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299465865
2014-07-13 17:58:58,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299468907
2014-07-13 17:58:58,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299470427
2014-07-13 17:58:58,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299473652
2014-07-13 17:58:58,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299475063
2014-07-13 17:58:58,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299478469
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299480397
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299481289
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299483806
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299485773
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299489366
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299490705
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299492151
2014-07-13 17:58:58,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299496465
2014-07-13 17:59:00,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:00,972 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:59:00,972 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 257.6m
2014-07-13 17:59:02,568 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1160ms
GC pool 'ParNew' had collection(s): count=1 time=1374ms
2014-07-13 17:59:02,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8079 synced till here 8053
2014-07-13 17:59:02,962 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299538449 with entries=109, filesize=92.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299540971
2014-07-13 17:59:03,529 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:59:03,531 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 257.8m
2014-07-13 17:59:03,769 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:05,168 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:05,209 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8188 synced till here 8160
2014-07-13 17:59:05,368 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:05,763 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299540971 with entries=109, filesize=91.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299545168
2014-07-13 17:59:07,732 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:07,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8296 synced till here 8262
2014-07-13 17:59:08,108 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299545168 with entries=108, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299547733
2014-07-13 17:59:09,310 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1043ms
GC pool 'ParNew' had collection(s): count=2 time=1069ms
2014-07-13 17:59:10,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:11,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8411 synced till here 8379
2014-07-13 17:59:11,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299547733 with entries=115, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299550214
2014-07-13 17:59:14,145 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:14,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8521 synced till here 8491
2014-07-13 17:59:14,468 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299550214 with entries=110, filesize=102.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299554145
2014-07-13 17:59:16,419 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:16,654 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8645 synced till here 8596
2014-07-13 17:59:17,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299554145 with entries=124, filesize=102.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299556420
2014-07-13 17:59:18,433 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:59:19,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:19,568 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:59:20,418 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8762 synced till here 8737
2014-07-13 17:59:20,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299556420 with entries=117, filesize=99.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299559567
2014-07-13 17:59:20,638 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/8cd775b36d084cd78fe66883874f6b43 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8cd775b36d084cd78fe66883874f6b43
2014-07-13 17:59:20,991 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2116, memsize=208.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/4dc86f1555544833a256289cf94ef674
2014-07-13 17:59:21,004 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/4dc86f1555544833a256289cf94ef674 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4dc86f1555544833a256289cf94ef674
2014-07-13 17:59:21,046 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 17:59:21,071 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0aabb33c579f4454a537f68487f49da9, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0aabb33c579f4454a537f68487f49da9
2014-07-13 17:59:21,088 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/88386aa496ec40709f65381fd139233c, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/88386aa496ec40709f65381fd139233c
2014-07-13 17:59:21,104 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8b27f57eb1dc4e7892954eda97536242, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8b27f57eb1dc4e7892954eda97536242
2014-07-13 17:59:21,112 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/59aa1badd82647ffb6a6176f03c26ae2, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/59aa1badd82647ffb6a6176f03c26ae2
2014-07-13 17:59:21,113 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 4 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into 8cd775b36d084cd78fe66883874f6b43(size=241.5m), total size for store is 346.1m. This selection was in queue for 0sec, and took 55sec to execute.
2014-07-13 17:59:21,113 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=4, fileSize=264.0m, priority=16, time=253413037944693; duration=55sec
2014-07-13 17:59:21,113 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-13 17:59:21,113 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-13 17:59:21,114 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 384029775 starting at candidate #0 after considering 6 permutations with 6 in ratio
2014-07-13 17:59:21,114 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating major compaction
2014-07-13 17:59:21,114 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:59:21,114 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=366.2m
2014-07-13 17:59:21,114 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f3d343b4305e45988041e90352f3d91e, keycount=84377, bloomtype=ROW, size=60.1m, encoding=NONE, seqNum=643, earliestPutTs=1405299288490
2014-07-13 17:59:21,114 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/33cd95040426474c9f081d83377a61fa, keycount=52249, bloomtype=ROW, size=37.2m, encoding=NONE, seqNum=840, earliestPutTs=1405299339464
2014-07-13 17:59:21,114 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57a14f6ea8c84fcf83bb5f81f7a75f63, keycount=107883, bloomtype=ROW, size=76.9m, encoding=NONE, seqNum=1202, earliestPutTs=1405299364653
2014-07-13 17:59:21,115 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ac093b773c4c4a7ca135c560f4086d68, keycount=123763, bloomtype=ROW, size=88.2m, encoding=NONE, seqNum=1716, earliestPutTs=1405299400940
2014-07-13 17:59:21,115 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/894f031d3620471db381dd578cdcbe79, keycount=145971, bloomtype=ROW, size=103.9m, encoding=NONE, seqNum=1963, earliestPutTs=1405299468616
2014-07-13 17:59:21,144 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4dc86f1555544833a256289cf94ef674, entries=759790, sequenceid=2116, filesize=54.2m
2014-07-13 17:59:21,144 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~277.0m/290493520, currentsize=331.9m/348022320 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 20172ms, sequenceid=2116, compaction requested=true
2014-07-13 17:59:21,144 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:8), split_queue=0, merge_queue=0
2014-07-13 17:59:21,145 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 298.1m
2014-07-13 17:59:21,177 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2118, memsize=200.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/300be6153c804026a9ab81d87b6057c4
2014-07-13 17:59:21,191 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/300be6153c804026a9ab81d87b6057c4 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/300be6153c804026a9ab81d87b6057c4
2014-07-13 17:59:21,216 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/300be6153c804026a9ab81d87b6057c4, entries=728590, sequenceid=2118, filesize=51.9m
2014-07-13 17:59:21,216 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~270.7m/283901520, currentsize=317.7m/333128560 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 17685ms, sequenceid=2118, compaction requested=false
2014-07-13 17:59:21,216 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 294.8m
2014-07-13 17:59:21,234 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:21,268 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:59:21,334 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:21,354 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:59:21,378 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:21,564 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:22,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8853 synced till here 8851
2014-07-13 17:59:22,563 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299559567 with entries=91, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299561378
2014-07-13 17:59:22,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299497593
2014-07-13 17:59:22,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299501877
2014-07-13 17:59:22,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299505636
2014-07-13 17:59:22,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299507321
2014-07-13 17:59:22,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299512471
2014-07-13 17:59:22,563 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299514995
2014-07-13 17:59:23,426 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:23,452 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8943 synced till here 8940
2014-07-13 17:59:24,006 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299561378 with entries=90, filesize=68.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299563426
2014-07-13 17:59:24,996 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:25,523 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9039 synced till here 9031
2014-07-13 17:59:25,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299563426 with entries=96, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299565115
2014-07-13 17:59:25,861 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2098, memsize=73.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/054a37e8697b4a9a8ad65205b0318719
2014-07-13 17:59:25,873 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/054a37e8697b4a9a8ad65205b0318719 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/054a37e8697b4a9a8ad65205b0318719
2014-07-13 17:59:26,071 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/054a37e8697b4a9a8ad65205b0318719, entries=266810, sequenceid=2098, filesize=19.0m
2014-07-13 17:59:26,072 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~298.1m/312588960, currentsize=89.5m/93851280 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 4926ms, sequenceid=2098, compaction requested=true
2014-07-13 17:59:26,072 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:9), split_queue=0, merge_queue=0
2014-07-13 17:59:26,072 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 427.5m
2014-07-13 17:59:26,152 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2090, memsize=73.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/34b3e42db5cb4ab8a416e6d30ab52ced
2014-07-13 17:59:26,164 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/34b3e42db5cb4ab8a416e6d30ab52ced as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/34b3e42db5cb4ab8a416e6d30ab52ced
2014-07-13 17:59:26,181 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/34b3e42db5cb4ab8a416e6d30ab52ced, entries=267910, sequenceid=2090, filesize=19.1m
2014-07-13 17:59:26,182 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~297.3m/311722720, currentsize=88.9m/93169120 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 4966ms, sequenceid=2090, compaction requested=true
2014-07-13 17:59:26,183 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:10), split_queue=0, merge_queue=0
2014-07-13 17:59:26,184 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 428.3m
2014-07-13 17:59:26,351 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:26,550 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:26,553 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:26,569 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9112 synced till here 9111
2014-07-13 17:59:26,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299565115 with entries=73, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299566550
2014-07-13 17:59:26,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299516766
2014-07-13 17:59:26,582 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299538449
2014-07-13 17:59:27,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:27,691 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9203 synced till here 9190
2014-07-13 17:59:27,897 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299566550 with entries=91, filesize=72.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299567573
2014-07-13 17:59:29,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:29,509 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9276 synced till here 9273
2014-07-13 17:59:29,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299567573 with entries=73, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299569481
2014-07-13 17:59:30,745 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:31,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9359 synced till here 9354
2014-07-13 17:59:31,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299569481 with entries=83, filesize=75.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299570745
2014-07-13 17:59:31,793 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2406, memsize=113.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/2dc2f4c8e5534d8dbc296c7f6567333d
2014-07-13 17:59:31,813 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/2dc2f4c8e5534d8dbc296c7f6567333d as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2dc2f4c8e5534d8dbc296c7f6567333d
2014-07-13 17:59:31,833 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2dc2f4c8e5534d8dbc296c7f6567333d, entries=414640, sequenceid=2406, filesize=29.5m
2014-07-13 17:59:31,834 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~427.5m/448247840, currentsize=112.3m/117713520 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 5761ms, sequenceid=2406, compaction requested=false
2014-07-13 17:59:32,158 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2409, memsize=120.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/c15dc97ee7874bb483f7affb46d221e6
2014-07-13 17:59:32,172 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/c15dc97ee7874bb483f7affb46d221e6 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c15dc97ee7874bb483f7affb46d221e6
2014-07-13 17:59:32,173 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:33,463 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c15dc97ee7874bb483f7affb46d221e6, entries=438010, sequenceid=2409, filesize=31.2m
2014-07-13 17:59:33,463 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~432.8m/453819200, currentsize=133.7m/140157360 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 7279ms, sequenceid=2409, compaction requested=true
2014-07-13 17:59:33,464 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:11), split_queue=0, merge_queue=0
2014-07-13 17:59:33,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9453 synced till here 9450
2014-07-13 17:59:33,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299570745 with entries=94, filesize=79.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299572173
2014-07-13 17:59:33,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299540971
2014-07-13 17:59:33,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299545168
2014-07-13 17:59:33,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299547733
2014-07-13 17:59:33,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299550214
2014-07-13 17:59:33,498 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299554145
2014-07-13 17:59:33,498 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299556420
2014-07-13 17:59:34,076 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:59:34,076 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 258.2m
2014-07-13 17:59:34,208 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:59:34,208 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.2m
2014-07-13 17:59:34,325 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:34,485 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:34,596 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:35,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299572173 with entries=68, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299574596
2014-07-13 17:59:36,422 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:37,080 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9617 synced till here 9614
2014-07-13 17:59:37,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299574596 with entries=96, filesize=84.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299576423
2014-07-13 17:59:38,852 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:38,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9699 synced till here 9692
2014-07-13 17:59:38,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299576423 with entries=82, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299578852
2014-07-13 17:59:39,651 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 17:59:40,145 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:40,157 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 17:59:40,171 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299578852 with entries=66, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299580145
2014-07-13 17:59:41,839 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:41,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9843 synced till here 9833
2014-07-13 17:59:42,058 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299580145 with entries=78, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299581840
2014-07-13 17:59:43,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:44,085 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9917 synced till here 9911
2014-07-13 17:59:44,154 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299581840 with entries=74, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299583751
2014-07-13 17:59:44,746 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2270, memsize=241.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/c1cb7fb29cf84641902ec27afd9cb91e
2014-07-13 17:59:44,761 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/c1cb7fb29cf84641902ec27afd9cb91e as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c1cb7fb29cf84641902ec27afd9cb91e
2014-07-13 17:59:44,773 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c1cb7fb29cf84641902ec27afd9cb91e, entries=877350, sequenceid=2270, filesize=62.5m
2014-07-13 17:59:44,773 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.2m/277008880, currentsize=198.5m/208159200 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10697ms, sequenceid=2270, compaction requested=true
2014-07-13 17:59:44,773 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:12), split_queue=0, merge_queue=0
2014-07-13 17:59:44,774 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 340.4m
2014-07-13 17:59:45,418 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2261, memsize=242.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/f630bf7c6614433998633ea6d4fdaa68
2014-07-13 17:59:45,419 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:45,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9979 synced till here 9977
2014-07-13 17:59:45,434 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/f630bf7c6614433998633ea6d4fdaa68 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f630bf7c6614433998633ea6d4fdaa68
2014-07-13 17:59:45,452 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f630bf7c6614433998633ea6d4fdaa68, entries=883440, sequenceid=2261, filesize=62.9m
2014-07-13 17:59:45,452 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~266.4m/279338240, currentsize=200.7m/210417840 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 11244ms, sequenceid=2261, compaction requested=true
2014-07-13 17:59:45,452 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:13), split_queue=0, merge_queue=0
2014-07-13 17:59:45,452 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 343.6m
2014-07-13 17:59:45,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299583751 with entries=62, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299585419
2014-07-13 17:59:45,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299559567
2014-07-13 17:59:45,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299561378
2014-07-13 17:59:45,458 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299563426
2014-07-13 17:59:45,674 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:45,683 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:47,149 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:47,379 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10053 synced till here 10051
2014-07-13 17:59:47,417 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299585419 with entries=74, filesize=68.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299587150
2014-07-13 17:59:48,124 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 17:59:48,677 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:48,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299587150 with entries=73, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299588677
2014-07-13 17:59:48,779 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 17:59:49,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:49,918 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10189 synced till here 10186
2014-07-13 17:59:49,968 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299588677 with entries=63, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299589880
2014-07-13 17:59:51,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:51,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10272 synced till here 10263
2014-07-13 17:59:52,060 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299589880 with entries=83, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299591623
2014-07-13 17:59:55,262 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:55,340 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299591623 with entries=76, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299595286
2014-07-13 17:59:56,689 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2629, memsize=310.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/afc384a8a32047cab9ab4766064ebd38
2014-07-13 17:59:56,701 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2625, memsize=311.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/65815424c53c4594b604ce87911d47f0
2014-07-13 17:59:56,705 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/afc384a8a32047cab9ab4766064ebd38 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/afc384a8a32047cab9ab4766064ebd38
2014-07-13 17:59:56,710 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:56,712 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/65815424c53c4594b604ce87911d47f0 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/65815424c53c4594b604ce87911d47f0
2014-07-13 17:59:56,715 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/afc384a8a32047cab9ab4766064ebd38, entries=1130890, sequenceid=2629, filesize=80.5m
2014-07-13 17:59:56,715 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~343.6m/360304240, currentsize=174.8m/183241280 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 11263ms, sequenceid=2629, compaction requested=true
2014-07-13 17:59:56,715 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:14), split_queue=0, merge_queue=0
2014-07-13 17:59:56,715 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 396.1m
2014-07-13 17:59:56,737 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/65815424c53c4594b604ce87911d47f0, entries=1134470, sequenceid=2625, filesize=80.8m
2014-07-13 17:59:56,737 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~345.1m/361891360, currentsize=173.7m/182131920 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 11963ms, sequenceid=2625, compaction requested=true
2014-07-13 17:59:56,737 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:15), split_queue=0, merge_queue=0
2014-07-13 17:59:56,738 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 393.0m
2014-07-13 17:59:56,768 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10421 synced till here 10414
2014-07-13 17:59:56,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299595286 with entries=73, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299596710
2014-07-13 17:59:56,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299565115
2014-07-13 17:59:56,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299566550
2014-07-13 17:59:56,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299567573
2014-07-13 17:59:56,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299569481
2014-07-13 17:59:56,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299570745
2014-07-13 17:59:56,987 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:57,045 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 17:59:57,917 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 17:59:58,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299596710 with entries=81, filesize=71.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299597917
2014-07-13 18:00:00,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:00,809 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10574 synced till here 10571
2014-07-13 18:00:01,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299597917 with entries=72, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299600792
2014-07-13 18:00:02,328 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:00:02,331 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:00:02,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:02,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10658 synced till here 10646
2014-07-13 18:00:02,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299600792 with entries=84, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299602520
2014-07-13 18:00:04,474 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:05,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10742 synced till here 10735
2014-07-13 18:00:05,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299602520 with entries=84, filesize=74.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299604474
2014-07-13 18:00:06,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:06,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10843 synced till here 10823
2014-07-13 18:00:07,041 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299604474 with entries=101, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299606894
2014-07-13 18:00:08,784 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:08,850 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10939 synced till here 10909
2014-07-13 18:00:09,060 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299606894 with entries=96, filesize=83.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299608784
2014-07-13 18:00:10,863 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:10,908 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11060 synced till here 11022
2014-07-13 18:00:11,136 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299608784 with entries=121, filesize=92.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299610863
2014-07-13 18:00:12,686 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:13,106 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11201 synced till here 11185
2014-07-13 18:00:13,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299610863 with entries=141, filesize=106.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299612687
2014-07-13 18:00:14,546 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2494, memsize=338.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1195eb6e7bcd4ecf880eaf004734bce4
2014-07-13 18:00:14,575 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2505, memsize=339.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/4deff2d1f5214f9e8db31a405b544235
2014-07-13 18:00:14,595 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/4deff2d1f5214f9e8db31a405b544235 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4deff2d1f5214f9e8db31a405b544235
2014-07-13 18:00:14,597 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1195eb6e7bcd4ecf880eaf004734bce4 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1195eb6e7bcd4ecf880eaf004734bce4
2014-07-13 18:00:14,607 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4deff2d1f5214f9e8db31a405b544235, entries=1237310, sequenceid=2505, filesize=88.2m
2014-07-13 18:00:14,608 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~397.7m/416973600, currentsize=315.5m/330806640 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 17893ms, sequenceid=2505, compaction requested=true
2014-07-13 18:00:14,608 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:16), split_queue=0, merge_queue=0
2014-07-13 18:00:14,608 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 484.4m
2014-07-13 18:00:14,613 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1195eb6e7bcd4ecf880eaf004734bce4, entries=1232160, sequenceid=2494, filesize=87.8m
2014-07-13 18:00:14,613 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~393.0m/412129760, currentsize=305.5m/320289120 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 17875ms, sequenceid=2494, compaction requested=true
2014-07-13 18:00:14,613 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:17), split_queue=0, merge_queue=0
2014-07-13 18:00:14,614 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 490.4m
2014-07-13 18:00:14,698 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:00:14,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:14,814 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:00:14,837 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11281 synced till here 11268
2014-07-13 18:00:15,931 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:15,976 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:16,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299612687 with entries=80, filesize=71.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299614814
2014-07-13 18:00:16,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299572173
2014-07-13 18:00:16,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299574596
2014-07-13 18:00:16,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299576423
2014-07-13 18:00:16,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299578852
2014-07-13 18:00:16,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299580145
2014-07-13 18:00:16,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299581840
2014-07-13 18:00:17,746 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:17,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11386 synced till here 11381
2014-07-13 18:00:17,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299614814 with entries=105, filesize=79.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299617747
2014-07-13 18:00:18,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:18,764 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11462 synced till here 11455
2014-07-13 18:00:18,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299617747 with entries=76, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299618739
2014-07-13 18:00:20,249 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:20,298 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11529 synced till here 11526
2014-07-13 18:00:20,985 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299618739 with entries=67, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299620249
2014-07-13 18:00:21,662 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:21,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11595 synced till here 11590
2014-07-13 18:00:21,728 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299620249 with entries=66, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299621662
2014-07-13 18:00:22,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:22,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11682 synced till here 11674
2014-07-13 18:00:22,993 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299621662 with entries=87, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299622908
2014-07-13 18:00:24,209 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:24,427 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11786 synced till here 11779
2014-07-13 18:00:24,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299622908 with entries=104, filesize=80.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299624210
2014-07-13 18:00:26,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:26,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11872 synced till here 11870
2014-07-13 18:00:27,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299624210 with entries=86, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299626407
2014-07-13 18:00:27,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:28,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11973 synced till here 11951
2014-07-13 18:00:28,839 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299626407 with entries=101, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299627769
2014-07-13 18:00:30,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:30,287 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12088 synced till here 12059
2014-07-13 18:00:30,527 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299627769 with entries=115, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299630271
2014-07-13 18:00:32,511 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:32,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12185 synced till here 12174
2014-07-13 18:00:32,631 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299630271 with entries=97, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299632511
2014-07-13 18:00:32,769 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2928, memsize=327.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c48023fecb4745c38d34fa8a87029118
2014-07-13 18:00:32,792 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c48023fecb4745c38d34fa8a87029118 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c48023fecb4745c38d34fa8a87029118
2014-07-13 18:00:32,816 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c48023fecb4745c38d34fa8a87029118, entries=1191120, sequenceid=2928, filesize=84.8m
2014-07-13 18:00:32,816 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~496.4m/520463920, currentsize=348.6m/365577280 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 18208ms, sequenceid=2928, compaction requested=true
2014-07-13 18:00:32,817 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:18), split_queue=0, merge_queue=0
2014-07-13 18:00:32,817 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 690.2m
2014-07-13 18:00:32,841 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:00:33,776 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2937, memsize=337.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ecf86536d7754f4da119ed413d4cdbc8
2014-07-13 18:00:33,789 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ecf86536d7754f4da119ed413d4cdbc8 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ecf86536d7754f4da119ed413d4cdbc8
2014-07-13 18:00:33,801 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ecf86536d7754f4da119ed413d4cdbc8, entries=1227860, sequenceid=2937, filesize=87.4m
2014-07-13 18:00:33,801 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~507.1m/531743120, currentsize=349.3m/366229280 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 19187ms, sequenceid=2937, compaction requested=true
2014-07-13 18:00:33,801 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-13 18:00:33,802 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 706.6m
2014-07-13 18:00:33,902 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:33,912 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/bd7698a58982419da84f577379cbe7c3 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/bd7698a58982419da84f577379cbe7c3
2014-07-13 18:00:33,927 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:00:33,936 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f3d343b4305e45988041e90352f3d91e, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f3d343b4305e45988041e90352f3d91e
2014-07-13 18:00:33,938 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/33cd95040426474c9f081d83377a61fa, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/33cd95040426474c9f081d83377a61fa
2014-07-13 18:00:33,941 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57a14f6ea8c84fcf83bb5f81f7a75f63, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57a14f6ea8c84fcf83bb5f81f7a75f63
2014-07-13 18:00:33,944 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ac093b773c4c4a7ca135c560f4086d68, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ac093b773c4c4a7ca135c560f4086d68
2014-07-13 18:00:33,947 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/894f031d3620471db381dd578cdcbe79, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/894f031d3620471db381dd578cdcbe79
2014-07-13 18:00:33,947 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 5 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into bd7698a58982419da84f577379cbe7c3(size=347.2m), total size for store is 594.3m. This selection was in queue for 0sec, and took 1mins, 12sec to execute.
2014-07-13 18:00:33,947 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=5, fileSize=366.2m, priority=15, time=253468541024270; duration=1mins, 12sec
2014-07-13 18:00:33,948 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-13 18:00:33,948 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-13 18:00:33,948 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 7 files of size 600598285 starting at candidate #0 after considering 15 permutations with 15 in ratio
2014-07-13 18:00:33,948 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating major compaction
2014-07-13 18:00:33,949 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:00:33,949 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 7 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=572.8m
2014-07-13 18:00:33,949 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/aae1b6e65d594cc299503648b4fb3579, keycount=176399, bloomtype=ROW, size=125.7m, encoding=NONE, seqNum=693, earliestPutTs=1405299306402
2014-07-13 18:00:33,949 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8c353e8f601947c6abc5fcab4ee4d130, keycount=94033, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=1257, earliestPutTs=1405299377208
2014-07-13 18:00:33,949 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/54fca91ea29b476c922b829526bf6026, keycount=164521, bloomtype=ROW, size=117.2m, encoding=NONE, seqNum=1610, earliestPutTs=1405299453248
2014-07-13 18:00:33,949 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c37f4b732d4f4a3f866263b0cc16e918, keycount=130824, bloomtype=ROW, size=93.1m, encoding=NONE, seqNum=1907, earliestPutTs=1405299483765
2014-07-13 18:00:33,949 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/34b3e42db5cb4ab8a416e6d30ab52ced, keycount=26791, bloomtype=ROW, size=19.1m, encoding=NONE, seqNum=2090, earliestPutTs=1405299537554
2014-07-13 18:00:33,949 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f630bf7c6614433998633ea6d4fdaa68, keycount=88344, bloomtype=ROW, size=62.9m, encoding=NONE, seqNum=2261, earliestPutTs=1405299561324
2014-07-13 18:00:33,950 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1195eb6e7bcd4ecf880eaf004734bce4, keycount=123216, bloomtype=ROW, size=87.8m, encoding=NONE, seqNum=2494, earliestPutTs=1405299574685
2014-07-13 18:00:34,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:34,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299632511 with entries=80, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299634078
2014-07-13 18:00:34,124 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299583751
2014-07-13 18:00:34,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299585419
2014-07-13 18:00:34,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299587150
2014-07-13 18:00:34,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299588677
2014-07-13 18:00:34,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299589880
2014-07-13 18:00:34,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299591623
2014-07-13 18:00:34,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299595286
2014-07-13 18:00:34,202 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:00:34,515 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:34,691 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:35,472 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:35,491 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12341 synced till here 12335
2014-07-13 18:00:35,551 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299634078 with entries=76, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299635472
2014-07-13 18:00:38,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:38,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12430 synced till here 12427
2014-07-13 18:00:38,305 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299635472 with entries=89, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299638131
2014-07-13 18:00:39,468 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:39,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12497 synced till here 12496
2014-07-13 18:00:39,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299638131 with entries=67, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299639468
2014-07-13 18:00:40,715 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:40,743 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12563 synced till here 12554
2014-07-13 18:00:40,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299639468 with entries=66, filesize=68.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299640716
2014-07-13 18:00:42,033 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:42,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12646 synced till here 12644
2014-07-13 18:00:42,099 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299640716 with entries=83, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299642033
2014-07-13 18:00:44,470 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:44,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299642033 with entries=78, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299644471
2014-07-13 18:00:46,291 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:46,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299644471 with entries=116, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299646291
2014-07-13 18:00:47,039 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2940, memsize=328.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/140f2419b9764680a69d8c5bf3a104f8
2014-07-13 18:00:47,059 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/140f2419b9764680a69d8c5bf3a104f8 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/140f2419b9764680a69d8c5bf3a104f8
2014-07-13 18:00:47,080 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/140f2419b9764680a69d8c5bf3a104f8, entries=1196850, sequenceid=2940, filesize=85.2m
2014-07-13 18:00:47,080 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~693.2m/726899520, currentsize=249.8m/261977040 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 14263ms, sequenceid=2940, compaction requested=true
2014-07-13 18:00:47,081 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:19), split_queue=0, merge_queue=0
2014-07-13 18:00:47,081 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 563.7m
2014-07-13 18:00:47,474 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:47,775 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2944, memsize=331.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/a77709cdb8134ea497811aee64ba02fc
2014-07-13 18:00:47,785 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/a77709cdb8134ea497811aee64ba02fc as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/a77709cdb8134ea497811aee64ba02fc
2014-07-13 18:00:47,797 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/a77709cdb8134ea497811aee64ba02fc, entries=1206990, sequenceid=2944, filesize=85.9m
2014-07-13 18:00:47,798 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~710.0m/744510640, currentsize=232.5m/243834560 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 13996ms, sequenceid=2944, compaction requested=false
2014-07-13 18:00:47,798 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 547.2m
2014-07-13 18:00:48,360 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:00:48,437 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:00:48,965 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:00:49,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:50,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 12910 synced till here 12905
2014-07-13 18:00:50,411 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299646291 with entries=70, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299649971
2014-07-13 18:00:50,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299596710
2014-07-13 18:00:50,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299597917
2014-07-13 18:00:50,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299600792
2014-07-13 18:00:50,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299602520
2014-07-13 18:00:50,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299604474
2014-07-13 18:00:50,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299606894
2014-07-13 18:00:50,414 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299608784
2014-07-13 18:00:50,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299610863
2014-07-13 18:00:51,258 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:51,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299649971 with entries=96, filesize=96.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299651532
2014-07-13 18:00:53,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:53,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13081 synced till here 13077
2014-07-13 18:00:53,453 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299651532 with entries=75, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299653274
2014-07-13 18:00:54,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:54,617 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13187 synced till here 13185
2014-07-13 18:00:54,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299653274 with entries=106, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299654594
2014-07-13 18:00:57,423 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:57,566 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13257 synced till here 13256
2014-07-13 18:00:57,712 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299654594 with entries=70, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299657423
2014-07-13 18:00:59,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:00:59,114 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13331 synced till here 13327
2014-07-13 18:01:00,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299657423 with entries=74, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299659081
2014-07-13 18:01:00,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:00,938 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13396 synced till here 13393
2014-07-13 18:01:00,979 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299659081 with entries=65, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299660901
2014-07-13 18:01:01,457 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3328, memsize=369.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/2bf0f75181494e778adbe35c126b8592
2014-07-13 18:01:01,473 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/2bf0f75181494e778adbe35c126b8592 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2bf0f75181494e778adbe35c126b8592
2014-07-13 18:01:01,487 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2bf0f75181494e778adbe35c126b8592, entries=1345870, sequenceid=3328, filesize=95.8m
2014-07-13 18:01:01,487 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~563.7m/591046240, currentsize=236.0m/247478320 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 14406ms, sequenceid=3328, compaction requested=true
2014-07-13 18:01:01,488 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:20), split_queue=0, merge_queue=0
2014-07-13 18:01:01,488 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 481.7m
2014-07-13 18:01:02,000 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:01:02,062 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3329, memsize=369.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/80045fa76bbf4fba81ec84f42b8e8f40
2014-07-13 18:01:02,075 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/80045fa76bbf4fba81ec84f42b8e8f40 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/80045fa76bbf4fba81ec84f42b8e8f40
2014-07-13 18:01:02,090 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/80045fa76bbf4fba81ec84f42b8e8f40, entries=1345630, sequenceid=3329, filesize=95.8m
2014-07-13 18:01:02,091 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~551.3m/578124640, currentsize=240.3m/251942400 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 14292ms, sequenceid=3329, compaction requested=true
2014-07-13 18:01:02,091 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:21), split_queue=0, merge_queue=0
2014-07-13 18:01:02,091 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 470.3m
2014-07-13 18:01:02,438 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:01:02,450 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:01:02,467 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:02,513 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:01:03,093 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13489 synced till here 13479
2014-07-13 18:01:03,164 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299660901 with entries=93, filesize=87.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299662467
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299612687
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299614814
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299617747
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299618739
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299620249
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299621662
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299622908
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299624210
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299626407
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299627769
2014-07-13 18:01:03,165 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299630271
2014-07-13 18:01:04,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:04,489 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13559 synced till here 13555
2014-07-13 18:01:04,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299662467 with entries=70, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299664018
2014-07-13 18:01:06,515 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:06,535 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13627 synced till here 13624
2014-07-13 18:01:06,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299664018 with entries=68, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299666515
2014-07-13 18:01:07,859 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:08,499 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299666515 with entries=109, filesize=98.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299667860
2014-07-13 18:01:09,483 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:09,500 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13802 synced till here 13799
2014-07-13 18:01:09,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299667860 with entries=66, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299669483
2014-07-13 18:01:11,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:11,590 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13875 synced till here 13874
2014-07-13 18:01:11,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299669483 with entries=73, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299671571
2014-07-13 18:01:12,917 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:13,730 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 13989 synced till here 13984
2014-07-13 18:01:13,750 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299671571 with entries=114, filesize=105.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299672917
2014-07-13 18:01:14,814 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:14,842 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14060 synced till here 14059
2014-07-13 18:01:15,281 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299672917 with entries=71, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299674815
2014-07-13 18:01:17,420 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:17,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14129 synced till here 14126
2014-07-13 18:01:17,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299674815 with entries=69, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299677420
2014-07-13 18:01:18,860 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:18,890 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14193 synced till here 14182
2014-07-13 18:01:19,199 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299677420 with entries=64, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299678860
2014-07-13 18:01:21,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:21,228 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14286 synced till here 14278
2014-07-13 18:01:21,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299678860 with entries=93, filesize=88.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299681091
2014-07-13 18:01:21,754 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3283, memsize=475.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/c5ac6b392cd14a15896205b378f2e67f
2014-07-13 18:01:21,764 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3281, memsize=466.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/58f11ab78f8d4b5bad04c5d8a91deeb1
2014-07-13 18:01:21,771 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/c5ac6b392cd14a15896205b378f2e67f as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c5ac6b392cd14a15896205b378f2e67f
2014-07-13 18:01:21,789 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/58f11ab78f8d4b5bad04c5d8a91deeb1 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/58f11ab78f8d4b5bad04c5d8a91deeb1
2014-07-13 18:01:22,586 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c5ac6b392cd14a15896205b378f2e67f, entries=1732560, sequenceid=3283, filesize=123.4m
2014-07-13 18:01:22,589 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/58f11ab78f8d4b5bad04c5d8a91deeb1, entries=1699960, sequenceid=3281, filesize=121.1m
2014-07-13 18:01:22,590 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~481.7m/505146240, currentsize=398.7m/418072400 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 21102ms, sequenceid=3283, compaction requested=true
2014-07-13 18:01:22,590 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~472.8m/495718080, currentsize=375.5m/393757120 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 20499ms, sequenceid=3281, compaction requested=false
2014-07-13 18:01:22,591 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:22), split_queue=0, merge_queue=0
2014-07-13 18:01:22,591 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 639.4m
2014-07-13 18:01:22,592 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 630.4m
2014-07-13 18:01:22,675 DEBUG [RpcServer.handler=45,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:01:22,806 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:01:23,080 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:23,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14391 synced till here 14378
2014-07-13 18:01:23,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299681091 with entries=105, filesize=95.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299683081
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299632511
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299634078
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299635472
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299638131
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299639468
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299640716
2014-07-13 18:01:23,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299642033
2014-07-13 18:01:23,332 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299644471
2014-07-13 18:01:23,599 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:01:23,617 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:01:24,546 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:24,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14498 synced till here 14488
2014-07-13 18:01:24,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299683081 with entries=107, filesize=79.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299684547
2014-07-13 18:01:26,514 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:26,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14584 synced till here 14559
2014-07-13 18:01:26,723 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299684547 with entries=86, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299686515
2014-07-13 18:01:28,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:28,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14652 synced till here 14644
2014-07-13 18:01:28,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299686515 with entries=68, filesize=71.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299688397
2014-07-13 18:01:30,032 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:30,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14715 synced till here 14714
2014-07-13 18:01:30,100 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299688397 with entries=63, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299690033
2014-07-13 18:01:35,818 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:35,868 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299690033 with entries=110, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299695818
2014-07-13 18:01:37,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:37,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 14887 synced till here 14885
2014-07-13 18:01:37,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299695818 with entries=62, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299697148
2014-07-13 18:01:38,645 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:39,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299697148 with entries=92, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299698645
2014-07-13 18:01:41,023 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:41,467 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15083 synced till here 15082
2014-07-13 18:01:41,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299698645 with entries=104, filesize=94.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299701023
2014-07-13 18:01:42,880 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:43,037 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15158 synced till here 15157
2014-07-13 18:01:43,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299701023 with entries=75, filesize=72.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299702881
2014-07-13 18:01:44,138 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:44,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15225 synced till here 15218
2014-07-13 18:01:44,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299702881 with entries=67, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299704138
2014-07-13 18:01:45,719 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3673, memsize=555.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/6dfbcfde30ab463db3a691976cd8e33e
2014-07-13 18:01:45,735 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/6dfbcfde30ab463db3a691976cd8e33e as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6dfbcfde30ab463db3a691976cd8e33e
2014-07-13 18:01:45,750 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6dfbcfde30ab463db3a691976cd8e33e, entries=2021640, sequenceid=3673, filesize=143.9m
2014-07-13 18:01:45,750 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~649.9m/681484480, currentsize=343.1m/359776960 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 23159ms, sequenceid=3673, compaction requested=true
2014-07-13 18:01:45,751 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:23), split_queue=0, merge_queue=0
2014-07-13 18:01:45,751 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 810.0m
2014-07-13 18:01:45,855 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:45,875 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3669, memsize=555.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/e9a546a343dd491ba97821999a13f5ff
2014-07-13 18:01:45,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15303 synced till here 15301
2014-07-13 18:01:45,889 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/e9a546a343dd491ba97821999a13f5ff as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e9a546a343dd491ba97821999a13f5ff
2014-07-13 18:01:45,896 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299704138 with entries=78, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299705856
2014-07-13 18:01:45,908 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e9a546a343dd491ba97821999a13f5ff, entries=2021910, sequenceid=3669, filesize=143.9m
2014-07-13 18:01:45,908 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~643.8m/675042560, currentsize=353.2m/370387360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 23317ms, sequenceid=3669, compaction requested=true
2014-07-13 18:01:45,908 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:24), split_queue=0, merge_queue=0
2014-07-13 18:01:45,909 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 800.6m
2014-07-13 18:01:46,579 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:01:46,847 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:01:55,101 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:01:55,226 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:01:56,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:57,064 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15425 synced till here 15424
2014-07-13 18:01:57,080 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299705856 with entries=122, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299716772
2014-07-13 18:01:57,080 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299646291
2014-07-13 18:01:57,080 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299649971
2014-07-13 18:01:57,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299651532
2014-07-13 18:01:57,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299653274
2014-07-13 18:01:57,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299654594
2014-07-13 18:01:57,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299657423
2014-07-13 18:01:57,081 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299659081
2014-07-13 18:01:59,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:01:59,501 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15488 synced till here 15487
2014-07-13 18:01:59,524 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299716772 with entries=63, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299719485
2014-07-13 18:02:01,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:01,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15561 synced till here 15556
2014-07-13 18:02:01,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299719485 with entries=73, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299721147
2014-07-13 18:02:02,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:02,514 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299721147 with entries=67, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299722485
2014-07-13 18:02:03,835 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:04,275 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15726 synced till here 15723
2014-07-13 18:02:04,287 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299722485 with entries=98, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299723835
2014-07-13 18:02:05,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:05,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15793 synced till here 15786
2014-07-13 18:02:05,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299723835 with entries=67, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299725395
2014-07-13 18:02:06,763 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:06,807 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15885 synced till here 15876
2014-07-13 18:02:07,828 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3799, memsize=586.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/de3646a72157460fbbbc99480228ef90
2014-07-13 18:02:07,870 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=3792, memsize=584.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/77fbee8fe9784faa97a745b62a5a2797
2014-07-13 18:02:07,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299725395 with entries=92, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299726764
2014-07-13 18:02:07,883 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/de3646a72157460fbbbc99480228ef90 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/de3646a72157460fbbbc99480228ef90
2014-07-13 18:02:07,888 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/77fbee8fe9784faa97a745b62a5a2797 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/77fbee8fe9784faa97a745b62a5a2797
2014-07-13 18:02:07,897 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/de3646a72157460fbbbc99480228ef90, entries=2135610, sequenceid=3799, filesize=151.9m
2014-07-13 18:02:07,898 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~814.3m/853810240, currentsize=222.5m/233330720 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 22147ms, sequenceid=3799, compaction requested=true
2014-07-13 18:02:07,898 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/77fbee8fe9784faa97a745b62a5a2797, entries=2128810, sequenceid=3792, filesize=151.5m
2014-07-13 18:02:07,898 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~813.3m/852808720, currentsize=200.9m/210645280 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 21989ms, sequenceid=3792, compaction requested=true
2014-07-13 18:02:07,898 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:25), split_queue=0, merge_queue=0
2014-07-13 18:02:07,898 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-13 18:02:07,899 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 586.0m
2014-07-13 18:02:07,899 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 592.7m
2014-07-13 18:02:09,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:09,625 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 15986 synced till here 15959
2014-07-13 18:02:09,693 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:09,761 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:09,873 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299726764 with entries=101, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299729606
2014-07-13 18:02:09,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299660901
2014-07-13 18:02:09,875 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299662467
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299664018
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299666515
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299667860
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299669483
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299671571
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299672917
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299674815
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299677420
2014-07-13 18:02:09,876 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299678860
2014-07-13 18:02:10,093 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:02:11,261 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:02:11,655 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:11,755 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ddea0f2c3cee4378bd5bc2f128f03cd9 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ddea0f2c3cee4378bd5bc2f128f03cd9
2014-07-13 18:02:11,756 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16102 synced till here 16063
2014-07-13 18:02:12,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299729606 with entries=116, filesize=104.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299731655
2014-07-13 18:02:13,311 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:02:13,328 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/aae1b6e65d594cc299503648b4fb3579, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/aae1b6e65d594cc299503648b4fb3579
2014-07-13 18:02:13,332 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8c353e8f601947c6abc5fcab4ee4d130, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8c353e8f601947c6abc5fcab4ee4d130
2014-07-13 18:02:13,343 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/54fca91ea29b476c922b829526bf6026, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/54fca91ea29b476c922b829526bf6026
2014-07-13 18:02:13,346 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c37f4b732d4f4a3f866263b0cc16e918, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c37f4b732d4f4a3f866263b0cc16e918
2014-07-13 18:02:13,350 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/34b3e42db5cb4ab8a416e6d30ab52ced, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/34b3e42db5cb4ab8a416e6d30ab52ced
2014-07-13 18:02:13,354 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f630bf7c6614433998633ea6d4fdaa68, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f630bf7c6614433998633ea6d4fdaa68
2014-07-13 18:02:13,360 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1195eb6e7bcd4ecf880eaf004734bce4, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1195eb6e7bcd4ecf880eaf004734bce4
2014-07-13 18:02:13,361 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 7 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into ddea0f2c3cee4378bd5bc2f128f03cd9(size=532.9m), total size for store is 891.3m. This selection was in queue for 0sec, and took 1mins, 39sec to execute.
2014-07-13 18:02:13,361 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=7, fileSize=572.8m, priority=13, time=253541375661754; duration=1mins, 39sec
2014-07-13 18:02:13,362 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-13 18:02:13,362 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-13 18:02:13,363 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 9 files of size 973794091 starting at candidate #0 after considering 28 permutations with 28 in ratio
2014-07-13 18:02:13,363 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating major compaction
2014-07-13 18:02:13,363 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:02:13,364 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 9 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=928.7m
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3400b233c20a4b45ad1debf5cd2f566a, keycount=265285, bloomtype=ROW, size=188.9m, encoding=NONE, seqNum=1263, earliestPutTs=1405299306044
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/19b433e8cd30498c99686393f2033e36, keycount=175974, bloomtype=ROW, size=125.3m, encoding=NONE, seqNum=1655, earliestPutTs=1405299453185
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3c15be3a752e4888a0e031b637ac39b5, keycount=118311, bloomtype=ROW, size=84.2m, encoding=NONE, seqNum=1915, earliestPutTs=1405299485743
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/054a37e8697b4a9a8ad65205b0318719, keycount=26681, bloomtype=ROW, size=19.0m, encoding=NONE, seqNum=2098, earliestPutTs=1405299537544
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c1cb7fb29cf84641902ec27afd9cb91e, keycount=87735, bloomtype=ROW, size=62.5m, encoding=NONE, seqNum=2270, earliestPutTs=1405299561186
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4deff2d1f5214f9e8db31a405b544235, keycount=123731, bloomtype=ROW, size=88.2m, encoding=NONE, seqNum=2505, earliestPutTs=1405299574664
2014-07-13 18:02:13,364 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/140f2419b9764680a69d8c5bf3a104f8, keycount=119685, bloomtype=ROW, size=85.2m, encoding=NONE, seqNum=2940, earliestPutTs=1405299596736
2014-07-13 18:02:13,365 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c5ac6b392cd14a15896205b378f2e67f, keycount=173256, bloomtype=ROW, size=123.4m, encoding=NONE, seqNum=3283, earliestPutTs=1405299632846
2014-07-13 18:02:13,365 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/de3646a72157460fbbbc99480228ef90, keycount=213561, bloomtype=ROW, size=151.9m, encoding=NONE, seqNum=3799, earliestPutTs=1405299661563
2014-07-13 18:02:13,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:13,773 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:14,791 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16212 synced till here 16188
2014-07-13 18:02:15,078 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299731655 with entries=110, filesize=97.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299733772
2014-07-13 18:02:16,842 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1053ms
GC pool 'ParNew' had collection(s): count=1 time=1063ms
2014-07-13 18:02:17,054 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:17,133 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16321 synced till here 16291
2014-07-13 18:02:17,483 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299733772 with entries=109, filesize=94.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299737054
2014-07-13 18:02:19,244 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:19,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16426 synced till here 16422
2014-07-13 18:02:19,490 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299737054 with entries=105, filesize=92.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299739244
2014-07-13 18:02:21,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:21,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16539 synced till here 16520
2014-07-13 18:02:21,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299739244 with entries=113, filesize=91.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299741392
2014-07-13 18:02:22,730 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:23,576 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16676 synced till here 16674
2014-07-13 18:02:23,598 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299741392 with entries=137, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299742731
2014-07-13 18:02:24,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:24,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16752 synced till here 16742
2014-07-13 18:02:25,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299742731 with entries=76, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299744438
2014-07-13 18:02:26,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:26,318 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299744438 with entries=63, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299746275
2014-07-13 18:02:27,576 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:27,599 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16888 synced till here 16886
2014-07-13 18:02:27,730 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299746275 with entries=73, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299747576
2014-07-13 18:02:28,887 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:28,952 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 16963 synced till here 16950
2014-07-13 18:02:29,531 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299747576 with entries=75, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299748888
2014-07-13 18:02:30,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:30,250 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17047 synced till here 17039
2014-07-13 18:02:30,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299748888 with entries=84, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299750212
2014-07-13 18:02:34,068 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4015, memsize=480.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/accc5e61cdd749fca004a1bb9333f49a
2014-07-13 18:02:34,083 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/accc5e61cdd749fca004a1bb9333f49a as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/accc5e61cdd749fca004a1bb9333f49a
2014-07-13 18:02:34,095 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/accc5e61cdd749fca004a1bb9333f49a, entries=1751080, sequenceid=4015, filesize=124.8m
2014-07-13 18:02:34,095 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~596.1m/625067360, currentsize=489.9m/513710720 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 26196ms, sequenceid=4015, compaction requested=true
2014-07-13 18:02:34,095 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:26), split_queue=0, merge_queue=0
2014-07-13 18:02:34,096 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 680.9m
2014-07-13 18:02:34,380 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4033, memsize=501.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/d97f41a0d2904936999a60bd444809d3
2014-07-13 18:02:34,396 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/d97f41a0d2904936999a60bd444809d3 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d97f41a0d2904936999a60bd444809d3
2014-07-13 18:02:34,410 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d97f41a0d2904936999a60bd444809d3, entries=1824810, sequenceid=4033, filesize=130.0m
2014-07-13 18:02:34,410 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~618.8m/648881840, currentsize=455.8m/477907360 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 26511ms, sequenceid=4033, compaction requested=true
2014-07-13 18:02:34,410 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:27), split_queue=0, merge_queue=0
2014-07-13 18:02:34,410 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 676.6m
2014-07-13 18:02:34,492 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:02:34,539 DEBUG [RpcServer.handler=48,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:02:34,736 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:34,783 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:34,811 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299750212 with entries=91, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299754783
2014-07-13 18:02:34,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299681091
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299683081
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299684547
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299686515
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299688397
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299690033
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299695818
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299697148
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299698645
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299701023
2014-07-13 18:02:34,812 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299702881
2014-07-13 18:02:34,915 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:38,757 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:38,781 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17205 synced till here 17202
2014-07-13 18:02:38,838 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299754783 with entries=67, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299758757
2014-07-13 18:02:40,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:40,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17270 synced till here 17267
2014-07-13 18:02:40,269 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299758757 with entries=65, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299760184
2014-07-13 18:02:41,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:41,321 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17345 synced till here 17344
2014-07-13 18:02:41,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299760184 with entries=75, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299761213
2014-07-13 18:02:42,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:42,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17419 synced till here 17417
2014-07-13 18:02:42,332 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299761213 with entries=74, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299762301
2014-07-13 18:02:44,938 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:44,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17488 synced till here 17481
2014-07-13 18:02:45,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299762301 with entries=69, filesize=69.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299764938
2014-07-13 18:02:46,452 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:46,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17564 synced till here 17560
2014-07-13 18:02:46,692 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299764938 with entries=76, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299766452
2014-07-13 18:02:48,897 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:48,912 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17650 synced till here 17648
2014-07-13 18:02:48,960 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299766452 with entries=86, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299768897
2014-07-13 18:02:49,329 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4286, memsize=394.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/dfe42c33f61b474983ff3212c05e2941
2014-07-13 18:02:49,331 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4276, memsize=388.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/429530e660474aca9de612f95ad91be8
2014-07-13 18:02:49,406 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/dfe42c33f61b474983ff3212c05e2941 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/dfe42c33f61b474983ff3212c05e2941
2014-07-13 18:02:49,413 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/429530e660474aca9de612f95ad91be8 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/429530e660474aca9de612f95ad91be8
2014-07-13 18:02:49,451 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/dfe42c33f61b474983ff3212c05e2941, entries=1436970, sequenceid=4286, filesize=102.4m
2014-07-13 18:02:49,451 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~682.4m/715588160, currentsize=212.9m/223221600 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 15356ms, sequenceid=4286, compaction requested=false
2014-07-13 18:02:49,451 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 676.8m
2014-07-13 18:02:49,456 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/429530e660474aca9de612f95ad91be8, entries=1414650, sequenceid=4276, filesize=100.8m
2014-07-13 18:02:49,456 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~676.6m/709427360, currentsize=212.9m/223202000 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 15046ms, sequenceid=4276, compaction requested=true
2014-07-13 18:02:49,456 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:28), split_queue=0, merge_queue=0
2014-07-13 18:02:49,457 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 710.7m
2014-07-13 18:02:49,889 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:50,014 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:02:51,060 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:51,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17738 synced till here 17729
2014-07-13 18:02:51,517 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299768897 with entries=88, filesize=73.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299771061
2014-07-13 18:02:51,517 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299704138
2014-07-13 18:02:51,517 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299705856
2014-07-13 18:02:51,518 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299716772
2014-07-13 18:02:51,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299719485
2014-07-13 18:02:51,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299721147
2014-07-13 18:02:51,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299722485
2014-07-13 18:02:51,519 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299723835
2014-07-13 18:02:51,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299725395
2014-07-13 18:02:52,226 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:02:52,302 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:02:52,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:53,063 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17822 synced till here 17818
2014-07-13 18:02:53,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299771061 with entries=84, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299772649
2014-07-13 18:02:55,476 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:55,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17894 synced till here 17892
2014-07-13 18:02:55,628 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299772649 with entries=72, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299775477
2014-07-13 18:02:56,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:56,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 17970 synced till here 17968
2014-07-13 18:02:56,859 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299775477 with entries=76, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299776786
2014-07-13 18:02:58,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:02:58,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18041 synced till here 18037
2014-07-13 18:02:58,870 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299776786 with entries=71, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299778789
2014-07-13 18:03:01,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:01,529 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18105 synced till here 18103
2014-07-13 18:03:01,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299778789 with entries=64, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299781509
2014-07-13 18:03:02,655 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:02,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299781509 with entries=57, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299782655
2014-07-13 18:03:03,804 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:04,204 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299782655 with entries=104, filesize=87.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299783805
2014-07-13 18:03:05,055 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4422, memsize=421.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/4e7447a976a74b17b7b298120de12773
2014-07-13 18:03:05,070 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/4e7447a976a74b17b7b298120de12773 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4e7447a976a74b17b7b298120de12773
2014-07-13 18:03:05,140 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4e7447a976a74b17b7b298120de12773, entries=1533650, sequenceid=4422, filesize=109.2m
2014-07-13 18:03:05,141 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~676.8m/709706800, currentsize=254.5m/266818240 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 15690ms, sequenceid=4422, compaction requested=true
2014-07-13 18:03:05,141 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:29), split_queue=0, merge_queue=0
2014-07-13 18:03:05,141 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 466.8m
2014-07-13 18:03:05,389 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:05,568 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4424, memsize=428.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/58591163e6ba431289c8f17808186f37
2014-07-13 18:03:05,582 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/58591163e6ba431289c8f17808186f37 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/58591163e6ba431289c8f17808186f37
2014-07-13 18:03:05,595 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/58591163e6ba431289c8f17808186f37, entries=1560130, sequenceid=4424, filesize=111.1m
2014-07-13 18:03:05,595 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~710.7m/745250240, currentsize=254.2m/266561360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 16138ms, sequenceid=4424, compaction requested=true
2014-07-13 18:03:05,596 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:30), split_queue=0, merge_queue=0
2014-07-13 18:03:05,596 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 466.6m
2014-07-13 18:03:05,890 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:09,512 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:03:09,597 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:03:10,150 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.79 MB, free=3.95 GB, max=3.96 GB, blocks=7, accesses=92562, hits=21406, hitRatio=23.12%, , cachingAccesses=21420, cachingHits=21397, cachingHitsRatio=99.89%, evictions=0, evicted=16, evictedPerRun=Infinity
2014-07-13 18:03:11,116 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:11,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18371 synced till here 18368
2014-07-13 18:03:11,182 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299783805 with entries=105, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299791117
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299726764
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299729606
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299731655
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299733772
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299737054
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299739244
2014-07-13 18:03:11,182 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299741392
2014-07-13 18:03:11,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299742731
2014-07-13 18:03:11,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299744438
2014-07-13 18:03:11,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299746275
2014-07-13 18:03:11,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299747576
2014-07-13 18:03:11,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299748888
2014-07-13 18:03:12,299 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:12,329 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18447 synced till here 18439
2014-07-13 18:03:12,444 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299791117 with entries=76, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299792299
2014-07-13 18:03:13,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:13,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18532 synced till here 18531
2014-07-13 18:03:13,693 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299792299 with entries=85, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299793651
2014-07-13 18:03:15,777 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:15,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18625 synced till here 18619
2014-07-13 18:03:15,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299793651 with entries=93, filesize=68.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299795778
2014-07-13 18:03:17,599 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:17,710 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18725 synced till here 18724
2014-07-13 18:03:17,792 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299795778 with entries=100, filesize=70.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299797600
2014-07-13 18:03:19,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:19,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18804 synced till here 18802
2014-07-13 18:03:19,175 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299797600 with entries=79, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299799054
2014-07-13 18:03:19,929 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4627, memsize=457.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/011f644252844c12ab298a384e0e5f12
2014-07-13 18:03:19,949 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/011f644252844c12ab298a384e0e5f12 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/011f644252844c12ab298a384e0e5f12
2014-07-13 18:03:19,960 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/011f644252844c12ab298a384e0e5f12, entries=1666740, sequenceid=4627, filesize=118.7m
2014-07-13 18:03:19,960 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~466.8m/489431840, currentsize=186.0m/195049040 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 14819ms, sequenceid=4627, compaction requested=false
2014-07-13 18:03:19,961 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 449.0m
2014-07-13 18:03:20,220 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:20,546 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4617, memsize=457.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/3bc9669adf434f8ebf157ab730c94774
2014-07-13 18:03:20,559 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/3bc9669adf434f8ebf157ab730c94774 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3bc9669adf434f8ebf157ab730c94774
2014-07-13 18:03:20,825 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3bc9669adf434f8ebf157ab730c94774, entries=1666190, sequenceid=4617, filesize=118.7m
2014-07-13 18:03:20,825 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~466.6m/489226960, currentsize=203.7m/213602800 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 15229ms, sequenceid=4617, compaction requested=true
2014-07-13 18:03:20,826 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:31), split_queue=0, merge_queue=0
2014-07-13 18:03:20,826 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 459.3m
2014-07-13 18:03:20,910 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:20,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18873 synced till here 18868
2014-07-13 18:03:20,993 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299799054 with entries=69, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299800910
2014-07-13 18:03:20,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299750212
2014-07-13 18:03:20,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299754783
2014-07-13 18:03:20,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299758757
2014-07-13 18:03:20,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299760184
2014-07-13 18:03:20,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299761213
2014-07-13 18:03:20,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299762301
2014-07-13 18:03:20,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299764938
2014-07-13 18:03:20,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299766452
2014-07-13 18:03:21,134 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:22,097 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:22,631 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 18974 synced till here 18972
2014-07-13 18:03:22,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299800910 with entries=101, filesize=84.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299802098
2014-07-13 18:03:24,029 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:03:24,180 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:03:24,921 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:24,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19041 synced till here 19040
2014-07-13 18:03:25,068 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299802098 with entries=67, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299804922
2014-07-13 18:03:32,794 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:32,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19171 synced till here 19167
2014-07-13 18:03:32,863 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299804922 with entries=130, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299812794
2014-07-13 18:03:33,315 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4669, memsize=438.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/d0410b87af344bd09668823e4c34ac72
2014-07-13 18:03:33,326 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/d0410b87af344bd09668823e4c34ac72 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d0410b87af344bd09668823e4c34ac72
2014-07-13 18:03:33,336 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d0410b87af344bd09668823e4c34ac72, entries=1597560, sequenceid=4669, filesize=113.8m
2014-07-13 18:03:33,337 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~449.0m/470758480, currentsize=114.2m/119695600 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 13376ms, sequenceid=4669, compaction requested=true
2014-07-13 18:03:33,337 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:32), split_queue=0, merge_queue=0
2014-07-13 18:03:33,337 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 319.3m
2014-07-13 18:03:33,498 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:34,725 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4678, memsize=451.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/8709335b71e440a3aca1a433a64c0a7f
2014-07-13 18:03:34,735 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/8709335b71e440a3aca1a433a64c0a7f as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/8709335b71e440a3aca1a433a64c0a7f
2014-07-13 18:03:34,749 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/8709335b71e440a3aca1a433a64c0a7f, entries=1644920, sequenceid=4678, filesize=117.2m
2014-07-13 18:03:34,749 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~462.0m/484484800, currentsize=124.1m/130141600 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 13923ms, sequenceid=4678, compaction requested=true
2014-07-13 18:03:34,749 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:33), split_queue=0, merge_queue=0
2014-07-13 18:03:34,750 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 328.6m
2014-07-13 18:03:34,751 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:34,773 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299812794 with entries=67, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299814751
2014-07-13 18:03:34,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299768897
2014-07-13 18:03:34,773 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299771061
2014-07-13 18:03:34,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299772649
2014-07-13 18:03:34,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299775477
2014-07-13 18:03:34,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299776786
2014-07-13 18:03:34,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299778789
2014-07-13 18:03:34,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299781509
2014-07-13 18:03:34,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299782655
2014-07-13 18:03:34,939 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:36,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:36,235 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19313 synced till here 19311
2014-07-13 18:03:36,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299814751 with entries=75, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299816219
2014-07-13 18:03:38,307 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:38,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19425 synced till here 19423
2014-07-13 18:03:38,682 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299816219 with entries=112, filesize=88.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299818307
2014-07-13 18:03:44,152 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4901, memsize=319.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/db68482a9333465883f1dc467e2db120
2014-07-13 18:03:44,413 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/db68482a9333465883f1dc467e2db120 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/db68482a9333465883f1dc467e2db120
2014-07-13 18:03:44,434 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/db68482a9333465883f1dc467e2db120, entries=1162520, sequenceid=4901, filesize=82.7m
2014-07-13 18:03:44,434 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~319.3m/334797680, currentsize=89.3m/93663200 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 11097ms, sequenceid=4901, compaction requested=true
2014-07-13 18:03:44,434 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:34), split_queue=0, merge_queue=0
2014-07-13 18:03:45,794 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4897, memsize=330.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/9ed1c16370be48a3933280e70ea92cf2
2014-07-13 18:03:45,812 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/9ed1c16370be48a3933280e70ea92cf2 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9ed1c16370be48a3933280e70ea92cf2
2014-07-13 18:03:45,826 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9ed1c16370be48a3933280e70ea92cf2, entries=1202030, sequenceid=4897, filesize=85.5m
2014-07-13 18:03:45,826 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~330.1m/346176640, currentsize=78.9m/82720080 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 11076ms, sequenceid=4897, compaction requested=true
2014-07-13 18:03:45,827 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:35), split_queue=0, merge_queue=0
2014-07-13 18:03:54,078 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:54,102 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19536 synced till here 19534
2014-07-13 18:03:54,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299818307 with entries=111, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299834079
2014-07-13 18:03:54,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299783805
2014-07-13 18:03:54,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299791117
2014-07-13 18:03:54,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299792299
2014-07-13 18:03:54,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299793651
2014-07-13 18:03:54,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299795778
2014-07-13 18:03:54,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299797600
2014-07-13 18:03:54,396 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:03:54,397 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 258.1m
2014-07-13 18:03:54,661 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:54,933 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 256.8m
2014-07-13 18:03:54,934 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:03:54,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:54,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19599 synced till here 19596
2014-07-13 18:03:55,008 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299834079 with entries=63, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299834967
2014-07-13 18:03:55,608 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:03:56,598 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:57,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19676 synced till here 19673
2014-07-13 18:03:57,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299834967 with entries=77, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299836598
2014-07-13 18:03:59,958 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:03:59,974 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19760 synced till here 19751
2014-07-13 18:04:00,048 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299836598 with entries=84, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299839958
2014-07-13 18:04:01,957 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:01,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19840 synced till here 19830
2014-07-13 18:04:02,053 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299839958 with entries=80, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299841958
2014-07-13 18:04:02,548 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:04:03,266 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:03,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 19924 synced till here 19915
2014-07-13 18:04:03,361 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299841958 with entries=84, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299843266
2014-07-13 18:04:03,566 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:04:04,324 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:04,526 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20015 synced till here 20012
2014-07-13 18:04:04,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299843266 with entries=91, filesize=77.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299844325
2014-07-13 18:04:05,644 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:05,670 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20085 synced till here 20080
2014-07-13 18:04:05,734 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299844325 with entries=70, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299845645
2014-07-13 18:04:05,877 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4804, memsize=253.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a6b5f1612ad7426b8ace016b72e60c17
2014-07-13 18:04:05,891 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a6b5f1612ad7426b8ace016b72e60c17 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a6b5f1612ad7426b8ace016b72e60c17
2014-07-13 18:04:05,901 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a6b5f1612ad7426b8ace016b72e60c17, entries=922550, sequenceid=4804, filesize=65.7m
2014-07-13 18:04:05,901 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.2m/272815920, currentsize=227.3m/238356000 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 11505ms, sequenceid=4804, compaction requested=true
2014-07-13 18:04:05,902 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:36), split_queue=0, merge_queue=0
2014-07-13 18:04:05,902 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 340.0m
2014-07-13 18:04:06,141 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:06,603 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4811, memsize=252.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a0d6b75556bd4e42bc46ca41f1f80521
2014-07-13 18:04:06,615 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a0d6b75556bd4e42bc46ca41f1f80521 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a0d6b75556bd4e42bc46ca41f1f80521
2014-07-13 18:04:06,916 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a0d6b75556bd4e42bc46ca41f1f80521, entries=917810, sequenceid=4811, filesize=65.4m
2014-07-13 18:04:06,917 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~259.0m/271540160, currentsize=223.3m/234149120 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 11983ms, sequenceid=4811, compaction requested=true
2014-07-13 18:04:06,917 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:37), split_queue=0, merge_queue=0
2014-07-13 18:04:06,917 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 344.5m
2014-07-13 18:04:07,194 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:11,134 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:11,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20181 synced till here 20176
2014-07-13 18:04:11,377 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299845645 with entries=96, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299851134
2014-07-13 18:04:11,377 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299799054
2014-07-13 18:04:11,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299800910
2014-07-13 18:04:11,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299802098
2014-07-13 18:04:11,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299804922
2014-07-13 18:04:12,119 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:04:12,376 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:04:13,238 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:13,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20345 synced till here 20343
2014-07-13 18:04:13,901 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299851134 with entries=164, filesize=104.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299853239
2014-07-13 18:04:15,301 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:15,322 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20416 synced till here 20410
2014-07-13 18:04:15,405 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299853239 with entries=71, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299855301
2014-07-13 18:04:15,726 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5173, memsize=288.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/eea2f7ff442c4225bbe19a6152991edb
2014-07-13 18:04:15,744 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/eea2f7ff442c4225bbe19a6152991edb as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/eea2f7ff442c4225bbe19a6152991edb
2014-07-13 18:04:15,757 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/eea2f7ff442c4225bbe19a6152991edb, entries=1049460, sequenceid=5173, filesize=74.7m
2014-07-13 18:04:15,757 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~340.0m/356563680, currentsize=106.1m/111209680 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 9855ms, sequenceid=5173, compaction requested=true
2014-07-13 18:04:15,758 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:38), split_queue=0, merge_queue=0
2014-07-13 18:04:15,758 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 349.1m
2014-07-13 18:04:16,225 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:16,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:16,862 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299855301 with entries=101, filesize=81.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299856480
2014-07-13 18:04:17,044 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5175, memsize=294.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/e88b266d62ac4758b7f8868c1ec36c3c
2014-07-13 18:04:17,067 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/e88b266d62ac4758b7f8868c1ec36c3c as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e88b266d62ac4758b7f8868c1ec36c3c
2014-07-13 18:04:17,106 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e88b266d62ac4758b7f8868c1ec36c3c, entries=1071440, sequenceid=5175, filesize=76.3m
2014-07-13 18:04:17,107 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~346.1m/362874560, currentsize=117.4m/123127200 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 10190ms, sequenceid=5175, compaction requested=true
2014-07-13 18:04:17,107 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:39), split_queue=0, merge_queue=0
2014-07-13 18:04:17,107 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 356.3m
2014-07-13 18:04:17,305 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:19,491 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:19,818 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20621 synced till here 20620
2014-07-13 18:04:19,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299856480 with entries=104, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299859492
2014-07-13 18:04:19,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299812794
2014-07-13 18:04:19,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299814751
2014-07-13 18:04:19,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299816219
2014-07-13 18:04:19,826 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299818307
2014-07-13 18:04:20,906 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:20,936 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299859492 with entries=74, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299860907
2014-07-13 18:04:24,853 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4983, memsize=277.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ae2c8944ef184d4db9d06d42dcda13df
2014-07-13 18:04:24,868 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ae2c8944ef184d4db9d06d42dcda13df as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ae2c8944ef184d4db9d06d42dcda13df
2014-07-13 18:04:24,879 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ae2c8944ef184d4db9d06d42dcda13df, entries=1008880, sequenceid=4983, filesize=71.9m
2014-07-13 18:04:24,879 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~349.1m/366010720, currentsize=106.8m/111996480 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 9121ms, sequenceid=4983, compaction requested=true
2014-07-13 18:04:24,880 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:40), split_queue=0, merge_queue=0
2014-07-13 18:04:26,485 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4996, memsize=284.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/1424bc1acb164111bf3f7d25958102a9
2014-07-13 18:04:26,498 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/1424bc1acb164111bf3f7d25958102a9 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1424bc1acb164111bf3f7d25958102a9
2014-07-13 18:04:26,510 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1424bc1acb164111bf3f7d25958102a9, entries=1037440, sequenceid=4996, filesize=73.9m
2014-07-13 18:04:26,511 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~356.3m/373638160, currentsize=87.4m/91685280 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 9404ms, sequenceid=4996, compaction requested=true
2014-07-13 18:04:26,511 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-13 18:04:30,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:30,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20768 synced till here 20765
2014-07-13 18:04:30,657 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299860907 with entries=73, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299870607
2014-07-13 18:04:30,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299834079
2014-07-13 18:04:30,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299834967
2014-07-13 18:04:30,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299836598
2014-07-13 18:04:30,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299839958
2014-07-13 18:04:30,657 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299841958
2014-07-13 18:04:30,658 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299843266
2014-07-13 18:04:30,658 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299844325
2014-07-13 18:04:32,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:32,232 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20850 synced till here 20842
2014-07-13 18:04:32,316 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299870607 with entries=82, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299872213
2014-07-13 18:04:33,094 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:04:33,095 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 258.5m
2014-07-13 18:04:33,236 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:33,493 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:04:33,493 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 257.4m
2014-07-13 18:04:33,618 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:33,634 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20911 synced till here 20910
2014-07-13 18:04:33,648 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299872213 with entries=61, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299873618
2014-07-13 18:04:33,677 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:35,425 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:35,454 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 20996 synced till here 20995
2014-07-13 18:04:35,473 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299873618 with entries=85, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299875426
2014-07-13 18:04:37,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:37,664 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21140 synced till here 21134
2014-07-13 18:04:37,888 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299875426 with entries=144, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299877101
2014-07-13 18:04:39,167 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:04:39,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:39,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21210 synced till here 21209
2014-07-13 18:04:39,519 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299877101 with entries=70, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299879482
2014-07-13 18:04:39,851 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:04:40,442 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/f5e0b600bc864f1d8f6344e499b2e386 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f5e0b600bc864f1d8f6344e499b2e386
2014-07-13 18:04:40,470 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:04:40,484 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3400b233c20a4b45ad1debf5cd2f566a, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3400b233c20a4b45ad1debf5cd2f566a
2014-07-13 18:04:40,486 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/19b433e8cd30498c99686393f2033e36, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/19b433e8cd30498c99686393f2033e36
2014-07-13 18:04:40,491 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3c15be3a752e4888a0e031b637ac39b5, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3c15be3a752e4888a0e031b637ac39b5
2014-07-13 18:04:40,493 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/054a37e8697b4a9a8ad65205b0318719, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/054a37e8697b4a9a8ad65205b0318719
2014-07-13 18:04:40,496 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c1cb7fb29cf84641902ec27afd9cb91e, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c1cb7fb29cf84641902ec27afd9cb91e
2014-07-13 18:04:40,498 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4deff2d1f5214f9e8db31a405b544235, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4deff2d1f5214f9e8db31a405b544235
2014-07-13 18:04:40,501 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/140f2419b9764680a69d8c5bf3a104f8, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/140f2419b9764680a69d8c5bf3a104f8
2014-07-13 18:04:40,504 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c5ac6b392cd14a15896205b378f2e67f, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c5ac6b392cd14a15896205b378f2e67f
2014-07-13 18:04:40,510 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/de3646a72157460fbbbc99480228ef90, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/de3646a72157460fbbbc99480228ef90
2014-07-13 18:04:40,511 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed major compaction of 9 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into f5e0b600bc864f1d8f6344e499b2e386(size=883.8m), total size for store is 1.2g. This selection was in queue for 0sec, and took 2mins, 27sec to execute.
2014-07-13 18:04:40,511 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=9, fileSize=928.7m, priority=11, time=253640790222802; duration=2mins, 27sec
2014-07-13 18:04:40,511 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-13 18:04:40,511 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 13 store files, 0 compacting, 13 eligible, 20 blocking
2014-07-13 18:04:40,514 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 955949050 starting at candidate #2 after considering 60 permutations with 58 in ratio
2014-07-13 18:04:40,514 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating minor compaction
2014-07-13 18:04:40,515 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:04:40,515 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=911.7m
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4dc86f1555544833a256289cf94ef674, keycount=75979, bloomtype=ROW, size=54.2m, encoding=NONE, seqNum=2116
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c15dc97ee7874bb483f7affb46d221e6, keycount=43801, bloomtype=ROW, size=31.2m, encoding=NONE, seqNum=2409
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/afc384a8a32047cab9ab4766064ebd38, keycount=113089, bloomtype=ROW, size=80.5m, encoding=NONE, seqNum=2629
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ecf86536d7754f4da119ed413d4cdbc8, keycount=122786, bloomtype=ROW, size=87.4m, encoding=NONE, seqNum=2937
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/80045fa76bbf4fba81ec84f42b8e8f40, keycount=134563, bloomtype=ROW, size=95.8m, encoding=NONE, seqNum=3329
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6dfbcfde30ab463db3a691976cd8e33e, keycount=202164, bloomtype=ROW, size=143.9m, encoding=NONE, seqNum=3673
2014-07-13 18:04:40,515 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d97f41a0d2904936999a60bd444809d3, keycount=182481, bloomtype=ROW, size=130.0m, encoding=NONE, seqNum=4033
2014-07-13 18:04:40,516 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4e7447a976a74b17b7b298120de12773, keycount=153365, bloomtype=ROW, size=109.2m, encoding=NONE, seqNum=4422
2014-07-13 18:04:40,516 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d0410b87af344bd09668823e4c34ac72, keycount=159756, bloomtype=ROW, size=113.8m, encoding=NONE, seqNum=4669
2014-07-13 18:04:40,516 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a6b5f1612ad7426b8ace016b72e60c17, keycount=92255, bloomtype=ROW, size=65.7m, encoding=NONE, seqNum=4804
2014-07-13 18:04:40,699 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:41,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:41,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299879482 with entries=104, filesize=60.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299881011
2014-07-13 18:04:41,740 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5403, memsize=258.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/443e079b8dd945829666ccc48e0efb73
2014-07-13 18:04:41,754 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/443e079b8dd945829666ccc48e0efb73 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/443e079b8dd945829666ccc48e0efb73
2014-07-13 18:04:41,767 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/443e079b8dd945829666ccc48e0efb73, entries=941200, sequenceid=5403, filesize=67.1m
2014-07-13 18:04:41,767 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.5m/271056160, currentsize=157.2m/164829200 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 8672ms, sequenceid=5403, compaction requested=true
2014-07-13 18:04:41,767 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:41), split_queue=0, merge_queue=0
2014-07-13 18:04:41,767 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 296.3m
2014-07-13 18:04:41,940 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:42,112 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5402, memsize=261.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/51a003beeaea40418f653b772477ad95
2014-07-13 18:04:42,126 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/51a003beeaea40418f653b772477ad95 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/51a003beeaea40418f653b772477ad95
2014-07-13 18:04:42,137 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/51a003beeaea40418f653b772477ad95, entries=953670, sequenceid=5402, filesize=67.9m
2014-07-13 18:04:42,137 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.9m/274647280, currentsize=136.8m/143486000 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 8644ms, sequenceid=5402, compaction requested=true
2014-07-13 18:04:42,137 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:42), split_queue=0, merge_queue=0
2014-07-13 18:04:42,138 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 276.9m
2014-07-13 18:04:42,292 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:04:50,033 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5148, memsize=276.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/60b6217ba83c45889dc2db8a2f1567ff
2014-07-13 18:04:50,051 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/60b6217ba83c45889dc2db8a2f1567ff as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/60b6217ba83c45889dc2db8a2f1567ff
2014-07-13 18:04:50,063 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/60b6217ba83c45889dc2db8a2f1567ff, entries=1008310, sequenceid=5148, filesize=71.8m
2014-07-13 18:04:50,063 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~276.9m/290385360, currentsize=0.0/0 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 7925ms, sequenceid=5148, compaction requested=true
2014-07-13 18:04:50,063 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:43), split_queue=0, merge_queue=0
2014-07-13 18:04:50,097 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5146, memsize=296.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/0387885e8f8d41b6a2533accad1ba233
2014-07-13 18:04:50,108 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/0387885e8f8d41b6a2533accad1ba233 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0387885e8f8d41b6a2533accad1ba233
2014-07-13 18:04:50,124 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0387885e8f8d41b6a2533accad1ba233, entries=1078910, sequenceid=5146, filesize=76.8m
2014-07-13 18:04:50,125 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~296.3m/310716160, currentsize=0.0/0 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 8358ms, sequenceid=5146, compaction requested=true
2014-07-13 18:04:50,125 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:44), split_queue=0, merge_queue=0
2014-07-13 18:04:57,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:58,146 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21455 synced till here 21454
2014-07-13 18:04:58,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299881011 with entries=141, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299897569
2014-07-13 18:04:58,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299845645
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299851134
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299853239
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299855301
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299856480
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299859492
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299860907
2014-07-13 18:04:58,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299870607
2014-07-13 18:04:59,150 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:04:59,184 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299897569 with entries=62, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299899151
2014-07-13 18:05:00,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:00,369 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21579 synced till here 21575
2014-07-13 18:05:00,465 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299899151 with entries=62, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299900343
2014-07-13 18:05:00,960 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:05:00,960 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 256.7m
2014-07-13 18:05:01,101 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:03,016 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:03,126 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21673 synced till here 21668
2014-07-13 18:05:03,148 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299900343 with entries=94, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299903017
2014-07-13 18:05:03,574 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:05:03,575 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 261.5m
2014-07-13 18:05:03,724 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:04,220 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:04,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21769 synced till here 21766
2014-07-13 18:05:04,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299903017 with entries=96, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299904220
2014-07-13 18:05:07,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:07,247 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21838 synced till here 21835
2014-07-13 18:05:07,294 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299904220 with entries=69, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299907230
2014-07-13 18:05:08,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:08,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299907230 with entries=83, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299908536
2014-07-13 18:05:09,734 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5661, memsize=256.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/0f37a6d74b254f8db2a7ce7ccef0c3a8
2014-07-13 18:05:09,749 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/0f37a6d74b254f8db2a7ce7ccef0c3a8 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/0f37a6d74b254f8db2a7ce7ccef0c3a8
2014-07-13 18:05:09,796 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/0f37a6d74b254f8db2a7ce7ccef0c3a8, entries=934580, sequenceid=5661, filesize=66.6m
2014-07-13 18:05:09,797 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~256.7m/269151200, currentsize=111.6m/117025600 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 8837ms, sequenceid=5661, compaction requested=true
2014-07-13 18:05:09,797 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:45), split_queue=0, merge_queue=0
2014-07-13 18:05:11,642 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:11,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 21999 synced till here 21991
2014-07-13 18:05:11,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299908536 with entries=78, filesize=70.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299911672
2014-07-13 18:05:12,009 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:05:12,009 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 257.4m
2014-07-13 18:05:12,095 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:05:12,213 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:12,726 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5669, memsize=259.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ea8c2ddd0c064464a0f8f2eb103606b2
2014-07-13 18:05:12,740 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ea8c2ddd0c064464a0f8f2eb103606b2 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ea8c2ddd0c064464a0f8f2eb103606b2
2014-07-13 18:05:12,752 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ea8c2ddd0c064464a0f8f2eb103606b2, entries=946190, sequenceid=5669, filesize=67.4m
2014-07-13 18:05:12,753 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~261.5m/274162320, currentsize=142.9m/149816720 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 9178ms, sequenceid=5669, compaction requested=true
2014-07-13 18:05:12,753 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:46), split_queue=0, merge_queue=0
2014-07-13 18:05:12,753 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 269.1m
2014-07-13 18:05:12,881 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:12,904 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22061 synced till here 22060
2014-07-13 18:05:12,954 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299911672 with entries=62, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299912882
2014-07-13 18:05:12,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299872213
2014-07-13 18:05:12,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299873618
2014-07-13 18:05:12,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299875426
2014-07-13 18:05:12,955 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299877101
2014-07-13 18:05:12,955 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299879482
2014-07-13 18:05:12,955 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:14,327 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:14,587 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22142 synced till here 22141
2014-07-13 18:05:14,602 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299912882 with entries=81, filesize=75.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299914327
2014-07-13 18:05:15,637 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:15,780 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22211 synced till here 22208
2014-07-13 18:05:15,813 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299914327 with entries=69, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299915637
2014-07-13 18:05:16,770 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:05:16,869 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:16,924 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22280 synced till here 22277
2014-07-13 18:05:16,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299915637 with entries=69, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299916870
2014-07-13 18:05:18,879 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:05:19,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:19,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22346 synced till here 22345
2014-07-13 18:05:19,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299916870 with entries=66, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299919004
2014-07-13 18:05:20,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:20,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22417 synced till here 22416
2014-07-13 18:05:20,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299919004 with entries=71, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299920275
2014-07-13 18:05:21,043 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5278, memsize=251.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/e68905eb1af741258cab1c4cd9870a32
2014-07-13 18:05:21,065 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/e68905eb1af741258cab1c4cd9870a32 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/e68905eb1af741258cab1c4cd9870a32
2014-07-13 18:05:21,087 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/e68905eb1af741258cab1c4cd9870a32, entries=916930, sequenceid=5278, filesize=65.3m
2014-07-13 18:05:21,087 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.0m/273713040, currentsize=175.8m/184390320 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 9078ms, sequenceid=5278, compaction requested=true
2014-07-13 18:05:21,087 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:47), split_queue=0, merge_queue=0
2014-07-13 18:05:21,088 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 336.1m
2014-07-13 18:05:21,263 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:21,907 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5287, memsize=266.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a840ff105daa4604b2823457d2d833ae
2014-07-13 18:05:21,923 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a840ff105daa4604b2823457d2d833ae as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a840ff105daa4604b2823457d2d833ae
2014-07-13 18:05:21,932 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a840ff105daa4604b2823457d2d833ae, entries=971790, sequenceid=5287, filesize=69.2m
2014-07-13 18:05:21,933 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~275.9m/289276720, currentsize=160.3m/168080240 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 9180ms, sequenceid=5287, compaction requested=true
2014-07-13 18:05:21,934 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:48), split_queue=0, merge_queue=0
2014-07-13 18:05:21,934 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 311.5m
2014-07-13 18:05:22,101 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:30,348 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5904, memsize=316.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ea460f6a20554bd39e51370deccd5404
2014-07-13 18:05:30,363 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ea460f6a20554bd39e51370deccd5404 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ea460f6a20554bd39e51370deccd5404
2014-07-13 18:05:30,381 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ea460f6a20554bd39e51370deccd5404, entries=1152280, sequenceid=5904, filesize=82.1m
2014-07-13 18:05:30,382 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~336.1m/352447680, currentsize=0.0/0 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 9294ms, sequenceid=5904, compaction requested=true
2014-07-13 18:05:30,382 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:49), split_queue=0, merge_queue=0
2014-07-13 18:05:30,593 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5891, memsize=291.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1e458ffd3de84be1a5384b7392b3839c
2014-07-13 18:05:30,603 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1e458ffd3de84be1a5384b7392b3839c as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1e458ffd3de84be1a5384b7392b3839c
2014-07-13 18:05:30,612 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1e458ffd3de84be1a5384b7392b3839c, entries=1062930, sequenceid=5891, filesize=75.7m
2014-07-13 18:05:30,612 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~311.5m/326608480, currentsize=0.0/0 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 8678ms, sequenceid=5891, compaction requested=true
2014-07-13 18:05:30,612 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:50), split_queue=0, merge_queue=0
2014-07-13 18:05:32,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:32,858 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22557 synced till here 22556
2014-07-13 18:05:32,994 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299920275 with entries=140, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299932340
2014-07-13 18:05:32,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299881011
2014-07-13 18:05:32,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299897569
2014-07-13 18:05:32,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299899151
2014-07-13 18:05:32,995 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299900343
2014-07-13 18:05:32,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299903017
2014-07-13 18:05:32,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299904220
2014-07-13 18:05:32,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299907230
2014-07-13 18:05:32,996 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299908536
2014-07-13 18:05:34,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:34,457 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22651 synced till here 22650
2014-07-13 18:05:34,585 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299932340 with entries=94, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299934240
2014-07-13 18:05:34,691 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 257.7m
2014-07-13 18:05:34,691 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:05:34,918 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:35,457 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 257.0m
2014-07-13 18:05:35,457 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:05:35,615 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:35,764 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:35,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22730 synced till here 22726
2014-07-13 18:05:35,956 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299934240 with entries=79, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299935765
2014-07-13 18:05:37,351 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:37,734 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22845 synced till here 22843
2014-07-13 18:05:37,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299935765 with entries=115, filesize=96.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299937351
2014-07-13 18:05:42,964 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5415, memsize=250.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/c35085284d134d1fb0eb5a765abbf282
2014-07-13 18:05:42,979 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/c35085284d134d1fb0eb5a765abbf282 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c35085284d134d1fb0eb5a765abbf282
2014-07-13 18:05:42,992 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c35085284d134d1fb0eb5a765abbf282, entries=912640, sequenceid=5415, filesize=65.0m
2014-07-13 18:05:42,992 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.4m/275136160, currentsize=85.2m/89324400 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 8301ms, sequenceid=5415, compaction requested=true
2014-07-13 18:05:42,993 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:51), split_queue=0, merge_queue=0
2014-07-13 18:05:43,319 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5424, memsize=252.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/67e7c9f605cd4c6f95432f0ae18941ce
2014-07-13 18:05:43,330 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/67e7c9f605cd4c6f95432f0ae18941ce as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/67e7c9f605cd4c6f95432f0ae18941ce
2014-07-13 18:05:43,344 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/67e7c9f605cd4c6f95432f0ae18941ce, entries=920510, sequenceid=5424, filesize=65.6m
2014-07-13 18:05:43,344 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.1m/272682400, currentsize=72.9m/76476480 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 7887ms, sequenceid=5424, compaction requested=true
2014-07-13 18:05:43,344 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:52), split_queue=0, merge_queue=0
2014-07-13 18:05:44,113 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:44,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 22939 synced till here 22937
2014-07-13 18:05:44,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299937351 with entries=94, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299944113
2014-07-13 18:05:44,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299911672
2014-07-13 18:05:44,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299912882
2014-07-13 18:05:44,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299914327
2014-07-13 18:05:44,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299915637
2014-07-13 18:05:44,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299916870
2014-07-13 18:05:44,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299919004
2014-07-13 18:05:47,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:47,968 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23045 synced till here 23044
2014-07-13 18:05:47,990 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299944113 with entries=106, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299947097
2014-07-13 18:05:48,675 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:48,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23133 synced till here 23125
2014-07-13 18:05:48,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299947097 with entries=88, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299948675
2014-07-13 18:05:49,599 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:05:49,599 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 257.3m
2014-07-13 18:05:49,689 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:05:49,689 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 257.1m
2014-07-13 18:05:49,731 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:49,939 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:50,950 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:50,976 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23239 synced till here 23237
2014-07-13 18:05:51,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299948675 with entries=106, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299950950
2014-07-13 18:05:52,113 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:52,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23310 synced till here 23308
2014-07-13 18:05:52,146 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299950950 with entries=71, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299952114
2014-07-13 18:05:53,625 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:53,626 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:05:53,656 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23382 synced till here 23378
2014-07-13 18:05:54,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299952114 with entries=72, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299953626
2014-07-13 18:05:54,555 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:05:56,595 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:56,614 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23472 synced till here 23468
2014-07-13 18:05:56,678 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299953626 with entries=90, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299956595
2014-07-13 18:05:57,918 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6121, memsize=257.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/255deff7f2f04286a03d8a19f960e49c
2014-07-13 18:05:57,937 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/255deff7f2f04286a03d8a19f960e49c as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/255deff7f2f04286a03d8a19f960e49c
2014-07-13 18:05:57,956 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/255deff7f2f04286a03d8a19f960e49c, entries=936960, sequenceid=6121, filesize=66.7m
2014-07-13 18:05:57,956 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.3m/269837600, currentsize=129.9m/136180320 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 8357ms, sequenceid=6121, compaction requested=true
2014-07-13 18:05:57,956 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:53), split_queue=0, merge_queue=0
2014-07-13 18:05:57,956 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 293.9m
2014-07-13 18:05:58,127 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:58,395 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6110, memsize=260.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/9003d1092a634d10bc36dd0d71ea3a99
2014-07-13 18:05:58,407 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/9003d1092a634d10bc36dd0d71ea3a99 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9003d1092a634d10bc36dd0d71ea3a99
2014-07-13 18:05:58,416 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9003d1092a634d10bc36dd0d71ea3a99, entries=948580, sequenceid=6110, filesize=67.5m
2014-07-13 18:05:58,416 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.5m/273185520, currentsize=126.8m/133002880 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 8727ms, sequenceid=6110, compaction requested=true
2014-07-13 18:05:58,416 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:54), split_queue=0, merge_queue=0
2014-07-13 18:05:58,417 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 281.2m
2014-07-13 18:05:58,630 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:05:59,979 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:05:59,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23574 synced till here 23573
2014-07-13 18:06:00,006 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299956595 with entries=102, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299959979
2014-07-13 18:06:00,007 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299920275
2014-07-13 18:06:00,007 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299932340
2014-07-13 18:06:01,234 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:01,267 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23653 synced till here 23642
2014-07-13 18:06:01,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299959979 with entries=79, filesize=75.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299961234
2014-07-13 18:06:02,459 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:02,845 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23753 synced till here 23752
2014-07-13 18:06:02,857 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299961234 with entries=100, filesize=76.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299962459
2014-07-13 18:06:07,012 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5586, memsize=293.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a601aeb1be76425a9955ed06f6f49483
2014-07-13 18:06:07,028 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a601aeb1be76425a9955ed06f6f49483 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a601aeb1be76425a9955ed06f6f49483
2014-07-13 18:06:07,041 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a601aeb1be76425a9955ed06f6f49483, entries=1070160, sequenceid=5586, filesize=76.2m
2014-07-13 18:06:07,042 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~293.9m/308198720, currentsize=94.5m/99060640 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 9086ms, sequenceid=5586, compaction requested=true
2014-07-13 18:06:07,042 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:55), split_queue=0, merge_queue=0
2014-07-13 18:06:07,576 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5589, memsize=283.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/fc05dec57aa641e7bfbc918ceacda88f
2014-07-13 18:06:07,593 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/fc05dec57aa641e7bfbc918ceacda88f as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/fc05dec57aa641e7bfbc918ceacda88f
2014-07-13 18:06:07,605 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/fc05dec57aa641e7bfbc918ceacda88f, entries=1031940, sequenceid=5589, filesize=73.5m
2014-07-13 18:06:07,606 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~283.4m/297190560, currentsize=92.9m/97458800 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 9189ms, sequenceid=5589, compaction requested=true
2014-07-13 18:06:07,606 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:56), split_queue=0, merge_queue=0
2014-07-13 18:06:29,017 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:29,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23866 synced till here 23863
2014-07-13 18:06:29,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299962459 with entries=113, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299989018
2014-07-13 18:06:29,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299934240
2014-07-13 18:06:29,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299935765
2014-07-13 18:06:29,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299937351
2014-07-13 18:06:29,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299944113
2014-07-13 18:06:29,056 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299947097
2014-07-13 18:06:29,922 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:06:29,923 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 258.9m
2014-07-13 18:06:30,115 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:06:30,118 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:06:30,119 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.4m
2014-07-13 18:06:30,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:30,283 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 23938 synced till here 23936
2014-07-13 18:06:30,311 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:06:30,349 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299989018 with entries=72, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299990264
2014-07-13 18:06:31,526 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:31,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299990264 with entries=66, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299991527
2014-07-13 18:06:34,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:34,190 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24074 synced till here 24073
2014-07-13 18:06:34,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299991527 with entries=70, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299994146
2014-07-13 18:06:36,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:36,632 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24143 synced till here 24142
2014-07-13 18:06:36,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299994146 with entries=69, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299996503
2014-07-13 18:06:37,703 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:06:37,898 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:06:37,987 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:38,007 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24210 synced till here 24208
2014-07-13 18:06:38,036 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299996503 with entries=67, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299997987
2014-07-13 18:06:39,004 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6352, memsize=261.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/3bd44d9913be4b1babb48047614a2eb1
2014-07-13 18:06:39,024 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/3bd44d9913be4b1babb48047614a2eb1 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3bd44d9913be4b1babb48047614a2eb1
2014-07-13 18:06:39,059 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3bd44d9913be4b1babb48047614a2eb1, entries=951960, sequenceid=6352, filesize=67.8m
2014-07-13 18:06:39,059 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~261.5m/274157520, currentsize=141.5m/148410080 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 9136ms, sequenceid=6352, compaction requested=true
2014-07-13 18:06:39,059 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:57), split_queue=0, merge_queue=0
2014-07-13 18:06:39,060 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 278.8m
2014-07-13 18:06:39,220 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6343, memsize=260.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/bd617ebba34346bbbf4b43f68bec106b
2014-07-13 18:06:39,233 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/bd617ebba34346bbbf4b43f68bec106b as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd617ebba34346bbbf4b43f68bec106b
2014-07-13 18:06:39,244 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd617ebba34346bbbf4b43f68bec106b, entries=947280, sequenceid=6343, filesize=67.5m
2014-07-13 18:06:39,244 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.2m/272807840, currentsize=139.4m/146149920 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 9125ms, sequenceid=6343, compaction requested=true
2014-07-13 18:06:39,245 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:58), split_queue=0, merge_queue=0
2014-07-13 18:06:39,245 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 276.2m
2014-07-13 18:06:39,399 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:06:40,559 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:40,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24294 synced till here 24272
2014-07-13 18:06:40,712 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:06:40,736 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299997987 with entries=84, filesize=79.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300000560
2014-07-13 18:06:40,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299948675
2014-07-13 18:06:40,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299950950
2014-07-13 18:06:40,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299952114
2014-07-13 18:06:40,737 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299953626
2014-07-13 18:06:42,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:42,653 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24399 synced till here 24364
2014-07-13 18:06:42,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300000560 with entries=105, filesize=87.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300002590
2014-07-13 18:06:44,928 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:44,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24517 synced till here 24491
2014-07-13 18:06:45,225 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300002590 with entries=118, filesize=100.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300004929
2014-07-13 18:06:46,733 DEBUG [RpcServer.handler=5,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:06:46,974 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:47,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24630 synced till here 24596
2014-07-13 18:06:48,135 DEBUG [RpcServer.handler=29,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:06:48,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300004929 with entries=113, filesize=94.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300006974
2014-07-13 18:06:49,854 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1006ms
GC pool 'ParNew' had collection(s): count=1 time=1108ms
2014-07-13 18:06:50,081 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:50,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24733 synced till here 24699
2014-07-13 18:06:50,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300006974 with entries=103, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300010082
2014-07-13 18:06:52,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:52,293 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24841 synced till here 24812
2014-07-13 18:06:52,567 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300010082 with entries=108, filesize=93.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300012279
2014-07-13 18:06:54,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:54,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 24967 synced till here 24921
2014-07-13 18:06:54,724 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300012279 with entries=126, filesize=108.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300014369
2014-07-13 18:06:56,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:56,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25131 synced till here 25128
2014-07-13 18:06:56,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300014369 with entries=164, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300016344
2014-07-13 18:06:57,090 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5735, memsize=276.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a9cf951820cb488f9d804c53cea0dd7b
2014-07-13 18:06:57,106 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a9cf951820cb488f9d804c53cea0dd7b as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9cf951820cb488f9d804c53cea0dd7b
2014-07-13 18:06:57,123 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9cf951820cb488f9d804c53cea0dd7b, entries=1005090, sequenceid=5735, filesize=71.6m
2014-07-13 18:06:57,123 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~287.8m/301796800, currentsize=315.2m/330519760 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 18064ms, sequenceid=5735, compaction requested=true
2014-07-13 18:06:57,124 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:59), split_queue=0, merge_queue=0
2014-07-13 18:06:57,124 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 463.8m
2014-07-13 18:06:57,176 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:06:57,537 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:57,757 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:06:58,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25245 synced till here 25237
2014-07-13 18:06:58,283 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300016344 with entries=114, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300017537
2014-07-13 18:06:58,422 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=5738, memsize=274.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/585fd6cf14a24136b13a13276b5929a3
2014-07-13 18:06:58,440 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/585fd6cf14a24136b13a13276b5929a3 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/585fd6cf14a24136b13a13276b5929a3
2014-07-13 18:06:58,515 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/585fd6cf14a24136b13a13276b5929a3, entries=999920, sequenceid=5738, filesize=71.2m
2014-07-13 18:06:58,515 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~286.6m/300496000, currentsize=339.7m/356184960 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 19270ms, sequenceid=5738, compaction requested=true
2014-07-13 18:06:58,516 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-13 18:06:58,516 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 492.2m
2014-07-13 18:06:58,557 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:06:59,058 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:06:59,060 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:06:59,738 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300017537 with entries=85, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300019059
2014-07-13 18:06:59,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299956595
2014-07-13 18:06:59,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299959979
2014-07-13 18:06:59,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299961234
2014-07-13 18:06:59,739 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299962459
2014-07-13 18:07:00,397 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:00,866 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25401 synced till here 25392
2014-07-13 18:07:00,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300019059 with entries=71, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300020398
2014-07-13 18:07:01,655 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:01,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25461 synced till here 25460
2014-07-13 18:07:01,721 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300020398 with entries=60, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300021655
2014-07-13 18:07:02,399 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/f2aa1b3daf4248db8701f5529680093f as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/f2aa1b3daf4248db8701f5529680093f
2014-07-13 18:07:02,419 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:07:02,431 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4dc86f1555544833a256289cf94ef674, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4dc86f1555544833a256289cf94ef674
2014-07-13 18:07:02,438 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c15dc97ee7874bb483f7affb46d221e6, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c15dc97ee7874bb483f7affb46d221e6
2014-07-13 18:07:02,440 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/afc384a8a32047cab9ab4766064ebd38, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/afc384a8a32047cab9ab4766064ebd38
2014-07-13 18:07:02,443 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ecf86536d7754f4da119ed413d4cdbc8, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ecf86536d7754f4da119ed413d4cdbc8
2014-07-13 18:07:02,446 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/80045fa76bbf4fba81ec84f42b8e8f40, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/80045fa76bbf4fba81ec84f42b8e8f40
2014-07-13 18:07:02,450 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6dfbcfde30ab463db3a691976cd8e33e, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6dfbcfde30ab463db3a691976cd8e33e
2014-07-13 18:07:02,459 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d97f41a0d2904936999a60bd444809d3, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d97f41a0d2904936999a60bd444809d3
2014-07-13 18:07:02,471 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4e7447a976a74b17b7b298120de12773, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/4e7447a976a74b17b7b298120de12773
2014-07-13 18:07:02,477 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d0410b87af344bd09668823e4c34ac72, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d0410b87af344bd09668823e4c34ac72
2014-07-13 18:07:02,483 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a6b5f1612ad7426b8ace016b72e60c17, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a6b5f1612ad7426b8ace016b72e60c17
2014-07-13 18:07:02,483 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into f2aa1b3daf4248db8701f5529680093f(size=871.8m), total size for store is 1.6g. This selection was in queue for 0sec, and took 2mins, 21sec to execute.
2014-07-13 18:07:02,483 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=10, fileSize=911.7m, priority=7, time=253787941643042; duration=2mins, 21sec
2014-07-13 18:07:02,484 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-13 18:07:02,484 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-13 18:07:02,486 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 884502056 starting at candidate #7 after considering 92 permutations with 89 in ratio
2014-07-13 18:07:02,486 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:07:02,487 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:07:02,487 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=843.5m
2014-07-13 18:07:02,487 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/accc5e61cdd749fca004a1bb9333f49a, keycount=175108, bloomtype=ROW, size=124.8m, encoding=NONE, seqNum=4015
2014-07-13 18:07:02,487 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/58591163e6ba431289c8f17808186f37, keycount=156013, bloomtype=ROW, size=111.1m, encoding=NONE, seqNum=4424
2014-07-13 18:07:02,487 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/8709335b71e440a3aca1a433a64c0a7f, keycount=164492, bloomtype=ROW, size=117.2m, encoding=NONE, seqNum=4678
2014-07-13 18:07:02,487 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a0d6b75556bd4e42bc46ca41f1f80521, keycount=91781, bloomtype=ROW, size=65.4m, encoding=NONE, seqNum=4811
2014-07-13 18:07:02,487 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1424bc1acb164111bf3f7d25958102a9, keycount=103744, bloomtype=ROW, size=73.9m, encoding=NONE, seqNum=4996
2014-07-13 18:07:02,487 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/60b6217ba83c45889dc2db8a2f1567ff, keycount=100831, bloomtype=ROW, size=71.8m, encoding=NONE, seqNum=5148
2014-07-13 18:07:02,488 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a840ff105daa4604b2823457d2d833ae, keycount=97179, bloomtype=ROW, size=69.2m, encoding=NONE, seqNum=5287
2014-07-13 18:07:02,488 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/67e7c9f605cd4c6f95432f0ae18941ce, keycount=92051, bloomtype=ROW, size=65.6m, encoding=NONE, seqNum=5424
2014-07-13 18:07:02,488 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/fc05dec57aa641e7bfbc918ceacda88f, keycount=103194, bloomtype=ROW, size=73.5m, encoding=NONE, seqNum=5589
2014-07-13 18:07:02,488 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/585fd6cf14a24136b13a13276b5929a3, keycount=99992, bloomtype=ROW, size=71.2m, encoding=NONE, seqNum=5738
2014-07-13 18:07:02,995 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:03,945 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:03,963 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25530 synced till here 25529
2014-07-13 18:07:04,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300021655 with entries=69, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300023945
2014-07-13 18:07:05,172 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:05,987 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6674, memsize=179.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/001ffb3717364543ac1367f028052016
2014-07-13 18:07:06,014 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/001ffb3717364543ac1367f028052016 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/001ffb3717364543ac1367f028052016
2014-07-13 18:07:06,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300023945 with entries=63, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300025172
2014-07-13 18:07:06,077 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/001ffb3717364543ac1367f028052016, entries=655020, sequenceid=6674, filesize=46.7m
2014-07-13 18:07:06,077 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~474.4m/497433920, currentsize=180.6m/189382640 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 8953ms, sequenceid=6674, compaction requested=true
2014-07-13 18:07:06,077 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:60), split_queue=0, merge_queue=0
2014-07-13 18:07:06,078 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 480.3m
2014-07-13 18:07:06,445 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:07,791 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:07,841 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6676, memsize=198.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/8687feff819240f4ab888cda483fb82e
2014-07-13 18:07:08,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25667 synced till here 25661
2014-07-13 18:07:08,169 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/8687feff819240f4ab888cda483fb82e as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8687feff819240f4ab888cda483fb82e
2014-07-13 18:07:08,182 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8687feff819240f4ab888cda483fb82e, entries=724190, sequenceid=6676, filesize=51.6m
2014-07-13 18:07:08,182 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~497.5m/521641200, currentsize=185.3m/194282000 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 9666ms, sequenceid=6676, compaction requested=true
2014-07-13 18:07:08,183 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:61), split_queue=0, merge_queue=0
2014-07-13 18:07:08,183 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 510.3m
2014-07-13 18:07:08,227 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300025172 with entries=74, filesize=70.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300027792
2014-07-13 18:07:08,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299989018
2014-07-13 18:07:08,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299990264
2014-07-13 18:07:08,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299991527
2014-07-13 18:07:08,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299994146
2014-07-13 18:07:08,229 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299996503
2014-07-13 18:07:08,607 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:09,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:09,793 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25732 synced till here 25731
2014-07-13 18:07:09,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300027792 with entries=65, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300029479
2014-07-13 18:07:10,283 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:07:11,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:11,506 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25804 synced till here 25803
2014-07-13 18:07:11,523 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300029479 with entries=72, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300031436
2014-07-13 18:07:11,832 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:07:12,427 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:12,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300031436 with entries=61, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300032428
2014-07-13 18:07:14,406 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:14,752 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 25937 synced till here 25936
2014-07-13 18:07:14,761 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300032428 with entries=72, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300034407
2014-07-13 18:07:14,994 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6073, memsize=215.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/5d3853d6245a41a3aedd8f36487f90f3
2014-07-13 18:07:15,008 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/5d3853d6245a41a3aedd8f36487f90f3 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/5d3853d6245a41a3aedd8f36487f90f3
2014-07-13 18:07:15,023 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/5d3853d6245a41a3aedd8f36487f90f3, entries=782700, sequenceid=6073, filesize=55.8m
2014-07-13 18:07:15,023 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~480.3m/503660640, currentsize=169.2m/177406240 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 8945ms, sequenceid=6073, compaction requested=true
2014-07-13 18:07:15,023 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:62), split_queue=0, merge_queue=0
2014-07-13 18:07:15,024 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 330.8m
2014-07-13 18:07:15,249 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:15,574 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:16,026 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26015 synced till here 26013
2014-07-13 18:07:16,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300034407 with entries=78, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300035574
2014-07-13 18:07:17,996 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:18,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26083 synced till here 26082
2014-07-13 18:07:18,052 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300035574 with entries=68, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300037996
2014-07-13 18:07:18,140 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6091, memsize=242.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/427379afeb9a47979408745cebd4dfad
2014-07-13 18:07:18,156 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/427379afeb9a47979408745cebd4dfad as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/427379afeb9a47979408745cebd4dfad
2014-07-13 18:07:18,168 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/427379afeb9a47979408745cebd4dfad, entries=882630, sequenceid=6091, filesize=62.9m
2014-07-13 18:07:18,168 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~515.6m/540628320, currentsize=180.7m/189484400 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 9985ms, sequenceid=6091, compaction requested=true
2014-07-13 18:07:18,169 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:63), split_queue=0, merge_queue=0
2014-07-13 18:07:18,169 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 363.7m
2014-07-13 18:07:18,414 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:18,770 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:18,785 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26149 synced till here 26146
2014-07-13 18:07:18,848 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300037996 with entries=66, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300038770
2014-07-13 18:07:18,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405299997987
2014-07-13 18:07:18,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300000560
2014-07-13 18:07:18,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300002590
2014-07-13 18:07:18,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300004929
2014-07-13 18:07:18,848 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300006974
2014-07-13 18:07:18,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300010082
2014-07-13 18:07:18,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300012279
2014-07-13 18:07:18,849 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300014369
2014-07-13 18:07:19,544 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:07:19,953 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:19,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26216 synced till here 26213
2014-07-13 18:07:20,171 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300038770 with entries=67, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300039953
2014-07-13 18:07:21,149 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:07:21,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:21,922 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26302 synced till here 26298
2014-07-13 18:07:21,991 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300039953 with entries=86, filesize=83.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300041319
2014-07-13 18:07:23,289 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:23,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26378 synced till here 26376
2014-07-13 18:07:23,733 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300041319 with entries=76, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300043289
2014-07-13 18:07:24,520 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:25,036 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26461 synced till here 26460
2014-07-13 18:07:25,469 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300043289 with entries=83, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300044520
2014-07-13 18:07:27,110 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1093ms
GC pool 'ParNew' had collection(s): count=1 time=1122ms
2014-07-13 18:07:27,340 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:27,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26567 synced till here 26553
2014-07-13 18:07:27,553 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300044520 with entries=106, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300047340
2014-07-13 18:07:28,107 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6875, memsize=301.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/634cedb551464b83bbb57af979650341
2014-07-13 18:07:28,124 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/634cedb551464b83bbb57af979650341 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/634cedb551464b83bbb57af979650341
2014-07-13 18:07:29,021 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/634cedb551464b83bbb57af979650341, entries=1097070, sequenceid=6875, filesize=78.1m
2014-07-13 18:07:29,023 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~330.8m/346875760, currentsize=258.8m/271359760 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 13998ms, sequenceid=6875, compaction requested=true
2014-07-13 18:07:29,023 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:64), split_queue=0, merge_queue=0
2014-07-13 18:07:29,023 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 451.5m
2014-07-13 18:07:29,087 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:07:29,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:29,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26764 synced till here 26741
2014-07-13 18:07:29,932 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:29,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300047340 with entries=197, filesize=120.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300049503
2014-07-13 18:07:29,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300016344
2014-07-13 18:07:31,463 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:31,507 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 26873 synced till here 26860
2014-07-13 18:07:31,647 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300049503 with entries=109, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300051463
2014-07-13 18:07:34,309 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:34,419 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27002 synced till here 26987
2014-07-13 18:07:34,540 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300051463 with entries=129, filesize=95.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300054309
2014-07-13 18:07:35,233 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:35,806 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27110 synced till here 27101
2014-07-13 18:07:35,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300054309 with entries=108, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300055234
2014-07-13 18:07:36,361 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6896, memsize=336.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/d0e292a1f913494eaa83699bd5ea5086
2014-07-13 18:07:36,374 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/d0e292a1f913494eaa83699bd5ea5086 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d0e292a1f913494eaa83699bd5ea5086
2014-07-13 18:07:36,385 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d0e292a1f913494eaa83699bd5ea5086, entries=1225030, sequenceid=6896, filesize=87.2m
2014-07-13 18:07:36,386 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~369.6m/387502160, currentsize=367.6m/385470720 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 18217ms, sequenceid=6896, compaction requested=true
2014-07-13 18:07:36,386 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:65), split_queue=0, merge_queue=0
2014-07-13 18:07:36,386 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 556.7m
2014-07-13 18:07:36,405 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:07:36,559 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:37,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27224 synced till here 27222
2014-07-13 18:07:37,235 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:37,247 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300055234 with entries=114, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300056559
2014-07-13 18:07:37,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300017537
2014-07-13 18:07:37,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300019059
2014-07-13 18:07:37,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300020398
2014-07-13 18:07:37,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300021655
2014-07-13 18:07:37,248 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300023945
2014-07-13 18:07:37,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:37,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27338 synced till here 27321
2014-07-13 18:07:38,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300056559 with entries=114, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300057927
2014-07-13 18:07:39,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:39,233 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300057927 with entries=61, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300059205
2014-07-13 18:07:41,189 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:41,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27472 synced till here 27465
2014-07-13 18:07:41,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300059205 with entries=73, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300061686
2014-07-13 18:07:42,413 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:42,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27539 synced till here 27538
2014-07-13 18:07:42,463 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300061686 with entries=67, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300062414
2014-07-13 18:07:43,610 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:44,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27630 synced till here 27629
2014-07-13 18:07:44,358 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300062414 with entries=91, filesize=85.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300063610
2014-07-13 18:07:45,537 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:45,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27712 synced till here 27697
2014-07-13 18:07:45,906 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300063610 with entries=82, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300065538
2014-07-13 18:07:47,204 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:47,629 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27830 synced till here 27824
2014-07-13 18:07:47,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300065538 with entries=118, filesize=104.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300067205
2014-07-13 18:07:48,295 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6379, memsize=376.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/f32f2b78c5324774ad27291fb84b3f6d
2014-07-13 18:07:48,308 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/f32f2b78c5324774ad27291fb84b3f6d as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/f32f2b78c5324774ad27291fb84b3f6d
2014-07-13 18:07:48,319 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/f32f2b78c5324774ad27291fb84b3f6d, entries=1371510, sequenceid=6379, filesize=97.7m
2014-07-13 18:07:48,319 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~466.1m/488689120, currentsize=372.2m/390295680 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 19296ms, sequenceid=6379, compaction requested=true
2014-07-13 18:07:48,319 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:66), split_queue=0, merge_queue=0
2014-07-13 18:07:48,320 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 728.6m
2014-07-13 18:07:48,379 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:07:48,752 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:48,881 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:49,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 27944 synced till here 27943
2014-07-13 18:07:49,659 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300067205 with entries=114, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300068752
2014-07-13 18:07:49,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300025172
2014-07-13 18:07:50,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:50,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28007 synced till here 28006
2014-07-13 18:07:51,192 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300068752 with entries=63, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300070787
2014-07-13 18:07:52,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:52,209 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300070787 with entries=68, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300072166
2014-07-13 18:07:53,038 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6528, memsize=362.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/07bf2fd1db644795b184c60c5ed53c4e
2014-07-13 18:07:53,049 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/07bf2fd1db644795b184c60c5ed53c4e as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/07bf2fd1db644795b184c60c5ed53c4e
2014-07-13 18:07:53,067 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/07bf2fd1db644795b184c60c5ed53c4e, entries=1320050, sequenceid=6528, filesize=94.0m
2014-07-13 18:07:53,068 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~561.7m/588954240, currentsize=329.2m/345184560 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 16681ms, sequenceid=6528, compaction requested=true
2014-07-13 18:07:53,068 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:67), split_queue=0, merge_queue=0
2014-07-13 18:07:53,068 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 771.3m
2014-07-13 18:07:53,208 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:07:53,560 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:53,653 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28156 synced till here 28146
2014-07-13 18:07:54,062 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300072166 with entries=81, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300073560
2014-07-13 18:07:54,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300027792
2014-07-13 18:07:54,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300029479
2014-07-13 18:07:54,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300031436
2014-07-13 18:07:54,066 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300032428
2014-07-13 18:07:54,071 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:07:54,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:54,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28226 synced till here 28225
2014-07-13 18:07:55,020 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300073560 with entries=70, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300074961
2014-07-13 18:07:56,093 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:56,113 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28307 synced till here 28305
2014-07-13 18:07:56,130 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300074961 with entries=81, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300076093
2014-07-13 18:07:57,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:57,349 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28401 synced till here 28397
2014-07-13 18:07:57,459 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300076093 with entries=94, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300077315
2014-07-13 18:07:58,694 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:07:58,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28535 synced till here 28515
2014-07-13 18:07:58,818 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300077315 with entries=134, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300078694
2014-07-13 18:08:00,556 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:01,338 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28674 synced till here 28658
2014-07-13 18:08:01,550 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300078694 with entries=139, filesize=89.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300080556
2014-07-13 18:08:03,378 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:03,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28782 synced till here 28767
2014-07-13 18:08:03,658 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300080556 with entries=108, filesize=103.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300083378
2014-07-13 18:08:05,034 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:05,074 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28850 synced till here 28846
2014-07-13 18:08:05,144 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300083378 with entries=68, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300085034
2014-07-13 18:08:06,673 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:06,728 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 28929 synced till here 28922
2014-07-13 18:08:06,800 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300085034 with entries=79, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300086674
2014-07-13 18:08:08,620 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:08,659 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29005 synced till here 28998
2014-07-13 18:08:08,765 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300086674 with entries=76, filesize=66.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300088620
2014-07-13 18:08:10,150 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.41 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=175956, hits=43216, hitRatio=24.56%, , cachingAccesses=43236, cachingHits=43198, cachingHitsRatio=99.91%, evictions=0, evicted=34, evictedPerRun=Infinity
2014-07-13 18:08:10,464 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:10,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29070 synced till here 29064
2014-07-13 18:08:10,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300088620 with entries=65, filesize=66.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300090465
2014-07-13 18:08:11,896 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:11,907 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7294, memsize=454.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/a925dffe9b7845feb05462336ac34e1a
2014-07-13 18:08:11,926 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29136 synced till here 29134
2014-07-13 18:08:11,928 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/a925dffe9b7845feb05462336ac34e1a as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a925dffe9b7845feb05462336ac34e1a
2014-07-13 18:08:11,947 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a925dffe9b7845feb05462336ac34e1a, entries=1652960, sequenceid=7294, filesize=117.7m
2014-07-13 18:08:11,947 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~730.1m/765590160, currentsize=485.7m/509305440 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 23627ms, sequenceid=7294, compaction requested=true
2014-07-13 18:08:11,947 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:68), split_queue=0, merge_queue=0
2014-07-13 18:08:11,948 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 863.1m
2014-07-13 18:08:11,966 DEBUG [RpcServer.handler=41,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:08:11,977 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300090465 with entries=66, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300091896
2014-07-13 18:08:11,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300034407
2014-07-13 18:08:11,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300035574
2014-07-13 18:08:13,382 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:13,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29227 synced till here 29211
2014-07-13 18:08:13,482 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:08:13,561 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300091896 with entries=91, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300093384
2014-07-13 18:08:14,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:14,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29307 synced till here 29305
2014-07-13 18:08:15,116 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300093384 with entries=80, filesize=71.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300094727
2014-07-13 18:08:16,832 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:17,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29445 synced till here 29421
2014-07-13 18:08:18,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300094727 with entries=138, filesize=123.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300096832
2014-07-13 18:08:20,056 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:20,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29544 synced till here 29529
2014-07-13 18:08:20,303 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300096832 with entries=99, filesize=92.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300100056
2014-07-13 18:08:21,282 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7338, memsize=497.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/4fb19225f3904a34956bc397bf5a67b2
2014-07-13 18:08:21,296 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/4fb19225f3904a34956bc397bf5a67b2 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/4fb19225f3904a34956bc397bf5a67b2
2014-07-13 18:08:21,310 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/4fb19225f3904a34956bc397bf5a67b2, entries=1812280, sequenceid=7338, filesize=129.0m
2014-07-13 18:08:21,310 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~775.6m/813286080, currentsize=556.5m/583515920 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 28242ms, sequenceid=7338, compaction requested=true
2014-07-13 18:08:21,311 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:69), split_queue=0, merge_queue=0
2014-07-13 18:08:21,311 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 914.9m
2014-07-13 18:08:21,358 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:08:21,396 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:21,420 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29618 synced till here 29617
2014-07-13 18:08:21,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300100056 with entries=74, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300101397
2014-07-13 18:08:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300037996
2014-07-13 18:08:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300038770
2014-07-13 18:08:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300039953
2014-07-13 18:08:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300041319
2014-07-13 18:08:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300043289
2014-07-13 18:08:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300044520
2014-07-13 18:08:22,016 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:08:26,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:27,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29722 synced till here 29721
2014-07-13 18:08:27,370 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300101397 with entries=104, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300106801
2014-07-13 18:08:29,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:29,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29794 synced till here 29791
2014-07-13 18:08:29,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300106801 with entries=72, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300109358
2014-07-13 18:08:30,249 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:30,649 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29872 synced till here 29871
2014-07-13 18:08:30,685 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300109358 with entries=78, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300110249
2014-07-13 18:08:35,172 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:35,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 29963 synced till here 29962
2014-07-13 18:08:35,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300110249 with entries=91, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300115173
2014-07-13 18:08:36,485 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:36,656 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30034 synced till here 30022
2014-07-13 18:08:36,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300115173 with entries=71, filesize=75.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300116635
2014-07-13 18:08:38,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:38,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30111 synced till here 30105
2014-07-13 18:08:38,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300116635 with entries=77, filesize=69.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300118494
2014-07-13 18:08:39,182 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7016, memsize=630.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/6f80a49304b04279be546633e4465b7c
2014-07-13 18:08:39,196 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/6f80a49304b04279be546633e4465b7c as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6f80a49304b04279be546633e4465b7c
2014-07-13 18:08:39,206 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6f80a49304b04279be546633e4465b7c, entries=2294800, sequenceid=7016, filesize=163.2m
2014-07-13 18:08:39,206 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~867.9m/910082400, currentsize=394.9m/414091520 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 27258ms, sequenceid=7016, compaction requested=true
2014-07-13 18:08:39,207 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:70), split_queue=0, merge_queue=0
2014-07-13 18:08:39,207 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 868.5m
2014-07-13 18:08:39,229 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:08:39,590 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:39,605 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30172 synced till here 30171
2014-07-13 18:08:39,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300118494 with entries=61, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300119590
2014-07-13 18:08:39,621 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300047340
2014-07-13 18:08:39,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300049503
2014-07-13 18:08:39,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300051463
2014-07-13 18:08:39,622 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300054309
2014-07-13 18:08:39,980 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:08:43,608 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:43,833 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30277 synced till here 30268
2014-07-13 18:08:44,190 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300119590 with entries=105, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300123609
2014-07-13 18:08:45,511 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:45,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30349 synced till here 30348
2014-07-13 18:08:45,855 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300123609 with entries=72, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300125512
2014-07-13 18:08:45,998 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7136, memsize=652.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/2ebe4a4205fc48ca921bb574c5638b2b
2014-07-13 18:08:46,019 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/2ebe4a4205fc48ca921bb574c5638b2b as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2ebe4a4205fc48ca921bb574c5638b2b
2014-07-13 18:08:46,035 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2ebe4a4205fc48ca921bb574c5638b2b, entries=2374650, sequenceid=7136, filesize=168.9m
2014-07-13 18:08:46,036 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~924.6m/969561920, currentsize=282.4m/296145200 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 24725ms, sequenceid=7136, compaction requested=true
2014-07-13 18:08:46,036 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:71), split_queue=0, merge_queue=0
2014-07-13 18:08:46,037 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 849.0m
2014-07-13 18:08:46,114 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:08:46,715 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:08:46,772 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:46,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30417 synced till here 30413
2014-07-13 18:08:46,892 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300125512 with entries=68, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300126772
2014-07-13 18:08:46,893 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300055234
2014-07-13 18:08:46,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300056559
2014-07-13 18:08:46,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300057927
2014-07-13 18:08:46,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300059205
2014-07-13 18:08:46,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300061686
2014-07-13 18:08:46,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300062414
2014-07-13 18:08:46,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300063610
2014-07-13 18:08:46,895 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300065538
2014-07-13 18:08:48,905 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:48,929 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300126772 with entries=71, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300128905
2014-07-13 18:08:50,170 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:50,192 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30558 synced till here 30557
2014-07-13 18:08:50,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300128905 with entries=70, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300130171
2014-07-13 18:08:51,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:51,786 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30636 synced till here 30622
2014-07-13 18:08:51,866 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300130171 with entries=78, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300131734
2014-07-13 18:08:53,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:53,746 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30721 synced till here 30717
2014-07-13 18:08:53,798 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300131734 with entries=85, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300133107
2014-07-13 18:08:54,455 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:08:54,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30790 synced till here 30783
2014-07-13 18:08:54,983 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300133107 with entries=69, filesize=69.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300134455
2014-07-13 18:09:03,338 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7896, memsize=639.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/698a82ab92e14a39a971a2744b982abf
2014-07-13 18:09:03,352 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/698a82ab92e14a39a971a2744b982abf as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/698a82ab92e14a39a971a2744b982abf
2014-07-13 18:09:03,362 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/698a82ab92e14a39a971a2744b982abf, entries=2328710, sequenceid=7896, filesize=165.8m
2014-07-13 18:09:03,363 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~872.8m/915207600, currentsize=294.4m/308654800 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 24156ms, sequenceid=7896, compaction requested=true
2014-07-13 18:09:03,363 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:72), split_queue=0, merge_queue=0
2014-07-13 18:09:03,363 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 656.0m
2014-07-13 18:09:03,717 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:08,060 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:09:09,244 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7954, memsize=657.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/414b8f9b8a76492a91bbcfa48daf8466
2014-07-13 18:09:09,258 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/414b8f9b8a76492a91bbcfa48daf8466 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/414b8f9b8a76492a91bbcfa48daf8466
2014-07-13 18:09:09,268 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/414b8f9b8a76492a91bbcfa48daf8466, entries=2395240, sequenceid=7954, filesize=170.6m
2014-07-13 18:09:09,269 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~856.0m/897535120, currentsize=210.3m/220477360 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 23232ms, sequenceid=7954, compaction requested=true
2014-07-13 18:09:09,269 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:73), split_queue=0, merge_queue=0
2014-07-13 18:09:09,269 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 483.3m
2014-07-13 18:09:09,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:09,535 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:09,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30888 synced till here 30885
2014-07-13 18:09:09,726 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300134455 with entries=98, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300149389
2014-07-13 18:09:09,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300067205
2014-07-13 18:09:09,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300068752
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300070787
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300072166
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300073560
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300074961
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300076093
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300077315
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300078694
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300080556
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300083378
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300085034
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300086674
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300088620
2014-07-13 18:09:09,727 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300090465
2014-07-13 18:09:10,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:10,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 30967 synced till here 30959
2014-07-13 18:09:10,851 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300149389 with entries=79, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300150778
2014-07-13 18:09:11,336 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:09:13,038 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:13,067 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31035 synced till here 31034
2014-07-13 18:09:13,083 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300150778 with entries=68, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300153039
2014-07-13 18:09:15,077 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:15,337 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31128 synced till here 31119
2014-07-13 18:09:15,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300153039 with entries=93, filesize=90.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300155077
2014-07-13 18:09:18,228 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:18,253 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31196 synced till here 31195
2014-07-13 18:09:18,276 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300155077 with entries=68, filesize=62.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300158229
2014-07-13 18:09:19,326 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:19,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31270 synced till here 31269
2014-07-13 18:09:19,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300158229 with entries=74, filesize=64.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300159327
2014-07-13 18:09:20,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:20,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31333 synced till here 31332
2014-07-13 18:09:20,506 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300159327 with entries=63, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300160458
2014-07-13 18:09:20,586 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7373, memsize=510.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/847d6627850846b08a6ec83670b86f83
2014-07-13 18:09:20,598 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/847d6627850846b08a6ec83670b86f83 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/847d6627850846b08a6ec83670b86f83
2014-07-13 18:09:20,933 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/847d6627850846b08a6ec83670b86f83, entries=1857840, sequenceid=7373, filesize=132.3m
2014-07-13 18:09:20,934 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~656.0m/687914080, currentsize=218.9m/229557520 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 17571ms, sequenceid=7373, compaction requested=true
2014-07-13 18:09:20,934 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:74), split_queue=0, merge_queue=0
2014-07-13 18:09:20,935 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 495.7m
2014-07-13 18:09:21,204 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:22,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:22,979 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31403 synced till here 31402
2014-07-13 18:09:23,017 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300160458 with entries=70, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300162623
2014-07-13 18:09:23,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300091896
2014-07-13 18:09:23,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300093384
2014-07-13 18:09:23,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300094727
2014-07-13 18:09:23,017 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300096832
2014-07-13 18:09:23,124 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:09:23,920 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:24,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300162623 with entries=70, filesize=70.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300163920
2014-07-13 18:09:24,677 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7381, memsize=439.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/57c1231c5bd944b082b3827d1810f2e5
2014-07-13 18:09:24,692 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/57c1231c5bd944b082b3827d1810f2e5 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57c1231c5bd944b082b3827d1810f2e5
2014-07-13 18:09:24,701 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/57c1231c5bd944b082b3827d1810f2e5, entries=1598500, sequenceid=7381, filesize=113.8m
2014-07-13 18:09:24,701 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~483.3m/506732400, currentsize=264.1m/276965920 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 15432ms, sequenceid=7381, compaction requested=true
2014-07-13 18:09:24,702 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-13 18:09:24,702 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 460.0m
2014-07-13 18:09:24,721 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:09:25,182 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:25,512 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:25,901 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31543 synced till here 31540
2014-07-13 18:09:25,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300163920 with entries=70, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300165513
2014-07-13 18:09:25,952 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300100056
2014-07-13 18:09:25,952 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300101397
2014-07-13 18:09:25,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300106801
2014-07-13 18:09:25,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300109358
2014-07-13 18:09:25,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300110249
2014-07-13 18:09:25,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300115173
2014-07-13 18:09:25,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300116635
2014-07-13 18:09:27,830 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:28,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31626 synced till here 31620
2014-07-13 18:09:28,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300165513 with entries=83, filesize=76.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300167830
2014-07-13 18:09:29,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:29,283 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300167830 with entries=76, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300169252
2014-07-13 18:09:30,114 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:30,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31779 synced till here 31778
2014-07-13 18:09:30,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300169252 with entries=77, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300170115
2014-07-13 18:09:31,275 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:31,299 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31845 synced till here 31844
2014-07-13 18:09:31,330 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300170115 with entries=66, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300171276
2014-07-13 18:09:32,722 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:32,776 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 31924 synced till here 31921
2014-07-13 18:09:32,847 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300171276 with entries=79, filesize=66.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300172723
2014-07-13 18:09:33,387 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/6fb4c6752c5e4734a334300638b1b234 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/6fb4c6752c5e4734a334300638b1b234
2014-07-13 18:09:33,411 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:09:33,424 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/accc5e61cdd749fca004a1bb9333f49a, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/accc5e61cdd749fca004a1bb9333f49a
2014-07-13 18:09:33,426 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/58591163e6ba431289c8f17808186f37, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/58591163e6ba431289c8f17808186f37
2014-07-13 18:09:33,432 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/8709335b71e440a3aca1a433a64c0a7f, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/8709335b71e440a3aca1a433a64c0a7f
2014-07-13 18:09:33,435 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a0d6b75556bd4e42bc46ca41f1f80521, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a0d6b75556bd4e42bc46ca41f1f80521
2014-07-13 18:09:33,443 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1424bc1acb164111bf3f7d25958102a9, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1424bc1acb164111bf3f7d25958102a9
2014-07-13 18:09:33,446 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/60b6217ba83c45889dc2db8a2f1567ff, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/60b6217ba83c45889dc2db8a2f1567ff
2014-07-13 18:09:33,448 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a840ff105daa4604b2823457d2d833ae, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a840ff105daa4604b2823457d2d833ae
2014-07-13 18:09:33,450 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/67e7c9f605cd4c6f95432f0ae18941ce, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/67e7c9f605cd4c6f95432f0ae18941ce
2014-07-13 18:09:33,452 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/fc05dec57aa641e7bfbc918ceacda88f, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/fc05dec57aa641e7bfbc918ceacda88f
2014-07-13 18:09:33,456 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/585fd6cf14a24136b13a13276b5929a3, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/585fd6cf14a24136b13a13276b5929a3
2014-07-13 18:09:33,456 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into 6fb4c6752c5e4734a334300638b1b234(size=838.9m), total size for store is 2.1g. This selection was in queue for 0sec, and took 2mins, 30sec to execute.
2014-07-13 18:09:33,456 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=10, fileSize=843.5m, priority=3, time=253929913650262; duration=2mins, 30sec
2014-07-13 18:09:33,457 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-13 18:09:33,457 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 17 store files, 0 compacting, 17 eligible, 20 blocking
2014-07-13 18:09:33,460 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 802539402 starting at candidate #5 after considering 92 permutations with 90 in ratio
2014-07-13 18:09:33,460 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating minor compaction
2014-07-13 18:09:33,460 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:09:33,460 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=765.4m
2014-07-13 18:09:33,460 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3bc9669adf434f8ebf157ab730c94774, keycount=166619, bloomtype=ROW, size=118.7m, encoding=NONE, seqNum=4617
2014-07-13 18:09:33,460 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9ed1c16370be48a3933280e70ea92cf2, keycount=120203, bloomtype=ROW, size=85.5m, encoding=NONE, seqNum=4897
2014-07-13 18:09:33,460 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e88b266d62ac4758b7f8868c1ec36c3c, keycount=107144, bloomtype=ROW, size=76.3m, encoding=NONE, seqNum=5175
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/51a003beeaea40418f653b772477ad95, keycount=95367, bloomtype=ROW, size=67.9m, encoding=NONE, seqNum=5402
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ea8c2ddd0c064464a0f8f2eb103606b2, keycount=94619, bloomtype=ROW, size=67.4m, encoding=NONE, seqNum=5669
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1e458ffd3de84be1a5384b7392b3839c, keycount=106293, bloomtype=ROW, size=75.7m, encoding=NONE, seqNum=5891
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9003d1092a634d10bc36dd0d71ea3a99, keycount=94858, bloomtype=ROW, size=67.5m, encoding=NONE, seqNum=6110
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd617ebba34346bbbf4b43f68bec106b, keycount=94728, bloomtype=ROW, size=67.5m, encoding=NONE, seqNum=6343
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8687feff819240f4ab888cda483fb82e, keycount=72419, bloomtype=ROW, size=51.6m, encoding=NONE, seqNum=6676
2014-07-13 18:09:33,461 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d0e292a1f913494eaa83699bd5ea5086, keycount=122503, bloomtype=ROW, size=87.2m, encoding=NONE, seqNum=6896
2014-07-13 18:09:33,862 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:34,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:34,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300172723 with entries=87, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300174395
2014-07-13 18:09:35,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:35,841 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32086 synced till here 32084
2014-07-13 18:09:36,065 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300174395 with entries=75, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300175812
2014-07-13 18:09:37,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:37,330 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32168 synced till here 32160
2014-07-13 18:09:37,378 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300175812 with entries=82, filesize=74.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300177315
2014-07-13 18:09:37,406 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8253, memsize=444.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/fe611ee966044713b20dabca7e57d777
2014-07-13 18:09:37,422 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/fe611ee966044713b20dabca7e57d777 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/fe611ee966044713b20dabca7e57d777
2014-07-13 18:09:37,433 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/fe611ee966044713b20dabca7e57d777, entries=1617840, sequenceid=8253, filesize=115.1m
2014-07-13 18:09:37,433 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~495.7m/519749520, currentsize=339.0m/355466800 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 16498ms, sequenceid=8253, compaction requested=true
2014-07-13 18:09:37,433 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:75), split_queue=0, merge_queue=0
2014-07-13 18:09:37,434 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 542.2m
2014-07-13 18:09:37,434 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:09:38,055 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:40,699 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8279, memsize=415.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/be65c9230f914b08b28f0812d2eea02b
2014-07-13 18:09:40,715 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/be65c9230f914b08b28f0812d2eea02b as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/be65c9230f914b08b28f0812d2eea02b
2014-07-13 18:09:40,731 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/be65c9230f914b08b28f0812d2eea02b, entries=1513220, sequenceid=8279, filesize=107.7m
2014-07-13 18:09:40,732 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~476.9m/500073520, currentsize=283.7m/297462800 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 16030ms, sequenceid=8279, compaction requested=true
2014-07-13 18:09:40,733 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:76), split_queue=0, merge_queue=0
2014-07-13 18:09:40,733 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 533.3m
2014-07-13 18:09:41,089 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:42,977 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:09:43,725 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:43,749 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32277 synced till here 32276
2014-07-13 18:09:43,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300177315 with entries=109, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300183730
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300118494
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300119590
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300123609
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300125512
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300126772
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300128905
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300130171
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300131734
2014-07-13 18:09:43,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300133107
2014-07-13 18:09:46,398 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:47,019 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32401 synced till here 32400
2014-07-13 18:09:47,044 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300183730 with entries=124, filesize=78.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300186398
2014-07-13 18:09:48,161 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:48,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32479 synced till here 32477
2014-07-13 18:09:48,646 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300186398 with entries=78, filesize=66.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300188161
2014-07-13 18:09:49,408 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:49,853 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32548 synced till here 32547
2014-07-13 18:09:49,875 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300188161 with entries=69, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300189408
2014-07-13 18:09:50,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:51,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32620 synced till here 32617
2014-07-13 18:09:51,357 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300189408 with entries=72, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300190866
2014-07-13 18:09:52,253 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:09:52,294 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32686 synced till here 32682
2014-07-13 18:09:52,652 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300190866 with entries=66, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300192253
2014-07-13 18:09:54,137 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7665, memsize=487.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/115698d15b1f43c69f9acf4a1374df78
2014-07-13 18:09:54,155 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/115698d15b1f43c69f9acf4a1374df78 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/115698d15b1f43c69f9acf4a1374df78
2014-07-13 18:09:54,169 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/115698d15b1f43c69f9acf4a1374df78, entries=1776470, sequenceid=7665, filesize=126.5m
2014-07-13 18:09:54,169 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~545.2m/571637600, currentsize=200.6m/210300320 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 16736ms, sequenceid=7665, compaction requested=true
2014-07-13 18:09:54,170 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:77), split_queue=0, merge_queue=0
2014-07-13 18:09:54,170 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 544.5m
2014-07-13 18:09:54,522 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:09:56,761 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7670, memsize=475.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/7f8da401682148fa8e169bdaf737f588
2014-07-13 18:09:56,775 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/7f8da401682148fa8e169bdaf737f588 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7f8da401682148fa8e169bdaf737f588
2014-07-13 18:09:56,793 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7f8da401682148fa8e169bdaf737f588, entries=1731320, sequenceid=7670, filesize=123.3m
2014-07-13 18:09:56,793 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~533.3m/559190000, currentsize=195.5m/205027760 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 16060ms, sequenceid=7670, compaction requested=true
2014-07-13 18:09:56,794 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:78), split_queue=0, merge_queue=0
2014-07-13 18:09:56,794 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 475.6m
2014-07-13 18:09:57,045 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:08,493 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8664, memsize=476.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/a2f13627197c4c8cb2c7c3bbf66748c4
2014-07-13 18:10:08,509 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/a2f13627197c4c8cb2c7c3bbf66748c4 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a2f13627197c4c8cb2c7c3bbf66748c4
2014-07-13 18:10:08,522 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a2f13627197c4c8cb2c7c3bbf66748c4, entries=1734120, sequenceid=8664, filesize=123.5m
2014-07-13 18:10:08,523 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~544.5m/570925520, currentsize=0.0/0 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 14352ms, sequenceid=8664, compaction requested=true
2014-07-13 18:10:08,523 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:79), split_queue=0, merge_queue=0
2014-07-13 18:10:09,317 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8648, memsize=412.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/5ecba189a00a4ce593fc210dbc5d70c3
2014-07-13 18:10:09,338 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/5ecba189a00a4ce593fc210dbc5d70c3 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/5ecba189a00a4ce593fc210dbc5d70c3
2014-07-13 18:10:09,360 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/5ecba189a00a4ce593fc210dbc5d70c3, entries=1503430, sequenceid=8648, filesize=107.0m
2014-07-13 18:10:09,360 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~475.6m/498660400, currentsize=0.0/0 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 12566ms, sequenceid=8648, compaction requested=true
2014-07-13 18:10:09,360 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:80), split_queue=0, merge_queue=0
2014-07-13 18:10:10,679 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:10,697 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32758 synced till here 32757
2014-07-13 18:10:10,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300192253 with entries=72, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300210680
2014-07-13 18:10:10,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300134455
2014-07-13 18:10:10,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300149389
2014-07-13 18:10:10,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300150778
2014-07-13 18:10:10,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300153039
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300155077
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300158229
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300159327
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300160458
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300162623
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300163920
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300165513
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300167830
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300169252
2014-07-13 18:10:10,720 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300170115
2014-07-13 18:10:10,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300171276
2014-07-13 18:10:10,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300172723
2014-07-13 18:10:10,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300174395
2014-07-13 18:10:10,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300175812
2014-07-13 18:10:12,299 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:12,322 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32858 synced till here 32851
2014-07-13 18:10:12,359 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300210680 with entries=100, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300212300
2014-07-13 18:10:14,333 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:10:14,334 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 258.1m
2014-07-13 18:10:14,521 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:10:14,522 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 257.5m
2014-07-13 18:10:14,584 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:14,661 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:14,683 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 32955 synced till here 32953
2014-07-13 18:10:14,712 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300212300 with entries=97, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300214662
2014-07-13 18:10:14,780 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:15,893 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:15,926 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300214662 with entries=59, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300215893
2014-07-13 18:10:16,912 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:16,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33080 synced till here 33079
2014-07-13 18:10:16,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300215893 with entries=66, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300216912
2014-07-13 18:10:18,296 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:18,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300216912 with entries=79, filesize=80.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300218296
2014-07-13 18:10:19,799 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:20,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33257 synced till here 33254
2014-07-13 18:10:20,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300218296 with entries=98, filesize=86.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300219799
2014-07-13 18:10:21,362 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:21,435 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33332 synced till here 33326
2014-07-13 18:10:21,490 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300219799 with entries=75, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300221363
2014-07-13 18:10:22,616 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:10:22,688 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:10:22,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:22,993 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33414 synced till here 33413
2014-07-13 18:10:23,032 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300221363 with entries=82, filesize=71.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300222715
2014-07-13 18:10:24,470 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7804, memsize=252.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/2095c58d503f4cc0a4b6b4e28ff6daea
2014-07-13 18:10:24,471 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7808, memsize=255.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/77e38dc4ae054323bef170255691bfc9
2014-07-13 18:10:24,525 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/77e38dc4ae054323bef170255691bfc9 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77e38dc4ae054323bef170255691bfc9
2014-07-13 18:10:24,539 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/2095c58d503f4cc0a4b6b4e28ff6daea as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2095c58d503f4cc0a4b6b4e28ff6daea
2014-07-13 18:10:24,551 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77e38dc4ae054323bef170255691bfc9, entries=928890, sequenceid=7808, filesize=66.1m
2014-07-13 18:10:24,551 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.8m/277711280, currentsize=209.6m/219809680 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 10030ms, sequenceid=7808, compaction requested=true
2014-07-13 18:10:24,551 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:81), split_queue=0, merge_queue=0
2014-07-13 18:10:24,552 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 292.9m
2014-07-13 18:10:24,552 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2095c58d503f4cc0a4b6b4e28ff6daea, entries=920440, sequenceid=7804, filesize=65.5m
2014-07-13 18:10:24,553 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.7m/275467040, currentsize=218.6m/229228080 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 10219ms, sequenceid=7804, compaction requested=true
2014-07-13 18:10:24,553 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:82), split_queue=0, merge_queue=0
2014-07-13 18:10:24,553 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 292.8m
2014-07-13 18:10:24,704 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:24,715 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:25,696 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:26,370 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33554 synced till here 33550
2014-07-13 18:10:26,408 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300222715 with entries=140, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300225696
2014-07-13 18:10:26,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300177315
2014-07-13 18:10:26,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300183730
2014-07-13 18:10:26,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300186398
2014-07-13 18:10:26,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300188161
2014-07-13 18:10:26,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300189408
2014-07-13 18:10:26,409 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300190866
2014-07-13 18:10:26,859 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:10:27,500 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:10:27,709 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:27,736 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33637 synced till here 33636
2014-07-13 18:10:27,981 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300225696 with entries=83, filesize=65.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300227710
2014-07-13 18:10:28,861 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:28,951 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300227710 with entries=76, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300228861
2014-07-13 18:10:30,318 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:30,356 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33797 synced till here 33794
2014-07-13 18:10:30,379 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300228861 with entries=84, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300230319
2014-07-13 18:10:31,724 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:31,744 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 33862 synced till here 33856
2014-07-13 18:10:31,786 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300230319 with entries=65, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300231725
2014-07-13 18:10:34,561 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8893, memsize=292.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/6dc1c610abf24745b33f63842a8b0f7c
2014-07-13 18:10:34,579 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/6dc1c610abf24745b33f63842a8b0f7c as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/6dc1c610abf24745b33f63842a8b0f7c
2014-07-13 18:10:34,592 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/6dc1c610abf24745b33f63842a8b0f7c, entries=1066530, sequenceid=8893, filesize=75.9m
2014-07-13 18:10:34,592 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~292.9m/307152000, currentsize=155.2m/162741040 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10040ms, sequenceid=8893, compaction requested=true
2014-07-13 18:10:34,593 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:83), split_queue=0, merge_queue=0
2014-07-13 18:10:34,593 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 376.9m
2014-07-13 18:10:34,689 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8878, memsize=292.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/8fc272f699824310a1bfdc35848b40ea
2014-07-13 18:10:34,704 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/8fc272f699824310a1bfdc35848b40ea as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8fc272f699824310a1bfdc35848b40ea
2014-07-13 18:10:34,716 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8fc272f699824310a1bfdc35848b40ea, entries=1066020, sequenceid=8878, filesize=75.9m
2014-07-13 18:10:34,716 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~292.8m/307004800, currentsize=155.3m/162859760 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 10163ms, sequenceid=8878, compaction requested=true
2014-07-13 18:10:34,716 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:84), split_queue=0, merge_queue=0
2014-07-13 18:10:34,717 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 370.0m
2014-07-13 18:10:34,828 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:34,941 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:45,463 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7995, memsize=370.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/e8ce1e27779d4fb7bc89cd6d4851d6d4
2014-07-13 18:10:45,477 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/e8ce1e27779d4fb7bc89cd6d4851d6d4 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e8ce1e27779d4fb7bc89cd6d4851d6d4
2014-07-13 18:10:45,489 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7994, memsize=376.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/2fbd2db352bb4d6b88c66f0e8557b18d
2014-07-13 18:10:45,492 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e8ce1e27779d4fb7bc89cd6d4851d6d4, entries=1347320, sequenceid=7995, filesize=95.9m
2014-07-13 18:10:45,492 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~370.0m/388016480, currentsize=0.0/0 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 10775ms, sequenceid=7995, compaction requested=true
2014-07-13 18:10:45,493 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:85), split_queue=0, merge_queue=0
2014-07-13 18:10:45,513 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/2fbd2db352bb4d6b88c66f0e8557b18d as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2fbd2db352bb4d6b88c66f0e8557b18d
2014-07-13 18:10:45,530 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2fbd2db352bb4d6b88c66f0e8557b18d, entries=1372460, sequenceid=7994, filesize=97.7m
2014-07-13 18:10:45,530 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~376.9m/395258560, currentsize=0.0/0 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 10937ms, sequenceid=7994, compaction requested=true
2014-07-13 18:10:45,531 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:86), split_queue=0, merge_queue=0
2014-07-13 18:10:46,212 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:46,455 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300231725 with entries=105, filesize=67.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300246212
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300192253
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300210680
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300212300
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300214662
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300215893
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300216912
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300218296
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300219799
2014-07-13 18:10:46,455 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300221363
2014-07-13 18:10:47,972 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:48,240 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300246212 with entries=80, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300247973
2014-07-13 18:10:50,706 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:50,946 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34131 synced till here 34129
2014-07-13 18:10:50,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300247973 with entries=84, filesize=84.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300250706
2014-07-13 18:10:52,533 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:52,547 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:10:52,547 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 256.0m
2014-07-13 18:10:52,577 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34201 synced till here 34198
2014-07-13 18:10:52,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300250706 with entries=70, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300252533
2014-07-13 18:10:52,686 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:10:52,687 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.0m
2014-07-13 18:10:52,759 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:52,849 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:10:53,966 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:54,004 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34271 synced till here 34267
2014-07-13 18:10:54,055 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300252533 with entries=70, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300253967
2014-07-13 18:10:55,041 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:55,065 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34337 synced till here 34327
2014-07-13 18:10:55,143 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300253967 with entries=66, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300255042
2014-07-13 18:10:56,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:57,180 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34414 synced till here 34413
2014-07-13 18:10:57,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300255042 with entries=77, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300256968
2014-07-13 18:10:58,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:58,335 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34485 synced till here 34483
2014-07-13 18:10:58,354 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300256968 with entries=71, filesize=63.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300258303
2014-07-13 18:10:58,840 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:10:59,594 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:10:59,750 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:10:59,925 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34570 synced till here 34554
2014-07-13 18:11:00,106 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300258303 with entries=85, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300259750
2014-07-13 18:11:01,422 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:01,634 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34647 synced till here 34645
2014-07-13 18:11:01,691 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300259750 with entries=77, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300261423
2014-07-13 18:11:02,584 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9117, memsize=258.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/2c6461d427764710a55c4c1a29877308
2014-07-13 18:11:02,595 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/2c6461d427764710a55c4c1a29877308 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2c6461d427764710a55c4c1a29877308
2014-07-13 18:11:02,603 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2c6461d427764710a55c4c1a29877308, entries=939970, sequenceid=9117, filesize=67.0m
2014-07-13 18:11:02,604 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~258.2m/270702560, currentsize=208.0m/218053040 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10057ms, sequenceid=9117, compaction requested=true
2014-07-13 18:11:02,604 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:87), split_queue=0, merge_queue=0
2014-07-13 18:11:02,605 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 325.6m
2014-07-13 18:11:02,794 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:02,846 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:02,864 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9101, memsize=258.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c75f5e5bf4354725a9735dab20603ff4
2014-07-13 18:11:02,897 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c75f5e5bf4354725a9735dab20603ff4 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c75f5e5bf4354725a9735dab20603ff4
2014-07-13 18:11:02,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34719 synced till here 34712
2014-07-13 18:11:02,947 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c75f5e5bf4354725a9735dab20603ff4, entries=939510, sequenceid=9101, filesize=67.0m
2014-07-13 18:11:02,947 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.0m/270570720, currentsize=218.2m/228808160 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 10260ms, sequenceid=9101, compaction requested=true
2014-07-13 18:11:02,948 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:88), split_queue=0, merge_queue=0
2014-07-13 18:11:02,948 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 330.1m
2014-07-13 18:11:02,980 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300261423 with entries=72, filesize=70.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300262794
2014-07-13 18:11:02,980 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300222715
2014-07-13 18:11:02,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300225696
2014-07-13 18:11:02,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300227710
2014-07-13 18:11:02,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300228861
2014-07-13 18:11:02,981 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300230319
2014-07-13 18:11:03,228 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:03,986 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:04,009 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300262794 with entries=74, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300263987
2014-07-13 18:11:04,281 DEBUG [RpcServer.handler=8,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:11:04,397 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:11:05,151 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:05,314 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34869 synced till here 34868
2014-07-13 18:11:05,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300263987 with entries=76, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300265151
2014-07-13 18:11:07,375 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:07,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 34955 synced till here 34941
2014-07-13 18:11:07,489 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300265151 with entries=86, filesize=76.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300267375
2014-07-13 18:11:08,814 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:08,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35030 synced till here 35028
2014-07-13 18:11:08,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300267375 with entries=75, filesize=70.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300268814
2014-07-13 18:11:13,625 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8172, memsize=292.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/579203308c8642ea853ee09e1ec391cf
2014-07-13 18:11:13,638 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/579203308c8642ea853ee09e1ec391cf as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/579203308c8642ea853ee09e1ec391cf
2014-07-13 18:11:13,648 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/579203308c8642ea853ee09e1ec391cf, entries=1065520, sequenceid=8172, filesize=75.8m
2014-07-13 18:11:13,648 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~326.7m/342550880, currentsize=173.7m/182086400 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 11043ms, sequenceid=8172, compaction requested=true
2014-07-13 18:11:13,648 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:89), split_queue=0, merge_queue=0
2014-07-13 18:11:13,649 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 354.1m
2014-07-13 18:11:13,850 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:14,138 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8177, memsize=293.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/dd123bbd8b234d179dd847c5e13cb67e
2014-07-13 18:11:14,147 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/dd123bbd8b234d179dd847c5e13cb67e as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dd123bbd8b234d179dd847c5e13cb67e
2014-07-13 18:11:14,157 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dd123bbd8b234d179dd847c5e13cb67e, entries=1067970, sequenceid=8177, filesize=76.0m
2014-07-13 18:11:14,158 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~332.2m/348365600, currentsize=167.7m/175878320 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 11210ms, sequenceid=8177, compaction requested=true
2014-07-13 18:11:14,158 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:90), split_queue=0, merge_queue=0
2014-07-13 18:11:14,158 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:11:14,158 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:91), split_queue=0, merge_queue=0
2014-07-13 18:11:14,811 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:15,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35116 synced till here 35111
2014-07-13 18:11:15,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300268814 with entries=86, filesize=74.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300274812
2014-07-13 18:11:15,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300231725
2014-07-13 18:11:15,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300246212
2014-07-13 18:11:15,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300247973
2014-07-13 18:11:15,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300250706
2014-07-13 18:11:16,466 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:16,490 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35221 synced till here 35217
2014-07-13 18:11:16,559 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300274812 with entries=105, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300276466
2014-07-13 18:11:18,075 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:18,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35293 synced till here 35292
2014-07-13 18:11:18,112 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300276466 with entries=72, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300278075
2014-07-13 18:11:19,406 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:11:19,406 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 256.8m
2014-07-13 18:11:19,633 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:11:19,675 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:20,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:20,602 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300278075 with entries=60, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300280572
2014-07-13 18:11:22,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:22,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35434 synced till here 35433
2014-07-13 18:11:23,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300280572 with entries=81, filesize=79.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300282118
2014-07-13 18:11:24,149 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9337, memsize=285.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/af36bc436bed43bc8d13e3d5217d2cf0
2014-07-13 18:11:24,166 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/af36bc436bed43bc8d13e3d5217d2cf0 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/af36bc436bed43bc8d13e3d5217d2cf0
2014-07-13 18:11:24,178 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/af36bc436bed43bc8d13e3d5217d2cf0, entries=1040870, sequenceid=9337, filesize=74.0m
2014-07-13 18:11:24,206 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~354.1m/371278000, currentsize=141.2m/148021680 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10557ms, sequenceid=9337, compaction requested=true
2014-07-13 18:11:24,206 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:92), split_queue=0, merge_queue=0
2014-07-13 18:11:24,206 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 300.1m
2014-07-13 18:11:24,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:24,765 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:24,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35537 synced till here 35496
2014-07-13 18:11:25,966 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300282118 with entries=103, filesize=99.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300284705
2014-07-13 18:11:27,592 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:27,664 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35640 synced till here 35610
2014-07-13 18:11:27,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300284705 with entries=103, filesize=89.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300287592
2014-07-13 18:11:29,931 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:30,274 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35761 synced till here 35750
2014-07-13 18:11:31,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300287592 with entries=121, filesize=96.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300289931
2014-07-13 18:11:31,409 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8320, memsize=207.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a9afe9b589304db0a9315490dcb538ed
2014-07-13 18:11:31,422 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a9afe9b589304db0a9315490dcb538ed as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9afe9b589304db0a9315490dcb538ed
2014-07-13 18:11:31,453 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9afe9b589304db0a9315490dcb538ed, entries=756280, sequenceid=8320, filesize=53.9m
2014-07-13 18:11:31,453 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~259.4m/272011520, currentsize=204.2m/214068320 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 12047ms, sequenceid=8320, compaction requested=true
2014-07-13 18:11:31,454 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-13 18:11:31,765 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:11:31,773 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 261.6m
2014-07-13 18:11:32,000 DEBUG [RpcServer.handler=33,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:11:32,148 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:33,335 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:33,352 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35859 synced till here 35837
2014-07-13 18:11:33,588 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300289931 with entries=98, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300293336
2014-07-13 18:11:35,366 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:35,430 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 35971 synced till here 35939
2014-07-13 18:11:35,963 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300293336 with entries=112, filesize=90.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300295367
2014-07-13 18:11:37,964 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:38,007 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36087 synced till here 36061
2014-07-13 18:11:38,291 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300295367 with entries=116, filesize=101.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300297965
2014-07-13 18:11:40,155 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1b8c8dfe303447c1921178bfbf4b107c as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1b8c8dfe303447c1921178bfbf4b107c
2014-07-13 18:11:41,156 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:41,205 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36213 synced till here 36191
2014-07-13 18:11:41,441 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:11:41,473 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3bc9669adf434f8ebf157ab730c94774, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3bc9669adf434f8ebf157ab730c94774
2014-07-13 18:11:41,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300297965 with entries=126, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300301157
2014-07-13 18:11:41,480 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9ed1c16370be48a3933280e70ea92cf2, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9ed1c16370be48a3933280e70ea92cf2
2014-07-13 18:11:41,484 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e88b266d62ac4758b7f8868c1ec36c3c, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e88b266d62ac4758b7f8868c1ec36c3c
2014-07-13 18:11:41,529 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/51a003beeaea40418f653b772477ad95, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/51a003beeaea40418f653b772477ad95
2014-07-13 18:11:41,533 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ea8c2ddd0c064464a0f8f2eb103606b2, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ea8c2ddd0c064464a0f8f2eb103606b2
2014-07-13 18:11:41,536 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1e458ffd3de84be1a5384b7392b3839c, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1e458ffd3de84be1a5384b7392b3839c
2014-07-13 18:11:41,539 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9003d1092a634d10bc36dd0d71ea3a99, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/9003d1092a634d10bc36dd0d71ea3a99
2014-07-13 18:11:41,545 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd617ebba34346bbbf4b43f68bec106b, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/bd617ebba34346bbbf4b43f68bec106b
2014-07-13 18:11:41,549 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8687feff819240f4ab888cda483fb82e, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8687feff819240f4ab888cda483fb82e
2014-07-13 18:11:41,554 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d0e292a1f913494eaa83699bd5ea5086, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d0e292a1f913494eaa83699bd5ea5086
2014-07-13 18:11:41,555 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into 1b8c8dfe303447c1921178bfbf4b107c(size=762.2m), total size for store is 2.4g. This selection was in queue for 0sec, and took 2mins, 8sec to execute.
2014-07-13 18:11:41,555 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=10, fileSize=765.4m, priority=3, time=254080887035221; duration=2mins, 8sec
2014-07-13 18:11:41,555 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-13 18:11:41,556 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 19 store files, 0 compacting, 19 eligible, 20 blocking
2014-07-13 18:11:41,559 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 10 files of size 786561523 starting at candidate #3 after considering 108 permutations with 100 in ratio
2014-07-13 18:11:41,559 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating minor compaction
2014-07-13 18:11:41,560 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:11:41,560 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 10 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=750.1m
2014-07-13 18:11:41,560 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/db68482a9333465883f1dc467e2db120, keycount=116252, bloomtype=ROW, size=82.7m, encoding=NONE, seqNum=4901
2014-07-13 18:11:41,560 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/eea2f7ff442c4225bbe19a6152991edb, keycount=104946, bloomtype=ROW, size=74.7m, encoding=NONE, seqNum=5173
2014-07-13 18:11:41,560 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/443e079b8dd945829666ccc48e0efb73, keycount=94120, bloomtype=ROW, size=67.1m, encoding=NONE, seqNum=5403
2014-07-13 18:11:41,560 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/0f37a6d74b254f8db2a7ce7ccef0c3a8, keycount=93458, bloomtype=ROW, size=66.6m, encoding=NONE, seqNum=5661
2014-07-13 18:11:41,560 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ea460f6a20554bd39e51370deccd5404, keycount=115228, bloomtype=ROW, size=82.1m, encoding=NONE, seqNum=5904
2014-07-13 18:11:41,561 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/255deff7f2f04286a03d8a19f960e49c, keycount=93696, bloomtype=ROW, size=66.7m, encoding=NONE, seqNum=6121
2014-07-13 18:11:41,561 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3bd44d9913be4b1babb48047614a2eb1, keycount=95196, bloomtype=ROW, size=67.8m, encoding=NONE, seqNum=6352
2014-07-13 18:11:41,561 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/001ffb3717364543ac1367f028052016, keycount=65502, bloomtype=ROW, size=46.7m, encoding=NONE, seqNum=6674
2014-07-13 18:11:41,561 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/634cedb551464b83bbb57af979650341, keycount=109707, bloomtype=ROW, size=78.1m, encoding=NONE, seqNum=6875
2014-07-13 18:11:41,561 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a925dffe9b7845feb05462336ac34e1a, keycount=165296, bloomtype=ROW, size=117.7m, encoding=NONE, seqNum=7294
2014-07-13 18:11:41,873 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:43,654 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:43,699 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36321 synced till here 36294
2014-07-13 18:11:43,896 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8347, memsize=239.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/f347c1903f31429e9da84db82e557f36
2014-07-13 18:11:43,908 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/f347c1903f31429e9da84db82e557f36 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f347c1903f31429e9da84db82e557f36
2014-07-13 18:11:43,919 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f347c1903f31429e9da84db82e557f36, entries=870840, sequenceid=8347, filesize=62.0m
2014-07-13 18:11:43,920 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~305.2m/320030400, currentsize=375.9m/394126320 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 19714ms, sequenceid=8347, compaction requested=true
2014-07-13 18:11:43,920 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:93), split_queue=0, merge_queue=0
2014-07-13 18:11:43,920 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 455.9m
2014-07-13 18:11:43,981 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:11:44,117 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300301157 with entries=108, filesize=103.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300303655
2014-07-13 18:11:45,920 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:46,088 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:46,120 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36422 synced till here 36394
2014-07-13 18:11:47,289 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300303655 with entries=101, filesize=95.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300306088
2014-07-13 18:11:47,887 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9529, memsize=181.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ff63fc59bb6741a6b0e637edc45ea09a
2014-07-13 18:11:47,935 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ff63fc59bb6741a6b0e637edc45ea09a as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ff63fc59bb6741a6b0e637edc45ea09a
2014-07-13 18:11:48,022 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ff63fc59bb6741a6b0e637edc45ea09a, entries=659950, sequenceid=9529, filesize=47.0m
2014-07-13 18:11:48,023 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~275.9m/289279200, currentsize=197.9m/207518160 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 16249ms, sequenceid=9529, compaction requested=true
2014-07-13 18:11:48,023 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:94), split_queue=0, merge_queue=0
2014-07-13 18:11:48,023 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 817.3m
2014-07-13 18:11:48,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:48,343 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36540 synced till here 36518
2014-07-13 18:11:49,393 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300306088 with entries=118, filesize=93.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300308212
2014-07-13 18:11:50,025 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:11:51,312 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:51,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36653 synced till here 36645
2014-07-13 18:11:51,536 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300308212 with entries=113, filesize=90.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300311312
2014-07-13 18:11:51,970 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:11:52,999 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:53,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36782 synced till here 36743
2014-07-13 18:11:53,516 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300311312 with entries=129, filesize=112.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300313000
2014-07-13 18:11:55,044 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:55,095 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36885 synced till here 36859
2014-07-13 18:11:55,266 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300313000 with entries=103, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300315044
2014-07-13 18:11:56,463 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8618, memsize=131.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/9f5a10211ef44fabace620e2598b19f8
2014-07-13 18:11:56,481 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/9f5a10211ef44fabace620e2598b19f8 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/9f5a10211ef44fabace620e2598b19f8
2014-07-13 18:11:56,502 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/9f5a10211ef44fabace620e2598b19f8, entries=479880, sequenceid=8618, filesize=34.2m
2014-07-13 18:11:56,503 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~470.1m/492917360, currentsize=279.2m/292810400 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 12582ms, sequenceid=8618, compaction requested=true
2014-07-13 18:11:56,503 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:95), split_queue=0, merge_queue=0
2014-07-13 18:11:56,503 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 669.7m
2014-07-13 18:11:56,527 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:11:56,837 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:11:56,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 36977 synced till here 36970
2014-07-13 18:11:56,928 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300315044 with entries=92, filesize=81.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300316837
2014-07-13 18:11:57,296 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:01,872 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8811, memsize=92.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/31bcab7b70074d7c8c9411015dfeefd3
2014-07-13 18:12:01,885 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/31bcab7b70074d7c8c9411015dfeefd3 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/31bcab7b70074d7c8c9411015dfeefd3
2014-07-13 18:12:01,891 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:01,906 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/31bcab7b70074d7c8c9411015dfeefd3, entries=337610, sequenceid=8811, filesize=24.1m
2014-07-13 18:12:01,907 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~691.6m/725185120, currentsize=45.1m/47325680 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 5404ms, sequenceid=8811, compaction requested=true
2014-07-13 18:12:01,907 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:96), split_queue=0, merge_queue=0
2014-07-13 18:12:01,907 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 378.2m
2014-07-13 18:12:01,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37062 synced till here 37061
2014-07-13 18:12:01,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300316837 with entries=85, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300321891
2014-07-13 18:12:02,597 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:03,068 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:03,616 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37144 synced till here 37142
2014-07-13 18:12:03,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300321891 with entries=82, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300323069
2014-07-13 18:12:04,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:04,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37221 synced till here 37218
2014-07-13 18:12:04,570 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300323069 with entries=77, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300324460
2014-07-13 18:12:06,007 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:06,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37338 synced till here 37332
2014-07-13 18:12:06,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300324460 with entries=117, filesize=62.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300326008
2014-07-13 18:12:07,356 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9770, memsize=80.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/b01b7a34949142fcb53bf3562155b4d8
2014-07-13 18:12:07,369 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/b01b7a34949142fcb53bf3562155b4d8 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/b01b7a34949142fcb53bf3562155b4d8
2014-07-13 18:12:07,410 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:07,475 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/b01b7a34949142fcb53bf3562155b4d8, entries=293690, sequenceid=9770, filesize=20.9m
2014-07-13 18:12:07,476 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~384.0m/402616240, currentsize=119.9m/125746000 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 5569ms, sequenceid=9770, compaction requested=true
2014-07-13 18:12:07,476 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:97), split_queue=0, merge_queue=0
2014-07-13 18:12:07,476 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 449.6m
2014-07-13 18:12:07,673 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300326008 with entries=108, filesize=79.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300327410
2014-07-13 18:12:08,254 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:09,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:10,171 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37533 synced till here 37509
2014-07-13 18:12:10,277 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300327410 with entries=87, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300329311
2014-07-13 18:12:12,123 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9637, memsize=467.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/3823c2c95462416f987a16a6c8350423
2014-07-13 18:12:12,153 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/3823c2c95462416f987a16a6c8350423 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3823c2c95462416f987a16a6c8350423
2014-07-13 18:12:12,167 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3823c2c95462416f987a16a6c8350423, entries=1700230, sequenceid=9637, filesize=121.0m
2014-07-13 18:12:12,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:12,167 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~827.6m/867774640, currentsize=367.4m/385259840 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 24144ms, sequenceid=9637, compaction requested=true
2014-07-13 18:12:12,167 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:98), split_queue=0, merge_queue=0
2014-07-13 18:12:12,168 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:12:12,169 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 373.3m
2014-07-13 18:12:12,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37615 synced till here 37597
2014-07-13 18:12:12,486 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300329311 with entries=82, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300332167
2014-07-13 18:12:12,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300252533
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300253967
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300255042
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300256968
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300258303
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300259750
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300261423
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300262794
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300263987
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300265151
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300267375
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300268814
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300274812
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300276466
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300278075
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300280572
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300282118
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300284705
2014-07-13 18:12:12,487 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300287592
2014-07-13 18:12:12,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300289931
2014-07-13 18:12:12,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300293336
2014-07-13 18:12:12,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300295367
2014-07-13 18:12:12,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300297965
2014-07-13 18:12:12,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300301157
2014-07-13 18:12:12,585 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:12,749 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:12:14,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:14,473 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37735 synced till here 37716
2014-07-13 18:12:15,365 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300332167 with entries=120, filesize=102.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300334273
2014-07-13 18:12:15,479 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:12:16,971 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:17,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37855 synced till here 37828
2014-07-13 18:12:17,346 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300334273 with entries=120, filesize=110.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300336971
2014-07-13 18:12:19,370 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:19,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 37984 synced till here 37982
2014-07-13 18:12:19,534 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300336971 with entries=129, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300339371
2014-07-13 18:12:20,882 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8939, memsize=172.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/991001aa75394e44843c1f20c0314b56
2014-07-13 18:12:20,893 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/991001aa75394e44843c1f20c0314b56 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/991001aa75394e44843c1f20c0314b56
2014-07-13 18:12:20,910 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/991001aa75394e44843c1f20c0314b56, entries=629610, sequenceid=8939, filesize=44.8m
2014-07-13 18:12:20,911 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~455.0m/477082640, currentsize=240.0m/251634720 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 13435ms, sequenceid=8939, compaction requested=true
2014-07-13 18:12:20,911 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:99), split_queue=0, merge_queue=0
2014-07-13 18:12:20,911 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 403.6m
2014-07-13 18:12:21,124 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:21,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38092 synced till here 38061
2014-07-13 18:12:21,490 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:21,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300339371 with entries=108, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300341124
2014-07-13 18:12:21,498 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300303655
2014-07-13 18:12:22,275 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:12:22,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:23,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38189 synced till here 38165
2014-07-13 18:12:23,821 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300341124 with entries=97, filesize=84.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300342992
2014-07-13 18:12:24,541 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:25,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38316 synced till here 38305
2014-07-13 18:12:25,262 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300342992 with entries=127, filesize=85.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300344541
2014-07-13 18:12:26,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:26,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38392 synced till here 38389
2014-07-13 18:12:26,154 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300344541 with entries=76, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300346113
2014-07-13 18:12:26,191 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9878, memsize=219.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/99ac3f04f2554082b7809f610bc593dd
2014-07-13 18:12:26,204 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/99ac3f04f2554082b7809f610bc593dd as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/99ac3f04f2554082b7809f610bc593dd
2014-07-13 18:12:26,498 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/99ac3f04f2554082b7809f610bc593dd, entries=800270, sequenceid=9878, filesize=57.0m
2014-07-13 18:12:26,498 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~381.4m/399935920, currentsize=275.1m/288482080 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 14329ms, sequenceid=9878, compaction requested=true
2014-07-13 18:12:26,499 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:100), split_queue=0, merge_queue=0
2014-07-13 18:12:26,499 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:12:26,499 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:101), split_queue=0, merge_queue=0
2014-07-13 18:12:26,499 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 373.3m
2014-07-13 18:12:26,507 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:12:26,773 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:27,529 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:27,958 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38478 synced till here 38477
2014-07-13 18:12:27,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300346113 with entries=86, filesize=78.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300347529
2014-07-13 18:12:27,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300306088
2014-07-13 18:12:27,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300308212
2014-07-13 18:12:27,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300311312
2014-07-13 18:12:27,975 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300313000
2014-07-13 18:12:29,259 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:29,276 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38553 synced till here 38540
2014-07-13 18:12:29,576 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300347529 with entries=75, filesize=71.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300349259
2014-07-13 18:12:30,872 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:31,071 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38719 synced till here 38693
2014-07-13 18:12:31,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300349259 with entries=166, filesize=91.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300350872
2014-07-13 18:12:32,503 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:32,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38830 synced till here 38827
2014-07-13 18:12:32,740 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300350872 with entries=111, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300352503
2014-07-13 18:12:33,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:34,073 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38934 synced till here 38933
2014-07-13 18:12:34,087 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300352503 with entries=104, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300353799
2014-07-13 18:12:34,205 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9119, memsize=252.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c71a3de134db4ca6af70e1c44132df51
2014-07-13 18:12:34,220 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c71a3de134db4ca6af70e1c44132df51 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c71a3de134db4ca6af70e1c44132df51
2014-07-13 18:12:34,236 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c71a3de134db4ca6af70e1c44132df51, entries=919910, sequenceid=9119, filesize=65.4m
2014-07-13 18:12:34,236 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~414.4m/434520000, currentsize=309.3m/324317360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 13325ms, sequenceid=9119, compaction requested=true
2014-07-13 18:12:34,236 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:102), split_queue=0, merge_queue=0
2014-07-13 18:12:34,237 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 471.1m
2014-07-13 18:12:34,253 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:12:34,320 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9226, memsize=150.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/d572b14bcbe444aa85b9cdd005635b05
2014-07-13 18:12:34,333 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/d572b14bcbe444aa85b9cdd005635b05 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d572b14bcbe444aa85b9cdd005635b05
2014-07-13 18:12:34,347 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d572b14bcbe444aa85b9cdd005635b05, entries=546440, sequenceid=9226, filesize=38.9m
2014-07-13 18:12:34,347 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~376.4m/394680640, currentsize=174.2m/182674000 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 7848ms, sequenceid=9226, compaction requested=true
2014-07-13 18:12:34,347 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:103), split_queue=0, merge_queue=0
2014-07-13 18:12:34,347 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 311.0m
2014-07-13 18:12:34,539 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:34,657 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:35,698 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:35,983 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 38998 synced till here 38992
2014-07-13 18:12:36,206 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300353799 with entries=64, filesize=71.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300355698
2014-07-13 18:12:36,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300315044
2014-07-13 18:12:36,207 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300316837
2014-07-13 18:12:37,437 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:38,497 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39105 synced till here 39091
2014-07-13 18:12:38,687 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300355698 with entries=107, filesize=101.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300357438
2014-07-13 18:12:39,141 DEBUG [RpcServer.handler=17,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:12:40,364 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:40,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39231 synced till here 39208
2014-07-13 18:12:40,737 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300357438 with entries=126, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300360365
2014-07-13 18:12:42,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:43,870 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39375 synced till here 39362
2014-07-13 18:12:44,011 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300360365 with entries=144, filesize=100.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300362716
2014-07-13 18:12:44,970 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:45,902 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39474 synced till here 39434
2014-07-13 18:12:46,193 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300362716 with entries=99, filesize=88.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300364970
2014-07-13 18:12:48,115 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:48,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39593 synced till here 39561
2014-07-13 18:12:48,370 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300364970 with entries=119, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300368115
2014-07-13 18:12:50,396 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9390, memsize=246.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/01a428e23df4490284f4f047217464c1
2014-07-13 18:12:50,412 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/01a428e23df4490284f4f047217464c1 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/01a428e23df4490284f4f047217464c1
2014-07-13 18:12:50,426 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/01a428e23df4490284f4f047217464c1, entries=898980, sequenceid=9390, filesize=64.0m
2014-07-13 18:12:50,427 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~311.0m/326125920, currentsize=247.7m/259715920 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 16080ms, sequenceid=9390, compaction requested=true
2014-07-13 18:12:50,427 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:104), split_queue=0, merge_queue=0
2014-07-13 18:12:50,427 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:12:50,427 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:105), split_queue=0, merge_queue=0
2014-07-13 18:12:50,450 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:50,486 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:12:50,486 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 257.5m
2014-07-13 18:12:50,549 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39704 synced till here 39686
2014-07-13 18:12:50,709 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300368115 with entries=111, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300370451
2014-07-13 18:12:52,031 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:52,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:52,474 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39824 synced till here 39790
2014-07-13 18:12:53,582 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300370451 with entries=120, filesize=88.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300372434
2014-07-13 18:12:53,905 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10153, memsize=263.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/866af7036b03493f8c22706d1aec20f8
2014-07-13 18:12:53,920 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/866af7036b03493f8c22706d1aec20f8 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/866af7036b03493f8c22706d1aec20f8
2014-07-13 18:12:53,934 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/866af7036b03493f8c22706d1aec20f8, entries=960660, sequenceid=10153, filesize=68.4m
2014-07-13 18:12:53,935 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~485.1m/508621520, currentsize=293.3m/307538160 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 19698ms, sequenceid=10153, compaction requested=true
2014-07-13 18:12:53,935 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:106), split_queue=0, merge_queue=0
2014-07-13 18:12:53,990 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:12:54,003 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 298.7m
2014-07-13 18:12:54,434 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:55,285 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 39949 synced till here 39902
2014-07-13 18:12:55,403 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:12:55,712 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300372434 with entries=125, filesize=104.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300374434
2014-07-13 18:12:57,373 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:57,480 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40083 synced till here 40055
2014-07-13 18:12:57,715 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300374434 with entries=134, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300377373
2014-07-13 18:12:58,099 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=9628, memsize=91.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/5da08c62cde4412aa3303447eb704dbf
2014-07-13 18:12:58,128 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/5da08c62cde4412aa3303447eb704dbf as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/5da08c62cde4412aa3303447eb704dbf
2014-07-13 18:12:58,179 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/5da08c62cde4412aa3303447eb704dbf, entries=333280, sequenceid=9628, filesize=23.8m
2014-07-13 18:12:58,181 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~277.7m/291224960, currentsize=149.7m/156954080 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 7695ms, sequenceid=9628, compaction requested=true
2014-07-13 18:12:58,181 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:107), split_queue=0, merge_queue=0
2014-07-13 18:12:59,018 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:12:59,224 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300377373 with entries=124, filesize=94.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300379018
2014-07-13 18:13:00,206 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10318, memsize=87.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c7e8514a64594c87964ab33b8211a4c3
2014-07-13 18:13:00,228 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/c7e8514a64594c87964ab33b8211a4c3 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c7e8514a64594c87964ab33b8211a4c3
2014-07-13 18:13:00,243 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c7e8514a64594c87964ab33b8211a4c3, entries=317760, sequenceid=10318, filesize=22.7m
2014-07-13 18:13:00,244 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~311.2m/326355760, currentsize=109.3m/114649760 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 6241ms, sequenceid=10318, compaction requested=true
2014-07-13 18:13:00,244 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:108), split_queue=0, merge_queue=0
2014-07-13 18:13:01,521 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:01,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40302 synced till here 40291
2014-07-13 18:13:01,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300379018 with entries=95, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300381521
2014-07-13 18:13:02,787 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:02,804 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40384 synced till here 40383
2014-07-13 18:13:02,817 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300381521 with entries=82, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300382788
2014-07-13 18:13:03,119 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:13:03,119 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:13:03,121 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:109), split_queue=0, merge_queue=0
2014-07-13 18:13:03,828 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:04,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40470 synced till here 40468
2014-07-13 18:13:04,453 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300382788 with entries=86, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300383829
2014-07-13 18:13:05,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:05,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40555 synced till here 40545
2014-07-13 18:13:05,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300383829 with entries=85, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300385459
2014-07-13 18:13:06,032 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:06,698 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:06,722 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40630 synced till here 40627
2014-07-13 18:13:07,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300385459 with entries=75, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300386699
2014-07-13 18:13:07,376 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:07,500 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:13:07,508 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.9m
2014-07-13 18:13:07,953 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:13:08,009 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:08,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40726 synced till here 40715
2014-07-13 18:13:08,200 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300386699 with entries=96, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300388009
2014-07-13 18:13:08,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:09,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:09,738 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40815 synced till here 40801
2014-07-13 18:13:09,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300388009 with entries=89, filesize=75.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300389693
2014-07-13 18:13:09,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:10,611 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.41 MB, free=3.95 GB, max=3.96 GB, blocks=4, accesses=233997, hits=46390, hitRatio=19.82%, , cachingAccesses=46412, cachingHits=46370, cachingHitsRatio=99.90%, evictions=0, evicted=38, evictedPerRun=Infinity
2014-07-13 18:13:11,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:11,368 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40904 synced till here 40889
2014-07-13 18:13:11,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300389693 with entries=89, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300391277
2014-07-13 18:13:11,511 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:12,730 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:12,788 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 40984 synced till here 40973
2014-07-13 18:13:12,903 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300391277 with entries=80, filesize=71.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300392730
2014-07-13 18:13:12,903 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:14,429 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:14,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300392730 with entries=90, filesize=77.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300394429
2014-07-13 18:13:14,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:16,017 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10462, memsize=153.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/53f86886c60d4ca5a03e2a529b2616f0
2014-07-13 18:13:16,036 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/53f86886c60d4ca5a03e2a529b2616f0 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/53f86886c60d4ca5a03e2a529b2616f0
2014-07-13 18:13:16,116 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/53f86886c60d4ca5a03e2a529b2616f0, entries=558840, sequenceid=10462, filesize=39.8m
2014-07-13 18:13:16,117 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.0m/277895120, currentsize=194.5m/203990160 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 8609ms, sequenceid=10462, compaction requested=true
2014-07-13 18:13:16,117 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:110), split_queue=0, merge_queue=0
2014-07-13 18:13:16,167 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:16,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41179 synced till here 41160
2014-07-13 18:13:17,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300394429 with entries=105, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300396167
2014-07-13 18:13:17,079 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:17,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:18,626 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41284 synced till here 41279
2014-07-13 18:13:18,683 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300396167 with entries=105, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300397927
2014-07-13 18:13:18,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:19,002 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:13:19,002 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 257.2m
2014-07-13 18:13:19,277 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:13:19,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:19,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41350 synced till here 41342
2014-07-13 18:13:20,131 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300397927 with entries=66, filesize=73.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300399429
2014-07-13 18:13:20,132 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:20,873 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:20,969 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41421 synced till here 41412
2014-07-13 18:13:21,644 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300399429 with entries=71, filesize=73.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300400873
2014-07-13 18:13:21,644 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:22,394 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:23,320 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41515 synced till here 41485
2014-07-13 18:13:23,618 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300400873 with entries=94, filesize=83.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300402394
2014-07-13 18:13:23,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:13:25,238 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:13:25,674 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files, but is 1.6g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:13:25,674 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:25,674 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. due to global heap pressure
2014-07-13 18:13:25,675 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 1.6g
2014-07-13 18:13:25,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41624 synced till here 41614
2014-07-13 18:13:26,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300402394 with entries=109, filesize=100.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300405675
2014-07-13 18:13:27,667 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,668 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,670 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,672 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,673 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,674 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,674 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,675 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,677 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,677 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,682 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,697 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,758 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,762 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,773 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:27,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41718 synced till here 41688
2014-07-13 18:13:27,948 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,950 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,950 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,950 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,952 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:27,952 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,081 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,081 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,082 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,082 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,082 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,084 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,084 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,085 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,085 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,087 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,088 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,088 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,089 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,089 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,090 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,090 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,092 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,092 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,092 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,093 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,094 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,094 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,094 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,095 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,095 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,096 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,096 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,096 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,097 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,099 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:28,100 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300405675 with entries=94, filesize=90.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300407773
2014-07-13 18:13:29,284 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1005ms
GC pool 'ParNew' had collection(s): count=1 time=998ms
2014-07-13 18:13:29,531 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:13:31,414 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10621, memsize=207.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/39f2d9c02e0d455e9066ab568c884cac
2014-07-13 18:13:31,429 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/39f2d9c02e0d455e9066ab568c884cac as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/39f2d9c02e0d455e9066ab568c884cac
2014-07-13 18:13:31,442 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/39f2d9c02e0d455e9066ab568c884cac, entries=754150, sequenceid=10621, filesize=53.7m
2014-07-13 18:13:31,442 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.6m/275380240, currentsize=174.2m/182663440 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 12440ms, sequenceid=10621, compaction requested=true
2014-07-13 18:13:31,443 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:111), split_queue=0, merge_queue=0
2014-07-13 18:13:31,443 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3344ms
2014-07-13 18:13:31,443 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,444 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3347ms
2014-07-13 18:13:31,444 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,444 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3348ms
2014-07-13 18:13:31,444 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,444 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3349ms
2014-07-13 18:13:31,444 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,444 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3349ms
2014-07-13 18:13:31,444 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,445 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3350ms
2014-07-13 18:13:31,445 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,446 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3351ms
2014-07-13 18:13:31,446 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,446 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3352ms
2014-07-13 18:13:31,446 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,446 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3352ms
2014-07-13 18:13:31,446 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,449 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3354ms
2014-07-13 18:13:31,449 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,457 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3364ms
2014-07-13 18:13:31,457 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,457 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3365ms
2014-07-13 18:13:31,457 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,462 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3370ms
2014-07-13 18:13:31,462 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,464 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3372ms
2014-07-13 18:13:31,464 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,464 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3374ms
2014-07-13 18:13:31,464 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,465 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3375ms
2014-07-13 18:13:31,465 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,465 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3376ms
2014-07-13 18:13:31,465 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,465 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3376ms
2014-07-13 18:13:31,465 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,465 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3377ms
2014-07-13 18:13:31,466 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,466 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3378ms
2014-07-13 18:13:31,466 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,473 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3386ms
2014-07-13 18:13:31,473 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,474 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3388ms
2014-07-13 18:13:31,474 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,474 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3390ms
2014-07-13 18:13:31,474 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,474 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3390ms
2014-07-13 18:13:31,474 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,474 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3391ms
2014-07-13 18:13:31,475 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,475 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3393ms
2014-07-13 18:13:31,475 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,475 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3393ms
2014-07-13 18:13:31,475 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,475 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3393ms
2014-07-13 18:13:31,475 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,475 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3394ms
2014-07-13 18:13:31,476 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,476 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3396ms
2014-07-13 18:13:31,476 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,477 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3524ms
2014-07-13 18:13:31,477 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,477 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3525ms
2014-07-13 18:13:31,477 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,485 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3535ms
2014-07-13 18:13:31,485 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,485 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3535ms
2014-07-13 18:13:31,485 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,487 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3537ms
2014-07-13 18:13:31,487 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,487 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3539ms
2014-07-13 18:13:31,487 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,487 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3725ms
2014-07-13 18:13:31,487 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,490 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3732ms
2014-07-13 18:13:31,490 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,490 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3816ms
2014-07-13 18:13:31,490 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,493 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3811ms
2014-07-13 18:13:31,493 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,497 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3830ms
2014-07-13 18:13:31,497 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,501 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3824ms
2014-07-13 18:13:31,501 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,505 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3830ms
2014-07-13 18:13:31,505 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,509 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3835ms
2014-07-13 18:13:31,509 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,509 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3835ms
2014-07-13 18:13:31,509 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,509 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3836ms
2014-07-13 18:13:31,509 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,517 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3845ms
2014-07-13 18:13:31,517 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,517 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3847ms
2014-07-13 18:13:31,517 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,522 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3854ms
2014-07-13 18:13:31,522 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,529 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3862ms
2014-07-13 18:13:31,529 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:31,701 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:13:31,701 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files, but is 1.2g vs best flushable region's 175.3m. Choosing the bigger.
2014-07-13 18:13:31,701 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. due to global heap pressure
2014-07-13 18:13:31,702 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.2g
2014-07-13 18:13:32,910 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1125ms
GC pool 'ParNew' had collection(s): count=1 time=1137ms
2014-07-13 18:13:33,713 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:33,755 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41826 synced till here 41796
2014-07-13 18:13:34,931 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300407773 with entries=108, filesize=93.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300413713
2014-07-13 18:13:35,152 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,155 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,157 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,158 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,160 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,161 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,169 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,302 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,303 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,306 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,311 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,312 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,313 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,315 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,316 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,316 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,316 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,320 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,320 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,321 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,322 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,322 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,323 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,324 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,488 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,494 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,498 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,498 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,501 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,503 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,503 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,504 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,506 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,508 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,510 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,513 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,513 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,515 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,516 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,516 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,517 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,520 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,521 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,521 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,521 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,523 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,523 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,523 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,524 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,526 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:13:35,585 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:13:40,153 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,155 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,157 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,158 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,160 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,161 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,169 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,303 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,304 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,306 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,312 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,313 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,316 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,316 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,316 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,316 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,320 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,320 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,321 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,322 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,322 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,323 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,324 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,489 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,495 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,498 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,498 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,501 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,503 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,503 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,505 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,507 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,508 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,510 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,513 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,514 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,515 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,516 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,516 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,517 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,520 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,521 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,521 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,522 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,523 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,523 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,524 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:40,524 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:13:40,527 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:13:45,153 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,156 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,157 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,158 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,161 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,162 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,170 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,303 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,304 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,306 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,313 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,314 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,316 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,316 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,316 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,317 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,320 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,321 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,322 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,322 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,322 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,323 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,324 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,489 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,495 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,498 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,499 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,501 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,503 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,503 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,505 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,507 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,509 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,510 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,513 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,514 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,515 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,517 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,517 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,518 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,520 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,521 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,521 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,522 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,524 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:13:45,524 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,525 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,525 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:45,527 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:13:50,154 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:13:50,156 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,158 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,159 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,161 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,162 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,170 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,303 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,304 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,307 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,313 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,314 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,316 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,316 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,317 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,317 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,321 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,321 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,322 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,322 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,323 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,324 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,324 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,489 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,496 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,498 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,499 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,502 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,504 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,504 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,505 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,508 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,509 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,511 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,513 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:13:50,514 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,515 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,517 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,517 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,518 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,521 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,521 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,522 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,522 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,524 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,525 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:13:50,525 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:13:50,525 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:50,528 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:13:55,154 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,156 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,158 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,159 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,161 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,163 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,170 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,304 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,304 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,307 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,314 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,315 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,316 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,317 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,317 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,317 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,321 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,321 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,322 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,323 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,323 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,324 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,325 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,490 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,496 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,499 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,500 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,502 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,504 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,504 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,506 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,508 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,509 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,511 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,514 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,514 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,515 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,517 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,517 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,518 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,522 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,522 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,522 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,523 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,525 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,525 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,525 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:55,525 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:13:55,528 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:13:57,266 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10242, memsize=584.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/7bd0b3abb42b4a4abc4e691cb9c1855d
2014-07-13 18:13:57,516 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/7bd0b3abb42b4a4abc4e691cb9c1855d as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/7bd0b3abb42b4a4abc4e691cb9c1855d
2014-07-13 18:13:57,529 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/7bd0b3abb42b4a4abc4e691cb9c1855d, entries=2129180, sequenceid=10242, filesize=151.6m
2014-07-13 18:13:57,530 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1307166640, currentsize=45.5m/47697120 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 25828ms, sequenceid=10242, compaction requested=true
2014-07-13 18:13:57,530 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:112), split_queue=0, merge_queue=0
2014-07-13 18:13:57,530 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22004ms
2014-07-13 18:13:57,530 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,531 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 102052ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:13:57,531 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22007ms
2014-07-13 18:13:57,531 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,531 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., flushing=true, writesEnabled=true
2014-07-13 18:13:57,531 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22008ms
2014-07-13 18:13:57,531 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,531 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22008ms
2014-07-13 18:13:57,531 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,545 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22022ms
2014-07-13 18:13:57,545 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,545 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22024ms
2014-07-13 18:13:57,545 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,545 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22024ms
2014-07-13 18:13:57,545 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,545 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22025ms
2014-07-13 18:13:57,545 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,548 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22028ms
2014-07-13 18:13:57,548 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,548 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22031ms
2014-07-13 18:13:57,548 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,548 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22032ms
2014-07-13 18:13:57,548 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,548 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22032ms
2014-07-13 18:13:57,548 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,548 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22034ms
2014-07-13 18:13:57,548 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,549 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22036ms
2014-07-13 18:13:57,549 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,553 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22040ms
2014-07-13 18:13:57,553 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,553 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22043ms
2014-07-13 18:13:57,553 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,553 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22045ms
2014-07-13 18:13:57,553 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,553 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22047ms
2014-07-13 18:13:57,553 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,557 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22053ms
2014-07-13 18:13:57,557 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,558 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22055ms
2014-07-13 18:13:57,558 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,565 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22062ms
2014-07-13 18:13:57,565 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,565 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22064ms
2014-07-13 18:13:57,566 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,566 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22068ms
2014-07-13 18:13:57,566 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,569 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22071ms
2014-07-13 18:13:57,569 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,573 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22079ms
2014-07-13 18:13:57,573 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,573 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22085ms
2014-07-13 18:13:57,573 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,573 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22249ms
2014-07-13 18:13:57,573 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,573 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22250ms
2014-07-13 18:13:57,573 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,797 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22475ms
2014-07-13 18:13:57,797 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,797 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22476ms
2014-07-13 18:13:57,798 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,798 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22477ms
2014-07-13 18:13:57,798 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,801 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22481ms
2014-07-13 18:13:57,801 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,801 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22481ms
2014-07-13 18:13:57,801 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,801 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22485ms
2014-07-13 18:13:57,801 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,801 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22485ms
2014-07-13 18:13:57,801 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,803 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22488ms
2014-07-13 18:13:57,803 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,803 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22488ms
2014-07-13 18:13:57,803 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,804 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22491ms
2014-07-13 18:13:57,804 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,808 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22496ms
2014-07-13 18:13:57,809 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,809 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22499ms
2014-07-13 18:13:57,809 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,809 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22503ms
2014-07-13 18:13:57,809 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,810 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22507ms
2014-07-13 18:13:57,810 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,811 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22509ms
2014-07-13 18:13:57,811 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,813 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22644ms
2014-07-13 18:13:57,813 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,816 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22655ms
2014-07-13 18:13:57,817 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,821 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22661ms
2014-07-13 18:13:57,821 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,825 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22667ms
2014-07-13 18:13:57,825 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,825 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22668ms
2014-07-13 18:13:57,825 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,837 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22682ms
2014-07-13 18:13:57,837 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:57,837 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 22685ms
2014-07-13 18:13:57,837 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:13:58,027 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:58,103 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 41930 synced till here 41904
2014-07-13 18:13:58,190 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23061,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415128,"queuetimems":5402,"class":"HRegionServer","responsesize":6663,"method":"Multi"}
2014-07-13 18:13:58,332 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24364,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413967,"queuetimems":4620,"class":"HRegionServer","responsesize":13761,"method":"Multi"}
2014-07-13 18:13:58,337 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24347,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413989,"queuetimems":4278,"class":"HRegionServer","responsesize":9533,"method":"Multi"}
2014-07-13 18:13:58,375 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300413713 with entries=104, filesize=91.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300438027
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415493,"queuetimems":5424,"class":"HRegionServer","responsesize":4094,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413966,"queuetimems":4639,"class":"HRegionServer","responsesize":6131,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23294,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415304,"queuetimems":5393,"class":"HRegionServer","responsesize":5922,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23113,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415485,"queuetimems":5493,"class":"HRegionServer","responsesize":6474,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23096,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415501,"queuetimems":5416,"class":"HRegionServer","responsesize":4080,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24624,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413973,"queuetimems":4455,"class":"HRegionServer","responsesize":9531,"method":"Multi"}
2014-07-13 18:13:58,599 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23445,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415153,"queuetimems":5260,"class":"HRegionServer","responsesize":10628,"method":"Multi"}
2014-07-13 18:13:58,599 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413951,"queuetimems":5742,"class":"HRegionServer","responsesize":12347,"method":"Multi"}
2014-07-13 18:13:58,599 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23097,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415502,"queuetimems":5084,"class":"HRegionServer","responsesize":1627,"method":"Multi"}
2014-07-13 18:13:58,600 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23114,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415485,"queuetimems":5472,"class":"HRegionServer","responsesize":10239,"method":"Multi"}
2014-07-13 18:13:58,600 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23089,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415510,"queuetimems":5086,"class":"HRegionServer","responsesize":2151,"method":"Multi"}
2014-07-13 18:13:58,600 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23083,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415517,"queuetimems":4897,"class":"HRegionServer","responsesize":3239,"method":"Multi"}
2014-07-13 18:13:58,601 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415490,"queuetimems":5441,"class":"HRegionServer","responsesize":9201,"method":"Multi"}
2014-07-13 18:13:58,602 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413970,"queuetimems":4549,"class":"HRegionServer","responsesize":5067,"method":"Multi"}
2014-07-13 18:13:58,605 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24867,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413737,"queuetimems":5618,"class":"HRegionServer","responsesize":15866,"method":"Multi"}
2014-07-13 18:13:58,605 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23103,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415502,"queuetimems":5082,"class":"HRegionServer","responsesize":839,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24615,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413982,"queuetimems":4308,"class":"HRegionServer","responsesize":10243,"method":"Multi"}
2014-07-13 18:13:58,606 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24624,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413981,"queuetimems":4332,"class":"HRegionServer","responsesize":6601,"method":"Multi"}
2014-07-13 18:13:58,606 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413978,"queuetimems":4400,"class":"HRegionServer","responsesize":8130,"method":"Multi"}
2014-07-13 18:13:58,606 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23300,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415305,"queuetimems":5347,"class":"HRegionServer","responsesize":10085,"method":"Multi"}
2014-07-13 18:13:58,606 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23456,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415150,"queuetimems":5283,"class":"HRegionServer","responsesize":10151,"method":"Multi"}
2014-07-13 18:13:58,607 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24648,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413958,"queuetimems":4656,"class":"HRegionServer","responsesize":8043,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24616,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413981,"queuetimems":4374,"class":"HRegionServer","responsesize":11134,"method":"Multi"}
2014-07-13 18:13:58,614 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23309,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415304,"queuetimems":5366,"class":"HRegionServer","responsesize":10803,"method":"Multi"}
2014-07-13 18:13:58,614 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:13:58,614 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24626,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413988,"queuetimems":4297,"class":"HRegionServer","responsesize":8042,"method":"Multi"}
2014-07-13 18:13:58,616 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24645,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413971,"queuetimems":4502,"class":"HRegionServer","responsesize":14991,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24623,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413974,"queuetimems":4420,"class":"HRegionServer","responsesize":16447,"method":"Multi"}
2014-07-13 18:13:58,617 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23317,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415300,"queuetimems":5401,"class":"HRegionServer","responsesize":2842,"method":"Multi"}
2014-07-13 18:13:58,618 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24655,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413962,"queuetimems":4643,"class":"HRegionServer","responsesize":4976,"method":"Multi"}
2014-07-13 18:13:58,618 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24645,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413972,"queuetimems":4482,"class":"HRegionServer","responsesize":7967,"method":"Multi"}
2014-07-13 18:13:58,614 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23472,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415141,"queuetimems":5366,"class":"HRegionServer","responsesize":10484,"method":"Multi"}
2014-07-13 18:13:58,605 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413968,"queuetimems":4615,"class":"HRegionServer","responsesize":4365,"method":"Multi"}
2014-07-13 18:13:58,600 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23082,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415517,"queuetimems":5091,"class":"HRegionServer","responsesize":1343,"method":"Multi"}
2014-07-13 18:13:58,599 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24634,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413965,"queuetimems":4645,"class":"HRegionServer","responsesize":1217,"method":"Multi"}
2014-07-13 18:13:58,599 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23286,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415312,"queuetimems":5332,"class":"HRegionServer","responsesize":10278,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23112,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415486,"queuetimems":5456,"class":"HRegionServer","responsesize":7099,"method":"Multi"}
2014-07-13 18:13:58,598 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23449,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415149,"queuetimems":5311,"class":"HRegionServer","responsesize":6510,"method":"Multi"}
2014-07-13 18:13:58,623 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24677,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413946,"queuetimems":5792,"class":"HRegionServer","responsesize":19596,"method":"Multi"}
2014-07-13 18:13:58,625 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24662,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413962,"queuetimems":4648,"class":"HRegionServer","responsesize":13574,"method":"Multi"}
2014-07-13 18:13:58,629 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 272.2m
2014-07-13 18:13:58,629 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":30536,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300408079,"queuetimems":699,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-13 18:13:58,622 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24641,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413981,"queuetimems":4347,"class":"HRegionServer","responsesize":9935,"method":"Multi"}
2014-07-13 18:13:58,634 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24686,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413947,"queuetimems":5760,"class":"HRegionServer","responsesize":18254,"method":"Multi"}
2014-07-13 18:13:58,637 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415136,"queuetimems":5386,"class":"HRegionServer","responsesize":7675,"method":"Multi"}
2014-07-13 18:13:58,756 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23607,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415149,"queuetimems":5327,"class":"HRegionServer","responsesize":10071,"method":"Multi"}
2014-07-13 18:13:58,756 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23615,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300415141,"queuetimems":5341,"class":"HRegionServer","responsesize":10727,"method":"Multi"}
2014-07-13 18:13:59,644 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:13:59,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:13:59,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42022 synced till here 42010
2014-07-13 18:14:00,021 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26043,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413969,"queuetimems":4555,"class":"HRegionServer","responsesize":15536,"method":"Multi"}
2014-07-13 18:14:00,073 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300438027 with entries=92, filesize=86.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300439808
2014-07-13 18:14:00,446 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26477,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300413969,"queuetimems":4583,"class":"HRegionServer","responsesize":17768,"method":"Multi"}
2014-07-13 18:14:01,339 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:01,388 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42128 synced till here 42089
2014-07-13 18:14:01,860 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300439808 with entries=106, filesize=96.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300441340
2014-07-13 18:14:03,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:03,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42227 synced till here 42198
2014-07-13 18:14:03,400 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300441340 with entries=99, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300443118
2014-07-13 18:14:04,840 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10758, memsize=85.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/e36d35a1a4e54d83ac81925b2c6de1b2
2014-07-13 18:14:04,852 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/e36d35a1a4e54d83ac81925b2c6de1b2 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e36d35a1a4e54d83ac81925b2c6de1b2
2014-07-13 18:14:04,866 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e36d35a1a4e54d83ac81925b2c6de1b2, entries=309560, sequenceid=10758, filesize=22.1m
2014-07-13 18:14:04,867 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~279.5m/293087040, currentsize=111.7m/117171440 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 6238ms, sequenceid=10758, compaction requested=true
2014-07-13 18:14:04,867 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:113), split_queue=0, merge_queue=0
2014-07-13 18:14:04,884 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:05,018 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42320 synced till here 42298
2014-07-13 18:14:05,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300443118 with entries=93, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300444884
2014-07-13 18:14:05,723 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10696, memsize=832.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/7ad71a9c33ba4524a73ed46e7d688ad3
2014-07-13 18:14:05,747 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/7ad71a9c33ba4524a73ed46e7d688ad3 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/7ad71a9c33ba4524a73ed46e7d688ad3
2014-07-13 18:14:05,923 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/7ad71a9c33ba4524a73ed46e7d688ad3, entries=3029230, sequenceid=10696, filesize=215.6m
2014-07-13 18:14:05,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:05,924 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.6g/1748440960, currentsize=318.7m/334167840 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 40249ms, sequenceid=10696, compaction requested=true
2014-07-13 18:14:05,924 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:114), split_queue=0, merge_queue=0
2014-07-13 18:14:05,925 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:14:05,929 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:14:05,929 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:115), split_queue=0, merge_queue=0
2014-07-13 18:14:05,964 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42421 synced till here 42395
2014-07-13 18:14:06,621 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:14:06,621 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:14:06,621 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:116), split_queue=0, merge_queue=0
2014-07-13 18:14:06,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300444884 with entries=101, filesize=94.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300445924
2014-07-13 18:14:06,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300321891
2014-07-13 18:14:06,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300323069
2014-07-13 18:14:06,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300324460
2014-07-13 18:14:06,674 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300326008
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300327410
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300329311
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300332167
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300334273
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300336971
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300339371
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300341124
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300342992
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300344541
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300346113
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300347529
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300349259
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300350872
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300352503
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300353799
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300355698
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300357438
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300360365
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300362716
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300364970
2014-07-13 18:14:06,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300368115
2014-07-13 18:14:07,457 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:07,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42528 synced till here 42500
2014-07-13 18:14:07,627 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300445924 with entries=107, filesize=97.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300447457
2014-07-13 18:14:08,669 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:14:08,669 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 257.1m
2014-07-13 18:14:08,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:08,820 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42599 synced till here 42597
2014-07-13 18:14:08,854 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300447457 with entries=71, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300448797
2014-07-13 18:14:08,978 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:10,240 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:10,271 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300448797 with entries=155, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300450241
2014-07-13 18:14:11,330 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:11,403 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42841 synced till here 42838
2014-07-13 18:14:11,427 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300450241 with entries=87, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300451330
2014-07-13 18:14:11,804 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10891, memsize=58.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/319d81badbc04c1e9cedc7884427436f
2014-07-13 18:14:11,816 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/319d81badbc04c1e9cedc7884427436f as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/319d81badbc04c1e9cedc7884427436f
2014-07-13 18:14:11,832 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/319d81badbc04c1e9cedc7884427436f, entries=213770, sequenceid=10891, filesize=15.2m
2014-07-13 18:14:11,833 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~264.4m/277276240, currentsize=84.4m/88513600 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 3164ms, sequenceid=10891, compaction requested=true
2014-07-13 18:14:11,833 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-13 18:14:12,665 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:12,799 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 42950 synced till here 42944
2014-07-13 18:14:12,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300451330 with entries=109, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300452665
2014-07-13 18:14:12,998 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:14,535 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:14,555 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43041 synced till here 43037
2014-07-13 18:14:14,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300452665 with entries=91, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300454536
2014-07-13 18:14:14,617 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:15,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:16,337 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43154 synced till here 43148
2014-07-13 18:14:16,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300454536 with entries=113, filesize=108.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300455776
2014-07-13 18:14:16,385 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:18,571 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:18,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300455776 with entries=62, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300458572
2014-07-13 18:14:18,623 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:20,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:20,273 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43298 synced till here 43296
2014-07-13 18:14:20,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300458572 with entries=82, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300460120
2014-07-13 18:14:20,293 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:20,585 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:14:20,585 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 258.7m
2014-07-13 18:14:21,116 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:21,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:21,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43380 synced till here 43366
2014-07-13 18:14:21,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300460120 with entries=82, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300461391
2014-07-13 18:14:21,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:21,593 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/d8de0f0f8eea4608acc920df7317da9f as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/d8de0f0f8eea4608acc920df7317da9f
2014-07-13 18:14:21,893 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:14:22,081 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/db68482a9333465883f1dc467e2db120, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/db68482a9333465883f1dc467e2db120
2014-07-13 18:14:22,085 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/eea2f7ff442c4225bbe19a6152991edb, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/eea2f7ff442c4225bbe19a6152991edb
2014-07-13 18:14:22,089 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/443e079b8dd945829666ccc48e0efb73, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/443e079b8dd945829666ccc48e0efb73
2014-07-13 18:14:22,093 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/0f37a6d74b254f8db2a7ce7ccef0c3a8, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/0f37a6d74b254f8db2a7ce7ccef0c3a8
2014-07-13 18:14:22,096 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ea460f6a20554bd39e51370deccd5404, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ea460f6a20554bd39e51370deccd5404
2014-07-13 18:14:22,100 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/255deff7f2f04286a03d8a19f960e49c, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/255deff7f2f04286a03d8a19f960e49c
2014-07-13 18:14:22,104 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3bd44d9913be4b1babb48047614a2eb1, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/3bd44d9913be4b1babb48047614a2eb1
2014-07-13 18:14:22,107 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/001ffb3717364543ac1367f028052016, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/001ffb3717364543ac1367f028052016
2014-07-13 18:14:22,112 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/634cedb551464b83bbb57af979650341, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/634cedb551464b83bbb57af979650341
2014-07-13 18:14:22,114 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a925dffe9b7845feb05462336ac34e1a, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/a925dffe9b7845feb05462336ac34e1a
2014-07-13 18:14:22,115 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 10 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into d8de0f0f8eea4608acc920df7317da9f(size=745.6m), total size for store is 2.7g. This selection was in queue for 0sec, and took 2mins, 40sec to execute.
2014-07-13 18:14:22,115 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=10, fileSize=750.1m, priority=2, time=254208986542814; duration=2mins, 40sec
2014-07-13 18:14:22,115 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-13 18:14:22,115 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:14:22,119 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 123663822 starting at candidate #18 after considering 132 permutations with 110 in ratio
2014-07-13 18:14:22,119 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating minor compaction
2014-07-13 18:14:22,119 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:14:22,119 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=117.9m
2014-07-13 18:14:22,119 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/9f5a10211ef44fabace620e2598b19f8, keycount=47988, bloomtype=ROW, size=34.2m, encoding=NONE, seqNum=8618
2014-07-13 18:14:22,119 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/991001aa75394e44843c1f20c0314b56, keycount=62961, bloomtype=ROW, size=44.8m, encoding=NONE, seqNum=8939
2014-07-13 18:14:22,120 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d572b14bcbe444aa85b9cdd005635b05, keycount=54644, bloomtype=ROW, size=38.9m, encoding=NONE, seqNum=9226
2014-07-13 18:14:22,161 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:22,776 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 700.2m
2014-07-13 18:14:23,434 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:23,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:24,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43472 synced till here 43471
2014-07-13 18:14:24,066 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300461391 with entries=92, filesize=78.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300463727
2014-07-13 18:14:24,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:25,300 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:25,344 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43555 synced till here 43553
2014-07-13 18:14:25,368 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300463727 with entries=83, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300465301
2014-07-13 18:14:25,369 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:27,247 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:27,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43634 synced till here 43632
2014-07-13 18:14:27,417 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300465301 with entries=79, filesize=72.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300467247
2014-07-13 18:14:27,418 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:28,586 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:28,796 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43724 synced till here 43716
2014-07-13 18:14:29,191 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300467247 with entries=90, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300468587
2014-07-13 18:14:29,191 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:29,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:29,898 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43793 synced till here 43789
2014-07-13 18:14:29,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300468587 with entries=69, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300469875
2014-07-13 18:14:29,999 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:30,514 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11075, memsize=251.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1ee02f7387ab40c9b514c178cd4c5094
2014-07-13 18:14:30,538 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/1ee02f7387ab40c9b514c178cd4c5094 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1ee02f7387ab40c9b514c178cd4c5094
2014-07-13 18:14:30,549 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/1ee02f7387ab40c9b514c178cd4c5094, entries=917310, sequenceid=11075, filesize=65.2m
2014-07-13 18:14:30,550 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~267.8m/280822400, currentsize=178.7m/187427760 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 9965ms, sequenceid=11075, compaction requested=true
2014-07-13 18:14:30,550 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:117), split_queue=0, merge_queue=0
2014-07-13 18:14:31,102 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:31,659 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300469875 with entries=64, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300471102
2014-07-13 18:14:31,660 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): ecd2c8d6e263c2e3db5b8717fb22b6df
2014-07-13 18:14:33,449 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90330ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:14:33,449 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 1.6g
2014-07-13 18:14:34,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:34,658 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 43940 synced till here 43935
2014-07-13 18:14:34,672 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300471102 with entries=83, filesize=68.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300474458
2014-07-13 18:14:35,108 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:35,965 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:35,988 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11107, memsize=300.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/37ff51fb4d1a46bb80298d43d2ef1fb2
2014-07-13 18:14:36,003 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300474458 with entries=67, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300475966
2014-07-13 18:14:36,014 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/37ff51fb4d1a46bb80298d43d2ef1fb2 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/37ff51fb4d1a46bb80298d43d2ef1fb2
2014-07-13 18:14:36,028 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/37ff51fb4d1a46bb80298d43d2ef1fb2, entries=1094650, sequenceid=11107, filesize=77.9m
2014-07-13 18:14:36,029 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~700.2m/734186560, currentsize=217.4m/227974480 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 13253ms, sequenceid=11107, compaction requested=true
2014-07-13 18:14:36,029 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:118), split_queue=0, merge_queue=0
2014-07-13 18:14:36,637 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:14:36,638 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:14:36,638 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:119), split_queue=0, merge_queue=0
2014-07-13 18:14:37,198 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:37,405 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44096 synced till here 44093
2014-07-13 18:14:37,498 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300475966 with entries=89, filesize=82.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300477198
2014-07-13 18:14:37,941 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:14:37,941 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 256.8m
2014-07-13 18:14:38,142 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:38,894 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:38,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44166 synced till here 44164
2014-07-13 18:14:38,933 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300477198 with entries=70, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300478895
2014-07-13 18:14:39,656 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/e2c2c128cfa84a4987df519402d8c5b7 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/e2c2c128cfa84a4987df519402d8c5b7
2014-07-13 18:14:39,764 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:14:39,772 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/9f5a10211ef44fabace620e2598b19f8, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/9f5a10211ef44fabace620e2598b19f8
2014-07-13 18:14:39,776 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/991001aa75394e44843c1f20c0314b56, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/991001aa75394e44843c1f20c0314b56
2014-07-13 18:14:39,778 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d572b14bcbe444aa85b9cdd005635b05, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/d572b14bcbe444aa85b9cdd005635b05
2014-07-13 18:14:39,778 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into e2c2c128cfa84a4987df519402d8c5b7(size=92.4m), total size for store is 2.7g. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-13 18:14:39,778 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=3, fileSize=117.9m, priority=-2, time=254369546107132; duration=17sec
2014-07-13 18:14:39,779 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-13 18:14:39,779 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-13 18:14:39,779 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:14:39,784 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 185922514 starting at candidate #17 after considering 124 permutations with 94 in ratio
2014-07-13 18:14:39,785 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:14:39,785 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:14:39,785 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=177.3m
2014-07-13 18:14:39,785 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/31bcab7b70074d7c8c9411015dfeefd3, keycount=33761, bloomtype=ROW, size=24.1m, encoding=NONE, seqNum=8811
2014-07-13 18:14:39,785 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c71a3de134db4ca6af70e1c44132df51, keycount=91991, bloomtype=ROW, size=65.4m, encoding=NONE, seqNum=9119
2014-07-13 18:14:39,785 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/01a428e23df4490284f4f047217464c1, keycount=89898, bloomtype=ROW, size=64.0m, encoding=NONE, seqNum=9390
2014-07-13 18:14:39,785 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/5da08c62cde4412aa3303447eb704dbf, keycount=33328, bloomtype=ROW, size=23.8m, encoding=NONE, seqNum=9628
2014-07-13 18:14:39,858 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:39,985 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:40,242 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44246 synced till here 44245
2014-07-13 18:14:40,574 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300478895 with entries=80, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300479985
2014-07-13 18:14:41,403 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:41,823 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44318 synced till here 44316
2014-07-13 18:14:41,876 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300479985 with entries=72, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300481403
2014-07-13 18:14:42,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:42,693 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44384 synced till here 44383
2014-07-13 18:14:42,714 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300481403 with entries=66, filesize=63.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300482670
2014-07-13 18:14:44,516 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:44,549 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300482670 with entries=58, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300484516
2014-07-13 18:14:45,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:45,751 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44515 synced till here 44510
2014-07-13 18:14:45,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300484516 with entries=73, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300485716
2014-07-13 18:14:46,870 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:46,899 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44580 synced till here 44571
2014-07-13 18:14:47,187 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300485716 with entries=65, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300486870
2014-07-13 18:14:48,049 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11293, memsize=246.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/5c1562ef9a954ed9a897acd347d9998b
2014-07-13 18:14:48,069 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/5c1562ef9a954ed9a897acd347d9998b as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/5c1562ef9a954ed9a897acd347d9998b
2014-07-13 18:14:48,090 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/5c1562ef9a954ed9a897acd347d9998b, entries=895920, sequenceid=11293, filesize=63.8m
2014-07-13 18:14:48,091 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~260.0m/272656640, currentsize=223.8m/234682960 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10149ms, sequenceid=11293, compaction requested=true
2014-07-13 18:14:48,091 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-13 18:14:48,091 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.1g
2014-07-13 18:14:48,512 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:49,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44703 synced till here 44661
2014-07-13 18:14:49,784 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300486870 with entries=123, filesize=92.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300488512
2014-07-13 18:14:50,069 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:14:50,216 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:14:51,282 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:14:51,304 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44812 synced till here 44794
2014-07-13 18:14:51,427 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300488512 with entries=109, filesize=89.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300491283
2014-07-13 18:14:51,558 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,558 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,559 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,559 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,559 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,561 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,568 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,598 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,600 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,610 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,621 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,621 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,626 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,644 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,662 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,662 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,662 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,662 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,664 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,671 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,687 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,707 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,711 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,711 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,715 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,715 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:51,730 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:52,779 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:52,812 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,531 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,535 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,544 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,567 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,589 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,623 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,632 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,636 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,639 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,653 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,660 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,685 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,692 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,699 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,725 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,741 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,762 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,788 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,792 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,801 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:53,832 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:14:56,558 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:56,558 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:56,559 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:56,560 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:57,274 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:57,275 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5564ms
2014-07-13 18:14:57,275 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5613ms
2014-07-13 18:14:57,275 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5655ms
2014-07-13 18:14:57,275 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5677ms
2014-07-13 18:14:57,276 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5614ms
2014-07-13 18:14:57,276 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5612ms
2014-07-13 18:14:57,276 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5589ms
2014-07-13 18:14:57,276 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5569ms
2014-07-13 18:14:57,277 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5605ms
2014-07-13 18:14:57,277 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5566ms
2014-07-13 18:14:57,277 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5562ms
2014-07-13 18:14:57,277 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5547ms
2014-07-13 18:14:57,278 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5563ms
2014-07-13 18:14:57,278 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5717ms
2014-07-13 18:14:57,278 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5710ms
2014-07-13 18:14:57,278 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5678ms
2014-07-13 18:14:57,279 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5669ms
2014-07-13 18:14:57,279 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5658ms
2014-07-13 18:14:57,279 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5635ms
2014-07-13 18:14:57,279 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5653ms
2014-07-13 18:14:57,279 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5617ms
2014-07-13 18:14:57,279 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5617ms
2014-07-13 18:14:57,780 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:57,812 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,531 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,535 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,545 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,568 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:58,589 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:58,624 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,632 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,636 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:58,639 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:58,653 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,660 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,685 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,692 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,699 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,726 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,741 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,762 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,789 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:58,793 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:14:58,801 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:14:58,832 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:15:01,712 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10153ms
2014-07-13 18:15:01,713 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10156ms
2014-07-13 18:15:01,713 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10156ms
2014-07-13 18:15:01,713 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10154ms
2014-07-13 18:15:02,275 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10716ms
2014-07-13 18:15:02,275 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10564ms
2014-07-13 18:15:02,276 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10613ms
2014-07-13 18:15:02,276 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10614ms
2014-07-13 18:15:02,276 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10678ms
2014-07-13 18:15:02,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10657ms
2014-07-13 18:15:02,277 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10570ms
2014-07-13 18:15:02,277 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10590ms
2014-07-13 18:15:02,277 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10613ms
2014-07-13 18:15:02,277 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10566ms
2014-07-13 18:15:02,277 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10606ms
2014-07-13 18:15:02,278 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10563ms
2014-07-13 18:15:02,278 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10548ms
2014-07-13 18:15:02,278 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10563ms
2014-07-13 18:15:02,278 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10717ms
2014-07-13 18:15:02,278 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10710ms
2014-07-13 18:15:02,279 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10679ms
2014-07-13 18:15:02,279 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10669ms
2014-07-13 18:15:02,279 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10658ms
2014-07-13 18:15:02,279 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10635ms
2014-07-13 18:15:02,279 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10653ms
2014-07-13 18:15:02,280 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10617ms
2014-07-13 18:15:02,280 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10618ms
2014-07-13 18:15:02,780 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:02,812 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,532 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,535 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,545 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,568 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,589 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,624 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,633 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,636 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,639 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,654 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,660 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,685 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,693 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,699 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,726 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,741 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,763 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,789 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,793 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:03,802 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:15:03,833 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:15:06,713 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15154ms
2014-07-13 18:15:06,714 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15155ms
2014-07-13 18:15:06,714 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15157ms
2014-07-13 18:15:06,715 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15157ms
2014-07-13 18:15:07,275 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15716ms
2014-07-13 18:15:07,276 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15564ms
2014-07-13 18:15:07,276 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15614ms
2014-07-13 18:15:07,276 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15614ms
2014-07-13 18:15:07,277 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15679ms
2014-07-13 18:15:07,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15657ms
2014-07-13 18:15:07,277 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15570ms
2014-07-13 18:15:07,277 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15590ms
2014-07-13 18:15:07,278 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15613ms
2014-07-13 18:15:07,278 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15563ms
2014-07-13 18:15:07,278 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15607ms
2014-07-13 18:15:07,278 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15567ms
2014-07-13 18:15:07,278 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15563ms
2014-07-13 18:15:07,279 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15549ms
2014-07-13 18:15:07,279 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15711ms
2014-07-13 18:15:07,279 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15718ms
2014-07-13 18:15:07,279 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15669ms
2014-07-13 18:15:07,279 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15679ms
2014-07-13 18:15:07,279 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15658ms
2014-07-13 18:15:07,280 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15635ms
2014-07-13 18:15:07,280 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15654ms
2014-07-13 18:15:07,280 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15618ms
2014-07-13 18:15:07,280 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15618ms
2014-07-13 18:15:07,627 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c1b0e8f0eff744f5a48a9f87669a5daa as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c1b0e8f0eff744f5a48a9f87669a5daa
2014-07-13 18:15:07,641 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:15:07,652 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/31bcab7b70074d7c8c9411015dfeefd3, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/31bcab7b70074d7c8c9411015dfeefd3
2014-07-13 18:15:07,654 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c71a3de134db4ca6af70e1c44132df51, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c71a3de134db4ca6af70e1c44132df51
2014-07-13 18:15:07,656 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/01a428e23df4490284f4f047217464c1, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/01a428e23df4490284f4f047217464c1
2014-07-13 18:15:07,668 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/5da08c62cde4412aa3303447eb704dbf, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/5da08c62cde4412aa3303447eb704dbf
2014-07-13 18:15:07,669 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into c1b0e8f0eff744f5a48a9f87669a5daa(size=142.7m), total size for store is 2.6g. This selection was in queue for 0sec, and took 27sec to execute.
2014-07-13 18:15:07,669 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=4, fileSize=177.3m, priority=-1, time=254387211873045; duration=27sec
2014-07-13 18:15:07,669 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-13 18:15:07,670 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:15:07,673 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 160903213 starting at candidate #15 after considering 124 permutations with 107 in ratio
2014-07-13 18:15:07,673 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating minor compaction
2014-07-13 18:15:07,673 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:15:07,674 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=153.4m
2014-07-13 18:15:07,674 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c7e8514a64594c87964ab33b8211a4c3, keycount=31776, bloomtype=ROW, size=22.7m, encoding=NONE, seqNum=10318
2014-07-13 18:15:07,674 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/53f86886c60d4ca5a03e2a529b2616f0, keycount=55884, bloomtype=ROW, size=39.8m, encoding=NONE, seqNum=10462
2014-07-13 18:15:07,674 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/39f2d9c02e0d455e9066ab568c884cac, keycount=75415, bloomtype=ROW, size=53.7m, encoding=NONE, seqNum=10621
2014-07-13 18:15:07,674 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e36d35a1a4e54d83ac81925b2c6de1b2, keycount=30956, bloomtype=ROW, size=22.1m, encoding=NONE, seqNum=10758
2014-07-13 18:15:07,674 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/319d81badbc04c1e9cedc7884427436f, keycount=21377, bloomtype=ROW, size=15.2m, encoding=NONE, seqNum=10891
2014-07-13 18:15:07,760 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:07,780 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:07,813 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,532 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,535 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:15:08,545 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,569 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:15:08,590 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:15:08,625 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,633 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,636 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,639 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,654 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,661 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,686 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,693 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,699 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:15:08,726 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,742 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,763 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,789 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,793 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,802 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:08,833 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:15:09,965 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10793, memsize=792.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a00fac69289045708da1752761589c07
2014-07-13 18:15:09,983 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a00fac69289045708da1752761589c07 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a00fac69289045708da1752761589c07
2014-07-13 18:15:09,994 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a00fac69289045708da1752761589c07, entries=2884400, sequenceid=10793, filesize=205.3m
2014-07-13 18:15:09,995 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.6g/1668481280, currentsize=415.9m/436074240 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 36546ms, sequenceid=10793, compaction requested=true
2014-07-13 18:15:09,995 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:120), split_queue=0, merge_queue=0
2014-07-13 18:15:09,995 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16163ms
2014-07-13 18:15:09,995 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:09,995 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 286.9m
2014-07-13 18:15:09,995 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16194ms
2014-07-13 18:15:09,995 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:09,996 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16204ms
2014-07-13 18:15:09,996 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:09,996 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16208ms
2014-07-13 18:15:09,996 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:09,996 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16234ms
2014-07-13 18:15:09,996 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:09,996 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16255ms
2014-07-13 18:15:09,996 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:09,996 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16271ms
2014-07-13 18:15:09,996 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,001 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16302ms
2014-07-13 18:15:10,001 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,001 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16309ms
2014-07-13 18:15:10,001 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,001 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16316ms
2014-07-13 18:15:10,001 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,002 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16341ms
2014-07-13 18:15:10,002 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,002 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16349ms
2014-07-13 18:15:10,002 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,002 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16364ms
2014-07-13 18:15:10,002 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,003 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16368ms
2014-07-13 18:15:10,003 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,003 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16371ms
2014-07-13 18:15:10,003 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,009 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16386ms
2014-07-13 18:15:10,019 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,021 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16433ms
2014-07-13 18:15:10,021 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,022 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16455ms
2014-07-13 18:15:10,022 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,022 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16478ms
2014-07-13 18:15:10,022 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,022 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16487ms
2014-07-13 18:15:10,022 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,022 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 16491ms
2014-07-13 18:15:10,022 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,025 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17213ms
2014-07-13 18:15:10,025 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,028 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 17249ms
2014-07-13 18:15:10,029 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,029 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18367ms
2014-07-13 18:15:10,029 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,029 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18367ms
2014-07-13 18:15:10,029 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,029 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18403ms
2014-07-13 18:15:10,030 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,030 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18386ms
2014-07-13 18:15:10,030 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,030 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18409ms
2014-07-13 18:15:10,030 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,030 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18430ms
2014-07-13 18:15:10,030 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,037 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18427ms
2014-07-13 18:15:10,037 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,038 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18477ms
2014-07-13 18:15:10,038 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,041 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18473ms
2014-07-13 18:15:10,041 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,041 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18311ms
2014-07-13 18:15:10,041 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,041 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18326ms
2014-07-13 18:15:10,041 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,045 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18334ms
2014-07-13 18:15:10,045 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,047 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18376ms
2014-07-13 18:15:10,047 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,047 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18332ms
2014-07-13 18:15:10,047 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,048 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18384ms
2014-07-13 18:15:10,048 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,048 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18361ms
2014-07-13 18:15:10,048 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,048 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18341ms
2014-07-13 18:15:10,048 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,053 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18433ms
2014-07-13 18:15:10,053 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,053 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18455ms
2014-07-13 18:15:10,053 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,053 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18391ms
2014-07-13 18:15:10,053 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,053 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18391ms
2014-07-13 18:15:10,053 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,053 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18342ms
2014-07-13 18:15:10,054 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,054 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18495ms
2014-07-13 18:15:10,054 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,054 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18497ms
2014-07-13 18:15:10,054 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,056 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18499ms
2014-07-13 18:15:10,056 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,056 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18497ms
2014-07-13 18:15:10,056 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,061 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18502ms
2014-07-13 18:15:10,061 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:15:10,091 DEBUG [RpcServer.handler=11,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:15:10,092 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18582,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491509,"queuetimems":0,"class":"HRegionServer","responsesize":1444,"method":"Multi"}
2014-07-13 18:15:10,098 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18615,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491483,"queuetimems":1,"class":"HRegionServer","responsesize":4130,"method":"Multi"}
2014-07-13 18:15:10,730 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:10,907 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19637,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491269,"queuetimems":0,"class":"HRegionServer","responsesize":7041,"method":"Multi"}
2014-07-13 18:15:11,098 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:11,100 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19562,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491537,"queuetimems":0,"class":"HRegionServer","responsesize":13208,"method":"Multi"}
2014-07-13 18:15:11,100 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19592,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491508,"queuetimems":0,"class":"HRegionServer","responsesize":10184,"method":"Multi"}
2014-07-13 18:15:11,100 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19653,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491447,"queuetimems":1,"class":"HRegionServer","responsesize":18336,"method":"Multi"}
2014-07-13 18:15:11,100 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19819,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491280,"queuetimems":0,"class":"HRegionServer","responsesize":7010,"method":"Multi"}
2014-07-13 18:15:11,100 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19623,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491476,"queuetimems":0,"class":"HRegionServer","responsesize":11801,"method":"Multi"}
2014-07-13 18:15:11,105 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19658,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491447,"queuetimems":0,"class":"HRegionServer","responsesize":923,"method":"Multi"}
2014-07-13 18:15:11,106 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17306,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493799,"queuetimems":0,"class":"HRegionServer","responsesize":2954,"method":"Multi"}
2014-07-13 18:15:11,105 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493787,"queuetimems":1,"class":"HRegionServer","responsesize":1712,"method":"Multi"}
2014-07-13 18:15:11,112 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493637,"queuetimems":0,"class":"HRegionServer","responsesize":1093,"method":"Multi"}
2014-07-13 18:15:11,113 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17390,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493722,"queuetimems":0,"class":"HRegionServer","responsesize":7190,"method":"Multi"}
2014-07-13 18:15:11,113 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17454,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493659,"queuetimems":1,"class":"HRegionServer","responsesize":2722,"method":"Multi"}
2014-07-13 18:15:11,116 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19605,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491510,"queuetimems":0,"class":"HRegionServer","responsesize":600,"method":"Multi"}
2014-07-13 18:15:11,113 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491400,"queuetimems":1,"class":"HRegionServer","responsesize":7800,"method":"Multi"}
2014-07-13 18:15:11,113 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17415,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493698,"queuetimems":0,"class":"HRegionServer","responsesize":2746,"method":"Multi"}
2014-07-13 18:15:11,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 44927 synced till here 44903
2014-07-13 18:15:11,311 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19690,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491620,"queuetimems":0,"class":"HRegionServer","responsesize":348,"method":"Multi"}
2014-07-13 18:15:11,311 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491598,"queuetimems":1,"class":"HRegionServer","responsesize":1789,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17556,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493756,"queuetimems":0,"class":"HRegionServer","responsesize":6629,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17621,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493691,"queuetimems":0,"class":"HRegionServer","responsesize":3902,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17532,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493780,"queuetimems":0,"class":"HRegionServer","responsesize":8077,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17779,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493533,"queuetimems":0,"class":"HRegionServer","responsesize":6904,"method":"Multi"}
2014-07-13 18:15:11,313 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17677,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493635,"queuetimems":1,"class":"HRegionServer","responsesize":2193,"method":"Multi"}
2014-07-13 18:15:11,313 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19628,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491684,"queuetimems":0,"class":"HRegionServer","responsesize":10227,"method":"Multi"}
2014-07-13 18:15:11,313 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17630,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493683,"queuetimems":0,"class":"HRegionServer","responsesize":7538,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17661,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493651,"queuetimems":0,"class":"HRegionServer","responsesize":4739,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493629,"queuetimems":0,"class":"HRegionServer","responsesize":4685,"method":"Multi"}
2014-07-13 18:15:11,313 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17575,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493738,"queuetimems":0,"class":"HRegionServer","responsesize":6204,"method":"Multi"}
2014-07-13 18:15:11,312 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17486,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493826,"queuetimems":0,"class":"HRegionServer","responsesize":7874,"method":"Multi"}
2014-07-13 18:15:11,398 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19790,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491608,"queuetimems":0,"class":"HRegionServer","responsesize":4564,"method":"Multi"}
2014-07-13 18:15:11,399 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20208,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491190,"queuetimems":1,"class":"HRegionServer","responsesize":15858,"method":"Multi"}
2014-07-13 18:15:11,398 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19778,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491620,"queuetimems":0,"class":"HRegionServer","responsesize":5325,"method":"Multi"}
2014-07-13 18:15:11,399 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18625,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300492774,"queuetimems":0,"class":"HRegionServer","responsesize":18404,"method":"Multi"}
2014-07-13 18:15:11,401 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17836,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493564,"queuetimems":0,"class":"HRegionServer","responsesize":19069,"method":"Multi"}
2014-07-13 18:15:11,402 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19806,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491596,"queuetimems":0,"class":"HRegionServer","responsesize":14472,"method":"Multi"}
2014-07-13 18:15:11,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300491283 with entries=115, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300511099
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300370451
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300372434
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300374434
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300377373
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300379018
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300381521
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300382788
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300383829
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300385459
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300386699
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300388009
2014-07-13 18:15:11,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300389693
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300391277
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300392730
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300394429
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300396167
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300397927
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300399429
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300400873
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300402394
2014-07-13 18:15:11,416 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300405675
2014-07-13 18:15:11,749 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20124,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491625,"queuetimems":0,"class":"HRegionServer","responsesize":2260,"method":"Multi"}
2014-07-13 18:15:11,761 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491642,"queuetimems":0,"class":"HRegionServer","responsesize":7715,"method":"Multi"}
2014-07-13 18:15:11,770 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20101,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491668,"queuetimems":0,"class":"HRegionServer","responsesize":11297,"method":"Multi"}
2014-07-13 18:15:11,781 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20053,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491728,"queuetimems":0,"class":"HRegionServer","responsesize":10374,"method":"Multi"}
2014-07-13 18:15:11,782 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18195,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493586,"queuetimems":0,"class":"HRegionServer","responsesize":9280,"method":"Multi"}
2014-07-13 18:15:11,782 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":18161,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493620,"queuetimems":0,"class":"HRegionServer","responsesize":12919,"method":"Multi"}
2014-07-13 18:15:11,783 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20218,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491565,"queuetimems":0,"class":"HRegionServer","responsesize":12595,"method":"Multi"}
2014-07-13 18:15:12,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:12,780 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21466,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491313,"queuetimems":0,"class":"HRegionServer","responsesize":15683,"method":"Multi"}
2014-07-13 18:15:12,780 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21391,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491388,"queuetimems":0,"class":"HRegionServer","responsesize":16589,"method":"Multi"}
2014-07-13 18:15:12,780 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491348,"queuetimems":0,"class":"HRegionServer","responsesize":15414,"method":"Multi"}
2014-07-13 18:15:12,790 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300491714,"queuetimems":0,"class":"HRegionServer","responsesize":16550,"method":"Multi"}
2014-07-13 18:15:12,790 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19261,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493529,"queuetimems":1,"class":"HRegionServer","responsesize":15634,"method":"Multi"}
2014-07-13 18:15:12,791 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19249,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300493542,"queuetimems":0,"class":"HRegionServer","responsesize":14640,"method":"Multi"}
2014-07-13 18:15:12,799 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":19989,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300492809,"queuetimems":0,"class":"HRegionServer","responsesize":13927,"method":"Multi"}
2014-07-13 18:15:12,888 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45069 synced till here 45036
2014-07-13 18:15:14,018 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300511099 with entries=142, filesize=106.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300512778
2014-07-13 18:15:15,006 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:15,168 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45192 synced till here 45185
2014-07-13 18:15:15,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300512778 with entries=123, filesize=95.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300515007
2014-07-13 18:15:16,786 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:16,872 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45311 synced till here 45279
2014-07-13 18:15:17,824 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300515007 with entries=119, filesize=96.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300516786
2014-07-13 18:15:18,718 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:19,279 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45430 synced till here 45429
2014-07-13 18:15:19,337 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300516786 with entries=119, filesize=86.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300518718
2014-07-13 18:15:20,131 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:20,374 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45553 synced till here 45532
2014-07-13 18:15:21,004 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300518718 with entries=123, filesize=96.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300520132
2014-07-13 18:15:21,969 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:21,984 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45662 synced till here 45643
2014-07-13 18:15:22,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300520132 with entries=109, filesize=87.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300521969
2014-07-13 18:15:23,175 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11000, memsize=714.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/54ed19677b8047e9bb72ea5f8b0b015f
2014-07-13 18:15:23,203 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/54ed19677b8047e9bb72ea5f8b0b015f as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/54ed19677b8047e9bb72ea5f8b0b015f
2014-07-13 18:15:23,222 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/54ed19677b8047e9bb72ea5f8b0b015f, entries=2602760, sequenceid=11000, filesize=185.1m
2014-07-13 18:15:23,229 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.1g/1205123680, currentsize=421.2m/441661680 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 35132ms, sequenceid=11000, compaction requested=true
2014-07-13 18:15:23,229 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:121), split_queue=0, merge_queue=0
2014-07-13 18:15:23,229 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 768.8m
2014-07-13 18:15:23,252 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:15:23,379 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:23,403 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11458, memsize=215.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/36401e0cf4014e4eb2de467c0143d21e
2014-07-13 18:15:23,404 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45756 synced till here 45742
2014-07-13 18:15:23,418 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/36401e0cf4014e4eb2de467c0143d21e as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/36401e0cf4014e4eb2de467c0143d21e
2014-07-13 18:15:23,430 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/36401e0cf4014e4eb2de467c0143d21e, entries=783140, sequenceid=11458, filesize=55.8m
2014-07-13 18:15:23,430 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~286.9m/300843360, currentsize=267.0m/279934320 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 13435ms, sequenceid=11458, compaction requested=true
2014-07-13 18:15:23,430 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:122), split_queue=0, merge_queue=0
2014-07-13 18:15:23,430 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:15:23,431 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:123), split_queue=0, merge_queue=0
2014-07-13 18:15:23,452 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:15:23,454 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 272.0m
2014-07-13 18:15:23,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300521969 with entries=94, filesize=67.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300523380
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300407773
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300413713
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300438027
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300439808
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300441340
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300443118
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300444884
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300445924
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300447457
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300448797
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300450241
2014-07-13 18:15:23,476 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300451330
2014-07-13 18:15:23,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300452665
2014-07-13 18:15:23,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300454536
2014-07-13 18:15:23,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300455776
2014-07-13 18:15:23,477 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300458572
2014-07-13 18:15:23,644 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:24,222 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:24,642 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:24,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45861 synced till here 45857
2014-07-13 18:15:24,769 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300523380 with entries=105, filesize=65.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300524642
2014-07-13 18:15:25,981 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:26,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 45955 synced till here 45954
2014-07-13 18:15:26,246 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11647, memsize=44.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/49aca054e3cf4fde807e40009d6202bf
2014-07-13 18:15:26,260 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/49aca054e3cf4fde807e40009d6202bf as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/49aca054e3cf4fde807e40009d6202bf
2014-07-13 18:15:26,271 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/49aca054e3cf4fde807e40009d6202bf, entries=160330, sequenceid=11647, filesize=11.4m
2014-07-13 18:15:26,272 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~272.0m/285166960, currentsize=75.1m/78788960 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 2817ms, sequenceid=11647, compaction requested=true
2014-07-13 18:15:26,272 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-13 18:15:26,279 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300524642 with entries=94, filesize=82.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300525981
2014-07-13 18:15:28,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:28,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46070 synced till here 46068
2014-07-13 18:15:28,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300525981 with entries=115, filesize=82.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300528086
2014-07-13 18:15:29,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:29,704 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46136 synced till here 46133
2014-07-13 18:15:30,000 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300528086 with entries=66, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300529671
2014-07-13 18:15:31,047 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:31,265 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300529671 with entries=77, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300531047
2014-07-13 18:15:32,311 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:32,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46288 synced till here 46287
2014-07-13 18:15:32,751 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300531047 with entries=75, filesize=75.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300532312
2014-07-13 18:15:32,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:15:33,755 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/a1b5bfb83a584482a23af73e853d907f as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/a1b5bfb83a584482a23af73e853d907f
2014-07-13 18:15:34,321 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:34,367 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:15:34,376 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46378 synced till here 46377
2014-07-13 18:15:34,384 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c7e8514a64594c87964ab33b8211a4c3, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c7e8514a64594c87964ab33b8211a4c3
2014-07-13 18:15:34,387 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/53f86886c60d4ca5a03e2a529b2616f0, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/53f86886c60d4ca5a03e2a529b2616f0
2014-07-13 18:15:34,390 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/39f2d9c02e0d455e9066ab568c884cac, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/39f2d9c02e0d455e9066ab568c884cac
2014-07-13 18:15:34,394 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e36d35a1a4e54d83ac81925b2c6de1b2, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e36d35a1a4e54d83ac81925b2c6de1b2
2014-07-13 18:15:34,398 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/319d81badbc04c1e9cedc7884427436f, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/319d81badbc04c1e9cedc7884427436f
2014-07-13 18:15:34,398 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 5 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into a1b5bfb83a584482a23af73e853d907f(size=110.8m), total size for store is 2.8g. This selection was in queue for 0sec, and took 26sec to execute.
2014-07-13 18:15:34,398 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=5, fileSize=153.4m, priority=-1, time=254415100357792; duration=26sec
2014-07-13 18:15:34,399 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-13 18:15:34,399 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:15:34,402 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 350058379 starting at candidate #5 after considering 124 permutations with 103 in ratio
2014-07-13 18:15:34,409 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating minor compaction
2014-07-13 18:15:34,409 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:15:34,409 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=333.8m
2014-07-13 18:15:34,409 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/e68905eb1af741258cab1c4cd9870a32, keycount=91693, bloomtype=ROW, size=65.3m, encoding=NONE, seqNum=5278
2014-07-13 18:15:34,409 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c35085284d134d1fb0eb5a765abbf282, keycount=91264, bloomtype=ROW, size=65.0m, encoding=NONE, seqNum=5415
2014-07-13 18:15:34,409 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a601aeb1be76425a9955ed06f6f49483, keycount=107016, bloomtype=ROW, size=76.2m, encoding=NONE, seqNum=5586
2014-07-13 18:15:34,410 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9cf951820cb488f9d804c53cea0dd7b, keycount=100509, bloomtype=ROW, size=71.6m, encoding=NONE, seqNum=5735
2014-07-13 18:15:34,410 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/5d3853d6245a41a3aedd8f36487f90f3, keycount=78270, bloomtype=ROW, size=55.8m, encoding=NONE, seqNum=6073
2014-07-13 18:15:34,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300532312 with entries=90, filesize=77.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300534322
2014-07-13 18:15:34,415 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:15:34,527 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 1.1g
2014-07-13 18:15:34,591 DEBUG [RpcServer.handler=28,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:15:34,928 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:35,470 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:36,819 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:36,844 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300534322 with entries=64, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300536819
2014-07-13 18:15:37,705 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:38,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46508 synced till here 46503
2014-07-13 18:15:38,249 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300536819 with entries=66, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300537706
2014-07-13 18:15:38,759 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11312, memsize=345.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/bbc72fd6c33943698396337a66acc1dc
2014-07-13 18:15:38,778 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/bbc72fd6c33943698396337a66acc1dc as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/bbc72fd6c33943698396337a66acc1dc
2014-07-13 18:15:38,946 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/bbc72fd6c33943698396337a66acc1dc, entries=1259270, sequenceid=11312, filesize=89.7m
2014-07-13 18:15:38,946 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~772.6m/810105280, currentsize=324.0m/339780800 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 15717ms, sequenceid=11312, compaction requested=true
2014-07-13 18:15:38,947 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:124), split_queue=0, merge_queue=0
2014-07-13 18:15:38,947 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 322.7m
2014-07-13 18:15:38,949 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:15:39,137 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:40,277 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:40,689 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46610 synced till here 46607
2014-07-13 18:15:40,724 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300537706 with entries=102, filesize=98.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300540277
2014-07-13 18:15:42,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:42,195 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46686 synced till here 46682
2014-07-13 18:15:42,230 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300540277 with entries=76, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300542165
2014-07-13 18:15:43,279 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:43,380 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300542165 with entries=61, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300543279
2014-07-13 18:15:44,855 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:44,886 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46819 synced till here 46817
2014-07-13 18:15:44,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300543279 with entries=72, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300544855
2014-07-13 18:15:46,192 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:46,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46898 synced till here 46888
2014-07-13 18:15:46,353 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300544855 with entries=79, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300546193
2014-07-13 18:15:49,242 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:49,281 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 46972 synced till here 46971
2014-07-13 18:15:49,316 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300546193 with entries=74, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300549242
2014-07-13 18:15:50,270 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11872, memsize=322.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/58aa8feadc994403ab24b7b054d826aa
2014-07-13 18:15:50,282 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/58aa8feadc994403ab24b7b054d826aa as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/58aa8feadc994403ab24b7b054d826aa
2014-07-13 18:15:50,304 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/58aa8feadc994403ab24b7b054d826aa, entries=1175240, sequenceid=11872, filesize=83.7m
2014-07-13 18:15:50,304 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~324.2m/339970320, currentsize=194.3m/203740320 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 11357ms, sequenceid=11872, compaction requested=true
2014-07-13 18:15:50,305 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:125), split_queue=0, merge_queue=0
2014-07-13 18:15:50,305 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 522.7m
2014-07-13 18:15:50,567 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:50,628 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:15:51,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47069 synced till here 47067
2014-07-13 18:15:51,178 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300549242 with entries=97, filesize=88.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300550567
2014-07-13 18:15:52,148 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:52,183 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300550567 with entries=57, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300552149
2014-07-13 18:15:52,819 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:15:54,460 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:54,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47201 synced till here 47198
2014-07-13 18:15:54,739 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300552149 with entries=75, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300554460
2014-07-13 18:15:55,696 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:55,715 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47271 synced till here 47267
2014-07-13 18:15:56,123 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300554460 with entries=70, filesize=65.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300555696
2014-07-13 18:15:57,129 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:57,805 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47348 synced till here 47347
2014-07-13 18:15:58,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300555696 with entries=77, filesize=77.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300557129
2014-07-13 18:15:59,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:15:59,450 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47424 synced till here 47412
2014-07-13 18:15:59,584 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300557129 with entries=76, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300559389
2014-07-13 18:16:00,800 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:01,032 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47495 synced till here 47494
2014-07-13 18:16:01,064 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300559389 with entries=71, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300560800
2014-07-13 18:16:02,458 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:02,505 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47580 synced till here 47577
2014-07-13 18:16:02,525 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300560800 with entries=85, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300562458
2014-07-13 18:16:03,362 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:03,366 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,366 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,367 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,368 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,370 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,377 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,443 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,444 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,445 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,466 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,487 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,496 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,776 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,793 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300562458 with entries=77, filesize=65.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300563363
2014-07-13 18:16:03,813 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,826 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,828 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,845 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,868 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,883 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,886 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,900 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,921 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,939 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,942 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,944 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:03,977 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,011 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,040 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,047 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,062 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,064 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,068 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,077 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,078 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,080 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,080 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,117 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,118 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,149 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,180 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,191 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,198 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,205 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,223 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,239 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,283 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,298 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,304 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,341 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:04,852 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11813, memsize=739.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/905fda3a36b14a7784b3e9a079903416
2014-07-13 18:16:04,869 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/905fda3a36b14a7784b3e9a079903416 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/905fda3a36b14a7784b3e9a079903416
2014-07-13 18:16:04,880 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/905fda3a36b14a7784b3e9a079903416, entries=2692490, sequenceid=11813, filesize=191.7m
2014-07-13 18:16:04,881 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.1g/1161263760, currentsize=515.2m/540241920 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 30354ms, sequenceid=11813, compaction requested=true
2014-07-13 18:16:04,881 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:126), split_queue=0, merge_queue=0
2014-07-13 18:16:04,882 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 541ms
2014-07-13 18:16:04,882 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,882 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 453.0m
2014-07-13 18:16:04,882 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 578ms
2014-07-13 18:16:04,882 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,882 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 584ms
2014-07-13 18:16:04,882 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,890 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 607ms
2014-07-13 18:16:04,890 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,890 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 651ms
2014-07-13 18:16:04,890 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,890 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 667ms
2014-07-13 18:16:04,890 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,891 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 685ms
2014-07-13 18:16:04,891 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,891 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 693ms
2014-07-13 18:16:04,891 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,892 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 701ms
2014-07-13 18:16:04,909 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,909 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 729ms
2014-07-13 18:16:04,909 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,916 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 767ms
2014-07-13 18:16:04,916 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,916 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 798ms
2014-07-13 18:16:04,916 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,917 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 800ms
2014-07-13 18:16:04,917 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,917 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 837ms
2014-07-13 18:16:04,917 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,917 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 837ms
2014-07-13 18:16:04,917 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,917 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 839ms
2014-07-13 18:16:04,918 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,918 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 841ms
2014-07-13 18:16:04,918 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,918 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 850ms
2014-07-13 18:16:04,918 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,925 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 861ms
2014-07-13 18:16:04,925 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,934 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 872ms
2014-07-13 18:16:04,934 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,934 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 887ms
2014-07-13 18:16:04,935 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,935 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 895ms
2014-07-13 18:16:04,935 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,935 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 924ms
2014-07-13 18:16:04,935 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,938 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 961ms
2014-07-13 18:16:04,939 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,939 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 996ms
2014-07-13 18:16:04,939 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,939 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 997ms
2014-07-13 18:16:04,939 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,941 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1003ms
2014-07-13 18:16:04,941 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,945 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1024ms
2014-07-13 18:16:04,945 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,949 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1049ms
2014-07-13 18:16:04,949 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,952 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1066ms
2014-07-13 18:16:04,952 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,952 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1069ms
2014-07-13 18:16:04,952 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,952 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1084ms
2014-07-13 18:16:04,953 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,961 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1116ms
2014-07-13 18:16:04,961 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,961 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1133ms
2014-07-13 18:16:04,961 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,961 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1135ms
2014-07-13 18:16:04,961 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,964 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1151ms
2014-07-13 18:16:04,964 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,964 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1171ms
2014-07-13 18:16:04,965 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,965 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1189ms
2014-07-13 18:16:04,965 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,965 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1469ms
2014-07-13 18:16:04,965 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,965 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1478ms
2014-07-13 18:16:04,965 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,969 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1503ms
2014-07-13 18:16:04,969 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,970 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1525ms
2014-07-13 18:16:04,970 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,970 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1526ms
2014-07-13 18:16:04,970 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,970 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1527ms
2014-07-13 18:16:04,970 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,970 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1593ms
2014-07-13 18:16:04,970 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,974 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1604ms
2014-07-13 18:16:04,974 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,974 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1606ms
2014-07-13 18:16:04,974 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,975 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1607ms
2014-07-13 18:16:04,975 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,975 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1609ms
2014-07-13 18:16:04,975 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:04,975 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1610ms
2014-07-13 18:16:04,975 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:05,159 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:05,183 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:16:06,809 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:07,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47785 synced till here 47740
2014-07-13 18:16:07,364 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300563363 with entries=128, filesize=101.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300566809
2014-07-13 18:16:07,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300460120
2014-07-13 18:16:07,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300461391
2014-07-13 18:16:07,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300463727
2014-07-13 18:16:07,364 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300465301
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300467247
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300468587
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300469875
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300471102
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300474458
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300475966
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300477198
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300478895
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300479985
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300481403
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300482670
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300484516
2014-07-13 18:16:07,365 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300485716
2014-07-13 18:16:08,291 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:09,029 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:09,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 47899 synced till here 47869
2014-07-13 18:16:10,359 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300566809 with entries=114, filesize=95.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300569029
2014-07-13 18:16:10,359 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:12,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:12,410 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48021 synced till here 47989
2014-07-13 18:16:12,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300569029 with entries=122, filesize=91.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300572322
2014-07-13 18:16:12,772 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:14,494 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=11611, memsize=503.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/4c343eaffc7f4e5eb3dcc8bc01f64738
2014-07-13 18:16:14,506 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/4c343eaffc7f4e5eb3dcc8bc01f64738 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/4c343eaffc7f4e5eb3dcc8bc01f64738
2014-07-13 18:16:14,515 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/4c343eaffc7f4e5eb3dcc8bc01f64738, entries=1834440, sequenceid=11611, filesize=130.6m
2014-07-13 18:16:14,515 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~522.7m/548053520, currentsize=387.5m/406345200 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 24210ms, sequenceid=11611, compaction requested=true
2014-07-13 18:16:14,515 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:127), split_queue=0, merge_queue=0
2014-07-13 18:16:14,516 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 677.0m
2014-07-13 18:16:14,518 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:16:14,792 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:14,847 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48133 synced till here 48121
2014-07-13 18:16:15,880 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300572322 with entries=112, filesize=97.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300574793
2014-07-13 18:16:15,881 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:16,410 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:16,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:16,741 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48250 synced till here 48229
2014-07-13 18:16:16,921 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300574793 with entries=117, filesize=91.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300576717
2014-07-13 18:16:16,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:18,365 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:18,395 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48362 synced till here 48325
2014-07-13 18:16:19,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300576717 with entries=112, filesize=92.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300578366
2014-07-13 18:16:19,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:20,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:20,125 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48445 synced till here 48439
2014-07-13 18:16:20,193 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300578366 with entries=83, filesize=67.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300580110
2014-07-13 18:16:20,194 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:21,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:21,575 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48515 synced till here 48514
2014-07-13 18:16:21,621 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300580110 with entries=70, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300581539
2014-07-13 18:16:21,622 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:22,755 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:22,808 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48608 synced till here 48588
2014-07-13 18:16:22,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300581539 with entries=93, filesize=74.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300582755
2014-07-13 18:16:22,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:25,473 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:25,520 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48727 synced till here 48693
2014-07-13 18:16:25,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300582755 with entries=119, filesize=104.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300585473
2014-07-13 18:16:25,877 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:26,146 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,154 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,155 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,156 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,156 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,161 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,164 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,400 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,406 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:26,408 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,189 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,190 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,190 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,192 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,192 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,192 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,193 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,193 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,194 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,194 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,197 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,197 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,197 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,198 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,198 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,199 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,200 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,202 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,216 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,217 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,223 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,247 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,263 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,265 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,266 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,266 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,281 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,313 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,320 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,332 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,333 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,347 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,361 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,371 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,383 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,387 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,391 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,421 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,446 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:27,458 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:28,568 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12150, memsize=373.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/2ac8eb01e63e4cae9ecdc867bd6f0451
2014-07-13 18:16:28,585 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/2ac8eb01e63e4cae9ecdc867bd6f0451 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2ac8eb01e63e4cae9ecdc867bd6f0451
2014-07-13 18:16:28,602 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2ac8eb01e63e4cae9ecdc867bd6f0451, entries=1358860, sequenceid=12150, filesize=96.7m
2014-07-13 18:16:28,602 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~453.0m/475018080, currentsize=482.1m/505507840 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 23720ms, sequenceid=12150, compaction requested=true
2014-07-13 18:16:28,602 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:128), split_queue=0, merge_queue=0
2014-07-13 18:16:28,603 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1145ms
2014-07-13 18:16:28,603 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:16:28,603 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,603 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:129), split_queue=0, merge_queue=0
2014-07-13 18:16:28,605 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1159ms
2014-07-13 18:16:28,605 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,605 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1184ms
2014-07-13 18:16:28,605 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,605 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1214ms
2014-07-13 18:16:28,605 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,605 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1218ms
2014-07-13 18:16:28,605 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,605 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1222ms
2014-07-13 18:16:28,605 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,621 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1251ms
2014-07-13 18:16:28,621 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,621 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1260ms
2014-07-13 18:16:28,621 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,621 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1274ms
2014-07-13 18:16:28,621 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,621 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1288ms
2014-07-13 18:16:28,621 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,637 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1305ms
2014-07-13 18:16:28,637 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,645 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1325ms
2014-07-13 18:16:28,645 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,645 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1332ms
2014-07-13 18:16:28,645 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,649 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:16:28,649 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 482.7m
2014-07-13 18:16:28,657 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1376ms
2014-07-13 18:16:28,657 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,657 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1391ms
2014-07-13 18:16:28,657 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,657 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1391ms
2014-07-13 18:16:28,657 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,657 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1392ms
2014-07-13 18:16:28,657 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,657 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1394ms
2014-07-13 18:16:28,657 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,665 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1418ms
2014-07-13 18:16:28,665 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,665 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1442ms
2014-07-13 18:16:28,665 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,665 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1449ms
2014-07-13 18:16:28,665 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,669 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1453ms
2014-07-13 18:16:28,669 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,669 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1467ms
2014-07-13 18:16:28,669 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,670 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1470ms
2014-07-13 18:16:28,670 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,670 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1472ms
2014-07-13 18:16:28,670 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,671 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1473ms
2014-07-13 18:16:28,671 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,677 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1479ms
2014-07-13 18:16:28,677 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,677 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1480ms
2014-07-13 18:16:28,677 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,677 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1480ms
2014-07-13 18:16:28,677 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,679 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1482ms
2014-07-13 18:16:28,679 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,679 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1485ms
2014-07-13 18:16:28,679 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,679 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1485ms
2014-07-13 18:16:28,679 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,679 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1486ms
2014-07-13 18:16:28,680 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,680 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1487ms
2014-07-13 18:16:28,680 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,689 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1497ms
2014-07-13 18:16:28,689 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,689 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1497ms
2014-07-13 18:16:28,689 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,689 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1497ms
2014-07-13 18:16:28,689 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,692 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1502ms
2014-07-13 18:16:28,692 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,701 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1511ms
2014-07-13 18:16:28,701 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,706 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1517ms
2014-07-13 18:16:28,706 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,706 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2299ms
2014-07-13 18:16:28,706 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,706 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2300ms
2014-07-13 18:16:28,706 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,706 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2306ms
2014-07-13 18:16:28,707 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,707 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2543ms
2014-07-13 18:16:28,707 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,707 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2546ms
2014-07-13 18:16:28,707 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,707 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2551ms
2014-07-13 18:16:28,707 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,715 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2559ms
2014-07-13 18:16:28,715 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,715 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2560ms
2014-07-13 18:16:28,715 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,717 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2564ms
2014-07-13 18:16:28,717 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:28,717 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2571ms
2014-07-13 18:16:28,717 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:29,057 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:30,047 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48852 synced till here 48816
2014-07-13 18:16:30,330 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:30,399 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300585473 with entries=125, filesize=103.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300589057
2014-07-13 18:16:30,400 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:32,369 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:32,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 48976 synced till here 48934
2014-07-13 18:16:32,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300589057 with entries=124, filesize=113.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300592370
2014-07-13 18:16:32,918 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:34,622 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,623 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,623 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,624 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,626 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,628 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,628 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,789 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:34,794 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,795 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,795 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,796 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,799 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,800 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,800 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,801 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,802 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,803 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,803 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,804 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,805 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,805 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,807 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,807 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,807 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,808 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,808 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,808 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,809 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,809 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,809 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,809 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,810 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,810 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,810 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,810 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,810 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,811 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49079 synced till here 49068
2014-07-13 18:16:34,812 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,929 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,930 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,932 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,932 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,933 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,933 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,933 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,933 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,934 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,937 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,938 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,942 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,942 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:16:34,944 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300592370 with entries=103, filesize=87.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300594790
2014-07-13 18:16:34,945 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:39,489 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12432, memsize=153.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ca1d9d93837c496e94ded800f2925206
2014-07-13 18:16:39,511 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/ca1d9d93837c496e94ded800f2925206 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ca1d9d93837c496e94ded800f2925206
2014-07-13 18:16:39,529 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ca1d9d93837c496e94ded800f2925206, entries=556920, sequenceid=12432, filesize=39.7m
2014-07-13 18:16:39,530 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~494.0m/518009360, currentsize=112.3m/117721680 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 10881ms, sequenceid=12432, compaction requested=true
2014-07-13 18:16:39,530 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:130), split_queue=0, merge_queue=0
2014-07-13 18:16:39,530 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4588ms
2014-07-13 18:16:39,530 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,531 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4590ms
2014-07-13 18:16:39,531 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,533 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4595ms
2014-07-13 18:16:39,533 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,534 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4597ms
2014-07-13 18:16:39,534 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,534 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4600ms
2014-07-13 18:16:39,534 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,534 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4601ms
2014-07-13 18:16:39,535 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,549 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4616ms
2014-07-13 18:16:39,549 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,550 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4616ms
2014-07-13 18:16:39,550 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,565 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4633ms
2014-07-13 18:16:39,565 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,565 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4633ms
2014-07-13 18:16:39,565 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,568 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4636ms
2014-07-13 18:16:39,568 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,569 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4639ms
2014-07-13 18:16:39,569 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,573 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4644ms
2014-07-13 18:16:39,573 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,573 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4761ms
2014-07-13 18:16:39,573 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,575 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4764ms
2014-07-13 18:16:39,575 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,575 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4765ms
2014-07-13 18:16:39,575 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,575 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4766ms
2014-07-13 18:16:39,575 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,575 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4766ms
2014-07-13 18:16:39,576 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,577 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4768ms
2014-07-13 18:16:39,577 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,583 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4773ms
2014-07-13 18:16:39,583 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,583 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4774ms
2014-07-13 18:16:39,583 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,583 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4774ms
2014-07-13 18:16:39,583 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,583 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4775ms
2014-07-13 18:16:39,584 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,584 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4776ms
2014-07-13 18:16:39,584 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,584 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4776ms
2014-07-13 18:16:39,584 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,594 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4785ms
2014-07-13 18:16:39,594 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,595 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4787ms
2014-07-13 18:16:39,595 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,595 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4788ms
2014-07-13 18:16:39,595 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,603 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4796ms
2014-07-13 18:16:39,603 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,606 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4801ms
2014-07-13 18:16:39,606 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,607 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4801ms
2014-07-13 18:16:39,607 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,608 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4804ms
2014-07-13 18:16:39,608 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,608 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4808ms
2014-07-13 18:16:39,608 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,608 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4806ms
2014-07-13 18:16:39,608 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,608 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4806ms
2014-07-13 18:16:39,608 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,609 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4807ms
2014-07-13 18:16:39,609 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,623 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:16:39,623 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,624 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:16:39,624 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,626 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:16:39,626 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,628 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:16:39,628 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:39,628 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:16:39,628 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,426 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4855ms
2014-07-13 18:16:40,426 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,426 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5626ms
2014-07-13 18:16:40,426 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,430 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5630ms
2014-07-13 18:16:40,431 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,431 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5635ms
2014-07-13 18:16:40,431 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,441 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5645ms
2014-07-13 18:16:40,441 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,442 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5647ms
2014-07-13 18:16:40,442 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,445 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5650ms
2014-07-13 18:16:40,445 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,448 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5821ms
2014-07-13 18:16:40,448 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:40,450 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5826ms
2014-07-13 18:16:40,450 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:16:41,221 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10167,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300591053,"queuetimems":776,"class":"HRegionServer","responsesize":18093,"method":"Multi"}
2014-07-13 18:16:41,269 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10212,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300591057,"queuetimems":616,"class":"HRegionServer","responsesize":15883,"method":"Multi"}
2014-07-13 18:16:41,282 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10217,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300591065,"queuetimems":570,"class":"HRegionServer","responsesize":15691,"method":"Multi"}
2014-07-13 18:16:41,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:41,556 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49185 synced till here 49155
2014-07-13 18:16:42,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300594790 with entries=106, filesize=88.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300601484
2014-07-13 18:16:42,796 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:16:43,329 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:16:43,330 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files, but is 1.7g vs best flushable region's 160.2m. Choosing the bigger.
2014-07-13 18:16:43,330 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. due to global heap pressure
2014-07-13 18:16:43,330 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.7g
2014-07-13 18:16:43,602 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12241, memsize=475.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ae8e93e40bfa4171846668fff22c12df
2014-07-13 18:16:43,604 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/676309d7fd21452ab6ac997047c73ed6 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/676309d7fd21452ab6ac997047c73ed6
2014-07-13 18:16:43,619 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ae8e93e40bfa4171846668fff22c12df as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ae8e93e40bfa4171846668fff22c12df
2014-07-13 18:16:43,635 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ae8e93e40bfa4171846668fff22c12df, entries=1731260, sequenceid=12241, filesize=123.3m
2014-07-13 18:16:43,635 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~708.3m/742694000, currentsize=469.8m/492575280 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 29119ms, sequenceid=12241, compaction requested=true
2014-07-13 18:16:43,636 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-13 18:16:43,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:43,760 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49288 synced till here 49262
2014-07-13 18:16:44,878 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:16:44,885 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:16:44,886 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 472.5m
2014-07-13 18:16:44,931 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/e68905eb1af741258cab1c4cd9870a32, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/e68905eb1af741258cab1c4cd9870a32
2014-07-13 18:16:44,935 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c35085284d134d1fb0eb5a765abbf282, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/c35085284d134d1fb0eb5a765abbf282
2014-07-13 18:16:44,941 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a601aeb1be76425a9955ed06f6f49483, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a601aeb1be76425a9955ed06f6f49483
2014-07-13 18:16:44,945 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9cf951820cb488f9d804c53cea0dd7b, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9cf951820cb488f9d804c53cea0dd7b
2014-07-13 18:16:44,948 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/5d3853d6245a41a3aedd8f36487f90f3, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/5d3853d6245a41a3aedd8f36487f90f3
2014-07-13 18:16:44,949 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 5 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into 676309d7fd21452ab6ac997047c73ed6(size=330.5m), total size for store is 2.9g. This selection was in queue for 0sec, and took 1mins, 10sec to execute.
2014-07-13 18:16:44,950 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=5, fileSize=333.8m, priority=-1, time=254441835957215; duration=1mins, 10sec
2014-07-13 18:16:44,950 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-13 18:16:44,950 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:16:44,952 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 170152383 starting at candidate #1 after considering 124 permutations with 94 in ratio
2014-07-13 18:16:44,952 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:16:44,952 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:16:44,952 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=162.3m
2014-07-13 18:16:44,953 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/300be6153c804026a9ab81d87b6057c4, keycount=72859, bloomtype=ROW, size=51.9m, encoding=NONE, seqNum=2118
2014-07-13 18:16:44,953 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2dc2f4c8e5534d8dbc296c7f6567333d, keycount=41464, bloomtype=ROW, size=29.5m, encoding=NONE, seqNum=2406
2014-07-13 18:16:44,953 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/65815424c53c4594b604ce87911d47f0, keycount=113447, bloomtype=ROW, size=80.8m, encoding=NONE, seqNum=2625
2014-07-13 18:16:45,014 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:45,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300601484 with entries=103, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300603735
2014-07-13 18:16:45,710 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:45,838 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:45,909 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49394 synced till here 49364
2014-07-13 18:16:46,705 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300603735 with entries=106, filesize=90.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300605838
2014-07-13 18:16:47,170 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:47,404 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:47,423 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49487 synced till here 49473
2014-07-13 18:16:47,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300605838 with entries=93, filesize=79.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300607405
2014-07-13 18:16:47,538 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:16:49,263 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:49,311 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49659 synced till here 49656
2014-07-13 18:16:49,373 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300607405 with entries=172, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300609264
2014-07-13 18:16:50,585 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:50,606 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49721 synced till here 49720
2014-07-13 18:16:50,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300609264 with entries=62, filesize=62.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300610586
2014-07-13 18:16:51,900 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:51,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49801 synced till here 49796
2014-07-13 18:16:52,015 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300610586 with entries=80, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300611901
2014-07-13 18:16:53,394 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12533, memsize=152.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/f7af3958712e4d3085f560956ac299cf
2014-07-13 18:16:53,402 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:53,414 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/f7af3958712e4d3085f560956ac299cf as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f7af3958712e4d3085f560956ac299cf
2014-07-13 18:16:53,433 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f7af3958712e4d3085f560956ac299cf, entries=556390, sequenceid=12533, filesize=39.6m
2014-07-13 18:16:53,434 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~481.4m/504826560, currentsize=191.6m/200920720 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 8548ms, sequenceid=12533, compaction requested=true
2014-07-13 18:16:53,434 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:131), split_queue=0, merge_queue=0
2014-07-13 18:16:53,434 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 365.5m
2014-07-13 18:16:53,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300611901 with entries=63, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300613403
2014-07-13 18:16:53,840 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:16:55,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:55,132 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 49929 synced till here 49928
2014-07-13 18:16:55,163 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300613403 with entries=65, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300615091
2014-07-13 18:16:56,364 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:56,392 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50006 synced till here 49996
2014-07-13 18:16:56,497 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300615091 with entries=77, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300616364
2014-07-13 18:16:56,754 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:16:57,882 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:16:57,936 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50118 synced till here 50116
2014-07-13 18:16:58,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300616364 with entries=112, filesize=74.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300617883
2014-07-13 18:16:59,671 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:00,009 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50233 synced till here 50229
2014-07-13 18:17:00,045 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,049 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,049 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,051 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,055 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,057 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,060 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,060 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300617883 with entries=115, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300619671
2014-07-13 18:17:00,072 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,073 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,073 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,075 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,078 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,078 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,078 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,080 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,091 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,092 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,101 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,135 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,152 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,152 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,152 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,153 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,154 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,155 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,155 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,159 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,159 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,175 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,202 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,213 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,214 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,214 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,215 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,218 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,275 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,318 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,325 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,327 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,340 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,344 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,367 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,372 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,382 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,394 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:17:00,402 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12690, memsize=127.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/c9bc1c0a29314eae8c19f7cbd6dbb9c1
2014-07-13 18:17:00,413 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/c9bc1c0a29314eae8c19f7cbd6dbb9c1 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c9bc1c0a29314eae8c19f7cbd6dbb9c1
2014-07-13 18:17:00,424 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c9bc1c0a29314eae8c19f7cbd6dbb9c1, entries=464230, sequenceid=12690, filesize=33.1m
2014-07-13 18:17:00,425 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~371.4m/389458000, currentsize=137.1m/143710960 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 6991ms, sequenceid=12690, compaction requested=true
2014-07-13 18:17:00,425 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:132), split_queue=0, merge_queue=0
2014-07-13 18:17:00,425 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 32ms
2014-07-13 18:17:00,425 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,425 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 43ms
2014-07-13 18:17:00,425 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,425 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 330.5m
2014-07-13 18:17:00,425 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 53ms
2014-07-13 18:17:00,426 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,429 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 62ms
2014-07-13 18:17:00,429 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,429 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 85ms
2014-07-13 18:17:00,430 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,432 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 92ms
2014-07-13 18:17:00,432 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,432 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 105ms
2014-07-13 18:17:00,432 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,432 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 107ms
2014-07-13 18:17:00,432 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,432 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 114ms
2014-07-13 18:17:00,432 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,445 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 170ms
2014-07-13 18:17:00,445 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,445 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 227ms
2014-07-13 18:17:00,445 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,445 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 230ms
2014-07-13 18:17:00,445 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,446 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 232ms
2014-07-13 18:17:00,446 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,446 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 232ms
2014-07-13 18:17:00,446 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,446 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 233ms
2014-07-13 18:17:00,446 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,448 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 246ms
2014-07-13 18:17:00,448 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,449 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 274ms
2014-07-13 18:17:00,449 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,449 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 290ms
2014-07-13 18:17:00,449 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,449 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 291ms
2014-07-13 18:17:00,449 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,450 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 295ms
2014-07-13 18:17:00,450 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,450 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 295ms
2014-07-13 18:17:00,450 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,453 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 299ms
2014-07-13 18:17:00,453 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,458 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 305ms
2014-07-13 18:17:00,459 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,459 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 307ms
2014-07-13 18:17:00,459 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,459 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 307ms
2014-07-13 18:17:00,459 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,459 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 307ms
2014-07-13 18:17:00,459 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,459 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 325ms
2014-07-13 18:17:00,459 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,461 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 360ms
2014-07-13 18:17:00,461 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,461 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 369ms
2014-07-13 18:17:00,461 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,461 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 370ms
2014-07-13 18:17:00,461 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,467 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 387ms
2014-07-13 18:17:00,467 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,476 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 399ms
2014-07-13 18:17:00,476 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,476 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 398ms
2014-07-13 18:17:00,476 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,476 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 400ms
2014-07-13 18:17:00,476 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,476 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 401ms
2014-07-13 18:17:00,477 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,477 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 404ms
2014-07-13 18:17:00,477 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,477 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 405ms
2014-07-13 18:17:00,477 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,478 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 406ms
2014-07-13 18:17:00,478 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,478 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 418ms
2014-07-13 18:17:00,478 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,478 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 422ms
2014-07-13 18:17:00,479 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,479 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 424ms
2014-07-13 18:17:00,479 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,479 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 428ms
2014-07-13 18:17:00,479 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,479 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 430ms
2014-07-13 18:17:00,479 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,483 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 436ms
2014-07-13 18:17:00,483 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,484 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 439ms
2014-07-13 18:17:00,484 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:17:00,799 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:05,739 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:05,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300619671 with entries=190, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300625739
2014-07-13 18:17:07,933 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12784, memsize=209.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/2ec8d7e16022450198094daff45b20ba
2014-07-13 18:17:07,951 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/2ec8d7e16022450198094daff45b20ba as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/2ec8d7e16022450198094daff45b20ba
2014-07-13 18:17:07,965 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/2ec8d7e16022450198094daff45b20ba, entries=762060, sequenceid=12784, filesize=54.3m
2014-07-13 18:17:07,966 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~330.5m/346515840, currentsize=60.3m/63266560 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 7541ms, sequenceid=12784, compaction requested=true
2014-07-13 18:17:07,966 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-13 18:17:09,935 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/30c123a754ea44938b40767ed9ddc271 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/30c123a754ea44938b40767ed9ddc271
2014-07-13 18:17:09,958 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:17:09,971 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/300be6153c804026a9ab81d87b6057c4, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/300be6153c804026a9ab81d87b6057c4
2014-07-13 18:17:09,977 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2dc2f4c8e5534d8dbc296c7f6567333d, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2dc2f4c8e5534d8dbc296c7f6567333d
2014-07-13 18:17:09,980 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/65815424c53c4594b604ce87911d47f0, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/65815424c53c4594b604ce87911d47f0
2014-07-13 18:17:09,981 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into 30c123a754ea44938b40767ed9ddc271(size=144.5m), total size for store is 3.0g. This selection was in queue for 0sec, and took 25sec to execute.
2014-07-13 18:17:09,981 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=3, fileSize=162.3m, priority=-1, time=254512379329744; duration=25sec
2014-07-13 18:17:09,981 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-13 18:17:09,981 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:17:09,982 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 137395775 starting at candidate #14 after considering 124 permutations with 106 in ratio
2014-07-13 18:17:09,982 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating minor compaction
2014-07-13 18:17:09,982 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:17:09,983 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=131.0m
2014-07-13 18:17:09,983 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/5c1562ef9a954ed9a897acd347d9998b, keycount=89592, bloomtype=ROW, size=63.8m, encoding=NONE, seqNum=11293
2014-07-13 18:17:09,983 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/36401e0cf4014e4eb2de467c0143d21e, keycount=78314, bloomtype=ROW, size=55.8m, encoding=NONE, seqNum=11458
2014-07-13 18:17:09,983 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/49aca054e3cf4fde807e40009d6202bf, keycount=16033, bloomtype=ROW, size=11.4m, encoding=NONE, seqNum=11647
2014-07-13 18:17:10,037 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:10,695 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 1.2g
2014-07-13 18:17:11,680 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:20,948 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12180, memsize=858.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/697beccac91e495a8b9a0eb1c0730e10
2014-07-13 18:17:20,966 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/697beccac91e495a8b9a0eb1c0730e10 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/697beccac91e495a8b9a0eb1c0730e10
2014-07-13 18:17:20,980 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/697beccac91e495a8b9a0eb1c0730e10, entries=3125630, sequenceid=12180, filesize=222.5m
2014-07-13 18:17:20,980 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.7g/1842082720, currentsize=300.1m/314669120 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 37650ms, sequenceid=12180, compaction requested=true
2014-07-13 18:17:20,981 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-13 18:17:21,328 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:17:21,328 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 301.7m
2014-07-13 18:17:21,522 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:26,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:26,162 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300625739 with entries=164, filesize=62.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300646085
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300486870
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300488512
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300491283
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300511099
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300512778
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300515007
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300516786
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300518718
2014-07-13 18:17:26,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300520132
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300521969
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300523380
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300524642
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300525981
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300528086
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300529671
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300531047
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300532312
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300534322
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300536819
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300537706
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300540277
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300542165
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300543279
2014-07-13 18:17:26,163 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300544855
2014-07-13 18:17:26,164 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300546193
2014-07-13 18:17:27,077 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/6261442c49394a768193335cf6c7be31 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/6261442c49394a768193335cf6c7be31
2014-07-13 18:17:27,174 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:17:27,332 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/5c1562ef9a954ed9a897acd347d9998b, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/5c1562ef9a954ed9a897acd347d9998b
2014-07-13 18:17:27,334 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/36401e0cf4014e4eb2de467c0143d21e, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/36401e0cf4014e4eb2de467c0143d21e
2014-07-13 18:17:27,341 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/49aca054e3cf4fde807e40009d6202bf, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/49aca054e3cf4fde807e40009d6202bf
2014-07-13 18:17:27,342 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into 6261442c49394a768193335cf6c7be31(size=124.3m), total size for store is 3.1g. This selection was in queue for 0sec, and took 17sec to execute.
2014-07-13 18:17:27,342 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=3, fileSize=131.0m, priority=-1, time=254537409678613; duration=17sec
2014-07-13 18:17:27,342 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-13 18:17:27,342 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:17:27,343 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 227826834 starting at candidate #18 after considering 124 permutations with 107 in ratio
2014-07-13 18:17:27,343 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating minor compaction
2014-07-13 18:17:27,344 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:17:27,344 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=217.3m
2014-07-13 18:17:27,344 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ae8e93e40bfa4171846668fff22c12df, keycount=173126, bloomtype=ROW, size=123.3m, encoding=NONE, seqNum=12241
2014-07-13 18:17:27,344 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f7af3958712e4d3085f560956ac299cf, keycount=55639, bloomtype=ROW, size=39.6m, encoding=NONE, seqNum=12533
2014-07-13 18:17:27,344 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/2ec8d7e16022450198094daff45b20ba, keycount=76206, bloomtype=ROW, size=54.3m, encoding=NONE, seqNum=12784
2014-07-13 18:17:27,374 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:27,495 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12391, memsize=188.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/1d3957fc24904a668c12f647dae376e8
2014-07-13 18:17:27,513 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/1d3957fc24904a668c12f647dae376e8 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/1d3957fc24904a668c12f647dae376e8
2014-07-13 18:17:27,522 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/1d3957fc24904a668c12f647dae376e8, entries=685100, sequenceid=12391, filesize=48.8m
2014-07-13 18:17:27,523 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~301.7m/316359680, currentsize=33.2m/34858800 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 6195ms, sequenceid=12391, compaction requested=true
2014-07-13 18:17:27,523 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:133), split_queue=0, merge_queue=0
2014-07-13 18:17:28,686 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:28,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50697 synced till here 50693
2014-07-13 18:17:28,747 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300646085 with entries=110, filesize=66.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300648687
2014-07-13 18:17:28,928 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12449, memsize=479.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/1bebcee6ade342ed959ecc8eda3406bb
2014-07-13 18:17:28,940 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/1bebcee6ade342ed959ecc8eda3406bb as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1bebcee6ade342ed959ecc8eda3406bb
2014-07-13 18:17:28,949 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1bebcee6ade342ed959ecc8eda3406bb, entries=1746870, sequenceid=12449, filesize=124.5m
2014-07-13 18:17:28,949 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1253643440, currentsize=45.1m/47248240 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 18254ms, sequenceid=12449, compaction requested=true
2014-07-13 18:17:28,949 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:134), split_queue=0, merge_queue=0
2014-07-13 18:17:29,902 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:29,929 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300648687 with entries=64, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300649903
2014-07-13 18:17:29,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300549242
2014-07-13 18:17:29,929 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300550567
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300552149
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300554460
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300555696
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300557129
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300559389
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300560800
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300562458
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300563363
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300566809
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300569029
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300572322
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300574793
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300576717
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300578366
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300580110
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300581539
2014-07-13 18:17:29,930 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300582755
2014-07-13 18:17:29,932 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300585473
2014-07-13 18:17:29,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300589057
2014-07-13 18:17:29,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300592370
2014-07-13 18:17:29,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300594790
2014-07-13 18:17:29,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300601484
2014-07-13 18:17:29,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300603735
2014-07-13 18:17:29,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300605838
2014-07-13 18:17:29,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300607405
2014-07-13 18:17:29,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300609264
2014-07-13 18:17:29,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300610586
2014-07-13 18:17:29,934 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300611901
2014-07-13 18:17:29,947 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:17:29,947 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 257.0m
2014-07-13 18:17:30,179 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:31,355 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:31,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50825 synced till here 50823
2014-07-13 18:17:31,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300649903 with entries=64, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300651355
2014-07-13 18:17:32,714 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:32,728 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50891 synced till here 50885
2014-07-13 18:17:32,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300651355 with entries=66, filesize=66.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300652714
2014-07-13 18:17:33,778 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:34,175 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 50962 synced till here 50957
2014-07-13 18:17:34,199 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300652714 with entries=71, filesize=67.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300653778
2014-07-13 18:17:35,309 DEBUG [RpcServer.handler=37,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:17:35,310 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 258.6m
2014-07-13 18:17:35,395 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:35,465 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51036 synced till here 51029
2014-07-13 18:17:35,904 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:36,138 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300653778 with entries=74, filesize=69.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300655395
2014-07-13 18:17:37,631 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:37,662 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51098 synced till here 51095
2014-07-13 18:17:37,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300655395 with entries=62, filesize=63.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300657631
2014-07-13 18:17:37,766 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:17:38,317 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13007, memsize=217.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/33cb7a1192b44d8382affb868caf762c
2014-07-13 18:17:38,332 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/33cb7a1192b44d8382affb868caf762c as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/33cb7a1192b44d8382affb868caf762c
2014-07-13 18:17:38,345 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/33cb7a1192b44d8382affb868caf762c, entries=791790, sequenceid=13007, filesize=56.4m
2014-07-13 18:17:38,346 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~260.6m/273266720, currentsize=141.3m/148209040 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 8399ms, sequenceid=13007, compaction requested=true
2014-07-13 18:17:38,347 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:135), split_queue=0, merge_queue=0
2014-07-13 18:17:38,347 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:17:38,347 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:136), split_queue=0, merge_queue=0
2014-07-13 18:17:39,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:39,246 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51187 synced till here 51172
2014-07-13 18:17:39,369 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:17:39,370 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 257.6m
2014-07-13 18:17:39,401 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300657631 with entries=89, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300659211
2014-07-13 18:17:39,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300613403
2014-07-13 18:17:39,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300615091
2014-07-13 18:17:39,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300616364
2014-07-13 18:17:39,401 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300617883
2014-07-13 18:17:39,862 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:40,904 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:40,942 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51295 synced till here 51275
2014-07-13 18:17:41,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300659211 with entries=108, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300660904
2014-07-13 18:17:43,128 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:44,399 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51432 synced till here 51407
2014-07-13 18:17:44,658 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300660904 with entries=137, filesize=123.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300663129
2014-07-13 18:17:45,033 DEBUG [RpcServer.handler=3,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:17:46,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:46,834 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51571 synced till here 51559
2014-07-13 18:17:46,978 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300663129 with entries=139, filesize=115.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300666558
2014-07-13 18:17:48,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:48,762 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51671 synced till here 51646
2014-07-13 18:17:49,007 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300666558 with entries=100, filesize=89.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300668693
2014-07-13 18:17:50,190 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12530, memsize=253.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ba3ca49d306f4d73bef6bd8cf2b41b33
2014-07-13 18:17:50,200 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:50,210 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ba3ca49d306f4d73bef6bd8cf2b41b33 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ba3ca49d306f4d73bef6bd8cf2b41b33
2014-07-13 18:17:50,223 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51752 synced till here 51750
2014-07-13 18:17:50,238 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ba3ca49d306f4d73bef6bd8cf2b41b33, entries=921760, sequenceid=12530, filesize=65.6m
2014-07-13 18:17:50,253 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~262.9m/275628560, currentsize=328.7m/344697840 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 14943ms, sequenceid=12530, compaction requested=true
2014-07-13 18:17:50,254 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:137), split_queue=0, merge_queue=0
2014-07-13 18:17:50,254 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 348.2m
2014-07-13 18:17:50,261 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300668693 with entries=81, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300670200
2014-07-13 18:17:50,429 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:17:51,349 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:52,110 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:52,677 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51871 synced till here 51864
2014-07-13 18:17:52,719 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300670200 with entries=119, filesize=97.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300672111
2014-07-13 18:17:53,421 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:53,445 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 51952 synced till here 51948
2014-07-13 18:17:53,491 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300672111 with entries=81, filesize=64.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300673421
2014-07-13 18:17:54,591 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12583, memsize=245.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/79b9b60d699d49fdadfc0107ddc39f00
2014-07-13 18:17:54,605 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/79b9b60d699d49fdadfc0107ddc39f00 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/79b9b60d699d49fdadfc0107ddc39f00
2014-07-13 18:17:54,719 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:54,891 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/79b9b60d699d49fdadfc0107ddc39f00, entries=894960, sequenceid=12583, filesize=63.7m
2014-07-13 18:17:54,892 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~264.8m/277628000, currentsize=349.3m/366250880 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 15522ms, sequenceid=12583, compaction requested=true
2014-07-13 18:17:54,892 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:138), split_queue=0, merge_queue=0
2014-07-13 18:17:54,892 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 433.1m
2014-07-13 18:17:54,904 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:17:55,456 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52092 synced till here 52087
2014-07-13 18:17:55,481 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300673421 with entries=140, filesize=100.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300674719
2014-07-13 18:17:55,575 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:17:56,735 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:56,750 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52165 synced till here 52160
2014-07-13 18:17:56,850 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300674719 with entries=73, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300676735
2014-07-13 18:17:58,180 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:58,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52230 synced till here 52221
2014-07-13 18:17:58,297 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300676735 with entries=65, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300678180
2014-07-13 18:17:58,693 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13238, memsize=158.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/4d66ddb5e67a4e6d907ce7df278504e7
2014-07-13 18:17:58,723 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/4d66ddb5e67a4e6d907ce7df278504e7 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4d66ddb5e67a4e6d907ce7df278504e7
2014-07-13 18:17:58,746 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4d66ddb5e67a4e6d907ce7df278504e7, entries=577730, sequenceid=13238, filesize=41.2m
2014-07-13 18:17:58,747 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~352.7m/369863760, currentsize=199.2m/208872080 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 8493ms, sequenceid=13238, compaction requested=true
2014-07-13 18:17:58,747 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:139), split_queue=0, merge_queue=0
2014-07-13 18:17:58,747 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:17:58,748 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:140), split_queue=0, merge_queue=0
2014-07-13 18:17:59,606 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:17:59,636 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52296 synced till here 52291
2014-07-13 18:17:59,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300678180 with entries=66, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300679607
2014-07-13 18:18:00,804 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:00,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300679607 with entries=70, filesize=62.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300680804
2014-07-13 18:18:01,081 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:18:01,081 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:18:01,081 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:141), split_queue=0, merge_queue=0
2014-07-13 18:18:01,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:01,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52435 synced till here 52429
2014-07-13 18:18:02,054 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300680804 with entries=69, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300681480
2014-07-13 18:18:03,171 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:03,196 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52509 synced till here 52508
2014-07-13 18:18:03,222 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300681480 with entries=74, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300683171
2014-07-13 18:18:03,340 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12836, memsize=170.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/0d6677ec5428490dbf536b590cef0232
2014-07-13 18:18:03,354 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/0d6677ec5428490dbf536b590cef0232 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0d6677ec5428490dbf536b590cef0232
2014-07-13 18:18:03,747 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0d6677ec5428490dbf536b590cef0232, entries=619750, sequenceid=12836, filesize=44.2m
2014-07-13 18:18:03,747 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~437.7m/458936240, currentsize=173.4m/181794880 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 8855ms, sequenceid=12836, compaction requested=true
2014-07-13 18:18:03,747 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:142), split_queue=0, merge_queue=0
2014-07-13 18:18:04,330 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:04,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52615 synced till here 52607
2014-07-13 18:18:04,608 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300683171 with entries=106, filesize=82.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300684330
2014-07-13 18:18:05,878 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:05,892 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52684 synced till here 52683
2014-07-13 18:18:05,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300684330 with entries=69, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300685878
2014-07-13 18:18:06,883 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:18:06,883 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:18:06,884 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-13 18:18:07,183 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:07,481 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52773 synced till here 52769
2014-07-13 18:18:07,535 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/aa1d5d2398914f57b19bec96a7e505eb as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/aa1d5d2398914f57b19bec96a7e505eb
2014-07-13 18:18:07,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300685878 with entries=89, filesize=88.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300687183
2014-07-13 18:18:07,621 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:18:08,108 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ae8e93e40bfa4171846668fff22c12df, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ae8e93e40bfa4171846668fff22c12df
2014-07-13 18:18:08,108 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 898.2m
2014-07-13 18:18:08,114 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f7af3958712e4d3085f560956ac299cf, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f7af3958712e4d3085f560956ac299cf
2014-07-13 18:18:08,118 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/2ec8d7e16022450198094daff45b20ba, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/2ec8d7e16022450198094daff45b20ba
2014-07-13 18:18:08,118 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into aa1d5d2398914f57b19bec96a7e505eb(size=187.6m), total size for store is 3.1g. This selection was in queue for 0sec, and took 40sec to execute.
2014-07-13 18:18:08,118 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=3, fileSize=217.3m, priority=-1, time=254554770613272; duration=40sec
2014-07-13 18:18:08,118 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-13 18:18:08,119 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:18:08,120 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 314593898 starting at candidate #11 after considering 124 permutations with 102 in ratio
2014-07-13 18:18:08,120 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:18:08,120 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:18:08,120 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=300.0m
2014-07-13 18:18:08,120 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77e38dc4ae054323bef170255691bfc9, keycount=92889, bloomtype=ROW, size=66.1m, encoding=NONE, seqNum=7808
2014-07-13 18:18:08,120 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e8ce1e27779d4fb7bc89cd6d4851d6d4, keycount=134732, bloomtype=ROW, size=95.9m, encoding=NONE, seqNum=7995
2014-07-13 18:18:08,121 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dd123bbd8b234d179dd847c5e13cb67e, keycount=106797, bloomtype=ROW, size=76.0m, encoding=NONE, seqNum=8177
2014-07-13 18:18:08,121 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f347c1903f31429e9da84db82e557f36, keycount=87084, bloomtype=ROW, size=62.0m, encoding=NONE, seqNum=8347
2014-07-13 18:18:08,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:08,660 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:18:08,670 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300687183 with entries=69, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300688649
2014-07-13 18:18:08,978 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:18:09,953 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:10,150 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.28 MB, free=3.95 GB, max=3.96 GB, blocks=3, accesses=299100, hits=55561, hitRatio=18.57%, , cachingAccesses=55587, cachingHits=55536, cachingHitsRatio=99.90%, evictions=0, evicted=48, evictedPerRun=Infinity
2014-07-13 18:18:10,220 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 52934 synced till here 52927
2014-07-13 18:18:10,273 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300688649 with entries=92, filesize=90.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300689954
2014-07-13 18:18:11,495 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:12,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53021 synced till here 53018
2014-07-13 18:18:12,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300689954 with entries=87, filesize=93.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300691495
2014-07-13 18:18:13,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:13,313 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53087 synced till here 53086
2014-07-13 18:18:13,348 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300691495 with entries=66, filesize=64.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300693273
2014-07-13 18:18:15,185 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:15,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53161 synced till here 53159
2014-07-13 18:18:15,743 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300693273 with entries=74, filesize=69.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300695185
2014-07-13 18:18:16,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:16,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53238 synced till here 53230
2014-07-13 18:18:17,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300695185 with entries=77, filesize=69.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300696614
2014-07-13 18:18:18,046 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:18,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53338 synced till here 53319
2014-07-13 18:18:18,938 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300696614 with entries=100, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300698046
2014-07-13 18:18:20,899 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:20,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53458 synced till here 53435
2014-07-13 18:18:21,181 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300698046 with entries=120, filesize=92.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300700900
2014-07-13 18:18:22,919 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:22,961 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53591 synced till here 53568
2014-07-13 18:18:23,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300700900 with entries=133, filesize=88.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300702919
2014-07-13 18:18:24,593 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:24,611 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53677 synced till here 53657
2014-07-13 18:18:24,777 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300702919 with entries=86, filesize=80.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300704594
2014-07-13 18:18:26,316 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:26,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300704594 with entries=91, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300706317
2014-07-13 18:18:27,811 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:18:27,811 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files, but is 1022.5m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:18:27,811 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. due to global heap pressure
2014-07-13 18:18:27,811 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 1022.5m
2014-07-13 18:18:28,135 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:28,162 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53866 synced till here 53856
2014-07-13 18:18:28,234 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300706317 with entries=98, filesize=73.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300708135
2014-07-13 18:18:29,637 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:18:29,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:29,812 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,816 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,836 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,864 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,873 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,888 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,890 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,894 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,895 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,895 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,896 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,897 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,897 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,902 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,903 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,904 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,921 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,933 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,947 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 53968 synced till here 53953
2014-07-13 18:18:29,963 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:29,968 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,000 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,006 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,008 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,009 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,009 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,010 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,027 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,049 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,055 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,059 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300708135 with entries=102, filesize=95.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300709774
2014-07-13 18:18:30,062 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,073 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,097 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,120 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,122 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,124 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,134 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,143 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,173 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:30,204 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,195 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,198 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,203 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,207 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,229 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,241 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,277 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,310 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,337 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,387 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:31,422 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:35,142 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5008ms
2014-07-13 18:18:35,142 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5115ms
2014-07-13 18:18:35,142 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5142ms
2014-07-13 18:18:35,142 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5221ms
2014-07-13 18:18:35,143 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5245ms
2014-07-13 18:18:35,143 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5249ms
2014-07-13 18:18:35,143 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5270ms
2014-07-13 18:18:35,143 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5327ms
2014-07-13 18:18:35,143 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5137ms
2014-07-13 18:18:35,144 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5135ms
2014-07-13 18:18:35,144 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5135ms
2014-07-13 18:18:35,144 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5135ms
2014-07-13 18:18:35,144 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5134ms
2014-07-13 18:18:35,144 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5095ms
2014-07-13 18:18:35,145 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5090ms
2014-07-13 18:18:35,145 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5049ms
2014-07-13 18:18:35,146 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5073ms
2014-07-13 18:18:35,146 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5084ms
2014-07-13 18:18:35,146 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5026ms
2014-07-13 18:18:35,147 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5026ms
2014-07-13 18:18:35,147 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5023ms
2014-07-13 18:18:35,148 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5336ms
2014-07-13 18:18:35,148 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-13 18:18:35,148 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5284ms
2014-07-13 18:18:35,148 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5312ms
2014-07-13 18:18:35,148 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5260ms
2014-07-13 18:18:35,148 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5258ms
2014-07-13 18:18:35,149 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5254ms
2014-07-13 18:18:35,149 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5254ms
2014-07-13 18:18:35,149 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5252ms
2014-07-13 18:18:35,150 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5253ms
2014-07-13 18:18:35,150 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5248ms
2014-07-13 18:18:35,150 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5248ms
2014-07-13 18:18:35,150 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5246ms
2014-07-13 18:18:35,150 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5187ms
2014-07-13 18:18:35,150 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5217ms
2014-07-13 18:18:35,151 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5182ms
2014-07-13 18:18:35,173 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:35,205 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:36,195 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,199 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:36,203 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,207 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,229 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,242 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,278 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,310 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,337 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:36,388 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:36,423 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:38,061 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13438, memsize=585.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/fb3bf6d975074a8184131bef99007943
2014-07-13 18:18:38,076 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/fb3bf6d975074a8184131bef99007943 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/fb3bf6d975074a8184131bef99007943
2014-07-13 18:18:38,085 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/fb3bf6d975074a8184131bef99007943, entries=2133430, sequenceid=13438, filesize=151.8m
2014-07-13 18:18:38,086 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~906.0m/950021680, currentsize=469.3m/492052320 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 29978ms, sequenceid=13438, compaction requested=true
2014-07-13 18:18:38,086 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:143), split_queue=0, merge_queue=0
2014-07-13 18:18:38,086 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6664ms
2014-07-13 18:18:38,086 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,086 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6699ms
2014-07-13 18:18:38,086 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,086 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6749ms
2014-07-13 18:18:38,086 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,087 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6777ms
2014-07-13 18:18:38,087 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,088 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6811ms
2014-07-13 18:18:38,088 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,089 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6848ms
2014-07-13 18:18:38,089 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,089 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6860ms
2014-07-13 18:18:38,089 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,093 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6886ms
2014-07-13 18:18:38,093 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,109 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6906ms
2014-07-13 18:18:38,109 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,109 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6911ms
2014-07-13 18:18:38,109 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,109 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6914ms
2014-07-13 18:18:38,109 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,109 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7905ms
2014-07-13 18:18:38,109 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,109 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7937ms
2014-07-13 18:18:38,109 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,109 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8141ms
2014-07-13 18:18:38,110 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,113 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8180ms
2014-07-13 18:18:38,113 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,114 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8151ms
2014-07-13 18:18:38,114 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,114 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8210ms
2014-07-13 18:18:38,114 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,115 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8213ms
2014-07-13 18:18:38,115 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,119 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8217ms
2014-07-13 18:18:38,119 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,119 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8223ms
2014-07-13 18:18:38,119 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,119 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8222ms
2014-07-13 18:18:38,119 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,119 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8224ms
2014-07-13 18:18:38,119 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,120 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8225ms
2014-07-13 18:18:38,120 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,120 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8230ms
2014-07-13 18:18:38,120 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,120 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8232ms
2014-07-13 18:18:38,120 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,120 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8284ms
2014-07-13 18:18:38,120 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,125 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8261ms
2014-07-13 18:18:38,125 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,125 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7982ms
2014-07-13 18:18:38,125 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,126 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8314ms
2014-07-13 18:18:38,126 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,126 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8002ms
2014-07-13 18:18:38,126 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,126 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8005ms
2014-07-13 18:18:38,126 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,129 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8009ms
2014-07-13 18:18:38,129 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,131 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8069ms
2014-07-13 18:18:38,131 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,131 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8058ms
2014-07-13 18:18:38,131 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,137 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8041ms
2014-07-13 18:18:38,137 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,137 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8082ms
2014-07-13 18:18:38,137 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,138 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8089ms
2014-07-13 18:18:38,138 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,138 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8128ms
2014-07-13 18:18:38,138 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,139 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8130ms
2014-07-13 18:18:38,139 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,139 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8130ms
2014-07-13 18:18:38,139 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,139 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8131ms
2014-07-13 18:18:38,139 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,189 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8183ms
2014-07-13 18:18:38,189 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,189 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8373ms
2014-07-13 18:18:38,189 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,189 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8316ms
2014-07-13 18:18:38,189 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,189 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8295ms
2014-07-13 18:18:38,190 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,190 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8293ms
2014-07-13 18:18:38,190 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,194 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8273ms
2014-07-13 18:18:38,194 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,194 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8194ms
2014-07-13 18:18:38,194 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,200 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8173ms
2014-07-13 18:18:38,200 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:38,200 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8066ms
2014-07-13 18:18:38,200 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:39,233 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:18:39,234 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 471.6m
2014-07-13 18:18:39,598 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10023,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709575,"queuetimems":1,"class":"HRegionServer","responsesize":19800,"method":"Multi"}
2014-07-13 18:18:39,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:39,931 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10029,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709902,"queuetimems":0,"class":"HRegionServer","responsesize":889,"method":"Multi"}
2014-07-13 18:18:39,941 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10045,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709895,"queuetimems":1,"class":"HRegionServer","responsesize":4354,"method":"Multi"}
2014-07-13 18:18:40,105 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54089 synced till here 54049
2014-07-13 18:18:40,105 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:18:40,164 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10292,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709872,"queuetimems":0,"class":"HRegionServer","responsesize":6652,"method":"Multi"}
2014-07-13 18:18:40,164 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10277,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709887,"queuetimems":0,"class":"HRegionServer","responsesize":9037,"method":"Multi"}
2014-07-13 18:18:40,164 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10104,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710060,"queuetimems":1,"class":"HRegionServer","responsesize":7780,"method":"Multi"}
2014-07-13 18:18:40,165 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710094,"queuetimems":0,"class":"HRegionServer","responsesize":10487,"method":"Multi"}
2014-07-13 18:18:40,164 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10232,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709932,"queuetimems":0,"class":"HRegionServer","responsesize":7527,"method":"Multi"}
2014-07-13 18:18:40,169 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10122,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710046,"queuetimems":0,"class":"HRegionServer","responsesize":13032,"method":"Multi"}
2014-07-13 18:18:40,174 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10101,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710072,"queuetimems":0,"class":"HRegionServer","responsesize":5697,"method":"Multi"}
2014-07-13 18:18:40,174 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710119,"queuetimems":1,"class":"HRegionServer","responsesize":12462,"method":"Multi"}
2014-07-13 18:18:40,174 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709904,"queuetimems":0,"class":"HRegionServer","responsesize":1408,"method":"Multi"}
2014-07-13 18:18:40,174 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10207,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709967,"queuetimems":1,"class":"HRegionServer","responsesize":4693,"method":"Multi"}
2014-07-13 18:18:40,164 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10560,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709604,"queuetimems":0,"class":"HRegionServer","responsesize":15934,"method":"Multi"}
2014-07-13 18:18:40,942 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10822,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710120,"queuetimems":0,"class":"HRegionServer","responsesize":1384,"method":"Multi"}
2014-07-13 18:18:40,947 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10822,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710124,"queuetimems":0,"class":"HRegionServer","responsesize":2460,"method":"Multi"}
2014-07-13 18:18:40,953 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709834,"queuetimems":1,"class":"HRegionServer","responsesize":9057,"method":"Multi"}
2014-07-13 18:18:40,953 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10820,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710133,"queuetimems":1,"class":"HRegionServer","responsesize":4595,"method":"Multi"}
2014-07-13 18:18:40,953 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11051,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709902,"queuetimems":1,"class":"HRegionServer","responsesize":5234,"method":"Multi"}
2014-07-13 18:18:40,955 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10804,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710142,"queuetimems":1,"class":"HRegionServer","responsesize":3308,"method":"Multi"}
2014-07-13 18:18:41,115 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11119,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709996,"queuetimems":1,"class":"HRegionServer","responsesize":15508,"method":"Multi"}
2014-07-13 18:18:41,116 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11197,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709919,"queuetimems":0,"class":"HRegionServer","responsesize":8269,"method":"Multi"}
2014-07-13 18:18:41,116 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10915,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710201,"queuetimems":0,"class":"HRegionServer","responsesize":13158,"method":"Multi"}
2014-07-13 18:18:41,130 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710023,"queuetimems":0,"class":"HRegionServer","responsesize":15275,"method":"Multi"}
2014-07-13 18:18:41,131 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11464,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709666,"queuetimems":0,"class":"HRegionServer","responsesize":17402,"method":"Multi"}
2014-07-13 18:18:41,130 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10961,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300710169,"queuetimems":0,"class":"HRegionServer","responsesize":14382,"method":"Multi"}
2014-07-13 18:18:41,141 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11181,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709960,"queuetimems":1,"class":"HRegionServer","responsesize":15139,"method":"Multi"}
2014-07-13 18:18:41,141 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709397,"queuetimems":1,"class":"HRegionServer","responsesize":17127,"method":"Multi"}
2014-07-13 18:18:41,149 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12540,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300708609,"queuetimems":1,"class":"HRegionServer","responsesize":19778,"method":"Multi"}
2014-07-13 18:18:41,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300709774 with entries=121, filesize=115.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300719833
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300619671
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300625739
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300646085
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300648687
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300649903
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300651355
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300652714
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300653778
2014-07-13 18:18:41,159 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300655395
2014-07-13 18:18:41,160 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300657631
2014-07-13 18:18:41,381 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10152,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300711228,"queuetimems":1,"class":"HRegionServer","responsesize":17541,"method":"Multi"}
2014-07-13 18:18:41,585 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10250,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300711335,"queuetimems":0,"class":"HRegionServer","responsesize":17402,"method":"Multi"}
2014-07-13 18:18:41,788 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11925,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709862,"queuetimems":1,"class":"HRegionServer","responsesize":15589,"method":"Multi"}
2014-07-13 18:18:42,824 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:42,827 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13011,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300709815,"queuetimems":0,"class":"HRegionServer","responsesize":18236,"method":"Multi"}
2014-07-13 18:18:42,915 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54215 synced till here 54186
2014-07-13 18:18:43,141 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300719833 with entries=126, filesize=109.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300722825
2014-07-13 18:18:44,716 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:44,873 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54306 synced till here 54285
2014-07-13 18:18:45,133 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300722825 with entries=91, filesize=83.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300724717
2014-07-13 18:18:46,797 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:47,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54426 synced till here 54402
2014-07-13 18:18:47,406 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300724717 with entries=120, filesize=114.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300726797
2014-07-13 18:18:49,123 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:49,129 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,130 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,130 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,131 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,132 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,133 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,134 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,135 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,142 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54510 synced till here 54499
2014-07-13 18:18:49,254 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,254 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300726797 with entries=84, filesize=82.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300729123
2014-07-13 18:18:49,254 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,265 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,277 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,289 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,295 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,306 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,326 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:49,390 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:50,279 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:50,336 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:50,390 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:50,439 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:50,699 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:50,749 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,216 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,245 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,250 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,289 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,323 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,354 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:51,367 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,698 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,735 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,761 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,781 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,838 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,849 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,874 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,878 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,889 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,902 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,916 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:52,954 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,093 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,136 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,172 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,201 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,203 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,238 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,263 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:53,265 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:18:54,131 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:54,131 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:54,132 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:54,132 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 18:18:54,132 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:54,134 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:54,135 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:18:54,135 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:54,177 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13681, memsize=261.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/eff957b23d9448d6847dfeb2d766789a
2014-07-13 18:18:54,194 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/eff957b23d9448d6847dfeb2d766789a as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/eff957b23d9448d6847dfeb2d766789a
2014-07-13 18:18:54,214 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/eff957b23d9448d6847dfeb2d766789a, entries=951140, sequenceid=13681, filesize=67.8m
2014-07-13 18:18:54,214 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~483.7m/507177760, currentsize=270.5m/283620320 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 14980ms, sequenceid=13681, compaction requested=true
2014-07-13 18:18:54,214 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:144), split_queue=0, merge_queue=0
2014-07-13 18:18:54,215 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-13 18:18:54,215 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,215 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 18:18:54,215 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,217 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5083ms
2014-07-13 18:18:54,217 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,217 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5085ms
2014-07-13 18:18:54,217 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,217 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5088ms
2014-07-13 18:18:54,217 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,217 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-13 18:18:54,217 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,218 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5087ms
2014-07-13 18:18:54,218 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,218 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5089ms
2014-07-13 18:18:54,218 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,218 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 954ms
2014-07-13 18:18:54,218 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,229 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 966ms
2014-07-13 18:18:54,229 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,229 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 991ms
2014-07-13 18:18:54,229 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,229 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1026ms
2014-07-13 18:18:54,229 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,229 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1028ms
2014-07-13 18:18:54,229 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,229 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1057ms
2014-07-13 18:18:54,230 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,230 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1094ms
2014-07-13 18:18:54,230 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,241 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1148ms
2014-07-13 18:18:54,241 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,241 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1287ms
2014-07-13 18:18:54,241 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,253 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1337ms
2014-07-13 18:18:54,253 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,254 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:54,254 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,261 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1359ms
2014-07-13 18:18:54,261 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,261 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1372ms
2014-07-13 18:18:54,261 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,261 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1383ms
2014-07-13 18:18:54,261 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,261 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1387ms
2014-07-13 18:18:54,261 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,261 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1412ms
2014-07-13 18:18:54,261 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,262 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1424ms
2014-07-13 18:18:54,262 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,265 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:18:54,265 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,273 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1493ms
2014-07-13 18:18:54,273 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,273 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1512ms
2014-07-13 18:18:54,273 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,278 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:54,278 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,279 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1544ms
2014-07-13 18:18:54,279 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,280 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1582ms
2014-07-13 18:18:54,280 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,280 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2913ms
2014-07-13 18:18:54,280 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,280 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2926ms
2014-07-13 18:18:54,280 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,281 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2958ms
2014-07-13 18:18:54,281 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,282 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2993ms
2014-07-13 18:18:54,282 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,282 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3032ms
2014-07-13 18:18:54,282 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,287 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3041ms
2014-07-13 18:18:54,287 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,290 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:18:54,290 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,293 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3077ms
2014-07-13 18:18:54,293 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,294 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3544ms
2014-07-13 18:18:54,294 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,294 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3596ms
2014-07-13 18:18:54,294 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,295 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3856ms
2014-07-13 18:18:54,296 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,296 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3906ms
2014-07-13 18:18:54,296 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,297 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3960ms
2014-07-13 18:18:54,297 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,297 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4018ms
2014-07-13 18:18:54,297 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,309 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 18:18:54,309 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,309 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4919ms
2014-07-13 18:18:54,309 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,309 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4983ms
2014-07-13 18:18:54,309 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,310 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5014ms
2014-07-13 18:18:54,310 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:54,317 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5063ms
2014-07-13 18:18:54,318 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:18:55,435 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:18:55,440 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:18:55,440 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:145), split_queue=0, merge_queue=0
2014-07-13 18:18:55,865 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:55,959 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54608 synced till here 54581
2014-07-13 18:18:56,086 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300729123 with entries=98, filesize=76.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300735865
2014-07-13 18:18:56,678 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:18:56,678 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files, but is 1.2g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:18:56,678 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. due to global heap pressure
2014-07-13 18:18:56,679 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 1.2g
2014-07-13 18:18:57,224 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:57,245 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54674 synced till here 54673
2014-07-13 18:18:57,288 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300735865 with entries=66, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300737224
2014-07-13 18:18:58,679 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:18:59,222 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:18:59,247 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300737224 with entries=119, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300739222
2014-07-13 18:19:00,367 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13346, memsize=613.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/70c300ebc3e4471d9fe76541d7ed372d
2014-07-13 18:19:00,377 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/70c300ebc3e4471d9fe76541d7ed372d as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/70c300ebc3e4471d9fe76541d7ed372d
2014-07-13 18:19:00,385 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/70c300ebc3e4471d9fe76541d7ed372d, entries=2233020, sequenceid=13346, filesize=159.0m
2014-07-13 18:19:00,385 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1083535120, currentsize=306.9m/321758640 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 32574ms, sequenceid=13346, compaction requested=true
2014-07-13 18:19:00,386 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:146), split_queue=0, merge_queue=0
2014-07-13 18:19:00,560 DEBUG [RpcServer.handler=18,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:19:00,560 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:19:00,560 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-13 18:19:01,478 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:01,510 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300739222 with entries=89, filesize=60.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300741479
2014-07-13 18:19:01,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300659211
2014-07-13 18:19:01,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300660904
2014-07-13 18:19:01,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300663129
2014-07-13 18:19:01,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300666558
2014-07-13 18:19:01,510 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300668693
2014-07-13 18:19:03,568 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:03,686 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 54965 synced till here 54964
2014-07-13 18:19:03,705 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300741479 with entries=83, filesize=68.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300743568
2014-07-13 18:19:04,824 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:04,838 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55031 synced till here 55025
2014-07-13 18:19:04,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300743568 with entries=66, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300744824
2014-07-13 18:19:05,745 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:05,826 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300744824 with entries=78, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300745745
2014-07-13 18:19:07,251 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:07,882 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55200 synced till here 55197
2014-07-13 18:19:07,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300745745 with entries=91, filesize=77.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300747252
2014-07-13 18:19:08,633 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:08,745 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55280 synced till here 55275
2014-07-13 18:19:08,822 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300747252 with entries=80, filesize=73.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300748633
2014-07-13 18:19:09,411 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a8ecd26fe3b84b3ba47ca2eaa805e4b9 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a8ecd26fe3b84b3ba47ca2eaa805e4b9
2014-07-13 18:19:09,441 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:19:09,493 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77e38dc4ae054323bef170255691bfc9, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77e38dc4ae054323bef170255691bfc9
2014-07-13 18:19:09,500 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e8ce1e27779d4fb7bc89cd6d4851d6d4, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e8ce1e27779d4fb7bc89cd6d4851d6d4
2014-07-13 18:19:09,506 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dd123bbd8b234d179dd847c5e13cb67e, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dd123bbd8b234d179dd847c5e13cb67e
2014-07-13 18:19:09,508 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f347c1903f31429e9da84db82e557f36, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/f347c1903f31429e9da84db82e557f36
2014-07-13 18:19:09,508 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into a8ecd26fe3b84b3ba47ca2eaa805e4b9(size=299.3m), total size for store is 3.4g. This selection was in queue for 0sec, and took 1mins, 1sec to execute.
2014-07-13 18:19:09,509 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=4, fileSize=300.0m, priority=-1, time=254595547157996; duration=1mins, 1sec
2014-07-13 18:19:09,509 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-13 18:19:09,510 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:19:09,511 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 135431212 starting at candidate #17 after considering 124 permutations with 108 in ratio
2014-07-13 18:19:09,511 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating minor compaction
2014-07-13 18:19:09,511 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:19:09,511 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=129.2m
2014-07-13 18:19:09,511 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ca1d9d93837c496e94ded800f2925206, keycount=55692, bloomtype=ROW, size=39.7m, encoding=NONE, seqNum=12432
2014-07-13 18:19:09,512 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c9bc1c0a29314eae8c19f7cbd6dbb9c1, keycount=46423, bloomtype=ROW, size=33.1m, encoding=NONE, seqNum=12690
2014-07-13 18:19:09,512 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/33cb7a1192b44d8382affb868caf762c, keycount=79179, bloomtype=ROW, size=56.4m, encoding=NONE, seqNum=13007
2014-07-13 18:19:09,665 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 484.7m
2014-07-13 18:19:09,908 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:09,951 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:19:10,097 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55373 synced till here 55367
2014-07-13 18:19:10,129 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:19:10,152 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300748633 with entries=93, filesize=76.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300749908
2014-07-13 18:19:11,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:12,042 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55464 synced till here 55463
2014-07-13 18:19:12,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300749908 with entries=91, filesize=64.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300751992
2014-07-13 18:19:13,102 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,137 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,138 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,144 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,155 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,158 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,177 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,180 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,187 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,192 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,207 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,220 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,220 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,223 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,223 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,226 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,229 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:13,229 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,231 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,232 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,237 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,241 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,260 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,270 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,273 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,282 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300751992 with entries=68, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300753229
2014-07-13 18:19:13,294 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,308 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,341 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,363 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,404 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,407 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,442 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,460 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,952 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,953 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,965 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,981 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:13,983 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:14,000 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:14,037 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:14,061 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:14,064 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:14,073 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:14,075 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,255 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,267 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,289 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,315 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,355 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,405 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:15,465 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:18,218 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5011ms
2014-07-13 18:19:18,219 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5080ms
2014-07-13 18:19:18,219 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5075ms
2014-07-13 18:19:18,219 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5064ms
2014-07-13 18:19:18,219 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5061ms
2014-07-13 18:19:18,220 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5043ms
2014-07-13 18:19:18,220 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,221 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5041ms
2014-07-13 18:19:18,221 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5034ms
2014-07-13 18:19:18,221 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5029ms
2014-07-13 18:19:18,221 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,221 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5120ms
2014-07-13 18:19:18,222 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5084ms
2014-07-13 18:19:18,223 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,224 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,226 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,230 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,231 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,232 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,237 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,242 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,261 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,271 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,273 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,294 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,308 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,342 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,363 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,404 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,407 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,442 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,460 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,953 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:18,953 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,965 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,981 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:18,983 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:19,000 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:19,037 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:19,061 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:19,064 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:19,073 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:19,075 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:19,231 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13700, memsize=231.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/77847bd192d34914a915d66aef03036f
2014-07-13 18:19:19,249 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/77847bd192d34914a915d66aef03036f as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77847bd192d34914a915d66aef03036f
2014-07-13 18:19:19,264 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77847bd192d34914a915d66aef03036f, entries=842180, sequenceid=13700, filesize=60.0m
2014-07-13 18:19:19,264 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~485.9m/509468000, currentsize=73.4m/76957360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 9599ms, sequenceid=13700, compaction requested=true
2014-07-13 18:19:19,264 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:147), split_queue=0, merge_queue=0
2014-07-13 18:19:19,265 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5190ms
2014-07-13 18:19:19,265 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,265 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 73.4m
2014-07-13 18:19:19,265 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5192ms
2014-07-13 18:19:19,265 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,266 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5201ms
2014-07-13 18:19:19,266 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,277 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5216ms
2014-07-13 18:19:19,277 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,278 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5240ms
2014-07-13 18:19:19,279 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,282 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5280ms
2014-07-13 18:19:19,282 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,284 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5302ms
2014-07-13 18:19:19,285 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,285 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5304ms
2014-07-13 18:19:19,285 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,285 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5320ms
2014-07-13 18:19:19,285 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,286 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5332ms
2014-07-13 18:19:19,286 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,287 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5334ms
2014-07-13 18:19:19,287 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,287 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5827ms
2014-07-13 18:19:19,287 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,290 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5848ms
2014-07-13 18:19:19,291 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,291 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:19:19,295 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5887ms
2014-07-13 18:19:19,295 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,296 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5891ms
2014-07-13 18:19:19,296 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,297 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5933ms
2014-07-13 18:19:19,297 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,297 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5956ms
2014-07-13 18:19:19,297 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,301 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5993ms
2014-07-13 18:19:19,301 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,301 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6007ms
2014-07-13 18:19:19,301 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,302 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6028ms
2014-07-13 18:19:19,302 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,302 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6032ms
2014-07-13 18:19:19,302 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,303 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6042ms
2014-07-13 18:19:19,303 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,303 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6062ms
2014-07-13 18:19:19,303 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,304 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6066ms
2014-07-13 18:19:19,304 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,313 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6081ms
2014-07-13 18:19:19,313 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,313 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6082ms
2014-07-13 18:19:19,313 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,313 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6084ms
2014-07-13 18:19:19,313 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,313 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6087ms
2014-07-13 18:19:19,314 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,314 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6091ms
2014-07-13 18:19:19,314 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,321 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6099ms
2014-07-13 18:19:19,321 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,322 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6184ms
2014-07-13 18:19:19,322 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,322 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6221ms
2014-07-13 18:19:19,323 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,330 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6109ms
2014-07-13 18:19:19,330 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,330 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6138ms
2014-07-13 18:19:19,330 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,331 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6143ms
2014-07-13 18:19:19,331 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,378 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6198ms
2014-07-13 18:19:19,378 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,378 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6158ms
2014-07-13 18:19:19,378 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,379 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6202ms
2014-07-13 18:19:19,379 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,379 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6221ms
2014-07-13 18:19:19,379 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,389 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6234ms
2014-07-13 18:19:19,389 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,395 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6251ms
2014-07-13 18:19:19,395 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,395 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6257ms
2014-07-13 18:19:19,395 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,395 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6188ms
2014-07-13 18:19:19,395 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,405 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3940ms
2014-07-13 18:19:19,405 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,413 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4009ms
2014-07-13 18:19:19,413 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,413 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4058ms
2014-07-13 18:19:19,413 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,417 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4102ms
2014-07-13 18:19:19,417 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,418 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4128ms
2014-07-13 18:19:19,418 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,418 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4151ms
2014-07-13 18:19:19,418 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:19,419 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4164ms
2014-07-13 18:19:19,419 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:21,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:21,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55663 synced till here 55632
2014-07-13 18:19:21,450 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300753229 with entries=131, filesize=98.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300761108
2014-07-13 18:19:23,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:23,119 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55790 synced till here 55759
2014-07-13 18:19:23,236 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13755, memsize=71.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/dbfe0aa424714264b281d553cdbfc9c0
2014-07-13 18:19:23,250 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/dbfe0aa424714264b281d553cdbfc9c0 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dbfe0aa424714264b281d553cdbfc9c0
2014-07-13 18:19:23,307 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dbfe0aa424714264b281d553cdbfc9c0, entries=261300, sequenceid=13755, filesize=18.6m
2014-07-13 18:19:23,314 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~73.4m/76957360, currentsize=68.1m/71450880 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 4048ms, sequenceid=13755, compaction requested=true
2014-07-13 18:19:23,314 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:148), split_queue=0, merge_queue=0
2014-07-13 18:19:23,314 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:19:23,314 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files, but is 1.3g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:19:23,314 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. due to global heap pressure
2014-07-13 18:19:23,314 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.3g
2014-07-13 18:19:23,433 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300761108 with entries=127, filesize=99.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300763038
2014-07-13 18:19:25,218 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:25,340 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 55914 synced till here 55912
2014-07-13 18:19:25,403 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300763038 with entries=124, filesize=93.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300765219
2014-07-13 18:19:25,555 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,557 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,564 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,571 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,590 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,617 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,617 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,628 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,638 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,640 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,641 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,642 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,642 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,646 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,648 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,649 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:25,653 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,246 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,251 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,255 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,258 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,260 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,260 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,265 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,266 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,271 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,287 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:19:26,288 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,293 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,294 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,294 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,297 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,298 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,299 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,301 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,305 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,305 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:26,791 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13860, memsize=589.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/954c4d975bdb46aba90ab2288a6b87a1
2014-07-13 18:19:26,813 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/954c4d975bdb46aba90ab2288a6b87a1 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/954c4d975bdb46aba90ab2288a6b87a1
2014-07-13 18:19:26,827 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/954c4d975bdb46aba90ab2288a6b87a1, entries=2146390, sequenceid=13860, filesize=152.9m
2014-07-13 18:19:26,828 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.2g/1330478080, currentsize=497.4m/521531200 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 30149ms, sequenceid=13860, compaction requested=true
2014-07-13 18:19:26,828 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:149), split_queue=0, merge_queue=0
2014-07-13 18:19:26,828 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 523ms
2014-07-13 18:19:26,828 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,828 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 523ms
2014-07-13 18:19:26,829 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,829 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 528ms
2014-07-13 18:19:26,829 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,829 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 530ms
2014-07-13 18:19:26,829 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,829 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 531ms
2014-07-13 18:19:26,829 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,829 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 532ms
2014-07-13 18:19:26,829 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,829 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 535ms
2014-07-13 18:19:26,830 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,830 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 536ms
2014-07-13 18:19:26,830 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,830 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 537ms
2014-07-13 18:19:26,830 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,832 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 544ms
2014-07-13 18:19:26,832 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,834 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 563ms
2014-07-13 18:19:26,834 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,834 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 568ms
2014-07-13 18:19:26,834 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,837 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 572ms
2014-07-13 18:19:26,837 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,837 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 577ms
2014-07-13 18:19:26,837 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,837 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 577ms
2014-07-13 18:19:26,837 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,838 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 580ms
2014-07-13 18:19:26,838 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,841 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 586ms
2014-07-13 18:19:26,841 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,842 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 591ms
2014-07-13 18:19:26,842 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,845 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 599ms
2014-07-13 18:19:26,845 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,845 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1192ms
2014-07-13 18:19:26,845 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,845 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1196ms
2014-07-13 18:19:26,845 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,845 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1197ms
2014-07-13 18:19:26,845 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,845 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1200ms
2014-07-13 18:19:26,845 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,845 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1204ms
2014-07-13 18:19:26,846 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,846 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1204ms
2014-07-13 18:19:26,846 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,848 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1207ms
2014-07-13 18:19:26,848 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,848 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1208ms
2014-07-13 18:19:26,848 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,848 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1210ms
2014-07-13 18:19:26,848 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,849 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1221ms
2014-07-13 18:19:26,849 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,857 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1240ms
2014-07-13 18:19:26,857 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,857 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1240ms
2014-07-13 18:19:26,857 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,857 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1267ms
2014-07-13 18:19:26,857 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,865 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1294ms
2014-07-13 18:19:26,865 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,871 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:19:26,872 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:19:26,872 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:150), split_queue=0, merge_queue=0
2014-07-13 18:19:26,873 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1309ms
2014-07-13 18:19:26,873 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,873 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1316ms
2014-07-13 18:19:26,873 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:26,873 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1318ms
2014-07-13 18:19:26,873 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:27,226 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:27,517 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56021 synced till here 56019
2014-07-13 18:19:27,529 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300765219 with entries=107, filesize=80.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300767227
2014-07-13 18:19:27,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300670200
2014-07-13 18:19:27,531 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300672111
2014-07-13 18:19:28,960 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:29,153 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56119 synced till here 56114
2014-07-13 18:19:29,313 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300767227 with entries=98, filesize=78.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300768961
2014-07-13 18:19:30,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:31,222 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56197 synced till here 56190
2014-07-13 18:19:31,304 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300768961 with entries=78, filesize=82.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300770539
2014-07-13 18:19:31,994 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:32,321 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/40c6ac76a9c84c9480f9303749e8288e as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/40c6ac76a9c84c9480f9303749e8288e
2014-07-13 18:19:32,323 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56273 synced till here 56264
2014-07-13 18:19:32,845 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300770539 with entries=76, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300771994
2014-07-13 18:19:32,890 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:19:32,902 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ca1d9d93837c496e94ded800f2925206, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ca1d9d93837c496e94ded800f2925206
2014-07-13 18:19:32,909 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c9bc1c0a29314eae8c19f7cbd6dbb9c1, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/c9bc1c0a29314eae8c19f7cbd6dbb9c1
2014-07-13 18:19:32,913 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/33cb7a1192b44d8382affb868caf762c, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/33cb7a1192b44d8382affb868caf762c
2014-07-13 18:19:32,914 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into 40c6ac76a9c84c9480f9303749e8288e(size=110.6m), total size for store is 3.4g. This selection was in queue for 0sec, and took 23sec to execute.
2014-07-13 18:19:32,914 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=3, fileSize=129.2m, priority=-1, time=254656938146412; duration=23sec
2014-07-13 18:19:32,914 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-13 18:19:32,914 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-13 18:19:32,914 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:19:32,915 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 166291485 starting at candidate #18 after considering 124 permutations with 108 in ratio
2014-07-13 18:19:32,916 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating minor compaction
2014-07-13 18:19:32,916 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:19:32,916 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=158.6m
2014-07-13 18:19:32,916 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/1d3957fc24904a668c12f647dae376e8, keycount=68510, bloomtype=ROW, size=48.8m, encoding=NONE, seqNum=12391
2014-07-13 18:19:32,916 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ba3ca49d306f4d73bef6bd8cf2b41b33, keycount=92176, bloomtype=ROW, size=65.6m, encoding=NONE, seqNum=12530
2014-07-13 18:19:32,916 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0d6677ec5428490dbf536b590cef0232, keycount=61975, bloomtype=ROW, size=44.2m, encoding=NONE, seqNum=12836
2014-07-13 18:19:33,010 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:19:33,077 DEBUG [RpcServer.handler=4,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:19:33,081 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:19:33,081 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:151), split_queue=0, merge_queue=0
2014-07-13 18:19:33,578 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:33,613 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56347 synced till here 56346
2014-07-13 18:19:33,639 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300771994 with entries=74, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300773578
2014-07-13 18:19:33,658 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 664.0m
2014-07-13 18:19:34,701 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:19:34,924 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:35,124 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300773578 with entries=73, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300774925
2014-07-13 18:19:36,471 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:36,495 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56496 synced till here 56489
2014-07-13 18:19:36,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300774925 with entries=76, filesize=69.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300776471
2014-07-13 18:19:37,779 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:37,813 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56560 synced till here 56558
2014-07-13 18:19:37,852 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300776471 with entries=64, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300777779
2014-07-13 18:19:39,684 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:39,711 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300777779 with entries=64, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300779684
2014-07-13 18:19:41,653 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,654 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,654 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,679 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,695 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:41,700 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,713 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,720 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,750 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,773 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,793 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,818 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,837 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,874 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,922 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,948 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,954 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:41,965 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300779684 with entries=67, filesize=64.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300781696
2014-07-13 18:19:41,988 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,022 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,048 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,076 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,117 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,670 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,681 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,715 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,738 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,750 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,774 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,781 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,791 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,826 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,845 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,856 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,901 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,923 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:42,968 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,020 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,048 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,093 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,138 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,178 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,196 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,255 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,271 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,320 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,327 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,339 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,346 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,352 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,404 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:43,410 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:19:46,653 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,654 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,654 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,680 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,700 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,713 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,720 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,750 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,774 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,793 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,818 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,838 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,874 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,922 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,948 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:46,955 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:46,988 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,022 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,048 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,077 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:47,117 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,670 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,681 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:47,715 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:47,738 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,751 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:47,775 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:47,781 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,791 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,826 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,845 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,857 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,902 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:47,923 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:47,968 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,020 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,049 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,093 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,138 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,178 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,196 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,255 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,271 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,321 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:19:48,327 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,340 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,346 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,352 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,404 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:48,410 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:19:51,654 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,654 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:51,655 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,680 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,700 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,713 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:51,720 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:51,750 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:51,774 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,794 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,818 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:51,838 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,874 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,922 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,949 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,955 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:51,988 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:52,022 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:52,036 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14297, memsize=448.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/f2c2b059e11d4151a3db17a1074eb59f
2014-07-13 18:19:52,048 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:52,053 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/f2c2b059e11d4151a3db17a1074eb59f as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f2c2b059e11d4151a3db17a1074eb59f
2014-07-13 18:19:52,077 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:19:52,117 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:19:52,141 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/f2c2b059e11d4151a3db17a1074eb59f, entries=1631700, sequenceid=14297, filesize=116.2m
2014-07-13 18:19:52,142 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~666.8m/699170800, currentsize=149.2m/156471520 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 18484ms, sequenceid=14297, compaction requested=true
2014-07-13 18:19:52,142 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:152), split_queue=0, merge_queue=0
2014-07-13 18:19:52,142 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10025ms
2014-07-13 18:19:52,142 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,142 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 105259ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:19:52,143 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10067ms
2014-07-13 18:19:52,143 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,143 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10095ms
2014-07-13 18:19:52,143 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,145 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10123ms
2014-07-13 18:19:52,145 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,145 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10157ms
2014-07-13 18:19:52,145 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,145 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10191ms
2014-07-13 18:19:52,145 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,143 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., flushing=true, writesEnabled=true
2014-07-13 18:19:52,155 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10206ms
2014-07-13 18:19:52,155 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,155 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10234ms
2014-07-13 18:19:52,155 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,155 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10282ms
2014-07-13 18:19:52,155 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,161 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10324ms
2014-07-13 18:19:52,161 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,165 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10347ms
2014-07-13 18:19:52,165 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,165 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10372ms
2014-07-13 18:19:52,165 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,165 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10392ms
2014-07-13 18:19:52,165 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,165 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10415ms
2014-07-13 18:19:52,165 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,167 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10447ms
2014-07-13 18:19:52,167 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,167 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10454ms
2014-07-13 18:19:52,167 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,169 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10469ms
2014-07-13 18:19:52,169 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,182 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10503ms
2014-07-13 18:19:52,182 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,182 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10528ms
2014-07-13 18:19:52,182 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,182 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10528ms
2014-07-13 18:19:52,182 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,182 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10529ms
2014-07-13 18:19:52,182 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,183 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8773ms
2014-07-13 18:19:52,183 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,189 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8785ms
2014-07-13 18:19:52,189 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,189 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8837ms
2014-07-13 18:19:52,189 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,191 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8845ms
2014-07-13 18:19:52,191 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,197 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8858ms
2014-07-13 18:19:52,197 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,197 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8870ms
2014-07-13 18:19:52,197 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,197 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8877ms
2014-07-13 18:19:52,197 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,199 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8928ms
2014-07-13 18:19:52,199 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,200 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8944ms
2014-07-13 18:19:52,200 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,208 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9012ms
2014-07-13 18:19:52,209 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,209 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9031ms
2014-07-13 18:19:52,209 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,209 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9071ms
2014-07-13 18:19:52,209 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,209 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9116ms
2014-07-13 18:19:52,209 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,217 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9169ms
2014-07-13 18:19:52,217 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,225 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9205ms
2014-07-13 18:19:52,225 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,225 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9257ms
2014-07-13 18:19:52,225 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,225 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9302ms
2014-07-13 18:19:52,225 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,225 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9324ms
2014-07-13 18:19:52,225 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,233 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9377ms
2014-07-13 18:19:52,233 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,233 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9388ms
2014-07-13 18:19:52,233 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,233 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9407ms
2014-07-13 18:19:52,233 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,238 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9447ms
2014-07-13 18:19:52,238 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,238 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9457ms
2014-07-13 18:19:52,238 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,244 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9470ms
2014-07-13 18:19:52,244 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,245 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9494ms
2014-07-13 18:19:52,245 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,245 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9507ms
2014-07-13 18:19:52,245 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,245 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9531ms
2014-07-13 18:19:52,245 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,247 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9567ms
2014-07-13 18:19:52,247 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,248 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9577ms
2014-07-13 18:19:52,248 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:19:52,376 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10735,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781640,"queuetimems":0,"class":"HRegionServer","responsesize":9593,"method":"Multi"}
2014-07-13 18:19:52,732 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11118,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781614,"queuetimems":0,"class":"HRegionServer","responsesize":12609,"method":"Multi"}
2014-07-13 18:19:52,750 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11177,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781572,"queuetimems":0,"class":"HRegionServer","responsesize":3917,"method":"Multi"}
2014-07-13 18:19:52,750 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10803,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781946,"queuetimems":0,"class":"HRegionServer","responsesize":10191,"method":"Multi"}
2014-07-13 18:19:52,750 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10796,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781954,"queuetimems":1,"class":"HRegionServer","responsesize":3440,"method":"Multi"}
2014-07-13 18:19:52,750 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782046,"queuetimems":0,"class":"HRegionServer","responsesize":8856,"method":"Multi"}
2014-07-13 18:19:52,750 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781431,"queuetimems":0,"class":"HRegionServer","responsesize":15419,"method":"Multi"}
2014-07-13 18:19:52,750 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10763,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781986,"queuetimems":0,"class":"HRegionServer","responsesize":9527,"method":"Multi"}
2014-07-13 18:19:53,544 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782074,"queuetimems":0,"class":"HRegionServer","responsesize":9065,"method":"Multi"}
2014-07-13 18:19:53,548 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11712,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781836,"queuetimems":1,"class":"HRegionServer","responsesize":6437,"method":"Multi"}
2014-07-13 18:19:53,544 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11625,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781918,"queuetimems":0,"class":"HRegionServer","responsesize":14589,"method":"Multi"}
2014-07-13 18:19:53,623 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10297,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783326,"queuetimems":1,"class":"HRegionServer","responsesize":3934,"method":"Multi"}
2014-07-13 18:19:53,623 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10874,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782749,"queuetimems":0,"class":"HRegionServer","responsesize":4474,"method":"Multi"}
2014-07-13 18:19:53,704 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:53,746 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56786 synced till here 56769
2014-07-13 18:19:53,870 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12077,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781792,"queuetimems":1,"class":"HRegionServer","responsesize":6720,"method":"Multi"}
2014-07-13 18:19:53,870 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12099,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781771,"queuetimems":0,"class":"HRegionServer","responsesize":8465,"method":"Multi"}
2014-07-13 18:19:53,871 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12123,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781747,"queuetimems":1,"class":"HRegionServer","responsesize":11154,"method":"Multi"}
2014-07-13 18:19:53,972 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300781696 with entries=95, filesize=77.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300793704
2014-07-13 18:19:54,011 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11155,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782855,"queuetimems":0,"class":"HRegionServer","responsesize":4401,"method":"Multi"}
2014-07-13 18:19:54,012 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11047,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782965,"queuetimems":1,"class":"HRegionServer","responsesize":12847,"method":"Multi"}
2014-07-13 18:19:54,177 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11002,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783174,"queuetimems":0,"class":"HRegionServer","responsesize":11569,"method":"Multi"}
2014-07-13 18:19:54,177 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782736,"queuetimems":0,"class":"HRegionServer","responsesize":8349,"method":"Multi"}
2014-07-13 18:19:54,177 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12609,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781568,"queuetimems":0,"class":"HRegionServer","responsesize":16532,"method":"Multi"}
2014-07-13 18:19:54,177 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11511,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782666,"queuetimems":0,"class":"HRegionServer","responsesize":14379,"method":"Multi"}
2014-07-13 18:19:54,177 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10860,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783317,"queuetimems":1,"class":"HRegionServer","responsesize":13835,"method":"Multi"}
2014-07-13 18:19:54,185 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11395,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782790,"queuetimems":0,"class":"HRegionServer","responsesize":3242,"method":"Multi"}
2014-07-13 18:19:54,334 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11510,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782824,"queuetimems":1,"class":"HRegionServer","responsesize":7734,"method":"Multi"}
2014-07-13 18:19:54,335 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11414,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782921,"queuetimems":0,"class":"HRegionServer","responsesize":7308,"method":"Multi"}
2014-07-13 18:19:54,336 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11245,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783090,"queuetimems":0,"class":"HRegionServer","responsesize":11160,"method":"Multi"}
2014-07-13 18:19:54,334 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12518,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781816,"queuetimems":0,"class":"HRegionServer","responsesize":7823,"method":"Multi"}
2014-07-13 18:19:54,337 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12318,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782019,"queuetimems":0,"class":"HRegionServer","responsesize":10461,"method":"Multi"}
2014-07-13 18:19:54,334 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12463,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781871,"queuetimems":0,"class":"HRegionServer","responsesize":11099,"method":"Multi"}
2014-07-13 18:19:54,334 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11288,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783046,"queuetimems":0,"class":"HRegionServer","responsesize":9124,"method":"Multi"}
2014-07-13 18:19:54,334 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782114,"queuetimems":0,"class":"HRegionServer","responsesize":12311,"method":"Multi"}
2014-07-13 18:19:54,337 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11439,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782898,"queuetimems":0,"class":"HRegionServer","responsesize":12375,"method":"Multi"}
2014-07-13 18:19:54,356 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11018,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783338,"queuetimems":0,"class":"HRegionServer","responsesize":4897,"method":"Multi"}
2014-07-13 18:19:54,361 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783345,"queuetimems":0,"class":"HRegionServer","responsesize":4542,"method":"Multi"}
2014-07-13 18:19:54,362 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782773,"queuetimems":0,"class":"HRegionServer","responsesize":6492,"method":"Multi"}
2014-07-13 18:19:54,356 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10954,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783402,"queuetimems":0,"class":"HRegionServer","responsesize":7879,"method":"Multi"}
2014-07-13 18:19:54,362 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11092,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783269,"queuetimems":0,"class":"HRegionServer","responsesize":6518,"method":"Multi"}
2014-07-13 18:19:54,373 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11530,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782843,"queuetimems":0,"class":"HRegionServer","responsesize":7796,"method":"Multi"}
2014-07-13 18:19:54,373 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12663,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781710,"queuetimems":1,"class":"HRegionServer","responsesize":10502,"method":"Multi"}
2014-07-13 18:19:54,381 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11187,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783194,"queuetimems":0,"class":"HRegionServer","responsesize":7633,"method":"Multi"}
2014-07-13 18:19:54,381 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12705,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300781676,"queuetimems":0,"class":"HRegionServer","responsesize":11524,"method":"Multi"}
2014-07-13 18:19:54,388 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11608,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782780,"queuetimems":0,"class":"HRegionServer","responsesize":2756,"method":"Multi"}
2014-07-13 18:19:54,393 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11681,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782712,"queuetimems":0,"class":"HRegionServer","responsesize":9632,"method":"Multi"}
2014-07-13 18:19:54,394 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10985,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783409,"queuetimems":0,"class":"HRegionServer","responsesize":2889,"method":"Multi"}
2014-07-13 18:19:54,401 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11049,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783351,"queuetimems":0,"class":"HRegionServer","responsesize":4262,"method":"Multi"}
2014-07-13 18:19:55,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:55,604 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56886 synced till here 56864
2014-07-13 18:19:56,061 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300793704 with entries=100, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300795539
2014-07-13 18:19:56,306 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13627,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300782678,"queuetimems":0,"class":"HRegionServer","responsesize":16242,"method":"Multi"}
2014-07-13 18:19:57,499 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14363,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783136,"queuetimems":0,"class":"HRegionServer","responsesize":15351,"method":"Multi"}
2014-07-13 18:19:57,844 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:57,845 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14590,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783254,"queuetimems":0,"class":"HRegionServer","responsesize":18236,"method":"Multi"}
2014-07-13 18:19:57,846 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14827,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300783018,"queuetimems":0,"class":"HRegionServer","responsesize":15601,"method":"Multi"}
2014-07-13 18:19:57,873 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:19:57,873 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:19:57,874 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-13 18:19:57,954 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 56981 synced till here 56959
2014-07-13 18:19:58,113 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:19:58,113 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files, but is 1.2g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:19:58,113 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. due to global heap pressure
2014-07-13 18:19:58,114 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 1.2g
2014-07-13 18:19:58,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300795539 with entries=95, filesize=85.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300797844
2014-07-13 18:19:59,727 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:19:59,815 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57093 synced till here 57068
2014-07-13 18:20:00,057 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300797844 with entries=112, filesize=94.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300799728
2014-07-13 18:20:01,219 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,220 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,225 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,225 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,225 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,226 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,226 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,227 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,229 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,234 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,237 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,241 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,243 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,243 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,243 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,313 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,315 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,315 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,316 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,316 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,316 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,317 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,318 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,318 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:20:01,318 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,319 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,320 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,320 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,320 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,321 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,321 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,323 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,323 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,324 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,325 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,326 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,327 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,327 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,328 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,329 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,379 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,379 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,379 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,380 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,381 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,383 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,384 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,385 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,385 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,405 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,407 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:01,873 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/8e6c7a88a970433a8246d268316906bc as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/8e6c7a88a970433a8246d268316906bc
2014-07-13 18:20:01,957 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:20:02,143 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/1d3957fc24904a668c12f647dae376e8, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/1d3957fc24904a668c12f647dae376e8
2014-07-13 18:20:02,149 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ba3ca49d306f4d73bef6bd8cf2b41b33, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ba3ca49d306f4d73bef6bd8cf2b41b33
2014-07-13 18:20:02,156 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0d6677ec5428490dbf536b590cef0232, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/0d6677ec5428490dbf536b590cef0232
2014-07-13 18:20:02,156 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into 8e6c7a88a970433a8246d268316906bc(size=148.9m), total size for store is 3.2g. This selection was in queue for 0sec, and took 29sec to execute.
2014-07-13 18:20:02,156 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=3, fileSize=158.6m, priority=-1, time=254680342970459; duration=29sec
2014-07-13 18:20:02,157 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-13 18:20:02,157 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:20:02,158 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 315931398 starting at candidate #17 after considering 124 permutations with 101 in ratio
2014-07-13 18:20:02,158 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:20:02,158 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:20:02,158 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=301.3m
2014-07-13 18:20:02,158 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/79b9b60d699d49fdadfc0107ddc39f00, keycount=89496, bloomtype=ROW, size=63.7m, encoding=NONE, seqNum=12583
2014-07-13 18:20:02,159 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/70c300ebc3e4471d9fe76541d7ed372d, keycount=223302, bloomtype=ROW, size=159.0m, encoding=NONE, seqNum=13346
2014-07-13 18:20:02,159 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77847bd192d34914a915d66aef03036f, keycount=84218, bloomtype=ROW, size=60.0m, encoding=NONE, seqNum=13700
2014-07-13 18:20:02,159 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dbfe0aa424714264b281d553cdbfc9c0, keycount=26130, bloomtype=ROW, size=18.6m, encoding=NONE, seqNum=13755
2014-07-13 18:20:02,235 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:20:02,305 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=13833, memsize=766.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/cbe9f0642e124168b58011c80f728481
2014-07-13 18:20:02,320 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/cbe9f0642e124168b58011c80f728481 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/cbe9f0642e124168b58011c80f728481
2014-07-13 18:20:02,336 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/cbe9f0642e124168b58011c80f728481, entries=2789620, sequenceid=13833, filesize=198.7m
2014-07-13 18:20:02,336 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.3g/1401703040, currentsize=517.9m/543108240 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 39022ms, sequenceid=13833, compaction requested=true
2014-07-13 18:20:02,337 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:153), split_queue=0, merge_queue=0
2014-07-13 18:20:02,337 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 930ms
2014-07-13 18:20:02,337 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,337 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 932ms
2014-07-13 18:20:02,337 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,337 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 952ms
2014-07-13 18:20:02,337 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,337 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 952ms
2014-07-13 18:20:02,337 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,338 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 954ms
2014-07-13 18:20:02,338 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,338 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 955ms
2014-07-13 18:20:02,338 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,341 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 960ms
2014-07-13 18:20:02,341 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,342 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 962ms
2014-07-13 18:20:02,342 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,342 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 963ms
2014-07-13 18:20:02,342 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,342 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 963ms
2014-07-13 18:20:02,342 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,345 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 966ms
2014-07-13 18:20:02,345 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,345 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1016ms
2014-07-13 18:20:02,345 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,345 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1017ms
2014-07-13 18:20:02,345 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,357 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1030ms
2014-07-13 18:20:02,357 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,357 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1031ms
2014-07-13 18:20:02,357 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,365 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1039ms
2014-07-13 18:20:02,365 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,365 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1040ms
2014-07-13 18:20:02,365 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,365 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1041ms
2014-07-13 18:20:02,365 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,365 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1042ms
2014-07-13 18:20:02,365 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,365 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1043ms
2014-07-13 18:20:02,365 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,365 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1044ms
2014-07-13 18:20:02,365 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,366 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1045ms
2014-07-13 18:20:02,366 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,366 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1046ms
2014-07-13 18:20:02,366 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,367 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1047ms
2014-07-13 18:20:02,367 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,368 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1047ms
2014-07-13 18:20:02,368 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,370 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1051ms
2014-07-13 18:20:02,370 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,370 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1052ms
2014-07-13 18:20:02,370 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,371 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1052ms
2014-07-13 18:20:02,371 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,371 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1054ms
2014-07-13 18:20:02,371 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,371 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1055ms
2014-07-13 18:20:02,371 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,371 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1055ms
2014-07-13 18:20:02,371 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,377 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1061ms
2014-07-13 18:20:02,377 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,377 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1062ms
2014-07-13 18:20:02,377 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,377 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1062ms
2014-07-13 18:20:02,377 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,377 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1064ms
2014-07-13 18:20:02,377 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,377 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1151ms
2014-07-13 18:20:02,377 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,379 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1159ms
2014-07-13 18:20:02,379 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,385 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1142ms
2014-07-13 18:20:02,385 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,385 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1144ms
2014-07-13 18:20:02,385 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,385 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1148ms
2014-07-13 18:20:02,385 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,393 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1159ms
2014-07-13 18:20:02,393 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,397 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1168ms
2014-07-13 18:20:02,397 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,397 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1170ms
2014-07-13 18:20:02,397 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,397 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1171ms
2014-07-13 18:20:02,397 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,397 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1171ms
2014-07-13 18:20:02,397 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,405 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1180ms
2014-07-13 18:20:02,405 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,405 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1180ms
2014-07-13 18:20:02,405 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,405 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1181ms
2014-07-13 18:20:02,405 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,413 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1193ms
2014-07-13 18:20:02,413 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,415 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1196ms
2014-07-13 18:20:02,415 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:02,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:02,639 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57188 synced till here 57168
2014-07-13 18:20:02,778 DEBUG [RpcServer.handler=9,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:20:02,779 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 521.0m
2014-07-13 18:20:02,800 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300799728 with entries=95, filesize=79.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300802573
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300673421
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300674719
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300676735
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300678180
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300679607
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300680804
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300681480
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300683171
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300684330
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300685878
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300687183
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300688649
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300689954
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300691495
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300693273
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300695185
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300696614
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300698046
2014-07-13 18:20:02,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300700900
2014-07-13 18:20:02,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300702919
2014-07-13 18:20:02,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300704594
2014-07-13 18:20:02,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300706317
2014-07-13 18:20:02,802 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300708135
2014-07-13 18:20:03,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:03,968 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:20:04,062 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57295 synced till here 57277
2014-07-13 18:20:04,256 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300802573 with entries=107, filesize=95.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300803967
2014-07-13 18:20:06,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:06,255 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57412 synced till here 57394
2014-07-13 18:20:07,208 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300803967 with entries=117, filesize=99.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300806184
2014-07-13 18:20:07,836 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:07,854 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57488 synced till here 57485
2014-07-13 18:20:08,119 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300806184 with entries=76, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300807836
2014-07-13 18:20:10,682 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:10,862 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57580 synced till here 57564
2014-07-13 18:20:11,591 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300807836 with entries=92, filesize=78.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300810682
2014-07-13 18:20:12,411 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:12,564 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57703 synced till here 57701
2014-07-13 18:20:12,604 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300810682 with entries=123, filesize=78.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300812411
2014-07-13 18:20:13,879 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:14,268 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 57848 synced till here 57847
2014-07-13 18:20:14,284 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300812411 with entries=145, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300813879
2014-07-13 18:20:15,561 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:15,589 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300813879 with entries=91, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300815562
2014-07-13 18:20:17,230 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:17,524 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58015 synced till here 58010
2014-07-13 18:20:17,581 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300815562 with entries=76, filesize=67.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300817231
2014-07-13 18:20:18,622 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:18,652 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:18,698 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:18,714 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:18,783 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14211, memsize=342.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a9db301ed9f44040b940eaee67c8629e
2014-07-13 18:20:18,797 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/a9db301ed9f44040b940eaee67c8629e as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9db301ed9f44040b940eaee67c8629e
2014-07-13 18:20:18,806 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:18,813 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9db301ed9f44040b940eaee67c8629e, entries=1245700, sequenceid=14211, filesize=88.7m
2014-07-13 18:20:18,813 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~550.7m/577502880, currentsize=274.2m/287519600 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 16034ms, sequenceid=14211, compaction requested=true
2014-07-13 18:20:18,813 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:154), split_queue=0, merge_queue=0
2014-07-13 18:20:18,814 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8ms
2014-07-13 18:20:18,814 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:18,814 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 100ms
2014-07-13 18:20:18,814 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:18,814 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 116ms
2014-07-13 18:20:18,814 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:18,817 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 165ms
2014-07-13 18:20:18,817 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:18,817 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 196ms
2014-07-13 18:20:18,817 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:18,914 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:20:18,915 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:20:18,915 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:155), split_queue=0, merge_queue=0
2014-07-13 18:20:18,954 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:19,169 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300817231 with entries=75, filesize=62.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300818954
2014-07-13 18:20:20,833 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:20,860 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58153 synced till here 58152
2014-07-13 18:20:20,882 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300818954 with entries=63, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300820834
2014-07-13 18:20:22,356 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:22,379 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58225 synced till here 58220
2014-07-13 18:20:22,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300820834 with entries=72, filesize=69.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300822357
2014-07-13 18:20:23,447 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:20:23,447 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files, but is 1021.0m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:20:23,447 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. due to global heap pressure
2014-07-13 18:20:23,447 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 1021.0m
2014-07-13 18:20:23,579 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:23,828 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300822357 with entries=80, filesize=72.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300823579
2014-07-13 18:20:24,577 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:20:24,909 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:24,933 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58370 synced till here 58368
2014-07-13 18:20:24,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300823579 with entries=65, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300824909
2014-07-13 18:20:25,605 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,612 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,618 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,632 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,650 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,665 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,691 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,698 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,700 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,724 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,732 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,769 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,771 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,824 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:25,884 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:26,007 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:26,037 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,003 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,031 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,093 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,114 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,150 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,152 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,164 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,203 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,256 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,284 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,315 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,356 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,382 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,394 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,438 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,464 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,529 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:27,562 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:28,418 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:28,444 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:28,477 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:28,507 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,121 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,135 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,138 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,166 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,196 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,222 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,237 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,249 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,265 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,297 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:29,324 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:30,605 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,613 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:30,619 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,632 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,650 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,665 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,692 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:30,699 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,701 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,727 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 18:20:30,729 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14445, memsize=649.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/7d93a0dbe947439f91ac2f0c08d92988
2014-07-13 18:20:30,733 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:30,745 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/7d93a0dbe947439f91ac2f0c08d92988 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/7d93a0dbe947439f91ac2f0c08d92988
2014-07-13 18:20:30,759 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/7d93a0dbe947439f91ac2f0c08d92988, entries=2363580, sequenceid=14445, filesize=168.3m
2014-07-13 18:20:30,759 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1351992960, currentsize=510.1m/534857600 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 32645ms, sequenceid=14445, compaction requested=true
2014-07-13 18:20:30,759 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:156), split_queue=0, merge_queue=0
2014-07-13 18:20:30,760 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5028ms
2014-07-13 18:20:30,760 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,760 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5036ms
2014-07-13 18:20:30,760 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,760 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5060ms
2014-07-13 18:20:30,760 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,760 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5062ms
2014-07-13 18:20:30,760 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,760 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5069ms
2014-07-13 18:20:30,760 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,760 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5095ms
2014-07-13 18:20:30,761 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,761 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5111ms
2014-07-13 18:20:30,761 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,765 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5133ms
2014-07-13 18:20:30,765 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,765 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5147ms
2014-07-13 18:20:30,765 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,769 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5157ms
2014-07-13 18:20:30,769 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,769 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5164ms
2014-07-13 18:20:30,769 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,769 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1445ms
2014-07-13 18:20:30,769 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,770 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1473ms
2014-07-13 18:20:30,770 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,772 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:30,773 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,773 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1508ms
2014-07-13 18:20:30,773 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,773 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1524ms
2014-07-13 18:20:30,773 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,785 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1548ms
2014-07-13 18:20:30,785 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,785 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1563ms
2014-07-13 18:20:30,785 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,791 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1595ms
2014-07-13 18:20:30,791 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,791 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1625ms
2014-07-13 18:20:30,791 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,791 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1653ms
2014-07-13 18:20:30,791 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,791 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1656ms
2014-07-13 18:20:30,791 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,792 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1671ms
2014-07-13 18:20:30,792 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,792 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2285ms
2014-07-13 18:20:30,792 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,792 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2315ms
2014-07-13 18:20:30,793 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,799 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2355ms
2014-07-13 18:20:30,799 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,800 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2382ms
2014-07-13 18:20:30,800 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,809 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3247ms
2014-07-13 18:20:30,809 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,809 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3280ms
2014-07-13 18:20:30,809 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,809 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3345ms
2014-07-13 18:20:30,809 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,810 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3372ms
2014-07-13 18:20:30,810 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,810 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3416ms
2014-07-13 18:20:30,810 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,811 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3428ms
2014-07-13 18:20:30,811 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,811 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3455ms
2014-07-13 18:20:30,811 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,814 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3498ms
2014-07-13 18:20:30,814 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,814 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3530ms
2014-07-13 18:20:30,814 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,815 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3558ms
2014-07-13 18:20:30,815 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,818 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3614ms
2014-07-13 18:20:30,818 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,819 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3654ms
2014-07-13 18:20:30,819 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,824 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3671ms
2014-07-13 18:20:30,824 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,824 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:30,825 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,827 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3675ms
2014-07-13 18:20:30,827 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,832 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3718ms
2014-07-13 18:20:30,832 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,833 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3740ms
2014-07-13 18:20:30,833 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,839 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3808ms
2014-07-13 18:20:30,840 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,840 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3837ms
2014-07-13 18:20:30,840 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,841 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4803ms
2014-07-13 18:20:30,841 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,841 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4834ms
2014-07-13 18:20:30,841 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,842 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4957ms
2014-07-13 18:20:30,842 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,843 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5074ms
2014-07-13 18:20:30,843 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:30,914 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:20:30,914 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:20:30,915 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:157), split_queue=0, merge_queue=0
2014-07-13 18:20:32,475 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:32,496 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58475 synced till here 58453
2014-07-13 18:20:32,753 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300824909 with entries=105, filesize=94.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300832476
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300709774
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300719833
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300722825
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300724717
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300726797
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300729123
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300735865
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300737224
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300739222
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300741479
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300743568
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300744824
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300745745
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300747252
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300748633
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300749908
2014-07-13 18:20:32,754 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300751992
2014-07-13 18:20:34,613 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:34,751 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58553 synced till here 58544
2014-07-13 18:20:34,894 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300832476 with entries=78, filesize=70.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300834614
2014-07-13 18:20:36,649 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:36,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58665 synced till here 58623
2014-07-13 18:20:37,167 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300834614 with entries=112, filesize=105.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300836650
2014-07-13 18:20:39,117 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:40,300 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58785 synced till here 58766
2014-07-13 18:20:40,479 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300836650 with entries=120, filesize=101.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300839118
2014-07-13 18:20:42,337 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:42,350 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 58892 synced till here 58864
2014-07-13 18:20:42,620 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300839118 with entries=107, filesize=103.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300842338
2014-07-13 18:20:44,582 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:44,722 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59004 synced till here 58971
2014-07-13 18:20:45,103 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300842338 with entries=112, filesize=89.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300844582
2014-07-13 18:20:46,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:46,957 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:20:46,958 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files, but is 964.4m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:20:46,958 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. due to global heap pressure
2014-07-13 18:20:46,958 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 964.4m
2014-07-13 18:20:48,237 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59152 synced till here 59112
2014-07-13 18:20:48,603 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300844582 with entries=148, filesize=138.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300846929
2014-07-13 18:20:49,252 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,254 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,256 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,256 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,259 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,260 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,261 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,261 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,262 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,262 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,262 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,264 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,264 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,269 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,269 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,270 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,271 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,273 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,275 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,276 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,283 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,283 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,285 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,285 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:49,321 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,073 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,073 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,073 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,074 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,105 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,107 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,107 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,112 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:50,114 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,118 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,124 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,125 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,137 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59230 synced till here 59224
2014-07-13 18:20:50,178 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,180 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,181 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,182 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,182 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,184 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,194 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300846929 with entries=78, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300850112
2014-07-13 18:20:50,227 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,227 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,246 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,283 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,284 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,284 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,284 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,285 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:20:50,364 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:20:54,254 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:20:54,255 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,257 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,257 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,260 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,260 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,262 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,262 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,262 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,262 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:20:54,262 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,264 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,265 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,270 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,270 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,270 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,271 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,273 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,276 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,277 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,283 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:54,283 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,285 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,285 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:54,322 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,073 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5746ms
2014-07-13 18:20:55,074 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 18:20:55,074 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5015ms
2014-07-13 18:20:55,074 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5017ms
2014-07-13 18:20:55,106 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,107 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,108 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,114 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,118 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,124 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,125 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,178 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,181 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,181 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,182 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,183 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,185 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,227 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,227 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,247 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,284 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,284 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,285 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:55,285 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:20:55,285 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:20:56,260 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14443, memsize=541.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/19a4fe9c651e46de89825fe526b5e811
2014-07-13 18:20:56,276 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/19a4fe9c651e46de89825fe526b5e811 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/19a4fe9c651e46de89825fe526b5e811
2014-07-13 18:20:56,291 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/19a4fe9c651e46de89825fe526b5e811, entries=1971760, sequenceid=14443, filesize=140.4m
2014-07-13 18:20:56,291 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.0g/1075966560, currentsize=481.5m/504933920 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 32844ms, sequenceid=14443, compaction requested=true
2014-07-13 18:20:56,291 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:158), split_queue=0, merge_queue=0
2014-07-13 18:20:56,292 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6006ms
2014-07-13 18:20:56,292 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,292 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6008ms
2014-07-13 18:20:56,292 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,292 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6008ms
2014-07-13 18:20:56,292 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,292 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6008ms
2014-07-13 18:20:56,292 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,292 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6009ms
2014-07-13 18:20:56,292 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,292 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6046ms
2014-07-13 18:20:56,292 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,293 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6066ms
2014-07-13 18:20:56,293 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,293 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6066ms
2014-07-13 18:20:56,293 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,293 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6109ms
2014-07-13 18:20:56,293 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,293 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6111ms
2014-07-13 18:20:56,293 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,297 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6115ms
2014-07-13 18:20:56,297 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,297 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6116ms
2014-07-13 18:20:56,297 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,297 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6117ms
2014-07-13 18:20:56,297 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,298 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6120ms
2014-07-13 18:20:56,298 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,299 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6174ms
2014-07-13 18:20:56,299 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,299 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6175ms
2014-07-13 18:20:56,299 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,299 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6181ms
2014-07-13 18:20:56,299 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,299 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6185ms
2014-07-13 18:20:56,299 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,300 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6193ms
2014-07-13 18:20:56,300 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,313 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6206ms
2014-07-13 18:20:56,313 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,313 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6208ms
2014-07-13 18:20:56,313 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,321 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6264ms
2014-07-13 18:20:56,321 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,321 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6262ms
2014-07-13 18:20:56,321 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,321 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6251ms
2014-07-13 18:20:56,321 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,321 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6994ms
2014-07-13 18:20:56,321 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,321 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7000ms
2014-07-13 18:20:56,321 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,323 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7038ms
2014-07-13 18:20:56,323 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,329 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7044ms
2014-07-13 18:20:56,329 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,329 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7046ms
2014-07-13 18:20:56,329 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,329 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7047ms
2014-07-13 18:20:56,329 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,341 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7065ms
2014-07-13 18:20:56,341 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,341 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7066ms
2014-07-13 18:20:56,341 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,341 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7068ms
2014-07-13 18:20:56,341 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,342 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7071ms
2014-07-13 18:20:56,342 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,342 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7073ms
2014-07-13 18:20:56,342 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,343 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7072ms
2014-07-13 18:20:56,343 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,343 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7074ms
2014-07-13 18:20:56,343 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,344 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7080ms
2014-07-13 18:20:56,344 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,345 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7081ms
2014-07-13 18:20:56,345 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,353 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7092ms
2014-07-13 18:20:56,353 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,353 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7093ms
2014-07-13 18:20:56,353 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,365 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7103ms
2014-07-13 18:20:56,365 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,369 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7108ms
2014-07-13 18:20:56,369 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,377 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7116ms
2014-07-13 18:20:56,377 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,377 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7117ms
2014-07-13 18:20:56,377 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,382 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7123ms
2014-07-13 18:20:56,382 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,388 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7132ms
2014-07-13 18:20:56,388 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,388 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7132ms
2014-07-13 18:20:56,388 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,389 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7135ms
2014-07-13 18:20:56,389 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,393 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7141ms
2014-07-13 18:20:56,393 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:20:56,868 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:20:56,868 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:20:56,868 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:159), split_queue=0, merge_queue=0
2014-07-13 18:20:57,084 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:57,087 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10079,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300847007,"queuetimems":2858,"class":"HRegionServer","responsesize":15635,"method":"Multi"}
2014-07-13 18:20:57,719 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59311 synced till here 59293
2014-07-13 18:20:57,870 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10919,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300846950,"queuetimems":4119,"class":"HRegionServer","responsesize":14413,"method":"Multi"}
2014-07-13 18:20:57,949 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300850112 with entries=81, filesize=76.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300857084
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300753229
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300761108
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300763038
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300765219
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300767227
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300768961
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300770539
2014-07-13 18:20:57,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300771994
2014-07-13 18:20:58,681 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:20:58,779 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59424 synced till here 59393
2014-07-13 18:20:59,451 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10170,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300849281,"queuetimems":1953,"class":"HRegionServer","responsesize":14413,"method":"Multi"}
2014-07-13 18:20:59,587 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300857084 with entries=113, filesize=99.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300858681
2014-07-13 18:21:00,234 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:00,254 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59509 synced till here 59500
2014-07-13 18:21:00,334 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300858681 with entries=85, filesize=75.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300860235
2014-07-13 18:21:02,184 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/7403256406014ac298e28c0cadf155f9 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/7403256406014ac298e28c0cadf155f9
2014-07-13 18:21:02,209 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:21:02,230 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/79b9b60d699d49fdadfc0107ddc39f00, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/79b9b60d699d49fdadfc0107ddc39f00
2014-07-13 18:21:02,233 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/70c300ebc3e4471d9fe76541d7ed372d, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/70c300ebc3e4471d9fe76541d7ed372d
2014-07-13 18:21:02,238 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77847bd192d34914a915d66aef03036f, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/77847bd192d34914a915d66aef03036f
2014-07-13 18:21:02,241 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dbfe0aa424714264b281d553cdbfc9c0, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/dbfe0aa424714264b281d553cdbfc9c0
2014-07-13 18:21:02,241 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into 7403256406014ac298e28c0cadf155f9(size=284.0m), total size for store is 3.5g. This selection was in queue for 0sec, and took 1mins, 0sec to execute.
2014-07-13 18:21:02,241 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=4, fileSize=301.3m, priority=-1, time=254709585302575; duration=1mins, 0sec
2014-07-13 18:21:02,242 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:159), split_queue=0, merge_queue=0
2014-07-13 18:21:02,242 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:21:02,243 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 5 files of size 408168955 starting at candidate #10 after considering 132 permutations with 115 in ratio
2014-07-13 18:21:02,243 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating minor compaction
2014-07-13 18:21:02,244 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:21:02,244 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 5 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=389.3m
2014-07-13 18:21:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8fc272f699824310a1bfdc35848b40ea, keycount=106602, bloomtype=ROW, size=75.9m, encoding=NONE, seqNum=8878
2014-07-13 18:21:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c75f5e5bf4354725a9735dab20603ff4, keycount=93951, bloomtype=ROW, size=67.0m, encoding=NONE, seqNum=9101
2014-07-13 18:21:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3823c2c95462416f987a16a6c8350423, keycount=170023, bloomtype=ROW, size=121.0m, encoding=NONE, seqNum=9637
2014-07-13 18:21:02,244 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/99ac3f04f2554082b7809f610bc593dd, keycount=80027, bloomtype=ROW, size=57.0m, encoding=NONE, seqNum=9878
2014-07-13 18:21:02,245 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/866af7036b03493f8c22706d1aec20f8, keycount=96066, bloomtype=ROW, size=68.4m, encoding=NONE, seqNum=10153
2014-07-13 18:21:02,268 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 644.1m
2014-07-13 18:21:02,356 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:21:02,968 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:21:07,532 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:07,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59576 synced till here 59575
2014-07-13 18:21:07,569 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300860235 with entries=67, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300867533
2014-07-13 18:21:08,780 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14817, memsize=122.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/e6569c38471f4cf5a6db13763340944a
2014-07-13 18:21:08,812 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:08,819 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/e6569c38471f4cf5a6db13763340944a as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e6569c38471f4cf5a6db13763340944a
2014-07-13 18:21:08,873 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e6569c38471f4cf5a6db13763340944a, entries=445410, sequenceid=14817, filesize=31.7m
2014-07-13 18:21:08,874 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~644.1m/675386000, currentsize=48.5m/50893360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 6606ms, sequenceid=14817, compaction requested=true
2014-07-13 18:21:08,874 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:159), split_queue=0, merge_queue=0
2014-07-13 18:21:08,874 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 48.5m
2014-07-13 18:21:09,020 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:21:09,068 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59678 synced till here 59669
2014-07-13 18:21:09,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300867533 with entries=102, filesize=95.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300868813
2014-07-13 18:21:10,332 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14968, memsize=485.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/1f5f04fcbd3b47388bf3574eb6177858
2014-07-13 18:21:10,362 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/1f5f04fcbd3b47388bf3574eb6177858 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/1f5f04fcbd3b47388bf3574eb6177858
2014-07-13 18:21:10,379 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/1f5f04fcbd3b47388bf3574eb6177858, entries=1766970, sequenceid=14968, filesize=125.8m
2014-07-13 18:21:10,380 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~976.8m/1024199120, currentsize=203.7m/213556080 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 23422ms, sequenceid=14968, compaction requested=true
2014-07-13 18:21:10,380 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:160), split_queue=0, merge_queue=0
2014-07-13 18:21:10,737 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:11,413 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59825 synced till here 59816
2014-07-13 18:21:11,485 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300868813 with entries=147, filesize=96.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300870737
2014-07-13 18:21:11,485 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300773578
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300774925
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300776471
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300777779
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300779684
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300781696
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300793704
2014-07-13 18:21:11,486 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300795539
2014-07-13 18:21:12,116 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=14844, memsize=55.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/ef28881c66f34fcbb3db999fec0bf168
2014-07-13 18:21:12,130 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/ef28881c66f34fcbb3db999fec0bf168 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ef28881c66f34fcbb3db999fec0bf168
2014-07-13 18:21:12,143 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ef28881c66f34fcbb3db999fec0bf168, entries=200790, sequenceid=14844, filesize=14.3m
2014-07-13 18:21:12,143 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~55.1m/57825360, currentsize=81.3m/85200160 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 3269ms, sequenceid=14844, compaction requested=true
2014-07-13 18:21:12,144 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:161), split_queue=0, merge_queue=0
2014-07-13 18:21:12,385 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:12,406 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59894 synced till here 59893
2014-07-13 18:21:12,426 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300870737 with entries=69, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300872385
2014-07-13 18:21:13,054 DEBUG [RpcServer.handler=31,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:21:13,054 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:21:13,054 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:162), split_queue=0, merge_queue=0
2014-07-13 18:21:13,607 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:13,753 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 59964 synced till here 59962
2014-07-13 18:21:13,766 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300872385 with entries=70, filesize=72.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300873607
2014-07-13 18:21:15,095 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:15,142 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300873607 with entries=66, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300875095
2014-07-13 18:21:16,427 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:16,655 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60119 synced till here 60115
2014-07-13 18:21:16,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300875095 with entries=89, filesize=77.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300876427
2014-07-13 18:21:16,695 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:18,142 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:18,393 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60210 synced till here 60207
2014-07-13 18:21:18,422 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300876427 with entries=91, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300878142
2014-07-13 18:21:18,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:19,831 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:19,861 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60297 synced till here 60285
2014-07-13 18:21:19,969 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300878142 with entries=87, filesize=76.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300879832
2014-07-13 18:21:19,970 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:20,115 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:21:20,115 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:21:20,116 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:163), split_queue=0, merge_queue=0
2014-07-13 18:21:21,948 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:21,977 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60369 synced till here 60364
2014-07-13 18:21:22,029 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300879832 with entries=72, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300881949
2014-07-13 18:21:22,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:23,512 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:23,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60449 synced till here 60444
2014-07-13 18:21:23,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300881949 with entries=80, filesize=66.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300883513
2014-07-13 18:21:23,616 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:25,183 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:25,288 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60536 synced till here 60530
2014-07-13 18:21:25,317 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300883513 with entries=87, filesize=77.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300885184
2014-07-13 18:21:25,317 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:26,620 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:26,640 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60601 synced till here 60599
2014-07-13 18:21:26,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300885184 with entries=65, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300886621
2014-07-13 18:21:26,651 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:27,875 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:27,894 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60683 synced till here 60680
2014-07-13 18:21:27,915 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300886621 with entries=82, filesize=62.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300887876
2014-07-13 18:21:27,916 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:29,839 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:29,857 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:21:29,857 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files, but is 1.5g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:21:29,857 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. due to global heap pressure
2014-07-13 18:21:29,858 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.5g
2014-07-13 18:21:30,270 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 60833 synced till here 60819
2014-07-13 18:21:30,423 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300887876 with entries=150, filesize=121.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300889840
2014-07-13 18:21:30,424 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): c8c427e222de992c0f6302092c0a1292
2014-07-13 18:21:30,484 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:21:30,484 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files, but is 1.3g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:21:30,484 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. due to global heap pressure
2014-07-13 18:21:30,484 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 1.3g
2014-07-13 18:21:31,845 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,846 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,846 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,846 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,846 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,848 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,877 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,930 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,949 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,950 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,954 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,974 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,974 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,979 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,995 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:21:31,998 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,998 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,999 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:31,999 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,001 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,001 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,001 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,002 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,003 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,004 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,004 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,010 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,012 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300889840 with entries=88, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300891996
2014-07-13 18:21:32,048 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,079 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,125 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,232 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,327 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,327 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,327 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,328 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,328 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,376 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,418 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,445 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,468 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,468 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,502 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,509 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,534 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:21:32,539 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,559 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,604 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,612 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,619 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:21:32,630 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,664 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:32,688 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:21:36,846 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,846 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,846 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,847 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,847 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,848 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,877 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,931 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,949 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,950 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,955 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,974 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,975 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,979 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,998 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:36,999 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:36,999 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,000 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:37,001 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,001 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,001 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,002 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,003 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,004 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,004 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,010 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,012 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,049 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:37,079 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,125 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,327 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5095ms
2014-07-13 18:21:37,327 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:21:37,327 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 18:21:37,328 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 18:21:37,328 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5034ms
2014-07-13 18:21:37,328 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5061ms
2014-07-13 18:21:37,376 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,418 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,446 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:37,468 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,469 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:37,502 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,509 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,539 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,559 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,605 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:21:37,612 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,630 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,664 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:37,688 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:21:41,846 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,847 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,847 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,847 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,847 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,848 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:41,877 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:41,931 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,949 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:41,950 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:41,955 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,974 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,975 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,979 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,999 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:41,999 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:42,000 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,001 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,002 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:42,002 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,003 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,004 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,004 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,004 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:42,005 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:42,011 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,013 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:42,049 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,079 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:42,126 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:21:42,671 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10006ms
2014-07-13 18:21:42,671 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10295ms
2014-07-13 18:21:42,672 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10439ms
2014-07-13 18:21:42,672 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10254ms
2014-07-13 18:21:42,672 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10227ms
2014-07-13 18:21:42,673 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10204ms
2014-07-13 18:21:42,673 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10205ms
2014-07-13 18:21:42,674 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10171ms
2014-07-13 18:21:42,674 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10165ms
2014-07-13 18:21:42,674 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10135ms
2014-07-13 18:21:42,674 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10115ms
2014-07-13 18:21:42,675 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10070ms
2014-07-13 18:21:42,675 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10063ms
2014-07-13 18:21:42,675 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10045ms
2014-07-13 18:21:42,676 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10350ms
2014-07-13 18:21:42,677 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10352ms
2014-07-13 18:21:42,677 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10353ms
2014-07-13 18:21:42,678 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10383ms
2014-07-13 18:21:42,678 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10411ms
2014-07-13 18:21:42,688 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:21:47,178 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15053ms
2014-07-13 18:21:47,179 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15180ms
2014-07-13 18:21:47,179 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15205ms
2014-07-13 18:21:47,180 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15331ms
2014-07-13 18:21:47,180 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15179ms
2014-07-13 18:21:47,180 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15179ms
2014-07-13 18:21:47,180 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15179ms
2014-07-13 18:21:47,180 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15178ms
2014-07-13 18:21:47,181 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15178ms
2014-07-13 18:21:47,181 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15177ms
2014-07-13 18:21:47,181 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15177ms
2014-07-13 18:21:47,182 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15172ms
2014-07-13 18:21:47,182 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15170ms
2014-07-13 18:21:47,182 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15134ms
2014-07-13 18:21:47,183 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15104ms
2014-07-13 18:21:47,183 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15338ms
2014-07-13 18:21:47,183 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15337ms
2014-07-13 18:21:47,183 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15337ms
2014-07-13 18:21:47,183 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15337ms
2014-07-13 18:21:47,184 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15338ms
2014-07-13 18:21:47,184 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15307ms
2014-07-13 18:21:47,185 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15254ms
2014-07-13 18:21:47,185 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15236ms
2014-07-13 18:21:47,186 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15236ms
2014-07-13 18:21:47,186 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15232ms
2014-07-13 18:21:47,186 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15213ms
2014-07-13 18:21:47,186 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15208ms
2014-07-13 18:21:47,187 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15188ms
2014-07-13 18:21:47,187 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15188ms
2014-07-13 18:21:47,187 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15189ms
2014-07-13 18:21:47,671 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15007ms
2014-07-13 18:21:47,671 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15295ms
2014-07-13 18:21:47,672 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15440ms
2014-07-13 18:21:47,672 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15254ms
2014-07-13 18:21:47,672 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15227ms
2014-07-13 18:21:47,673 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15205ms
2014-07-13 18:21:47,674 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15206ms
2014-07-13 18:21:47,674 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15172ms
2014-07-13 18:21:47,674 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15165ms
2014-07-13 18:21:47,674 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15135ms
2014-07-13 18:21:47,675 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15116ms
2014-07-13 18:21:47,675 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15071ms
2014-07-13 18:21:47,675 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15063ms
2014-07-13 18:21:47,675 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15045ms
2014-07-13 18:21:47,676 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15351ms
2014-07-13 18:21:47,677 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15353ms
2014-07-13 18:21:47,677 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15353ms
2014-07-13 18:21:47,678 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15384ms
2014-07-13 18:21:47,678 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15411ms
2014-07-13 18:21:47,689 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:21:52,179 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20054ms
2014-07-13 18:21:52,179 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20205ms
2014-07-13 18:21:52,179 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20180ms
2014-07-13 18:21:52,180 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20332ms
2014-07-13 18:21:52,180 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20179ms
2014-07-13 18:21:52,180 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20179ms
2014-07-13 18:21:52,180 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20179ms
2014-07-13 18:21:52,181 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20179ms
2014-07-13 18:21:52,181 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20178ms
2014-07-13 18:21:52,181 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20177ms
2014-07-13 18:21:52,182 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20178ms
2014-07-13 18:21:52,182 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20172ms
2014-07-13 18:21:52,183 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20171ms
2014-07-13 18:21:52,183 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20338ms
2014-07-13 18:21:52,183 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20104ms
2014-07-13 18:21:52,184 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20135ms
2014-07-13 18:21:52,184 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20338ms
2014-07-13 18:21:52,184 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20338ms
2014-07-13 18:21:52,184 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20338ms
2014-07-13 18:21:52,184 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20338ms
2014-07-13 18:21:52,184 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20307ms
2014-07-13 18:21:52,185 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20255ms
2014-07-13 18:21:52,186 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20237ms
2014-07-13 18:21:52,186 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20236ms
2014-07-13 18:21:52,187 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20214ms
2014-07-13 18:21:52,187 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20233ms
2014-07-13 18:21:52,187 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20188ms
2014-07-13 18:21:52,187 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20189ms
2014-07-13 18:21:52,188 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20210ms
2014-07-13 18:21:52,188 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20190ms
2014-07-13 18:21:52,672 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20008ms
2014-07-13 18:21:52,672 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20440ms
2014-07-13 18:21:52,673 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20296ms
2014-07-13 18:21:52,673 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20228ms
2014-07-13 18:21:52,673 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20255ms
2014-07-13 18:21:52,673 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20205ms
2014-07-13 18:21:52,674 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20206ms
2014-07-13 18:21:52,674 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20172ms
2014-07-13 18:21:52,674 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20165ms
2014-07-13 18:21:52,675 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20136ms
2014-07-13 18:21:52,675 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20116ms
2014-07-13 18:21:52,675 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20063ms
2014-07-13 18:21:52,676 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20072ms
2014-07-13 18:21:52,676 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20046ms
2014-07-13 18:21:52,676 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20351ms
2014-07-13 18:21:52,677 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20353ms
2014-07-13 18:21:52,678 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20354ms
2014-07-13 18:21:52,678 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20384ms
2014-07-13 18:21:52,678 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20411ms
2014-07-13 18:21:52,689 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:21:57,179 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25054ms
2014-07-13 18:21:57,180 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25181ms
2014-07-13 18:21:57,180 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25206ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25179ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25180ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25333ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25179ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25180ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25177ms
2014-07-13 18:21:57,181 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25178ms
2014-07-13 18:21:57,182 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25178ms
2014-07-13 18:21:57,183 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25173ms
2014-07-13 18:21:57,183 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25171ms
2014-07-13 18:21:57,183 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25338ms
2014-07-13 18:21:57,184 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25105ms
2014-07-13 18:21:57,184 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25136ms
2014-07-13 18:21:57,184 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25338ms
2014-07-13 18:21:57,185 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25339ms
2014-07-13 18:21:57,185 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25339ms
2014-07-13 18:21:57,185 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25339ms
2014-07-13 18:21:57,185 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25308ms
2014-07-13 18:21:57,185 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25255ms
2014-07-13 18:21:57,186 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25237ms
2014-07-13 18:21:57,187 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25237ms
2014-07-13 18:21:57,187 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25214ms
2014-07-13 18:21:57,188 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25233ms
2014-07-13 18:21:57,188 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25210ms
2014-07-13 18:21:57,189 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25190ms
2014-07-13 18:21:57,189 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25190ms
2014-07-13 18:21:57,190 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25192ms
2014-07-13 18:21:57,672 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25008ms
2014-07-13 18:21:57,673 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25441ms
2014-07-13 18:21:57,673 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25297ms
2014-07-13 18:21:57,674 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25256ms
2014-07-13 18:21:57,675 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25229ms
2014-07-13 18:21:57,675 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25166ms
2014-07-13 18:21:57,675 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25173ms
2014-07-13 18:21:57,675 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25207ms
2014-07-13 18:21:57,675 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25207ms
2014-07-13 18:21:57,675 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25136ms
2014-07-13 18:21:57,676 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25116ms
2014-07-13 18:21:57,676 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25064ms
2014-07-13 18:21:57,676 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25072ms
2014-07-13 18:21:57,676 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25046ms
2014-07-13 18:21:57,677 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25352ms
2014-07-13 18:21:57,677 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25353ms
2014-07-13 18:21:57,678 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25354ms
2014-07-13 18:21:57,678 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25384ms
2014-07-13 18:21:57,679 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25412ms
2014-07-13 18:21:57,689 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 25001ms
2014-07-13 18:21:59,058 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15369, memsize=708.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/e5280a9c5fbc4216ad180808d4ef51f0
2014-07-13 18:21:59,081 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/e5280a9c5fbc4216ad180808d4ef51f0 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e5280a9c5fbc4216ad180808d4ef51f0
2014-07-13 18:21:59,102 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/e5280a9c5fbc4216ad180808d4ef51f0, entries=2577930, sequenceid=15369, filesize=183.6m
2014-07-13 18:21:59,102 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.3g/1382664560, currentsize=16.4m/17170400 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 28618ms, sequenceid=15369, compaction requested=true
2014-07-13 18:21:59,103 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:164), split_queue=0, merge_queue=0
2014-07-13 18:21:59,103 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 100189ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:21:59,103 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26415ms
2014-07-13 18:21:59,103 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,103 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., flushing=true, writesEnabled=true
2014-07-13 18:21:59,103 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26836ms
2014-07-13 18:21:59,103 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,104 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26809ms
2014-07-13 18:21:59,104 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,104 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26780ms
2014-07-13 18:21:59,104 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,104 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26780ms
2014-07-13 18:21:59,104 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,104 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26779ms
2014-07-13 18:21:59,104 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,105 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26475ms
2014-07-13 18:21:59,105 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,109 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26504ms
2014-07-13 18:21:59,113 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,113 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26501ms
2014-07-13 18:21:59,113 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,113 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26554ms
2014-07-13 18:21:59,114 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,114 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26575ms
2014-07-13 18:21:59,114 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,114 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26646ms
2014-07-13 18:21:59,114 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,115 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26647ms
2014-07-13 18:21:59,115 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,116 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26614ms
2014-07-13 18:21:59,116 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,116 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26607ms
2014-07-13 18:21:59,116 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,116 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26671ms
2014-07-13 18:21:59,116 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,117 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26699ms
2014-07-13 18:21:59,117 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,118 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26741ms
2014-07-13 18:21:59,118 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,119 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26886ms
2014-07-13 18:21:59,120 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,121 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 26457ms
2014-07-13 18:21:59,121 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,121 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27123ms
2014-07-13 18:21:59,121 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,121 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27122ms
2014-07-13 18:21:59,121 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,122 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27123ms
2014-07-13 18:21:59,122 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,124 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27146ms
2014-07-13 18:21:59,125 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,125 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27171ms
2014-07-13 18:21:59,125 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,126 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27152ms
2014-07-13 18:21:59,126 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,126 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27176ms
2014-07-13 18:21:59,126 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,126 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27177ms
2014-07-13 18:21:59,126 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,129 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27199ms
2014-07-13 18:21:59,129 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,130 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27253ms
2014-07-13 18:21:59,130 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,131 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27284ms
2014-07-13 18:21:59,131 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,132 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27285ms
2014-07-13 18:21:59,133 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,138 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27291ms
2014-07-13 18:21:59,138 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,138 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27292ms
2014-07-13 18:21:59,138 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,138 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27090ms
2014-07-13 18:21:59,138 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,138 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27059ms
2014-07-13 18:21:59,138 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,139 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27293ms
2014-07-13 18:21:59,139 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,141 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27129ms
2014-07-13 18:21:59,141 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,145 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27330,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891815,"queuetimems":0,"class":"HRegionServer","responsesize":420,"method":"Multi"}
2014-07-13 18:21:59,145 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27471,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891674,"queuetimems":0,"class":"HRegionServer","responsesize":456,"method":"Multi"}
2014-07-13 18:21:59,149 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27139ms
2014-07-13 18:21:59,150 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,153 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27149ms
2014-07-13 18:21:59,153 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,157 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27154ms
2014-07-13 18:21:59,157 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,161 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27157ms
2014-07-13 18:21:59,161 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,162 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27160ms
2014-07-13 18:21:59,162 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,165 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27163ms
2014-07-13 18:21:59,165 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,165 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27317ms
2014-07-13 18:21:59,165 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,166 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27164ms
2014-07-13 18:21:59,166 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,166 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27165ms
2014-07-13 18:21:59,166 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,166 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27192ms
2014-07-13 18:21:59,166 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,173 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27174ms
2014-07-13 18:21:59,173 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,177 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 27052ms
2014-07-13 18:21:59,177 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:21:59,210 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27446,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891763,"queuetimems":0,"class":"HRegionServer","responsesize":3757,"method":"Multi"}
2014-07-13 18:21:59,235 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28928,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300890306,"queuetimems":0,"class":"HRegionServer","responsesize":15298,"method":"Multi"}
2014-07-13 18:21:59,286 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28933,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300890352,"queuetimems":0,"class":"HRegionServer","responsesize":15404,"method":"Multi"}
2014-07-13 18:21:59,297 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26830,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892467,"queuetimems":0,"class":"HRegionServer","responsesize":675,"method":"Multi"}
2014-07-13 18:21:59,297 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891694,"queuetimems":0,"class":"HRegionServer","responsesize":5471,"method":"Multi"}
2014-07-13 18:21:59,362 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27612,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891750,"queuetimems":1,"class":"HRegionServer","responsesize":7738,"method":"Multi"}
2014-07-13 18:21:59,363 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27606,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891756,"queuetimems":0,"class":"HRegionServer","responsesize":2348,"method":"Multi"}
2014-07-13 18:21:59,467 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27651,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891815,"queuetimems":0,"class":"HRegionServer","responsesize":4498,"method":"Multi"}
2014-07-13 18:21:59,467 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27716,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891750,"queuetimems":0,"class":"HRegionServer","responsesize":1347,"method":"Multi"}
2014-07-13 18:21:59,467 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892324,"queuetimems":1,"class":"HRegionServer","responsesize":499,"method":"Multi"}
2014-07-13 18:21:59,467 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27738,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891728,"queuetimems":0,"class":"HRegionServer","responsesize":2189,"method":"Multi"}
2014-07-13 18:21:59,467 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27142,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892324,"queuetimems":0,"class":"HRegionServer","responsesize":487,"method":"Multi"}
2014-07-13 18:21:59,467 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27786,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891680,"queuetimems":1,"class":"HRegionServer","responsesize":3928,"method":"Multi"}
2014-07-13 18:21:59,471 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27788,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891683,"queuetimems":0,"class":"HRegionServer","responsesize":2537,"method":"Multi"}
2014-07-13 18:22:00,240 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891799,"queuetimems":0,"class":"HRegionServer","responsesize":6944,"method":"Multi"}
2014-07-13 18:22:00,240 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891628,"queuetimems":0,"class":"HRegionServer","responsesize":18299,"method":"Multi"}
2014-07-13 18:22:00,254 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891784,"queuetimems":1,"class":"HRegionServer","responsesize":10989,"method":"Multi"}
2014-07-13 18:22:00,345 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27744,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892601,"queuetimems":0,"class":"HRegionServer","responsesize":14423,"method":"Multi"}
2014-07-13 18:22:00,345 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892628,"queuetimems":0,"class":"HRegionServer","responsesize":7409,"method":"Multi"}
2014-07-13 18:22:00,349 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28085,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892264,"queuetimems":0,"class":"HRegionServer","responsesize":10882,"method":"Multi"}
2014-07-13 18:22:00,421 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27914,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892507,"queuetimems":0,"class":"HRegionServer","responsesize":4447,"method":"Multi"}
2014-07-13 18:22:00,421 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27885,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892536,"queuetimems":0,"class":"HRegionServer","responsesize":10331,"method":"Multi"}
2014-07-13 18:22:00,429 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27819,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892610,"queuetimems":0,"class":"HRegionServer","responsesize":5571,"method":"Multi"}
2014-07-13 18:22:00,531 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:00,531 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28583,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891948,"queuetimems":0,"class":"HRegionServer","responsesize":7634,"method":"Multi"}
2014-07-13 18:22:00,532 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28116,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892415,"queuetimems":0,"class":"HRegionServer","responsesize":14069,"method":"Multi"}
2014-07-13 18:22:00,588 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61051 synced till here 61021
2014-07-13 18:22:00,674 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892443,"queuetimems":0,"class":"HRegionServer","responsesize":10535,"method":"Multi"}
2014-07-13 18:22:00,674 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892372,"queuetimems":0,"class":"HRegionServer","responsesize":14889,"method":"Multi"}
2014-07-13 18:22:00,674 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28554,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892120,"queuetimems":0,"class":"HRegionServer","responsesize":14643,"method":"Multi"}
2014-07-13 18:22:00,674 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28117,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892557,"queuetimems":0,"class":"HRegionServer","responsesize":7658,"method":"Multi"}
2014-07-13 18:22:00,674 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28803,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891871,"queuetimems":0,"class":"HRegionServer","responsesize":18426,"method":"Multi"}
2014-07-13 18:22:00,675 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28951,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891723,"queuetimems":0,"class":"HRegionServer","responsesize":14556,"method":"Multi"}
2014-07-13 18:22:00,675 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28749,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891926,"queuetimems":0,"class":"HRegionServer","responsesize":17525,"method":"Multi"}
2014-07-13 18:22:00,678 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28211,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892467,"queuetimems":0,"class":"HRegionServer","responsesize":8643,"method":"Multi"}
2014-07-13 18:22:00,675 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":29000,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891674,"queuetimems":1,"class":"HRegionServer","responsesize":16107,"method":"Multi"}
2014-07-13 18:22:00,685 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28393,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892292,"queuetimems":1,"class":"HRegionServer","responsesize":10170,"method":"Multi"}
2014-07-13 18:22:00,678 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28602,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892076,"queuetimems":0,"class":"HRegionServer","responsesize":9709,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28089,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892686,"queuetimems":1,"class":"HRegionServer","responsesize":9688,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28278,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892497,"queuetimems":0,"class":"HRegionServer","responsesize":12657,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28766,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892010,"queuetimems":1,"class":"HRegionServer","responsesize":9037,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28729,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892046,"queuetimems":1,"class":"HRegionServer","responsesize":11762,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28822,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891954,"queuetimems":0,"class":"HRegionServer","responsesize":1901,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28827,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891949,"queuetimems":0,"class":"HRegionServer","responsesize":761,"method":"Multi"}
2014-07-13 18:22:00,776 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28802,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891974,"queuetimems":0,"class":"HRegionServer","responsesize":1400,"method":"Multi"}
2014-07-13 18:22:00,779 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28800,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891978,"queuetimems":0,"class":"HRegionServer","responsesize":1079,"method":"Multi"}
2014-07-13 18:22:00,781 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28809,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300891972,"queuetimems":0,"class":"HRegionServer","responsesize":5270,"method":"Multi"}
2014-07-13 18:22:00,782 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28120,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892661,"queuetimems":1,"class":"HRegionServer","responsesize":10244,"method":"Multi"}
2014-07-13 18:22:00,788 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28465,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892323,"queuetimems":0,"class":"HRegionServer","responsesize":9398,"method":"Multi"}
2014-07-13 18:22:00,815 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300891996 with entries=130, filesize=93.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300920531
2014-07-13 18:22:00,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300797844
2014-07-13 18:22:00,816 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300799728
2014-07-13 18:22:00,831 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300892228,"queuetimems":0,"class":"HRegionServer","responsesize":12479,"method":"Multi"}
2014-07-13 18:22:01,957 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:01,998 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61175 synced till here 61153
2014-07-13 18:22:02,192 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300920531 with entries=124, filesize=83.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300921957
2014-07-13 18:22:02,384 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15139, memsize=731.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/62db1db8de074f4b82607bd502f0d9e4
2014-07-13 18:22:02,395 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/62db1db8de074f4b82607bd502f0d9e4 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/62db1db8de074f4b82607bd502f0d9e4
2014-07-13 18:22:02,403 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/62db1db8de074f4b82607bd502f0d9e4, entries=2662720, sequenceid=15139, filesize=189.6m
2014-07-13 18:22:02,403 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.5g/1629084560, currentsize=123.5m/129450240 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 32545ms, sequenceid=15139, compaction requested=true
2014-07-13 18:22:02,404 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:165), split_queue=0, merge_queue=0
2014-07-13 18:22:03,378 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:03,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61297 synced till here 61275
2014-07-13 18:22:03,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300921957 with entries=122, filesize=92.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300923379
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300802573
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300803967
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300806184
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300807836
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300810682
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300812411
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300813879
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300815562
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300817231
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300818954
2014-07-13 18:22:03,675 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300820834
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300822357
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300823579
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300824909
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300832476
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300834614
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300836650
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300839118
2014-07-13 18:22:03,676 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300842338
2014-07-13 18:22:04,341 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:05,183 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61411 synced till here 61386
2014-07-13 18:22:05,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300923379 with entries=114, filesize=83.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300924342
2014-07-13 18:22:06,243 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:06,277 DEBUG [RpcServer.handler=6,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:22:06,284 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:22:06,284 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:166), split_queue=0, merge_queue=0
2014-07-13 18:22:06,921 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61555 synced till here 61521
2014-07-13 18:22:07,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300924342 with entries=144, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300926243
2014-07-13 18:22:07,883 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:07,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61676 synced till here 61650
2014-07-13 18:22:08,114 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300926243 with entries=121, filesize=87.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300927883
2014-07-13 18:22:09,199 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:09,325 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61795 synced till here 61768
2014-07-13 18:22:09,347 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:22:09,347 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:22:09,347 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:167), split_queue=0, merge_queue=0
2014-07-13 18:22:09,477 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300927883 with entries=119, filesize=83.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300929200
2014-07-13 18:22:10,556 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/651da923651043948f12fc5205c3ad18 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/651da923651043948f12fc5205c3ad18
2014-07-13 18:22:10,769 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:10,817 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 61904 synced till here 61886
2014-07-13 18:22:10,888 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:22:10,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300929200 with entries=109, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300930770
2014-07-13 18:22:10,914 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8fc272f699824310a1bfdc35848b40ea, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/8fc272f699824310a1bfdc35848b40ea
2014-07-13 18:22:10,917 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c75f5e5bf4354725a9735dab20603ff4, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/c75f5e5bf4354725a9735dab20603ff4
2014-07-13 18:22:10,930 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3823c2c95462416f987a16a6c8350423, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/3823c2c95462416f987a16a6c8350423
2014-07-13 18:22:10,941 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/99ac3f04f2554082b7809f610bc593dd, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/99ac3f04f2554082b7809f610bc593dd
2014-07-13 18:22:10,944 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/866af7036b03493f8c22706d1aec20f8, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/866af7036b03493f8c22706d1aec20f8
2014-07-13 18:22:10,944 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 5 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into 651da923651043948f12fc5205c3ad18(size=366.2m), total size for store is 3.7g. This selection was in queue for 0sec, and took 1mins, 8sec to execute.
2014-07-13 18:22:10,944 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=5, fileSize=389.3m, priority=-2, time=254769670656455; duration=1mins, 8sec
2014-07-13 18:22:10,944 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:167), split_queue=0, merge_queue=0
2014-07-13 18:22:10,945 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:22:10,946 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 307125330 starting at candidate #10 after considering 132 permutations with 118 in ratio
2014-07-13 18:22:10,946 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating minor compaction
2014-07-13 18:22:10,946 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:22:10,946 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=292.9m
2014-07-13 18:22:10,946 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2095c58d503f4cc0a4b6b4e28ff6daea, keycount=92044, bloomtype=ROW, size=65.5m, encoding=NONE, seqNum=7804
2014-07-13 18:22:10,946 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2fbd2db352bb4d6b88c66f0e8557b18d, keycount=137246, bloomtype=ROW, size=97.7m, encoding=NONE, seqNum=7994
2014-07-13 18:22:10,946 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/579203308c8642ea853ee09e1ec391cf, keycount=106552, bloomtype=ROW, size=75.8m, encoding=NONE, seqNum=8172
2014-07-13 18:22:10,946 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9afe9b589304db0a9315490dcb538ed, keycount=75628, bloomtype=ROW, size=53.9m, encoding=NONE, seqNum=8320
2014-07-13 18:22:11,179 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:22:11,216 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 318.7m
2014-07-13 18:22:11,485 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:22:13,174 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:13,205 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300930770 with entries=97, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300933175
2014-07-13 18:22:14,298 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15541, memsize=59.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/d9256d86cef44d1e87044123ffc35683
2014-07-13 18:22:14,314 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/d9256d86cef44d1e87044123ffc35683 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d9256d86cef44d1e87044123ffc35683
2014-07-13 18:22:14,324 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d9256d86cef44d1e87044123ffc35683, entries=214820, sequenceid=15541, filesize=15.3m
2014-07-13 18:22:14,325 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~320.2m/335805360, currentsize=27.4m/28762160 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 3109ms, sequenceid=15541, compaction requested=true
2014-07-13 18:22:14,325 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:167), split_queue=0, merge_queue=0
2014-07-13 18:22:15,945 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:15,973 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62144 synced till here 62143
2014-07-13 18:22:15,992 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300933175 with entries=143, filesize=61.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300935945
2014-07-13 18:22:17,278 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:17,319 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300935945 with entries=91, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300937278
2014-07-13 18:22:18,410 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:18,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300937278 with entries=73, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300938410
2014-07-13 18:22:18,432 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:19,440 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:19,797 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62399 synced till here 62397
2014-07-13 18:22:19,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300938410 with entries=91, filesize=83.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300939440
2014-07-13 18:22:19,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:21,433 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:21,994 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62495 synced till here 62488
2014-07-13 18:22:22,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300939440 with entries=96, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300941433
2014-07-13 18:22:22,137 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:23,010 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:23,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62563 synced till here 62561
2014-07-13 18:22:23,081 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300941433 with entries=68, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300943010
2014-07-13 18:22:23,082 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:24,244 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:24,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62631 synced till here 62628
2014-07-13 18:22:24,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300943010 with entries=68, filesize=65.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300944244
2014-07-13 18:22:24,397 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:25,052 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:22:25,053 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 256.2m
2014-07-13 18:22:25,315 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:22:25,494 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:25,672 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62698 synced till here 62695
2014-07-13 18:22:25,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300944244 with entries=67, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300945494
2014-07-13 18:22:25,707 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:26,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:26,903 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62791 synced till here 62788
2014-07-13 18:22:26,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300945494 with entries=93, filesize=65.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300946868
2014-07-13 18:22:26,996 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:28,643 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:28,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62875 synced till here 62855
2014-07-13 18:22:28,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300946868 with entries=84, filesize=78.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300948644
2014-07-13 18:22:28,801 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:30,119 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:30,191 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 62952 synced till here 62941
2014-07-13 18:22:30,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300948644 with entries=77, filesize=74.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300950120
2014-07-13 18:22:30,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:31,604 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:31,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63038 synced till here 63034
2014-07-13 18:22:31,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300950120 with entries=86, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300951604
2014-07-13 18:22:31,697 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:22:32,329 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:22:32,765 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files, but is 1.4g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:22:32,765 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. due to global heap pressure
2014-07-13 18:22:32,765 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 1.4g
2014-07-13 18:22:32,927 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:32,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63111 synced till here 63106
2014-07-13 18:22:33,002 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300951604 with entries=73, filesize=65.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300952928
2014-07-13 18:22:34,185 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:34,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63220 synced till here 63208
2014-07-13 18:22:34,495 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:22:34,533 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300952928 with entries=109, filesize=84.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300954186
2014-07-13 18:22:34,604 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,606 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,623 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,649 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,688 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,743 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,744 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,786 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,790 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,801 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,830 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,846 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,856 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,903 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,925 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,973 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,995 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:34,997 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,046 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,060 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,061 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,063 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,082 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,084 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,096 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,097 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,123 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,126 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,131 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,152 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,160 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,173 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,200 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,200 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,242 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,245 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,251 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,301 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,343 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,370 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,400 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,410 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,428 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,463 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,495 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:35,503 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:36,448 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:36,448 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:36,452 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:36,453 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:36,880 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15702, memsize=239.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/f0fa1876b2634b45acbcfd01bf30fb71
2014-07-13 18:22:36,892 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/f0fa1876b2634b45acbcfd01bf30fb71 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f0fa1876b2634b45acbcfd01bf30fb71
2014-07-13 18:22:36,903 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f0fa1876b2634b45acbcfd01bf30fb71, entries=870620, sequenceid=15702, filesize=62.0m
2014-07-13 18:22:36,904 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~265.9m/278788000, currentsize=245.2m/257123280 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 11851ms, sequenceid=15702, compaction requested=true
2014-07-13 18:22:36,904 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:168), split_queue=0, merge_queue=0
2014-07-13 18:22:36,904 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 451ms
2014-07-13 18:22:36,904 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,904 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 452ms
2014-07-13 18:22:36,904 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,905 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 457ms
2014-07-13 18:22:36,905 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,915 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 467ms
2014-07-13 18:22:36,915 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,916 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1413ms
2014-07-13 18:22:36,916 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,916 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1421ms
2014-07-13 18:22:36,916 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,916 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1453ms
2014-07-13 18:22:36,916 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,916 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1488ms
2014-07-13 18:22:36,916 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,917 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1507ms
2014-07-13 18:22:36,917 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,917 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1518ms
2014-07-13 18:22:36,917 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,921 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1551ms
2014-07-13 18:22:36,921 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,921 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1579ms
2014-07-13 18:22:36,921 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,921 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1620ms
2014-07-13 18:22:36,921 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,921 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1670ms
2014-07-13 18:22:36,921 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,922 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1677ms
2014-07-13 18:22:36,922 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,922 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1680ms
2014-07-13 18:22:36,922 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,922 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1722ms
2014-07-13 18:22:36,922 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,922 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1722ms
2014-07-13 18:22:36,922 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,923 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1749ms
2014-07-13 18:22:36,923 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,923 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1763ms
2014-07-13 18:22:36,923 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,924 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1771ms
2014-07-13 18:22:36,924 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,924 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1793ms
2014-07-13 18:22:36,924 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,924 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1798ms
2014-07-13 18:22:36,924 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,925 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1802ms
2014-07-13 18:22:36,925 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,927 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1831ms
2014-07-13 18:22:36,927 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,927 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1831ms
2014-07-13 18:22:36,927 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,929 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1845ms
2014-07-13 18:22:36,929 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,929 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1847ms
2014-07-13 18:22:36,929 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,929 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1867ms
2014-07-13 18:22:36,929 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,929 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1868ms
2014-07-13 18:22:36,929 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,937 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1877ms
2014-07-13 18:22:36,937 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,941 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1895ms
2014-07-13 18:22:36,941 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,941 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1944ms
2014-07-13 18:22:36,941 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,941 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1946ms
2014-07-13 18:22:36,941 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,941 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1968ms
2014-07-13 18:22:36,941 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,948 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2022ms
2014-07-13 18:22:36,948 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,953 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2051ms
2014-07-13 18:22:36,953 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,961 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2105ms
2014-07-13 18:22:36,962 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,962 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2116ms
2014-07-13 18:22:36,962 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,962 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2132ms
2014-07-13 18:22:36,962 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,963 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2162ms
2014-07-13 18:22:36,963 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,964 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2174ms
2014-07-13 18:22:36,964 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,964 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2178ms
2014-07-13 18:22:36,964 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,970 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2226ms
2014-07-13 18:22:36,970 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,970 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2227ms
2014-07-13 18:22:36,970 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,970 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2282ms
2014-07-13 18:22:36,970 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,977 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2328ms
2014-07-13 18:22:36,977 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,985 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2362ms
2014-07-13 18:22:36,985 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,993 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2387ms
2014-07-13 18:22:36,993 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:36,997 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2394ms
2014-07-13 18:22:36,997 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:22:37,548 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:22:37,548 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files, but is 1.3g vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:22:37,548 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. due to global heap pressure
2014-07-13 18:22:37,549 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 1.3g
2014-07-13 18:22:37,684 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:22:37,685 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:37,703 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63322 synced till here 63297
2014-07-13 18:22:39,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300954186 with entries=102, filesize=81.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300957685
2014-07-13 18:22:41,108 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:22:41,129 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63453 synced till here 63426
2014-07-13 18:22:41,275 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,276 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,276 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,277 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,277 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,277 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,277 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,278 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,278 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,279 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,279 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,279 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,280 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,281 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,281 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,281 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,281 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,281 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,282 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,282 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,282 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,282 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,283 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,283 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,283 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,284 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,284 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,284 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,284 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,284 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,285 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,285 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,287 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,395 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300957685 with entries=131, filesize=91.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300961109
2014-07-13 18:22:41,544 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:22:41,552 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,553 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,554 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,554 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,555 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,556 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,557 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,557 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,557 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,558 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,558 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,559 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,559 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,561 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,561 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,562 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:41,563 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:22:46,276 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,276 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,276 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,277 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,278 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,278 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,278 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,279 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:22:46,279 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,279 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,280 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,280 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,280 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,281 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,282 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,282 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,282 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,282 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,282 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,283 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,283 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:22:46,283 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,283 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,283 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,284 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,284 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,285 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,285 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,285 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,285 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,285 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,286 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:22:46,288 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,553 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,553 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,554 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,554 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,555 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,557 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,557 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,557 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,557 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,558 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,559 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,560 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,560 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,562 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,562 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:22:46,562 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:46,563 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:22:51,276 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,278 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,278 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,278 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,279 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,279 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:22:51,280 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,281 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,281 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-13 18:22:51,281 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,282 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,282 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,283 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,283 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10004ms
2014-07-13 18:22:51,283 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,284 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,284 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,284 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,284 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,285 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,285 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,285 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,285 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,285 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:22:51,287 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-13 18:22:51,287 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-13 18:22:51,287 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,287 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,287 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:22:51,287 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,288 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:22:51,288 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,553 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,554 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,554 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,554 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,555 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,557 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,557 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,558 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,559 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,559 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:22:51,559 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,560 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,560 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,562 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,562 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:22:51,563 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:51,563 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:22:56,277 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,278 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,278 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,279 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,279 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,280 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,280 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,281 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,282 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-13 18:22:56,282 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,282 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,283 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-13 18:22:56,283 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,283 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-13 18:22:56,284 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,284 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,284 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,285 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,285 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,285 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,285 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,285 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,286 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,286 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,287 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15006ms
2014-07-13 18:22:56,287 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15005ms
2014-07-13 18:22:56,287 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,287 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,288 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,288 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15004ms
2014-07-13 18:22:56,288 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:22:56,289 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,554 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,554 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,554 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,555 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:22:56,555 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:22:56,558 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,558 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,558 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,559 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,559 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,559 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,560 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,561 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:22:56,562 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,562 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,563 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:22:56,563 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:23:01,277 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,277 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,278 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,278 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,279 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,279 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,280 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,280 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,281 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,282 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20005ms
2014-07-13 18:23:01,282 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,283 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,283 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,283 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,283 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,284 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,284 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,284 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,285 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,285 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,285 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,285 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,286 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,286 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,286 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,287 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20006ms
2014-07-13 18:23:01,287 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20005ms
2014-07-13 18:23:01,287 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,288 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,288 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,288 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,289 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20004ms
2014-07-13 18:23:01,289 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,554 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,554 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,555 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,555 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,556 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,558 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,558 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,558 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,559 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,560 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:23:01,560 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,561 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,561 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:01,562 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,562 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,563 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,564 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:23:01,919 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/6373a3c9494f4a669ccd8f4a4e5b74ab as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/6373a3c9494f4a669ccd8f4a4e5b74ab
2014-07-13 18:23:02,100 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:23:02,225 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2095c58d503f4cc0a4b6b4e28ff6daea, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2095c58d503f4cc0a4b6b4e28ff6daea
2014-07-13 18:23:02,241 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2fbd2db352bb4d6b88c66f0e8557b18d, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/2fbd2db352bb4d6b88c66f0e8557b18d
2014-07-13 18:23:02,247 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/579203308c8642ea853ee09e1ec391cf, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/579203308c8642ea853ee09e1ec391cf
2014-07-13 18:23:02,251 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9afe9b589304db0a9315490dcb538ed, to hdfs://master:54310/hbase/archive/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9afe9b589304db0a9315490dcb538ed
2014-07-13 18:23:02,251 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into 6373a3c9494f4a669ccd8f4a4e5b74ab(size=291.0m), total size for store is 3.7g. This selection was in queue for 0sec, and took 51sec to execute.
2014-07-13 18:23:02,251 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., storeName=family, fileCount=4, fileSize=292.9m, priority=-2, time=254838372988482; duration=51sec
2014-07-13 18:23:02,252 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:168), split_queue=0, merge_queue=0
2014-07-13 18:23:02,252 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:23:02,253 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 148916034 starting at candidate #9 after considering 132 permutations with 116 in ratio
2014-07-13 18:23:02,253 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating minor compaction
2014-07-13 18:23:02,253 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:23:02,253 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=142.0m
2014-07-13 18:23:02,254 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/af36bc436bed43bc8d13e3d5217d2cf0, keycount=104087, bloomtype=ROW, size=74.0m, encoding=NONE, seqNum=9337
2014-07-13 18:23:02,254 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ff63fc59bb6741a6b0e637edc45ea09a, keycount=65995, bloomtype=ROW, size=47.0m, encoding=NONE, seqNum=9529
2014-07-13 18:23:02,254 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/b01b7a34949142fcb53bf3562155b4d8, keycount=29369, bloomtype=ROW, size=20.9m, encoding=NONE, seqNum=9770
2014-07-13 18:23:02,323 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:23:05,156 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15801, memsize=736.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/55932be608a0464d981ac0ff75908c29
2014-07-13 18:23:05,180 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/55932be608a0464d981ac0ff75908c29 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/55932be608a0464d981ac0ff75908c29
2014-07-13 18:23:05,198 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/55932be608a0464d981ac0ff75908c29, entries=2679720, sequenceid=15801, filesize=190.8m
2014-07-13 18:23:05,199 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.4g/1455767360, currentsize=132.5m/138898080 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 32433ms, sequenceid=15801, compaction requested=true
2014-07-13 18:23:05,199 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:168), split_queue=0, merge_queue=0
2014-07-13 18:23:05,199 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:23:05,199 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23636ms
2014-07-13 18:23:05,199 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:169), split_queue=0, merge_queue=0
2014-07-13 18:23:05,199 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,199 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 112145ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:23:05,199 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23637ms
2014-07-13 18:23:05,199 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 132.5m
2014-07-13 18:23:05,199 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,200 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23639ms
2014-07-13 18:23:05,200 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,201 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23640ms
2014-07-13 18:23:05,201 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,203 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23644ms
2014-07-13 18:23:05,203 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,204 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23644ms
2014-07-13 18:23:05,204 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,205 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23647ms
2014-07-13 18:23:05,205 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,205 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23648ms
2014-07-13 18:23:05,205 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,205 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23647ms
2014-07-13 18:23:05,205 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,206 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23648ms
2014-07-13 18:23:05,206 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,213 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23654ms
2014-07-13 18:23:05,213 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,213 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23657ms
2014-07-13 18:23:05,213 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,213 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23658ms
2014-07-13 18:23:05,213 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,215 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23661ms
2014-07-13 18:23:05,215 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,217 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23664ms
2014-07-13 18:23:05,217 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,221 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23668ms
2014-07-13 18:23:05,221 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,221 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23669ms
2014-07-13 18:23:05,221 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,223 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23936ms
2014-07-13 18:23:05,223 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,223 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23938ms
2014-07-13 18:23:05,224 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,232 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23947ms
2014-07-13 18:23:05,232 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,233 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23947ms
2014-07-13 18:23:05,233 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,233 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23949ms
2014-07-13 18:23:05,233 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,234 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23949ms
2014-07-13 18:23:05,234 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,238 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23955ms
2014-07-13 18:23:05,238 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,239 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23957ms
2014-07-13 18:23:05,239 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,240 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23956ms
2014-07-13 18:23:05,240 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,240 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23958ms
2014-07-13 18:23:05,240 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,241 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23956ms
2014-07-13 18:23:05,241 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,242 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23960ms
2014-07-13 18:23:05,242 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,242 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23958ms
2014-07-13 18:23:05,243 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,245 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23962ms
2014-07-13 18:23:05,245 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,245 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23964ms
2014-07-13 18:23:05,245 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,249 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23968ms
2014-07-13 18:23:05,249 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,249 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23968ms
2014-07-13 18:23:05,249 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,257 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23975ms
2014-07-13 18:23:05,257 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,257 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23978ms
2014-07-13 18:23:05,257 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,257 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23976ms
2014-07-13 18:23:05,258 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,259 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23979ms
2014-07-13 18:23:05,259 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,259 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23980ms
2014-07-13 18:23:05,259 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,265 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23984ms
2014-07-13 18:23:05,265 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,270 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23992ms
2014-07-13 18:23:05,270 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,270 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23991ms
2014-07-13 18:23:05,270 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,270 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23992ms
2014-07-13 18:23:05,270 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,270 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23993ms
2014-07-13 18:23:05,270 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,271 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23993ms
2014-07-13 18:23:05,271 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,272 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23994ms
2014-07-13 18:23:05,272 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,272 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23995ms
2014-07-13 18:23:05,272 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,273 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23997ms
2014-07-13 18:23:05,273 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,273 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 23998ms
2014-07-13 18:23:05,273 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,282 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 24006ms
2014-07-13 18:23:05,282 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:05,373 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:23:05,442 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24331,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961111,"queuetimems":1950,"class":"HRegionServer","responsesize":7909,"method":"Multi"}
2014-07-13 18:23:05,572 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24454,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961118,"queuetimems":1943,"class":"HRegionServer","responsesize":3215,"method":"Multi"}
2014-07-13 18:23:05,573 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25997,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959575,"queuetimems":649,"class":"HRegionServer","responsesize":8246,"method":"Multi"}
2014-07-13 18:23:05,573 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25997,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959575,"queuetimems":644,"class":"HRegionServer","responsesize":7572,"method":"Multi"}
2014-07-13 18:23:05,573 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26004,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959569,"queuetimems":1859,"class":"HRegionServer","responsesize":3154,"method":"Multi"}
2014-07-13 18:23:05,573 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26012,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959561,"queuetimems":1875,"class":"HRegionServer","responsesize":7406,"method":"Multi"}
2014-07-13 18:23:05,573 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26011,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959561,"queuetimems":1854,"class":"HRegionServer","responsesize":12049,"method":"Multi"}
2014-07-13 18:23:05,574 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25998,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959575,"queuetimems":1854,"class":"HRegionServer","responsesize":5872,"method":"Multi"}
2014-07-13 18:23:05,736 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26210,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959525,"queuetimems":2008,"class":"HRegionServer","responsesize":19564,"method":"Multi"}
2014-07-13 18:23:05,739 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959557,"queuetimems":1903,"class":"HRegionServer","responsesize":12533,"method":"Multi"}
2014-07-13 18:23:05,739 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26730,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959009,"queuetimems":1852,"class":"HRegionServer","responsesize":18958,"method":"Multi"}
2014-07-13 18:23:05,742 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25920,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959822,"queuetimems":883,"class":"HRegionServer","responsesize":1701,"method":"Multi"}
2014-07-13 18:23:05,739 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26194,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959545,"queuetimems":1951,"class":"HRegionServer","responsesize":11373,"method":"Multi"}
2014-07-13 18:23:05,744 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25929,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959814,"queuetimems":876,"class":"HRegionServer","responsesize":1808,"method":"Multi"}
2014-07-13 18:23:05,744 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26182,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959561,"queuetimems":1888,"class":"HRegionServer","responsesize":10583,"method":"Multi"}
2014-07-13 18:23:05,743 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":28015,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300957727,"queuetimems":812,"class":"HRegionServer","responsesize":14280,"method":"Multi"}
2014-07-13 18:23:05,753 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25958,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959795,"queuetimems":861,"class":"HRegionServer","responsesize":233,"method":"Multi"}
2014-07-13 18:23:05,754 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25958,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959795,"queuetimems":861,"class":"HRegionServer","responsesize":82,"method":"Multi"}
2014-07-13 18:23:05,743 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25936,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959806,"queuetimems":871,"class":"HRegionServer","responsesize":220,"method":"Multi"}
2014-07-13 18:23:05,760 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25947,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959813,"queuetimems":877,"class":"HRegionServer","responsesize":300,"method":"Multi"}
2014-07-13 18:23:05,762 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":24651,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961111,"queuetimems":1947,"class":"HRegionServer","responsesize":2136,"method":"Multi"}
2014-07-13 18:23:06,485 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25374,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961111,"queuetimems":1944,"class":"HRegionServer","responsesize":2096,"method":"Multi"}
2014-07-13 18:23:06,485 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26679,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959806,"queuetimems":870,"class":"HRegionServer","responsesize":2053,"method":"Multi"}
2014-07-13 18:23:06,626 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:06,627 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25076,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961551,"queuetimems":2142,"class":"HRegionServer","responsesize":13195,"method":"Multi"}
2014-07-13 18:23:06,628 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26797,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959830,"queuetimems":890,"class":"HRegionServer","responsesize":780,"method":"Multi"}
2014-07-13 18:23:06,628 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25355,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961273,"queuetimems":2061,"class":"HRegionServer","responsesize":12877,"method":"Multi"}
2014-07-13 18:23:06,627 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25346,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961281,"queuetimems":1950,"class":"HRegionServer","responsesize":8969,"method":"Multi"}
2014-07-13 18:23:06,629 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25074,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961555,"queuetimems":2064,"class":"HRegionServer","responsesize":5324,"method":"Multi"}
2014-07-13 18:23:06,631 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":26817,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959814,"queuetimems":876,"class":"HRegionServer","responsesize":699,"method":"Multi"}
2014-07-13 18:23:06,627 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25353,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961274,"queuetimems":2013,"class":"HRegionServer","responsesize":3856,"method":"Multi"}
2014-07-13 18:23:06,636 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25525,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961111,"queuetimems":1950,"class":"HRegionServer","responsesize":58,"method":"Multi"}
2014-07-13 18:23:06,636 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25083,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961553,"queuetimems":2143,"class":"HRegionServer","responsesize":891,"method":"Multi"}
2014-07-13 18:23:06,636 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25081,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961555,"queuetimems":2075,"class":"HRegionServer","responsesize":11122,"method":"Multi"}
2014-07-13 18:23:06,638 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959553,"queuetimems":1922,"class":"HRegionServer","responsesize":18789,"method":"Multi"}
2014-07-13 18:23:06,641 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27388,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300959253,"queuetimems":1943,"class":"HRegionServer","responsesize":15796,"method":"Multi"}
2014-07-13 18:23:06,667 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63579 synced till here 63535
2014-07-13 18:23:06,810 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25537,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961273,"queuetimems":2019,"class":"HRegionServer","responsesize":18231,"method":"Multi"}
2014-07-13 18:23:06,813 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25256,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961557,"queuetimems":2002,"class":"HRegionServer","responsesize":373,"method":"Multi"}
2014-07-13 18:23:06,816 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25260,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961556,"queuetimems":2002,"class":"HRegionServer","responsesize":18789,"method":"Multi"}
2014-07-13 18:23:06,824 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25267,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961557,"queuetimems":1970,"class":"HRegionServer","responsesize":12533,"method":"Multi"}
2014-07-13 18:23:06,824 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25270,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961554,"queuetimems":2096,"class":"HRegionServer","responsesize":12185,"method":"Multi"}
2014-07-13 18:23:06,826 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25274,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961551,"queuetimems":2192,"class":"HRegionServer","responsesize":13080,"method":"Multi"}
2014-07-13 18:23:06,829 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25275,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961554,"queuetimems":2121,"class":"HRegionServer","responsesize":11001,"method":"Multi"}
2014-07-13 18:23:06,830 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25550,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961279,"queuetimems":1968,"class":"HRegionServer","responsesize":2995,"method":"Multi"}
2014-07-13 18:23:06,832 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25281,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961551,"queuetimems":2184,"class":"HRegionServer","responsesize":4985,"method":"Multi"}
2014-07-13 18:23:06,832 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25275,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961557,"queuetimems":1952,"class":"HRegionServer","responsesize":10583,"method":"Multi"}
2014-07-13 18:23:06,841 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961274,"queuetimems":1969,"class":"HRegionServer","responsesize":1678,"method":"Multi"}
2014-07-13 18:23:06,841 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961558,"queuetimems":1915,"class":"HRegionServer","responsesize":11373,"method":"Multi"}
2014-07-13 18:23:06,845 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25289,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961556,"queuetimems":2001,"class":"HRegionServer","responsesize":620,"method":"Multi"}
2014-07-13 18:23:06,845 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":25294,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961551,"queuetimems":2172,"class":"HRegionServer","responsesize":6223,"method":"Multi"}
2014-07-13 18:23:06,972 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300961109 with entries=126, filesize=98.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300986627
2014-07-13 18:23:06,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300844582
2014-07-13 18:23:06,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300846929
2014-07-13 18:23:06,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300850112
2014-07-13 18:23:06,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300857084
2014-07-13 18:23:06,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300858681
2014-07-13 18:23:06,972 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300860235
2014-07-13 18:23:08,317 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:08,319 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":27044,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405300961274,"queuetimems":1972,"class":"HRegionServer","responsesize":15796,"method":"Multi"}
2014-07-13 18:23:08,378 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63701 synced till here 63678
2014-07-13 18:23:08,521 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300986627 with entries=122, filesize=85.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300988318
2014-07-13 18:23:09,720 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:09,769 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63831 synced till here 63798
2014-07-13 18:23:09,925 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15903, memsize=80.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/2e2d247a9c13405f8a5631167e84f1ec
2014-07-13 18:23:09,949 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/2e2d247a9c13405f8a5631167e84f1ec as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2e2d247a9c13405f8a5631167e84f1ec
2014-07-13 18:23:10,035 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300988318 with entries=130, filesize=94.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300989721
2014-07-13 18:23:10,035 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2e2d247a9c13405f8a5631167e84f1ec, entries=291890, sequenceid=15903, filesize=20.8m
2014-07-13 18:23:10,042 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~132.5m/138898080, currentsize=116.6m/122271520 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 4843ms, sequenceid=15903, compaction requested=true
2014-07-13 18:23:10,042 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:170), split_queue=0, merge_queue=0
2014-07-13 18:23:10,151 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=2, accesses=364618, hits=67433, hitRatio=18.49%, , cachingAccesses=67464, cachingHits=67401, cachingHitsRatio=99.90%, evictions=0, evicted=61, evictedPerRun=Infinity
2014-07-13 18:23:10,738 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:10,757 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 63954 synced till here 63920
2014-07-13 18:23:11,297 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=15894, memsize=740.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/bd6b40bc7b724519aae71c6be5035811
2014-07-13 18:23:11,310 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/bd6b40bc7b724519aae71c6be5035811 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/bd6b40bc7b724519aae71c6be5035811
2014-07-13 18:23:11,330 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/bd6b40bc7b724519aae71c6be5035811, entries=2694940, sequenceid=15894, filesize=191.9m
2014-07-13 18:23:11,331 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.3g/1384581040, currentsize=221.9m/232662560 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 33782ms, sequenceid=15894, compaction requested=true
2014-07-13 18:23:11,331 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:171), split_queue=0, merge_queue=0
2014-07-13 18:23:11,431 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300989721 with entries=123, filesize=94.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300990739
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300867533
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300868813
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300870737
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300872385
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300873607
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300875095
2014-07-13 18:23:11,431 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300876427
2014-07-13 18:23:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300878142
2014-07-13 18:23:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300879832
2014-07-13 18:23:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300881949
2014-07-13 18:23:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300883513
2014-07-13 18:23:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300885184
2014-07-13 18:23:11,432 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300886621
2014-07-13 18:23:12,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:12,110 DEBUG [RpcServer.handler=2,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:23:12,110 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:23:12,111 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:172), split_queue=0, merge_queue=0
2014-07-13 18:23:12,145 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64073 synced till here 64047
2014-07-13 18:23:12,425 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300990739 with entries=119, filesize=83.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300992096
2014-07-13 18:23:14,236 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:14,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64191 synced till here 64176
2014-07-13 18:23:14,451 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300992096 with entries=118, filesize=82.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300994237
2014-07-13 18:23:14,452 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:15,573 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:15,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300994237 with entries=68, filesize=61.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300995573
2014-07-13 18:23:15,594 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:16,124 DEBUG [RpcServer.handler=38,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:23:16,124 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:23:16,124 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:173), split_queue=0, merge_queue=0
2014-07-13 18:23:16,978 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:17,014 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300995573 with entries=92, filesize=61.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300996979
2014-07-13 18:23:17,015 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:17,867 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:17,884 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64448 synced till here 64443
2014-07-13 18:23:18,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300996979 with entries=97, filesize=64.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300997868
2014-07-13 18:23:18,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:19,632 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:19,658 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64541 synced till here 64540
2014-07-13 18:23:19,667 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300997868 with entries=93, filesize=63.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300999633
2014-07-13 18:23:19,668 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:20,928 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:20,945 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64615 synced till here 64610
2014-07-13 18:23:20,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300999633 with entries=74, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301000928
2014-07-13 18:23:20,988 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:22,091 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:22,334 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64696 synced till here 64694
2014-07-13 18:23:22,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301000928 with entries=81, filesize=77.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301002092
2014-07-13 18:23:22,371 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:23,741 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:23,759 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64766 synced till here 64763
2014-07-13 18:23:23,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301002092 with entries=70, filesize=66.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301003741
2014-07-13 18:23:23,791 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:25,003 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:25,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64834 synced till here 64828
2014-07-13 18:23:25,082 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301003741 with entries=68, filesize=67.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301005004
2014-07-13 18:23:25,082 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:26,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:26,585 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64904 synced till here 64898
2014-07-13 18:23:26,681 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301005004 with entries=70, filesize=68.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301006569
2014-07-13 18:23:26,681 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:27,436 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:27,880 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 64970 synced till here 64968
2014-07-13 18:23:27,898 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301006569 with entries=66, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301007436
2014-07-13 18:23:27,899 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:27,930 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/9013ea92728341e984259060235737e3 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9013ea92728341e984259060235737e3
2014-07-13 18:23:27,956 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:23:27,963 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/af36bc436bed43bc8d13e3d5217d2cf0, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/af36bc436bed43bc8d13e3d5217d2cf0
2014-07-13 18:23:27,965 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ff63fc59bb6741a6b0e637edc45ea09a, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/ff63fc59bb6741a6b0e637edc45ea09a
2014-07-13 18:23:27,967 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/b01b7a34949142fcb53bf3562155b4d8, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/b01b7a34949142fcb53bf3562155b4d8
2014-07-13 18:23:27,967 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into 9013ea92728341e984259060235737e3(size=125.7m), total size for store is 3.8g. This selection was in queue for 0sec, and took 25sec to execute.
2014-07-13 18:23:27,967 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=3, fileSize=142.0m, priority=-2, time=254889680339606; duration=25sec
2014-07-13 18:23:27,968 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:174), split_queue=0, merge_queue=0
2014-07-13 18:23:27,968 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:174), split_queue=0, merge_queue=0
2014-07-13 18:23:27,968 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:23:27,969 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 348275892 starting at candidate #13 after considering 132 permutations with 119 in ratio
2014-07-13 18:23:27,969 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: df2b912714c1f15f547c828466aaf923 - family: Initiating minor compaction
2014-07-13 18:23:27,969 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:23:27,969 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp, totalSize=332.1m
2014-07-13 18:23:27,969 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/58aa8feadc994403ab24b7b054d826aa, keycount=117524, bloomtype=ROW, size=83.7m, encoding=NONE, seqNum=11872
2014-07-13 18:23:27,969 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2ac8eb01e63e4cae9ecdc867bd6f0451, keycount=135886, bloomtype=ROW, size=96.7m, encoding=NONE, seqNum=12150
2014-07-13 18:23:27,969 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/40c6ac76a9c84c9480f9303749e8288e, keycount=155325, bloomtype=ROW, size=110.6m, encoding=NONE, seqNum=13007
2014-07-13 18:23:27,970 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4d66ddb5e67a4e6d907ce7df278504e7, keycount=57773, bloomtype=ROW, size=41.2m, encoding=NONE, seqNum=13238
2014-07-13 18:23:28,109 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:23:28,566 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:29,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301007436 with entries=88, filesize=80.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301008566
2014-07-13 18:23:29,202 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:29,911 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:29,950 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65130 synced till here 65122
2014-07-13 18:23:30,040 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301008566 with entries=72, filesize=72.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301009911
2014-07-13 18:23:30,041 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:31,702 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:32,043 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65219 synced till here 65214
2014-07-13 18:23:32,434 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301009911 with entries=89, filesize=82.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301011703
2014-07-13 18:23:32,435 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:23:32,563 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:23:32,564 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. due to global heap pressure
2014-07-13 18:23:32,564 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.5g
2014-07-13 18:23:33,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:33,199 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65305 synced till here 65298
2014-07-13 18:23:33,320 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:23:33,321 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files, but is 968.1m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:23:33,321 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. due to global heap pressure
2014-07-13 18:23:33,321 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 968.1m
2014-07-13 18:23:33,927 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301011703 with entries=86, filesize=72.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301013165
2014-07-13 18:23:34,523 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,524 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,526 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,527 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,528 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,537 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,542 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,551 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,572 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,574 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,593 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:23:34,594 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,594 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,595 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,596 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,596 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,596 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,597 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,598 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,611 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,623 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,642 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,648 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,649 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:34,656 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301013165 with entries=68, filesize=61.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301014653
2014-07-13 18:23:34,758 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,777 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:23:34,789 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,790 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,796 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,818 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,862 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,899 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,900 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,906 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,906 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,918 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,953 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:34,955 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,741 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,752 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,757 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,763 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,764 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,764 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,779 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,813 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,851 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,853 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,863 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:35,877 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:36,009 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:23:39,670 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5014ms
2014-07-13 18:23:39,671 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5073ms
2014-07-13 18:23:39,671 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5077ms
2014-07-13 18:23:39,671 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5129ms
2014-07-13 18:23:39,672 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5149ms
2014-07-13 18:23:39,672 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5061ms
2014-07-13 18:23:39,672 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5030ms
2014-07-13 18:23:39,672 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5049ms
2014-07-13 18:23:39,673 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5025ms
2014-07-13 18:23:39,673 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5024ms
2014-07-13 18:23:39,674 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5149ms
2014-07-13 18:23:39,675 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5138ms
2014-07-13 18:23:39,676 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5148ms
2014-07-13 18:23:39,676 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5149ms
2014-07-13 18:23:39,676 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5150ms
2014-07-13 18:23:39,676 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5125ms
2014-07-13 18:23:39,677 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5106ms
2014-07-13 18:23:39,677 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5103ms
2014-07-13 18:23:39,677 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5083ms
2014-07-13 18:23:39,677 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 18:23:39,678 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 18:23:39,678 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 18:23:39,678 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 18:23:39,679 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5082ms
2014-07-13 18:23:39,758 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,790 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:39,790 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,796 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,818 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,863 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,899 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,901 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:39,906 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,907 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:39,919 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:39,954 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:39,955 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,742 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:40,752 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,757 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,764 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,764 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,765 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:40,780 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,813 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,853 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-13 18:23:40,854 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:23:40,863 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:40,877 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:41,009 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:23:44,671 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10015ms
2014-07-13 18:23:44,671 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10073ms
2014-07-13 18:23:44,671 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10077ms
2014-07-13 18:23:44,672 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10130ms
2014-07-13 18:23:44,672 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10149ms
2014-07-13 18:23:44,673 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10061ms
2014-07-13 18:23:44,673 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10031ms
2014-07-13 18:23:44,673 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10050ms
2014-07-13 18:23:44,674 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10025ms
2014-07-13 18:23:44,674 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10025ms
2014-07-13 18:23:44,675 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10151ms
2014-07-13 18:23:44,676 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10139ms
2014-07-13 18:23:44,676 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10148ms
2014-07-13 18:23:44,676 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10149ms
2014-07-13 18:23:44,676 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10150ms
2014-07-13 18:23:44,677 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10126ms
2014-07-13 18:23:44,677 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10103ms
2014-07-13 18:23:44,678 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10106ms
2014-07-13 18:23:44,678 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10083ms
2014-07-13 18:23:44,679 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10084ms
2014-07-13 18:23:44,679 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10083ms
2014-07-13 18:23:44,680 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10084ms
2014-07-13 18:23:44,681 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10084ms
2014-07-13 18:23:44,681 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10085ms
2014-07-13 18:23:44,759 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,790 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,791 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,797 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:23:44,819 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,863 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,900 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,901 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,907 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,907 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,919 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,954 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:44,955 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:23:45,742 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,753 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,758 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,764 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,764 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:23:45,766 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,780 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,814 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:23:45,854 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:23:45,854 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,864 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:23:45,878 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:23:46,009 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:23:49,671 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15015ms
2014-07-13 18:23:49,672 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15074ms
2014-07-13 18:23:49,672 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15078ms
2014-07-13 18:23:49,673 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15130ms
2014-07-13 18:23:49,673 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15150ms
2014-07-13 18:23:49,673 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15062ms
2014-07-13 18:23:49,673 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15031ms
2014-07-13 18:23:49,673 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15050ms
2014-07-13 18:23:49,674 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15026ms
2014-07-13 18:23:49,674 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15025ms
2014-07-13 18:23:49,675 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15151ms
2014-07-13 18:23:49,676 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15139ms
2014-07-13 18:23:49,676 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15148ms
2014-07-13 18:23:49,676 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15149ms
2014-07-13 18:23:49,677 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15151ms
2014-07-13 18:23:49,677 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15126ms
2014-07-13 18:23:49,678 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15103ms
2014-07-13 18:23:49,678 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15107ms
2014-07-13 18:23:49,679 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15083ms
2014-07-13 18:23:49,679 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15085ms
2014-07-13 18:23:49,680 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15083ms
2014-07-13 18:23:49,680 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15084ms
2014-07-13 18:23:49,681 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15085ms
2014-07-13 18:23:49,681 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15085ms
2014-07-13 18:23:49,759 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,791 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:23:49,792 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:23:49,797 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,819 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,863 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,901 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,901 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,907 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,907 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,920 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,954 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:49,955 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:23:50,743 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:23:50,753 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,758 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,764 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,765 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,766 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:23:50,780 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,814 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,854 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15003ms
2014-07-13 18:23:50,854 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,864 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:50,878 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:51,010 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:23:54,653 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16344, memsize=504.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/029d0fa439064c459536c5de8f3d3309
2014-07-13 18:23:54,670 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/029d0fa439064c459536c5de8f3d3309 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/029d0fa439064c459536c5de8f3d3309
2014-07-13 18:23:54,672 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20016ms
2014-07-13 18:23:54,672 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20074ms
2014-07-13 18:23:54,673 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20079ms
2014-07-13 18:23:54,674 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20062ms
2014-07-13 18:23:54,674 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20151ms
2014-07-13 18:23:54,674 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20132ms
2014-07-13 18:23:54,674 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20051ms
2014-07-13 18:23:54,674 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20032ms
2014-07-13 18:23:54,674 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20026ms
2014-07-13 18:23:54,675 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20026ms
2014-07-13 18:23:54,675 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20151ms
2014-07-13 18:23:54,676 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20139ms
2014-07-13 18:23:54,676 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20148ms
2014-07-13 18:23:54,676 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20149ms
2014-07-13 18:23:54,677 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20151ms
2014-07-13 18:23:54,678 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20127ms
2014-07-13 18:23:54,678 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20104ms
2014-07-13 18:23:54,678 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20107ms
2014-07-13 18:23:54,679 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20084ms
2014-07-13 18:23:54,679 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20085ms
2014-07-13 18:23:54,680 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20084ms
2014-07-13 18:23:54,681 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20085ms
2014-07-13 18:23:54,681 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20085ms
2014-07-13 18:23:54,682 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20085ms
2014-07-13 18:23:54,684 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/029d0fa439064c459536c5de8f3d3309, entries=1836890, sequenceid=16344, filesize=130.9m
2014-07-13 18:23:54,684 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~974.7m/1021995120, currentsize=26.7m/27958480 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 21363ms, sequenceid=16344, compaction requested=true
2014-07-13 18:23:54,684 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:174), split_queue=0, merge_queue=0
2014-07-13 18:23:54,684 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20088ms
2014-07-13 18:23:54,685 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,685 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20089ms
2014-07-13 18:23:54,685 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,685 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20089ms
2014-07-13 18:23:54,685 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,685 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20089ms
2014-07-13 18:23:54,685 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,685 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20091ms
2014-07-13 18:23:54,685 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,689 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20094ms
2014-07-13 18:23:54,689 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,689 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20118ms
2014-07-13 18:23:54,689 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,689 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20115ms
2014-07-13 18:23:54,689 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,689 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20138ms
2014-07-13 18:23:54,689 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,690 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20164ms
2014-07-13 18:23:54,690 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,690 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20163ms
2014-07-13 18:23:54,690 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,692 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20164ms
2014-07-13 18:23:54,693 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,693 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20156ms
2014-07-13 18:23:54,693 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,693 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20169ms
2014-07-13 18:23:54,693 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,709 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20060ms
2014-07-13 18:23:54,709 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,709 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20061ms
2014-07-13 18:23:54,709 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,713 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20071ms
2014-07-13 18:23:54,713 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,714 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20091ms
2014-07-13 18:23:54,715 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,715 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20173ms
2014-07-13 18:23:54,715 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,715 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20192ms
2014-07-13 18:23:54,715 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,716 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20105ms
2014-07-13 18:23:54,716 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,716 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20122ms
2014-07-13 18:23:54,716 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,718 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20120ms
2014-07-13 18:23:54,718 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,718 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20062ms
2014-07-13 18:23:54,718 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,725 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18716ms
2014-07-13 18:23:54,725 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,737 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18860ms
2014-07-13 18:23:54,737 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,738 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18875ms
2014-07-13 18:23:54,738 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,741 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18888ms
2014-07-13 18:23:54,741 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,741 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18890ms
2014-07-13 18:23:54,741 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,741 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18928ms
2014-07-13 18:23:54,741 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,743 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18964ms
2014-07-13 18:23:54,743 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,743 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18979ms
2014-07-13 18:23:54,743 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,744 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18980ms
2014-07-13 18:23:54,745 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,745 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18982ms
2014-07-13 18:23:54,745 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,745 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18988ms
2014-07-13 18:23:54,745 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,745 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 18993ms
2014-07-13 18:23:54,745 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,749 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19008ms
2014-07-13 18:23:54,749 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,749 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19794ms
2014-07-13 18:23:54,749 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,749 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19796ms
2014-07-13 18:23:54,749 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,760 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:23:54,760 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,761 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19843ms
2014-07-13 18:23:54,761 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,769 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19863ms
2014-07-13 18:23:54,769 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,769 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19863ms
2014-07-13 18:23:54,769 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,773 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19873ms
2014-07-13 18:23:54,773 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,773 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19874ms
2014-07-13 18:23:54,773 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,773 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19911ms
2014-07-13 18:23:54,773 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,773 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19955ms
2014-07-13 18:23:54,773 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,776 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19980ms
2014-07-13 18:23:54,776 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,776 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19986ms
2014-07-13 18:23:54,777 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,777 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 19988ms
2014-07-13 18:23:54,777 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:23:54,833 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20899,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301013933,"queuetimems":0,"class":"HRegionServer","responsesize":15860,"method":"Multi"}
2014-07-13 18:23:54,881 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20393,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014487,"queuetimems":0,"class":"HRegionServer","responsesize":11422,"method":"Multi"}
2014-07-13 18:23:55,162 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20611,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014550,"queuetimems":0,"class":"HRegionServer","responsesize":5074,"method":"Multi"}
2014-07-13 18:23:55,162 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20867,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014294,"queuetimems":0,"class":"HRegionServer","responsesize":14547,"method":"Multi"}
2014-07-13 18:23:55,162 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20695,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014467,"queuetimems":0,"class":"HRegionServer","responsesize":12161,"method":"Multi"}
2014-07-13 18:23:55,162 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20839,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014322,"queuetimems":0,"class":"HRegionServer","responsesize":11875,"method":"Multi"}
2014-07-13 18:23:55,162 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014573,"queuetimems":0,"class":"HRegionServer","responsesize":3343,"method":"Multi"}
2014-07-13 18:23:55,169 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20725,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014444,"queuetimems":0,"class":"HRegionServer","responsesize":1801,"method":"Multi"}
2014-07-13 18:23:55,169 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014338,"queuetimems":0,"class":"HRegionServer","responsesize":6139,"method":"Multi"}
2014-07-13 18:23:55,182 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20670,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014511,"queuetimems":0,"class":"HRegionServer","responsesize":13380,"method":"Multi"}
2014-07-13 18:23:56,145 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014595,"queuetimems":0,"class":"HRegionServer","responsesize":558,"method":"Multi"}
2014-07-13 18:23:56,145 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21898,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014246,"queuetimems":1,"class":"HRegionServer","responsesize":15179,"method":"Multi"}
2014-07-13 18:23:56,145 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21551,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014594,"queuetimems":0,"class":"HRegionServer","responsesize":11000,"method":"Multi"}
2014-07-13 18:23:56,145 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22111,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014034,"queuetimems":0,"class":"HRegionServer","responsesize":15665,"method":"Multi"}
2014-07-13 18:23:56,158 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21588,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014569,"queuetimems":0,"class":"HRegionServer","responsesize":10678,"method":"Multi"}
2014-07-13 18:23:56,392 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:56,393 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20628,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015764,"queuetimems":0,"class":"HRegionServer","responsesize":2164,"method":"Multi"}
2014-07-13 18:23:56,393 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20640,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015752,"queuetimems":2,"class":"HRegionServer","responsesize":1420,"method":"Multi"}
2014-07-13 18:23:56,394 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21753,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014640,"queuetimems":0,"class":"HRegionServer","responsesize":7706,"method":"Multi"}
2014-07-13 18:23:56,394 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20532,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015861,"queuetimems":0,"class":"HRegionServer","responsesize":4656,"method":"Multi"}
2014-07-13 18:23:56,394 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21605,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014789,"queuetimems":0,"class":"HRegionServer","responsesize":3318,"method":"Multi"}
2014-07-13 18:23:56,394 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20389,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301016005,"queuetimems":0,"class":"HRegionServer","responsesize":4565,"method":"Multi"}
2014-07-13 18:23:56,395 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21443,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014951,"queuetimems":0,"class":"HRegionServer","responsesize":14468,"method":"Multi"}
2014-07-13 18:23:56,395 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20644,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015751,"queuetimems":2,"class":"HRegionServer","responsesize":16605,"method":"Multi"}
2014-07-13 18:23:56,394 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21784,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014609,"queuetimems":0,"class":"HRegionServer","responsesize":9560,"method":"Multi"}
2014-07-13 18:23:56,397 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21642,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014755,"queuetimems":0,"class":"HRegionServer","responsesize":11891,"method":"Multi"}
2014-07-13 18:23:56,397 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014541,"queuetimems":0,"class":"HRegionServer","responsesize":4731,"method":"Multi"}
2014-07-13 18:23:56,398 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21603,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014795,"queuetimems":0,"class":"HRegionServer","responsesize":3712,"method":"Multi"}
2014-07-13 18:23:56,399 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21481,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014917,"queuetimems":0,"class":"HRegionServer","responsesize":3871,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20556,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015851,"queuetimems":1,"class":"HRegionServer","responsesize":756,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21454,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014953,"queuetimems":1,"class":"HRegionServer","responsesize":1304,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21502,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014906,"queuetimems":0,"class":"HRegionServer","responsesize":590,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20630,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015778,"queuetimems":1,"class":"HRegionServer","responsesize":7766,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21503,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014905,"queuetimems":0,"class":"HRegionServer","responsesize":3570,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21508,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014899,"queuetimems":0,"class":"HRegionServer","responsesize":408,"method":"Multi"}
2014-07-13 18:23:56,408 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20644,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015763,"queuetimems":1,"class":"HRegionServer","responsesize":202,"method":"Multi"}
2014-07-13 18:23:56,417 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21600,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014817,"queuetimems":1,"class":"HRegionServer","responsesize":8148,"method":"Multi"}
2014-07-13 18:23:56,418 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21795,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014622,"queuetimems":0,"class":"HRegionServer","responsesize":5908,"method":"Multi"}
2014-07-13 18:23:56,418 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20542,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015875,"queuetimems":0,"class":"HRegionServer","responsesize":8121,"method":"Multi"}
2014-07-13 18:23:56,488 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65501 synced till here 65476
2014-07-13 18:23:56,565 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22121,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014443,"queuetimems":0,"class":"HRegionServer","responsesize":18022,"method":"Multi"}
2014-07-13 18:23:56,565 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21778,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014786,"queuetimems":0,"class":"HRegionServer","responsesize":15370,"method":"Multi"}
2014-07-13 18:23:56,574 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22625,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301013948,"queuetimems":0,"class":"HRegionServer","responsesize":19659,"method":"Multi"}
2014-07-13 18:23:56,577 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22166,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014410,"queuetimems":1,"class":"HRegionServer","responsesize":16250,"method":"Multi"}
2014-07-13 18:23:56,605 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22224,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014381,"queuetimems":1,"class":"HRegionServer","responsesize":18613,"method":"Multi"}
2014-07-13 18:23:56,619 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301014653 with entries=128, filesize=91.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301036393
2014-07-13 18:23:57,088 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22552,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014535,"queuetimems":0,"class":"HRegionServer","responsesize":15252,"method":"Multi"}
2014-07-13 18:23:57,579 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21840,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015739,"queuetimems":0,"class":"HRegionServer","responsesize":15179,"method":"Multi"}
2014-07-13 18:23:57,582 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21819,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015762,"queuetimems":0,"class":"HRegionServer","responsesize":15934,"method":"Multi"}
2014-07-13 18:23:57,593 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21743,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015850,"queuetimems":1,"class":"HRegionServer","responsesize":15836,"method":"Multi"}
2014-07-13 18:23:57,695 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22833,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014861,"queuetimems":1,"class":"HRegionServer","responsesize":15668,"method":"Multi"}
2014-07-13 18:23:57,698 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22799,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301014898,"queuetimems":0,"class":"HRegionServer","responsesize":15626,"method":"Multi"}
2014-07-13 18:23:57,698 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301015811,"queuetimems":0,"class":"HRegionServer","responsesize":15655,"method":"Multi"}
2014-07-13 18:23:58,001 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:23:58,290 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65674 synced till here 65653
2014-07-13 18:23:58,560 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301036393 with entries=173, filesize=127.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301038001
2014-07-13 18:23:59,852 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:00,839 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65835 synced till here 65786
2014-07-13 18:24:01,201 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301038001 with entries=161, filesize=123.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301039853
2014-07-13 18:24:02,802 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:02,814 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:24:02,815 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files, but is 968.1m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:24:02,815 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. due to global heap pressure
2014-07-13 18:24:02,815 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 968.1m
2014-07-13 18:24:02,856 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 65965 synced till here 65935
2014-07-13 18:24:03,067 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301039853 with entries=130, filesize=98.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301042802
2014-07-13 18:24:03,859 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:03,905 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:24:04,323 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,362 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,364 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,364 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,364 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,370 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,371 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,378 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,383 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66087 synced till here 66078
2014-07-13 18:24:04,476 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,483 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,484 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,485 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,485 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,488 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301042802 with entries=122, filesize=87.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301043859
2014-07-13 18:24:04,489 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,491 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,492 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,544 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:24:04,549 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,656 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,657 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,657 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,657 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,657 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,658 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,658 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,658 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,659 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,660 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,660 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,660 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,660 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,661 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,661 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,662 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,663 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,663 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,663 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,665 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,665 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,665 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,665 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,666 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,695 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,697 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,697 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,698 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,698 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,698 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,700 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,700 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:04,702 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:07,062 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16381, memsize=717.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/67a4bf0fceb849a5829d57fcacc38683
2014-07-13 18:24:07,103 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/67a4bf0fceb849a5829d57fcacc38683 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/67a4bf0fceb849a5829d57fcacc38683
2014-07-13 18:24:07,123 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/67a4bf0fceb849a5829d57fcacc38683, entries=2610950, sequenceid=16381, filesize=186.0m
2014-07-13 18:24:07,124 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.5g/1632371120, currentsize=318.9m/334385280 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 34560ms, sequenceid=16381, compaction requested=true
2014-07-13 18:24:07,124 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:175), split_queue=0, merge_queue=0
2014-07-13 18:24:07,124 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2422ms
2014-07-13 18:24:07,124 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:24:07,124 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,124 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:176), split_queue=0, merge_queue=0
2014-07-13 18:24:07,124 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2424ms
2014-07-13 18:24:07,124 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,125 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2424ms
2014-07-13 18:24:07,125 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,129 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2431ms
2014-07-13 18:24:07,129 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,129 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2431ms
2014-07-13 18:24:07,129 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,129 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2431ms
2014-07-13 18:24:07,129 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,129 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2432ms
2014-07-13 18:24:07,129 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,129 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2432ms
2014-07-13 18:24:07,129 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,130 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2435ms
2014-07-13 18:24:07,130 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,130 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2464ms
2014-07-13 18:24:07,130 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,133 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2468ms
2014-07-13 18:24:07,133 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,136 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2471ms
2014-07-13 18:24:07,136 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,136 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2473ms
2014-07-13 18:24:07,136 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,141 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2476ms
2014-07-13 18:24:07,141 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,141 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2478ms
2014-07-13 18:24:07,141 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,141 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2478ms
2014-07-13 18:24:07,141 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,145 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2482ms
2014-07-13 18:24:07,145 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,145 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2483ms
2014-07-13 18:24:07,145 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,145 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2484ms
2014-07-13 18:24:07,145 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,145 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2484ms
2014-07-13 18:24:07,145 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,146 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2485ms
2014-07-13 18:24:07,146 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,147 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2487ms
2014-07-13 18:24:07,147 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,149 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2492ms
2014-07-13 18:24:07,149 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,149 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2490ms
2014-07-13 18:24:07,149 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,150 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2491ms
2014-07-13 18:24:07,150 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,150 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2493ms
2014-07-13 18:24:07,150 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,150 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2492ms
2014-07-13 18:24:07,150 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,153 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2495ms
2014-07-13 18:24:07,153 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,153 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2497ms
2014-07-13 18:24:07,153 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,159 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2502ms
2014-07-13 18:24:07,160 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,160 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2503ms
2014-07-13 18:24:07,160 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,160 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2503ms
2014-07-13 18:24:07,160 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,160 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2504ms
2014-07-13 18:24:07,160 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,161 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2613ms
2014-07-13 18:24:07,161 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,161 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2669ms
2014-07-13 18:24:07,161 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,161 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2670ms
2014-07-13 18:24:07,161 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,161 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2672ms
2014-07-13 18:24:07,161 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,162 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2677ms
2014-07-13 18:24:07,162 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,169 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2684ms
2014-07-13 18:24:07,169 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,169 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2685ms
2014-07-13 18:24:07,169 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,170 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2690ms
2014-07-13 18:24:07,170 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,171 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2695ms
2014-07-13 18:24:07,171 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,175 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2797ms
2014-07-13 18:24:07,175 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,175 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2811ms
2014-07-13 18:24:07,175 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,176 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2806ms
2014-07-13 18:24:07,176 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,176 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2812ms
2014-07-13 18:24:07,176 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,176 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2812ms
2014-07-13 18:24:07,177 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,177 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2813ms
2014-07-13 18:24:07,177 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,185 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2823ms
2014-07-13 18:24:07,185 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,189 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 2866ms
2014-07-13 18:24:07,189 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:24:07,214 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:24:07,217 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 319.6m
2014-07-13 18:24:08,303 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:08,358 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66204 synced till here 66166
2014-07-13 18:24:08,500 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:24:08,591 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301043859 with entries=117, filesize=82.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301048303
2014-07-13 18:24:08,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300887876
2014-07-13 18:24:08,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300889840
2014-07-13 18:24:08,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300891996
2014-07-13 18:24:08,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300920531
2014-07-13 18:24:08,591 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300921957
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300923379
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300924342
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300926243
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300927883
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300929200
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300930770
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300933175
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300935945
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300937278
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300938410
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300939440
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300941433
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300943010
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300944244
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300945494
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300946868
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300948644
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300950120
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300951604
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300952928
2014-07-13 18:24:08,592 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300954186
2014-07-13 18:24:09,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:09,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66321 synced till here 66291
2014-07-13 18:24:10,089 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301048303 with entries=117, filesize=90.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301049796
2014-07-13 18:24:10,697 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:10,762 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301049796 with entries=77, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301050697
2014-07-13 18:24:12,435 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16687, memsize=85.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ff8b912051b64a9aba4bb8314f4257c7
2014-07-13 18:24:12,455 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/ff8b912051b64a9aba4bb8314f4257c7 as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ff8b912051b64a9aba4bb8314f4257c7
2014-07-13 18:24:12,468 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ff8b912051b64a9aba4bb8314f4257c7, entries=311840, sequenceid=16687, filesize=22.2m
2014-07-13 18:24:12,468 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~328.5m/344427600, currentsize=85.5m/89701440 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 5251ms, sequenceid=16687, compaction requested=true
2014-07-13 18:24:12,468 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:177), split_queue=0, merge_queue=0
2014-07-13 18:24:12,468 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 94784ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:24:12,469 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 400.6m
2014-07-13 18:24:12,795 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:24:12,984 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:13,188 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66459 synced till here 66458
2014-07-13 18:24:13,290 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301050697 with entries=61, filesize=64.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301052985
2014-07-13 18:24:14,004 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:14,041 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66521 synced till here 66516
2014-07-13 18:24:14,562 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301052985 with entries=62, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301054004
2014-07-13 18:24:15,707 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:15,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301054004 with entries=110, filesize=63.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301055709
2014-07-13 18:24:16,809 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16550, memsize=74.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ddf049d7f1664c1581247076a2841c3c
2014-07-13 18:24:16,822 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/ddf049d7f1664c1581247076a2841c3c as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ddf049d7f1664c1581247076a2841c3c
2014-07-13 18:24:16,833 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ddf049d7f1664c1581247076a2841c3c, entries=272240, sequenceid=16550, filesize=19.4m
2014-07-13 18:24:16,834 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~402.7m/422230640, currentsize=89.3m/93677920 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 4365ms, sequenceid=16550, compaction requested=true
2014-07-13 18:24:16,834 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:178), split_queue=0, merge_queue=0
2014-07-13 18:24:17,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:17,143 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66729 synced till here 66728
2014-07-13 18:24:17,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301055709 with entries=98, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301057127
2014-07-13 18:24:18,670 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:18,695 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66806 synced till here 66802
2014-07-13 18:24:18,751 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301057127 with entries=77, filesize=67.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301058670
2014-07-13 18:24:19,955 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:20,149 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301058670 with entries=102, filesize=75.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301059955
2014-07-13 18:24:20,948 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:24:20,949 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:24:20,949 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:179), split_queue=0, merge_queue=0
2014-07-13 18:24:21,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:21,359 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 66972 synced till here 66969
2014-07-13 18:24:21,396 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301059955 with entries=64, filesize=65.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301061339
2014-07-13 18:24:22,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:22,670 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67037 synced till here 67033
2014-07-13 18:24:22,703 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301061339 with entries=65, filesize=66.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301062650
2014-07-13 18:24:23,907 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:24,022 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67113 synced till here 67111
2014-07-13 18:24:24,025 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16620, memsize=428.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a937b577d1b84d21b040935fb71b5411
2014-07-13 18:24:24,048 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a937b577d1b84d21b040935fb71b5411 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a937b577d1b84d21b040935fb71b5411
2014-07-13 18:24:24,174 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301062650 with entries=76, filesize=69.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301063908
2014-07-13 18:24:24,239 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a937b577d1b84d21b040935fb71b5411, entries=1558370, sequenceid=16620, filesize=111.0m
2014-07-13 18:24:24,240 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~990.5m/1038584480, currentsize=409.8m/429677360 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 21425ms, sequenceid=16620, compaction requested=true
2014-07-13 18:24:24,240 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:180), split_queue=0, merge_queue=0
2014-07-13 18:24:24,353 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:24:24,353 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:24:24,354 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:181), split_queue=0, merge_queue=0
2014-07-13 18:24:24,393 DEBUG [RpcServer.handler=32,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:24:24,393 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:24:24,393 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-13 18:24:25,360 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:25,385 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67206 synced till here 67188
2014-07-13 18:24:25,504 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301063908 with entries=93, filesize=79.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301065360
2014-07-13 18:24:25,504 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300957685
2014-07-13 18:24:25,512 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:26,733 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:26,758 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67285 synced till here 67274
2014-07-13 18:24:26,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301065360 with entries=79, filesize=77.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301066733
2014-07-13 18:24:26,914 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:27,132 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/66b9e545dbb543958b6e97b48a7f5758 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/66b9e545dbb543958b6e97b48a7f5758
2014-07-13 18:24:27,230 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:24:27,243 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/58aa8feadc994403ab24b7b054d826aa, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/58aa8feadc994403ab24b7b054d826aa
2014-07-13 18:24:27,247 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2ac8eb01e63e4cae9ecdc867bd6f0451, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/2ac8eb01e63e4cae9ecdc867bd6f0451
2014-07-13 18:24:27,313 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/40c6ac76a9c84c9480f9303749e8288e, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/40c6ac76a9c84c9480f9303749e8288e
2014-07-13 18:24:27,317 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4d66ddb5e67a4e6d907ce7df278504e7, to hdfs://master:54310/hbase/archive/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/4d66ddb5e67a4e6d907ce7df278504e7
2014-07-13 18:24:27,317 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. into 66b9e545dbb543958b6e97b48a7f5758(size=324.6m), total size for store is 3.8g. This selection was in queue for 0sec, and took 59sec to execute.
2014-07-13 18:24:27,317 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., storeName=family, fileCount=4, fileSize=332.1m, priority=-2, time=254915396085986; duration=59sec
2014-07-13 18:24:27,317 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-13 18:24:27,318 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-13 18:24:27,318 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 238647105 starting at candidate #19 after considering 140 permutations with 119 in ratio
2014-07-13 18:24:27,319 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: c8c427e222de992c0f6302092c0a1292 - family: Initiating minor compaction
2014-07-13 18:24:27,319 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:24:27,319 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp, totalSize=227.6m
2014-07-13 18:24:27,319 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d9256d86cef44d1e87044123ffc35683, keycount=21482, bloomtype=ROW, size=15.3m, encoding=NONE, seqNum=15541
2014-07-13 18:24:27,319 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f0fa1876b2634b45acbcfd01bf30fb71, keycount=87062, bloomtype=ROW, size=62.0m, encoding=NONE, seqNum=15702
2014-07-13 18:24:27,319 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/029d0fa439064c459536c5de8f3d3309, keycount=183689, bloomtype=ROW, size=130.9m, encoding=NONE, seqNum=16344
2014-07-13 18:24:27,319 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ddf049d7f1664c1581247076a2841c3c, keycount=27224, bloomtype=ROW, size=19.4m, encoding=NONE, seqNum=16550
2014-07-13 18:24:27,358 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:24:28,480 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:28,610 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67356 synced till here 67354
2014-07-13 18:24:28,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301066733 with entries=71, filesize=72.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301068481
2014-07-13 18:24:28,637 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:29,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:29,724 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67421 synced till here 67419
2014-07-13 18:24:29,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301068481 with entries=65, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301069691
2014-07-13 18:24:29,757 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:31,137 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:31,297 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67497 synced till here 67480
2014-07-13 18:24:31,493 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301069691 with entries=76, filesize=78.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301071137
2014-07-13 18:24:31,494 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:33,453 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:33,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67577 synced till here 67574
2014-07-13 18:24:33,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301071137 with entries=80, filesize=65.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301073453
2014-07-13 18:24:33,537 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:34,776 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:34,806 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67639 synced till here 67636
2014-07-13 18:24:34,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301073453 with entries=62, filesize=64.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301074777
2014-07-13 18:24:34,909 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:35,734 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:35,863 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67714 synced till here 67708
2014-07-13 18:24:36,372 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301074777 with entries=75, filesize=70.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301075735
2014-07-13 18:24:36,374 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:37,211 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:37,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67779 synced till here 67775
2014-07-13 18:24:37,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301075735 with entries=65, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301077211
2014-07-13 18:24:37,350 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:39,021 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:39,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301077211 with entries=81, filesize=83.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301079021
2014-07-13 18:24:39,139 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=48, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:41,265 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:41,363 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 67937 synced till here 67928
2014-07-13 18:24:41,514 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301079021 with entries=77, filesize=71.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301081265
2014-07-13 18:24:41,515 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=49, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:24:42,993 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:42,999 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:24:42,999 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. due to global heap pressure
2014-07-13 18:24:42,999 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 1.7g
2014-07-13 18:24:43,158 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68018 synced till here 67996
2014-07-13 18:24:43,195 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:24:43,195 DEBUG [MemStoreFlusher.1] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files, but is 791.2m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:24:43,196 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. due to global heap pressure
2014-07-13 18:24:43,196 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 791.2m
2014-07-13 18:24:43,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301081265 with entries=81, filesize=85.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301082994
2014-07-13 18:24:44,293 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:24:44,617 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:24:45,035 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68093 synced till here 68090
2014-07-13 18:24:45,068 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301082994 with entries=75, filesize=76.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301084618
2014-07-13 18:24:45,507 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,512 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,526 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,541 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,544 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,565 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,582 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,586 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,586 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,591 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,612 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,612 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,626 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,639 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:24:45,639 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,669 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,678 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,687 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,692 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,714 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,722 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,728 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,755 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,783 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,786 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,809 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,825 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,834 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,852 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,862 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,901 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,927 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,952 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,958 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,981 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,983 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:45,997 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,020 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,036 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,059 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,117 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,126 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,281 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,282 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,302 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,310 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,404 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,450 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,473 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,490 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:46,515 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:24:50,507 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,512 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,526 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,542 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,544 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,565 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,583 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,587 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,587 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,592 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,612 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,613 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,627 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,639 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,669 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,678 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,688 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,692 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,714 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,722 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,728 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,755 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,784 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,786 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,809 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,826 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,834 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,852 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,862 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,902 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,927 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,952 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,958 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,981 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:50,984 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:50,997 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,021 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,037 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:51,059 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,118 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,127 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,282 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:51,282 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,303 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:51,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:51,404 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:51,450 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,474 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:24:51,490 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:51,515 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:24:55,507 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,513 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,527 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:24:55,542 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,544 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,565 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,583 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,587 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,588 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,592 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,613 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,613 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,627 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,640 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,670 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,679 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,688 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,692 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,714 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,723 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,728 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,755 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,784 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,786 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,809 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,826 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,835 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,852 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,862 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,902 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,928 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,952 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,959 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,981 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:55,984 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:55,998 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,021 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,037 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,059 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:56,118 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,127 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,282 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,283 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,303 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,404 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,451 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,474 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:24:56,490 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:24:56,516 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:00,508 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,513 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,527 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,542 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,545 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:25:00,566 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,584 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,587 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,588 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,593 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,613 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,613 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,627 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,640 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,670 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,679 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,688 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,693 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,715 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,723 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,729 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,756 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,784 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,787 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,810 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,826 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,835 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,853 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:25:00,863 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,903 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:00,928 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,952 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:25:00,959 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,982 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,985 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:00,998 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,021 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,037 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,059 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:25:01,118 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,127 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,282 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,283 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,304 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:01,311 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,404 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,451 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:01,475 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15002ms
2014-07-13 18:25:01,490 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:25:01,516 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:25:04,771 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/d0101d5e77ab4718beb8a6ac1a350d9b as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d0101d5e77ab4718beb8a6ac1a350d9b
2014-07-13 18:25:04,788 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:25:04,796 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d9256d86cef44d1e87044123ffc35683, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/d9256d86cef44d1e87044123ffc35683
2014-07-13 18:25:04,801 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f0fa1876b2634b45acbcfd01bf30fb71, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/f0fa1876b2634b45acbcfd01bf30fb71
2014-07-13 18:25:04,802 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/029d0fa439064c459536c5de8f3d3309, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/029d0fa439064c459536c5de8f3d3309
2014-07-13 18:25:04,807 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ddf049d7f1664c1581247076a2841c3c, to hdfs://master:54310/hbase/archive/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/ddf049d7f1664c1581247076a2841c3c
2014-07-13 18:25:04,807 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 4 file(s) in family of usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. into d0101d5e77ab4718beb8a6ac1a350d9b(size=210.7m), total size for store is 3.9g. This selection was in queue for 0sec, and took 37sec to execute.
2014-07-13 18:25:04,808 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., storeName=family, fileCount=4, fileSize=227.6m, priority=-3, time=254974745949900; duration=37sec
2014-07-13 18:25:04,808 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-13 18:25:04,808 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-13 18:25:04,808 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 23 store files, 0 compacting, 23 eligible, 20 blocking
2014-07-13 18:25:04,809 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 195461129 starting at candidate #18 after considering 140 permutations with 114 in ratio
2014-07-13 18:25:04,809 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:25:04,810 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:25:04,810 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=186.4m
2014-07-13 18:25:04,810 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/19a4fe9c651e46de89825fe526b5e811, keycount=197176, bloomtype=ROW, size=140.4m, encoding=NONE, seqNum=14443
2014-07-13 18:25:04,810 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e6569c38471f4cf5a6db13763340944a, keycount=44541, bloomtype=ROW, size=31.7m, encoding=NONE, seqNum=14817
2014-07-13 18:25:04,810 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ef28881c66f34fcbb3db999fec0bf168, keycount=20079, bloomtype=ROW, size=14.3m, encoding=NONE, seqNum=14844
2014-07-13 18:25:04,854 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:25:05,509 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:25:05,513 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,527 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,542 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,545 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,566 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,584 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,587 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,589 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,593 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,613 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,614 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,628 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,640 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,670 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,680 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,688 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,693 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,715 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,723 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,730 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20003ms
2014-07-13 18:25:05,756 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,785 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,787 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,810 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,827 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,835 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,853 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,863 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,903 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,928 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,953 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,959 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,982 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:05,985 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:05,998 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:06,021 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:06,037 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:06,060 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:06,119 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20001ms
2014-07-13 18:25:06,128 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20002ms
2014-07-13 18:25:06,658 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20143ms
2014-07-13 18:25:06,659 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20209ms
2014-07-13 18:25:06,659 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20357ms
2014-07-13 18:25:06,659 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20186ms
2014-07-13 18:25:06,659 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20169ms
2014-07-13 18:25:06,660 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20378ms
2014-07-13 18:25:06,660 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20378ms
2014-07-13 18:25:06,660 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20350ms
2014-07-13 18:25:06,660 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20257ms
2014-07-13 18:25:06,924 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17180, memsize=601.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/71ee879419a543bc96060d84f6e82e6a
2014-07-13 18:25:06,938 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/71ee879419a543bc96060d84f6e82e6a as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/71ee879419a543bc96060d84f6e82e6a
2014-07-13 18:25:07,220 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/71ee879419a543bc96060d84f6e82e6a, entries=2191300, sequenceid=17180, filesize=156.0m
2014-07-13 18:25:07,221 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~799.5m/838365440, currentsize=40.2m/42152160 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 24024ms, sequenceid=17180, compaction requested=true
2014-07-13 18:25:07,221 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:182), split_queue=0, merge_queue=0
2014-07-13 18:25:07,221 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20818ms
2014-07-13 18:25:07,221 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,221 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20911ms
2014-07-13 18:25:07,221 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 699.3m
2014-07-13 18:25:07,221 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,222 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20940ms
2014-07-13 18:25:07,222 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,233 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20952ms
2014-07-13 18:25:07,233 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,233 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20743ms
2014-07-13 18:25:07,233 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,233 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20760ms
2014-07-13 18:25:07,233 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,233 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20931ms
2014-07-13 18:25:07,233 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,249 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20799ms
2014-07-13 18:25:07,249 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,249 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 20734ms
2014-07-13 18:25:07,249 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,253 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21127ms
2014-07-13 18:25:07,253 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,253 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21136ms
2014-07-13 18:25:07,253 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,254 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21194ms
2014-07-13 18:25:07,254 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,254 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21218ms
2014-07-13 18:25:07,254 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,260 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21240ms
2014-07-13 18:25:07,260 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,261 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21263ms
2014-07-13 18:25:07,261 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,265 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21282ms
2014-07-13 18:25:07,265 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,265 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21284ms
2014-07-13 18:25:07,265 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,267 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21309ms
2014-07-13 18:25:07,267 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,269 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21317ms
2014-07-13 18:25:07,269 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,269 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21342ms
2014-07-13 18:25:07,269 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,269 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21368ms
2014-07-13 18:25:07,269 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,270 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21407ms
2014-07-13 18:25:07,270 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,273 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21421ms
2014-07-13 18:25:07,273 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,277 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21443ms
2014-07-13 18:25:07,277 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,277 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21452ms
2014-07-13 18:25:07,277 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,278 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21469ms
2014-07-13 18:25:07,278 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,278 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21493ms
2014-07-13 18:25:07,278 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,279 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21496ms
2014-07-13 18:25:07,279 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,280 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21525ms
2014-07-13 18:25:07,280 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,283 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21555ms
2014-07-13 18:25:07,283 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,283 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21561ms
2014-07-13 18:25:07,283 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,285 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21572ms
2014-07-13 18:25:07,285 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,285 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21594ms
2014-07-13 18:25:07,285 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,293 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21606ms
2014-07-13 18:25:07,293 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,297 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21619ms
2014-07-13 18:25:07,297 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,297 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21628ms
2014-07-13 18:25:07,297 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,301 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21662ms
2014-07-13 18:25:07,301 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,304 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21678ms
2014-07-13 18:25:07,304 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,309 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21697ms
2014-07-13 18:25:07,309 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,312 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21701ms
2014-07-13 18:25:07,312 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,317 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21726ms
2014-07-13 18:25:07,317 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,321 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21735ms
2014-07-13 18:25:07,321 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,322 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21735ms
2014-07-13 18:25:07,322 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,325 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21743ms
2014-07-13 18:25:07,325 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,325 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21760ms
2014-07-13 18:25:07,325 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,325 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21781ms
2014-07-13 18:25:07,325 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,328 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21787ms
2014-07-13 18:25:07,328 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,329 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21804ms
2014-07-13 18:25:07,329 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,333 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21821ms
2014-07-13 18:25:07,333 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,333 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 21827ms
2014-07-13 18:25:07,333 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:07,343 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":20940,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086403,"queuetimems":0,"class":"HRegionServer","responsesize":1256,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21334,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086282,"queuetimems":1,"class":"HRegionServer","responsesize":2159,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21127,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086489,"queuetimems":0,"class":"HRegionServer","responsesize":4489,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21306,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086310,"queuetimems":1,"class":"HRegionServer","responsesize":3306,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086473,"queuetimems":1,"class":"HRegionServer","responsesize":3215,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22129,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085487,"queuetimems":0,"class":"HRegionServer","responsesize":12464,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22169,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085447,"queuetimems":0,"class":"HRegionServer","responsesize":14139,"method":"Multi"}
2014-07-13 18:25:07,616 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22822,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301084794,"queuetimems":1,"class":"HRegionServer","responsesize":10836,"method":"Multi"}
2014-07-13 18:25:07,778 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22313,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085465,"queuetimems":1,"class":"HRegionServer","responsesize":3964,"method":"Multi"}
2014-07-13 18:25:07,778 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086279,"queuetimems":0,"class":"HRegionServer","responsesize":7559,"method":"Multi"}
2014-07-13 18:25:07,778 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22727,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085051,"queuetimems":0,"class":"HRegionServer","responsesize":16752,"method":"Multi"}
2014-07-13 18:25:07,778 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22317,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085461,"queuetimems":0,"class":"HRegionServer","responsesize":16509,"method":"Multi"}
2014-07-13 18:25:07,860 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:25:07,869 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21888,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085981,"queuetimems":0,"class":"HRegionServer","responsesize":476,"method":"Multi"}
2014-07-13 18:25:07,890 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21894,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085995,"queuetimems":0,"class":"HRegionServer","responsesize":8536,"method":"Multi"}
2014-07-13 18:25:08,015 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:08,017 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22290,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085726,"queuetimems":0,"class":"HRegionServer","responsesize":4045,"method":"Multi"}
2014-07-13 18:25:08,017 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21891,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086125,"queuetimems":0,"class":"HRegionServer","responsesize":3644,"method":"Multi"}
2014-07-13 18:25:08,017 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22340,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085676,"queuetimems":0,"class":"HRegionServer","responsesize":3773,"method":"Multi"}
2014-07-13 18:25:08,017 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086450,"queuetimems":1,"class":"HRegionServer","responsesize":1999,"method":"Multi"}
2014-07-13 18:25:08,017 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21716,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086301,"queuetimems":0,"class":"HRegionServer","responsesize":5833,"method":"Multi"}
2014-07-13 18:25:08,017 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21901,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086116,"queuetimems":1,"class":"HRegionServer","responsesize":5578,"method":"Multi"}
2014-07-13 18:25:08,019 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21963,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086056,"queuetimems":0,"class":"HRegionServer","responsesize":12088,"method":"Multi"}
2014-07-13 18:25:08,020 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21505,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086515,"queuetimems":0,"class":"HRegionServer","responsesize":1071,"method":"Multi"}
2014-07-13 18:25:08,136 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68223 synced till here 68182
2014-07-13 18:25:08,223 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22531,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085691,"queuetimems":0,"class":"HRegionServer","responsesize":3438,"method":"Multi"}
2014-07-13 18:25:08,223 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23469,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301084754,"queuetimems":0,"class":"HRegionServer","responsesize":15826,"method":"Multi"}
2014-07-13 18:25:08,223 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22243,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085980,"queuetimems":0,"class":"HRegionServer","responsesize":13027,"method":"Multi"}
2014-07-13 18:25:08,229 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22445,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085784,"queuetimems":0,"class":"HRegionServer","responsesize":3543,"method":"Multi"}
2014-07-13 18:25:08,229 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22397,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085832,"queuetimems":0,"class":"HRegionServer","responsesize":5865,"method":"Multi"}
2014-07-13 18:25:08,241 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22630,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085611,"queuetimems":0,"class":"HRegionServer","responsesize":1450,"method":"Multi"}
2014-07-13 18:25:08,241 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22285,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085956,"queuetimems":0,"class":"HRegionServer","responsesize":5451,"method":"Multi"}
2014-07-13 18:25:08,241 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22555,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085686,"queuetimems":0,"class":"HRegionServer","responsesize":3386,"method":"Multi"}
2014-07-13 18:25:08,241 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085524,"queuetimems":1,"class":"HRegionServer","responsesize":5930,"method":"Multi"}
2014-07-13 18:25:08,242 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22631,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085610,"queuetimems":0,"class":"HRegionServer","responsesize":10338,"method":"Multi"}
2014-07-13 18:25:08,243 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22319,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085924,"queuetimems":1,"class":"HRegionServer","responsesize":14611,"method":"Multi"}
2014-07-13 18:25:08,250 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22301,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085948,"queuetimems":0,"class":"HRegionServer","responsesize":13302,"method":"Multi"}
2014-07-13 18:25:08,250 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22400,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085850,"queuetimems":1,"class":"HRegionServer","responsesize":8572,"method":"Multi"}
2014-07-13 18:25:08,253 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22587,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085666,"queuetimems":0,"class":"HRegionServer","responsesize":10022,"method":"Multi"}
2014-07-13 18:25:08,250 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22498,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085751,"queuetimems":0,"class":"HRegionServer","responsesize":11335,"method":"Multi"}
2014-07-13 18:25:09,005 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22971,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086034,"queuetimems":0,"class":"HRegionServer","responsesize":10303,"method":"Multi"}
2014-07-13 18:25:09,006 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085823,"queuetimems":0,"class":"HRegionServer","responsesize":9086,"method":"Multi"}
2014-07-13 18:25:09,007 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23285,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085721,"queuetimems":0,"class":"HRegionServer","responsesize":6109,"method":"Multi"}
2014-07-13 18:25:09,007 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22989,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301086017,"queuetimems":0,"class":"HRegionServer","responsesize":12461,"method":"Multi"}
2014-07-13 18:25:09,006 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23496,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085510,"queuetimems":0,"class":"HRegionServer","responsesize":7515,"method":"Multi"}
2014-07-13 18:25:09,007 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23147,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085860,"queuetimems":0,"class":"HRegionServer","responsesize":6245,"method":"Multi"}
2014-07-13 18:25:09,009 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23112,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085897,"queuetimems":0,"class":"HRegionServer","responsesize":13065,"method":"Multi"}
2014-07-13 18:25:09,014 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23425,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085589,"queuetimems":0,"class":"HRegionServer","responsesize":10556,"method":"Multi"}
2014-07-13 18:25:09,015 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23304,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085710,"queuetimems":0,"class":"HRegionServer","responsesize":9878,"method":"Multi"}
2014-07-13 18:25:09,017 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085803,"queuetimems":0,"class":"HRegionServer","responsesize":9631,"method":"Multi"}
2014-07-13 18:25:09,018 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23379,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085638,"queuetimems":1,"class":"HRegionServer","responsesize":8832,"method":"Multi"}
2014-07-13 18:25:09,017 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23455,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085562,"queuetimems":0,"class":"HRegionServer","responsesize":12469,"method":"Multi"}
2014-07-13 18:25:09,030 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301084618 with entries=130, filesize=105.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301108016
2014-07-13 18:25:09,291 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23511,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301085779,"queuetimems":0,"class":"HRegionServer","responsesize":12651,"method":"Multi"}
2014-07-13 18:25:09,834 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:10,542 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68338 synced till here 68329
2014-07-13 18:25:10,725 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301108016 with entries=115, filesize=85.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301109834
2014-07-13 18:25:12,065 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:12,140 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68463 synced till here 68432
2014-07-13 18:25:12,449 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301109834 with entries=125, filesize=105.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301112065
2014-07-13 18:25:13,550 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:13,572 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68574 synced till here 68553
2014-07-13 18:25:13,863 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301112065 with entries=111, filesize=89.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301113550
2014-07-13 18:25:14,401 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:25:15,067 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:15,071 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,071 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,071 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,072 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,073 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,073 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,073 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,073 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,074 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,084 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68699 synced till here 68664
2014-07-13 18:25:15,216 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,217 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,217 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,219 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,220 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,220 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,220 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,222 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,223 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,224 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,224 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,225 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,226 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,227 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,227 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,307 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,309 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,310 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,310 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,311 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,311 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,312 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,312 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,312 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,313 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,313 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,313 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,314 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,319 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,319 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,320 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,320 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,320 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,320 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,320 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,320 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,321 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,321 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,321 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,322 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:15,322 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301113550 with entries=125, filesize=98.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301115068
2014-07-13 18:25:15,341 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:20,071 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,071 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,072 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,072 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,073 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,073 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,073 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,073 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,074 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,217 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,217 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,217 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,220 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,220 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,220 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,221 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,223 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,224 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,224 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,225 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,226 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,226 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,227 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,228 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,307 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,310 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,310 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,310 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,311 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,311 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,312 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,312 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,313 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,313 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,313 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,314 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,319 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5010ms
2014-07-13 18:25:20,320 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,320 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,320 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,320 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,320 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,320 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5003ms
2014-07-13 18:25:20,321 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,321 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5004ms
2014-07-13 18:25:20,321 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5005ms
2014-07-13 18:25:20,321 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5011ms
2014-07-13 18:25:20,321 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:25:20,322 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:20,341 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:25:25,071 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,072 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,072 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,072 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,073 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,073 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,073 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,074 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,074 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,217 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,218 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,218 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,220 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,220 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,221 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,221 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,223 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,224 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,225 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,226 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10002ms
2014-07-13 18:25:25,226 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,227 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,228 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,228 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,307 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,310 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,310 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,311 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,311 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,312 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,313 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,313 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,313 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,313 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,313 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,314 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,320 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10011ms
2014-07-13 18:25:25,320 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,320 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,321 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,322 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,322 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10005ms
2014-07-13 18:25:25,322 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:25:25,322 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:25:25,323 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:25:25,323 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10003ms
2014-07-13 18:25:25,323 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10013ms
2014-07-13 18:25:25,323 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10007ms
2014-07-13 18:25:25,324 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10006ms
2014-07-13 18:25:25,341 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:25:25,509 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16933, memsize=982.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/9c99a604b0d1479e98552bb28c456a16
2014-07-13 18:25:25,527 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/9c99a604b0d1479e98552bb28c456a16 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9c99a604b0d1479e98552bb28c456a16
2014-07-13 18:25:25,542 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/9c99a604b0d1479e98552bb28c456a16, entries=3577170, sequenceid=16933, filesize=254.7m
2014-07-13 18:25:25,542 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.7g/1796365600, currentsize=231.4m/242613920 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 42543ms, sequenceid=16933, compaction requested=true
2014-07-13 18:25:25,542 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:183), split_queue=0, merge_queue=0
2014-07-13 18:25:25,543 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10201ms
2014-07-13 18:25:25,543 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,543 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10226ms
2014-07-13 18:25:25,543 DEBUG [MemStoreFlusher.0] regionserver.HRegion: NOT flushing memstore for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., flushing=true, writesEnabled=true
2014-07-13 18:25:25,543 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,543 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:25:25,543 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:184), split_queue=0, merge_queue=0
2014-07-13 18:25:25,545 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10229ms
2014-07-13 18:25:25,546 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,546 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10236ms
2014-07-13 18:25:25,546 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,549 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10229ms
2014-07-13 18:25:25,549 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,549 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10227ms
2014-07-13 18:25:25,549 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,549 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10230ms
2014-07-13 18:25:25,549 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,553 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10234ms
2014-07-13 18:25:25,553 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,557 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10240ms
2014-07-13 18:25:25,557 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,557 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10237ms
2014-07-13 18:25:25,557 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,557 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10238ms
2014-07-13 18:25:25,558 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,561 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10242ms
2014-07-13 18:25:25,561 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,561 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10242ms
2014-07-13 18:25:25,561 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,561 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10252ms
2014-07-13 18:25:25,561 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,563 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10250ms
2014-07-13 18:25:25,563 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,563 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10250ms
2014-07-13 18:25:25,563 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,564 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10251ms
2014-07-13 18:25:25,564 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,564 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10252ms
2014-07-13 18:25:25,564 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,565 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10253ms
2014-07-13 18:25:25,565 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,567 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10255ms
2014-07-13 18:25:25,567 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,567 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10256ms
2014-07-13 18:25:25,567 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,572 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10262ms
2014-07-13 18:25:25,572 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,572 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10262ms
2014-07-13 18:25:25,572 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,573 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10263ms
2014-07-13 18:25:25,573 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,577 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10268ms
2014-07-13 18:25:25,577 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,577 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10270ms
2014-07-13 18:25:25,577 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,578 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10351ms
2014-07-13 18:25:25,578 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,578 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10351ms
2014-07-13 18:25:25,578 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,578 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10352ms
2014-07-13 18:25:25,578 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,578 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10353ms
2014-07-13 18:25:25,578 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,585 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10361ms
2014-07-13 18:25:25,585 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,585 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10361ms
2014-07-13 18:25:25,585 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,589 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10366ms
2014-07-13 18:25:25,589 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,589 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10367ms
2014-07-13 18:25:25,589 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,589 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10369ms
2014-07-13 18:25:25,589 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,597 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10377ms
2014-07-13 18:25:25,597 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,597 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10377ms
2014-07-13 18:25:25,597 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,605 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10386ms
2014-07-13 18:25:25,605 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,605 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10388ms
2014-07-13 18:25:25,605 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,605 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10388ms
2014-07-13 18:25:25,605 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,605 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10389ms
2014-07-13 18:25:25,605 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,610 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10536ms
2014-07-13 18:25:25,610 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,612 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10539ms
2014-07-13 18:25:25,612 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,612 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10539ms
2014-07-13 18:25:25,612 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,612 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10540ms
2014-07-13 18:25:25,612 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,612 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10540ms
2014-07-13 18:25:25,612 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,612 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10540ms
2014-07-13 18:25:25,613 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,621 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10550ms
2014-07-13 18:25:25,621 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,621 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10550ms
2014-07-13 18:25:25,621 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,621 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10550ms
2014-07-13 18:25:25,621 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:25:25,623 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11077,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114545,"queuetimems":7885,"class":"HRegionServer","responsesize":1256,"method":"Multi"}
2014-07-13 18:25:25,629 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11048,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114581,"queuetimems":7910,"class":"HRegionServer","responsesize":386,"method":"Multi"}
2014-07-13 18:25:25,741 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11372,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114369,"queuetimems":9348,"class":"HRegionServer","responsesize":10303,"method":"Multi"}
2014-07-13 18:25:25,875 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114397,"queuetimems":9120,"class":"HRegionServer","responsesize":12469,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10747,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115308,"queuetimems":5944,"class":"HRegionServer","responsesize":3773,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11698,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114357,"queuetimems":9496,"class":"HRegionServer","responsesize":10022,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11694,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114361,"queuetimems":9375,"class":"HRegionServer","responsesize":13027,"method":"Multi"}
2014-07-13 18:25:26,057 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11667,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114390,"queuetimems":9167,"class":"HRegionServer","responsesize":14139,"method":"Multi"}
2014-07-13 18:25:26,059 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10753,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115306,"queuetimems":5949,"class":"HRegionServer","responsesize":476,"method":"Multi"}
2014-07-13 18:25:26,060 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10837,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115222,"queuetimems":8486,"class":"HRegionServer","responsesize":3644,"method":"Multi"}
2014-07-13 18:25:26,060 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11702,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114357,"queuetimems":9449,"class":"HRegionServer","responsesize":12461,"method":"Multi"}
2014-07-13 18:25:26,061 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11680,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114381,"queuetimems":9238,"class":"HRegionServer","responsesize":3543,"method":"Multi"}
2014-07-13 18:25:26,061 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11700,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114361,"queuetimems":9363,"class":"HRegionServer","responsesize":5865,"method":"Multi"}
2014-07-13 18:25:26,061 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114358,"queuetimems":9420,"class":"HRegionServer","responsesize":3964,"method":"Multi"}
2014-07-13 18:25:26,061 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10721,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115340,"queuetimems":5967,"class":"HRegionServer","responsesize":1450,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11677,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114378,"queuetimems":9275,"class":"HRegionServer","responsesize":12651,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11654,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114402,"queuetimems":9097,"class":"HRegionServer","responsesize":10338,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11673,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114383,"queuetimems":9205,"class":"HRegionServer","responsesize":14611,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11662,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114393,"queuetimems":9141,"class":"HRegionServer","responsesize":13302,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13230,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301112825,"queuetimems":12312,"class":"HRegionServer","responsesize":15826,"method":"Multi"}
2014-07-13 18:25:26,056 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11682,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114373,"queuetimems":9327,"class":"HRegionServer","responsesize":11335,"method":"Multi"}
2014-07-13 18:25:26,077 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11696,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114381,"queuetimems":9244,"class":"HRegionServer","responsesize":476,"method":"Multi"}
2014-07-13 18:25:26,077 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10769,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115308,"queuetimems":5937,"class":"HRegionServer","responsesize":4045,"method":"Multi"}
2014-07-13 18:25:26,078 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11876,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114201,"queuetimems":9527,"class":"HRegionServer","responsesize":13065,"method":"Multi"}
2014-07-13 18:25:26,078 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11719,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114358,"queuetimems":9400,"class":"HRegionServer","responsesize":9086,"method":"Multi"}
2014-07-13 18:25:26,083 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11704,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114378,"queuetimems":9241,"class":"HRegionServer","responsesize":12464,"method":"Multi"}
2014-07-13 18:25:26,083 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11518,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114565,"queuetimems":7900,"class":"HRegionServer","responsesize":5578,"method":"Multi"}
2014-07-13 18:25:26,083 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11537,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114546,"queuetimems":7885,"class":"HRegionServer","responsesize":1071,"method":"Multi"}
2014-07-13 18:25:26,084 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114377,"queuetimems":9320,"class":"HRegionServer","responsesize":5451,"method":"Multi"}
2014-07-13 18:25:26,077 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11672,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114405,"queuetimems":9097,"class":"HRegionServer","responsesize":1450,"method":"Multi"}
2014-07-13 18:25:26,086 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11513,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114573,"queuetimems":7902,"class":"HRegionServer","responsesize":3215,"method":"Multi"}
2014-07-13 18:25:26,089 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11520,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114569,"queuetimems":7902,"class":"HRegionServer","responsesize":3306,"method":"Multi"}
2014-07-13 18:25:26,083 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11670,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114413,"queuetimems":8831,"class":"HRegionServer","responsesize":10556,"method":"Multi"}
2014-07-13 18:25:26,093 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114390,"queuetimems":9200,"class":"HRegionServer","responsesize":6109,"method":"Multi"}
2014-07-13 18:25:26,094 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11736,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114358,"queuetimems":9427,"class":"HRegionServer","responsesize":10836,"method":"Multi"}
2014-07-13 18:25:26,083 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11534,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114549,"queuetimems":7888,"class":"HRegionServer","responsesize":641,"method":"Multi"}
2014-07-13 18:25:26,097 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11896,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114201,"queuetimems":9462,"class":"HRegionServer","responsesize":12088,"method":"Multi"}
2014-07-13 18:25:26,098 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11741,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114357,"queuetimems":9476,"class":"HRegionServer","responsesize":9631,"method":"Multi"}
2014-07-13 18:25:26,083 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11726,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114357,"queuetimems":9520,"class":"HRegionServer","responsesize":8832,"method":"Multi"}
2014-07-13 18:25:26,089 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11688,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114401,"queuetimems":9118,"class":"HRegionServer","responsesize":3438,"method":"Multi"}
2014-07-13 18:25:26,101 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11724,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114377,"queuetimems":9305,"class":"HRegionServer","responsesize":7515,"method":"Multi"}
2014-07-13 18:25:26,163 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10947,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115216,"queuetimems":8520,"class":"HRegionServer","responsesize":1847,"method":"Multi"}
2014-07-13 18:25:26,169 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11967,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301114202,"queuetimems":9413,"class":"HRegionServer","responsesize":15826,"method":"Multi"}
2014-07-13 18:25:26,174 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10957,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115217,"queuetimems":8496,"class":"HRegionServer","responsesize":4489,"method":"Multi"}
2014-07-13 18:25:26,194 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11121,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115072,"queuetimems":8379,"class":"HRegionServer","responsesize":2159,"method":"Multi"}
2014-07-13 18:25:26,209 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10992,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115217,"queuetimems":8486,"class":"HRegionServer","responsesize":5833,"method":"Multi"}
2014-07-13 18:25:26,428 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:26,430 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11359,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115070,"queuetimems":8384,"class":"HRegionServer","responsesize":7559,"method":"Multi"}
2014-07-13 18:25:26,430 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11214,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115216,"queuetimems":8502,"class":"HRegionServer","responsesize":9878,"method":"Multi"}
2014-07-13 18:25:26,430 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11360,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115070,"queuetimems":8383,"class":"HRegionServer","responsesize":1213,"method":"Multi"}
2014-07-13 18:25:26,430 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11360,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301115070,"queuetimems":8380,"class":"HRegionServer","responsesize":1999,"method":"Multi"}
2014-07-13 18:25:26,736 DEBUG [RpcServer.handler=44,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:25:26,736 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 256.6m
2014-07-13 18:25:27,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68825 synced till here 68824
2014-07-13 18:25:27,307 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301115068 with entries=126, filesize=95.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301126429
2014-07-13 18:25:27,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300961109
2014-07-13 18:25:27,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300986627
2014-07-13 18:25:27,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300988318
2014-07-13 18:25:27,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300989721
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300990739
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300992096
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300994237
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300995573
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300996979
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300997868
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405300999633
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301000928
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301002092
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301003741
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301005004
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301006569
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301007436
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301008566
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301009911
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301011703
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301013165
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301014653
2014-07-13 18:25:27,308 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301036393
2014-07-13 18:25:27,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301038001
2014-07-13 18:25:27,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301039853
2014-07-13 18:25:27,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301042802
2014-07-13 18:25:27,713 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:25:28,274 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:28,309 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 68940 synced till here 68914
2014-07-13 18:25:29,033 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301126429 with entries=115, filesize=94.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301128274
2014-07-13 18:25:30,446 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:30,475 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301128274 with entries=111, filesize=61.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301130446
2014-07-13 18:25:30,476 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:31,111 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17091, memsize=66.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/aae2617381a541029c389c4759ccaf32
2014-07-13 18:25:31,125 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/.tmp/aae2617381a541029c389c4759ccaf32 as hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/aae2617381a541029c389c4759ccaf32
2014-07-13 18:25:31,145 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/df2b912714c1f15f547c828466aaf923/family/aae2617381a541029c389c4759ccaf32, entries=243500, sequenceid=17091, filesize=17.3m
2014-07-13 18:25:31,145 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~273.3m/286556000, currentsize=62.0m/65046240 for region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. in 4409ms, sequenceid=17091, compaction requested=true
2014-07-13 18:25:31,145 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:185), split_queue=0, merge_queue=0
2014-07-13 18:25:31,567 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:32,305 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69172 synced till here 69168
2014-07-13 18:25:32,342 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301130446 with entries=121, filesize=95.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301131568
2014-07-13 18:25:32,343 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:33,009 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=16954, memsize=625.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/a13bf93a57884cf8b15ece36b7ee4975
2014-07-13 18:25:33,021 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/a13bf93a57884cf8b15ece36b7ee4975 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/a13bf93a57884cf8b15ece36b7ee4975
2014-07-13 18:25:33,034 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/a13bf93a57884cf8b15ece36b7ee4975, entries=2277890, sequenceid=16954, filesize=162.1m
2014-07-13 18:25:33,034 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~699.3m/733255440, currentsize=353.0m/370124640 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 25813ms, sequenceid=16954, compaction requested=true
2014-07-13 18:25:33,035 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:186), split_queue=0, merge_queue=0
2014-07-13 18:25:33,098 DEBUG [RpcServer.handler=47,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:25:33,098 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:25:33,098 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:187), split_queue=0, merge_queue=0
2014-07-13 18:25:33,118 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:33,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301131568 with entries=62, filesize=67.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301133119
2014-07-13 18:25:33,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:34,165 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:34,822 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69315 synced till here 69314
2014-07-13 18:25:34,835 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301133119 with entries=81, filesize=76.5m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301134165
2014-07-13 18:25:34,836 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:35,771 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:36,034 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301134165 with entries=85, filesize=73.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301135771
2014-07-13 18:25:36,034 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:36,082 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/9fba97de50db4c43801b863d27f396d6 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/9fba97de50db4c43801b863d27f396d6
2014-07-13 18:25:36,114 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:25:36,123 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/19a4fe9c651e46de89825fe526b5e811, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/19a4fe9c651e46de89825fe526b5e811
2014-07-13 18:25:36,125 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e6569c38471f4cf5a6db13763340944a, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/e6569c38471f4cf5a6db13763340944a
2014-07-13 18:25:36,128 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ef28881c66f34fcbb3db999fec0bf168, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/ef28881c66f34fcbb3db999fec0bf168
2014-07-13 18:25:36,128 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into 9fba97de50db4c43801b863d27f396d6(size=175.2m), total size for store is 4.0g. This selection was in queue for 0sec, and took 31sec to execute.
2014-07-13 18:25:36,128 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=3, fileSize=186.4m, priority=-3, time=255012236666418; duration=31sec
2014-07-13 18:25:36,128 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:188), split_queue=0, merge_queue=0
2014-07-13 18:25:36,129 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:188), split_queue=0, merge_queue=0
2014-07-13 18:25:36,129 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:25:36,130 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 340911639 starting at candidate #1 after considering 132 permutations with 110 in ratio
2014-07-13 18:25:36,130 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:25:36,130 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:25:36,130 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=325.1m
2014-07-13 18:25:36,130 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/30c123a754ea44938b40767ed9ddc271, keycount=202838, bloomtype=ROW, size=144.5m, encoding=NONE, seqNum=2625
2014-07-13 18:25:36,130 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c48023fecb4745c38d34fa8a87029118, keycount=119112, bloomtype=ROW, size=84.8m, encoding=NONE, seqNum=2928
2014-07-13 18:25:36,130 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2bf0f75181494e778adbe35c126b8592, keycount=134587, bloomtype=ROW, size=95.8m, encoding=NONE, seqNum=3328
2014-07-13 18:25:36,534 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:25:37,252 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:37,345 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301135771 with entries=59, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301137252
2014-07-13 18:25:37,346 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:39,063 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:39,169 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69532 synced till here 69524
2014-07-13 18:25:39,269 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301137252 with entries=73, filesize=72.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301139063
2014-07-13 18:25:39,270 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:39,901 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:25:39,901 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923. has too many store files; delaying flush up to 90000ms
2014-07-13 18:25:39,901 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:188), split_queue=0, merge_queue=0
2014-07-13 18:25:40,602 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:40,628 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69604 synced till here 69595
2014-07-13 18:25:40,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301139063 with entries=72, filesize=71.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301140603
2014-07-13 18:25:40,810 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:42,103 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:42,132 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69674 synced till here 69666
2014-07-13 18:25:42,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301140603 with entries=70, filesize=68.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301142103
2014-07-13 18:25:42,185 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:43,322 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:43,345 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69736 synced till here 69735
2014-07-13 18:25:43,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301142103 with entries=62, filesize=63.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301143322
2014-07-13 18:25:43,363 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=42, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:44,692 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:44,714 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69806 synced till here 69800
2014-07-13 18:25:44,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301143322 with entries=70, filesize=67.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301144692
2014-07-13 18:25:44,865 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=43, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:46,207 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:46,252 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69877 synced till here 69868
2014-07-13 18:25:46,335 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301144692 with entries=71, filesize=74.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301146208
2014-07-13 18:25:46,335 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=44, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:47,101 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:47,597 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 69952 synced till here 69950
2014-07-13 18:25:47,626 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301146208 with entries=75, filesize=72.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301147101
2014-07-13 18:25:47,627 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=45, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:48,409 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:48,429 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70024 synced till here 70016
2014-07-13 18:25:48,502 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301147101 with entries=72, filesize=70.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301148410
2014-07-13 18:25:48,503 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=46, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:50,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:50,101 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70103 synced till here 70102
2014-07-13 18:25:50,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301148410 with entries=79, filesize=64.2m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301150069
2014-07-13 18:25:50,239 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=47, maxlogs=32; forcing flush of 1 regions(s): 60bba508114b247927d755fe2fd7c8ea
2014-07-13 18:25:51,182 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90234ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:25:51,183 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea., current region memstore size 1.6g
2014-07-13 18:25:52,053 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:52,097 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301150069 with entries=83, filesize=62.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301152054
2014-07-13 18:25:52,476 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:25:52,476 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files, but is 910.8m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:25:52,476 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. due to global heap pressure
2014-07-13 18:25:52,476 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 910.8m
2014-07-13 18:25:52,691 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:25:53,259 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:25:53,575 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:53,612 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70262 synced till here 70261
2014-07-13 18:25:53,636 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301152054 with entries=76, filesize=63.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301153575
2014-07-13 18:25:55,538 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:25:55,558 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70340 synced till here 70337
2014-07-13 18:25:55,587 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,590 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,599 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301153575 with entries=78, filesize=66.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301155538
2014-07-13 18:25:55,612 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,629 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,649 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,661 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,700 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,752 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,766 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,804 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,839 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,863 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,893 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:55,935 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:56,510 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:56,549 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,089 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,096 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,125 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,165 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,181 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,191 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,199 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,230 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,240 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,246 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,256 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,302 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,831 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,847 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,868 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,900 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,925 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,944 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,963 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,980 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:57,999 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:58,006 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,795 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,813 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,823 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,847 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,877 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,900 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,920 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,958 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:25:59,970 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:00,003 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:00,034 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:00,069 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:00,588 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:00,591 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:00,612 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:00,629 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:00,650 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:00,661 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:00,701 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:00,752 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:00,766 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:00,804 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:00,840 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:01,286 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5351ms
2014-07-13 18:26:01,287 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5423ms
2014-07-13 18:26:01,287 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5394ms
2014-07-13 18:26:01,510 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:01,549 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,089 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,096 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,125 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,165 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,181 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,191 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,200 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,230 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,241 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,246 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,256 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,303 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,832 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,847 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,868 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,900 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,925 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,944 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,963 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:02,980 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:02,999 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:03,007 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:04,796 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:04,813 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,823 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,848 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,877 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,900 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,920 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,958 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:04,970 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:05,003 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:05,034 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:05,069 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:05,588 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:05,591 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:05,612 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:05,630 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:05,657 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10008ms
2014-07-13 18:26:05,661 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:05,701 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:05,753 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:05,767 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:05,804 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:05,840 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:06,287 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10352ms
2014-07-13 18:26:06,287 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10424ms
2014-07-13 18:26:06,287 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10394ms
2014-07-13 18:26:06,511 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:06,550 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:07,090 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,097 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,125 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:07,165 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,182 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,192 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:07,200 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,231 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,241 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,246 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,257 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:07,303 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,833 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,848 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,868 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:07,901 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,926 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:07,945 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,963 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:07,981 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:08,000 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:08,008 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,796 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,814 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,823 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:09,848 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,878 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,901 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,921 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:09,958 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:09,971 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:10,004 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:10,034 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:10,069 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:10,750 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15050ms
2014-07-13 18:26:10,751 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15164ms
2014-07-13 18:26:10,751 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15139ms
2014-07-13 18:26:10,751 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15161ms
2014-07-13 18:26:10,752 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15090ms
2014-07-13 18:26:10,752 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15103ms
2014-07-13 18:26:10,752 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15123ms
2014-07-13 18:26:10,753 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:26:10,767 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:26:10,804 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15000ms
2014-07-13 18:26:10,841 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15001ms
2014-07-13 18:26:11,159 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17757, memsize=538.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c8416ebcb1ae4937ac905b5e218fb112
2014-07-13 18:26:11,174 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c8416ebcb1ae4937ac905b5e218fb112 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c8416ebcb1ae4937ac905b5e218fb112
2014-07-13 18:26:11,186 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c8416ebcb1ae4937ac905b5e218fb112, entries=1959300, sequenceid=17757, filesize=139.5m
2014-07-13 18:26:11,187 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~910.8m/955039440, currentsize=51.3m/53782720 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 18711ms, sequenceid=17757, compaction requested=true
2014-07-13 18:26:11,187 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:189), split_queue=0, merge_queue=0
2014-07-13 18:26:11,187 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15348ms
2014-07-13 18:26:11,187 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,187 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15383ms
2014-07-13 18:26:11,187 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,188 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15422ms
2014-07-13 18:26:11,188 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,188 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15436ms
2014-07-13 18:26:11,188 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,189 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15560ms
2014-07-13 18:26:11,189 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,193 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15544ms
2014-07-13 18:26:11,193 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,193 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15532ms
2014-07-13 18:26:11,193 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,193 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15603ms
2014-07-13 18:26:11,193 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,193 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15581ms
2014-07-13 18:26:11,193 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,193 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15606ms
2014-07-13 18:26:11,193 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,204 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15504ms
2014-07-13 18:26:11,204 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,204 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11135ms
2014-07-13 18:26:11,204 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,204 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11170ms
2014-07-13 18:26:11,204 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,209 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11206ms
2014-07-13 18:26:11,209 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,212 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11242ms
2014-07-13 18:26:11,212 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,212 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11254ms
2014-07-13 18:26:11,212 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,212 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11292ms
2014-07-13 18:26:11,212 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,212 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11312ms
2014-07-13 18:26:11,213 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,217 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11340ms
2014-07-13 18:26:11,217 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,225 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11378ms
2014-07-13 18:26:11,225 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,225 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11402ms
2014-07-13 18:26:11,225 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,227 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11414ms
2014-07-13 18:26:11,227 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,233 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11438ms
2014-07-13 18:26:11,233 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,233 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13227ms
2014-07-13 18:26:11,233 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,233 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13234ms
2014-07-13 18:26:11,233 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,234 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13253ms
2014-07-13 18:26:11,234 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,234 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13272ms
2014-07-13 18:26:11,234 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,234 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13290ms
2014-07-13 18:26:11,234 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,234 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13309ms
2014-07-13 18:26:11,234 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,234 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13334ms
2014-07-13 18:26:11,234 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,235 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13367ms
2014-07-13 18:26:11,235 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,245 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13398ms
2014-07-13 18:26:11,245 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,245 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13414ms
2014-07-13 18:26:11,245 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,246 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13943ms
2014-07-13 18:26:11,246 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,246 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 13990ms
2014-07-13 18:26:11,246 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,246 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14001ms
2014-07-13 18:26:11,247 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,247 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14007ms
2014-07-13 18:26:11,247 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,247 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14017ms
2014-07-13 18:26:11,247 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,247 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14048ms
2014-07-13 18:26:11,247 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,247 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14056ms
2014-07-13 18:26:11,247 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,248 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14067ms
2014-07-13 18:26:11,248 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,254 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15729,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155524,"queuetimems":0,"class":"HRegionServer","responsesize":4765,"method":"Multi"}
2014-07-13 18:26:11,257 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14093ms
2014-07-13 18:26:11,257 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,257 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14132ms
2014-07-13 18:26:11,257 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,257 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14162ms
2014-07-13 18:26:11,257 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,263 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14174ms
2014-07-13 18:26:11,263 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,263 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14714ms
2014-07-13 18:26:11,263 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,263 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 14753ms
2014-07-13 18:26:11,263 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,264 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15370ms
2014-07-13 18:26:11,264 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,265 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15401ms
2014-07-13 18:26:11,265 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,266 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 15330ms
2014-07-13 18:26:11,266 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:11,312 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15797,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155514,"queuetimems":0,"class":"HRegionServer","responsesize":9636,"method":"Multi"}
2014-07-13 18:26:11,517 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15858,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155659,"queuetimems":1,"class":"HRegionServer","responsesize":5266,"method":"Multi"}
2014-07-13 18:26:11,518 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155800,"queuetimems":0,"class":"HRegionServer","responsesize":9536,"method":"Multi"}
2014-07-13 18:26:11,715 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16070,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155644,"queuetimems":1,"class":"HRegionServer","responsesize":10680,"method":"Multi"}
2014-07-13 18:26:11,863 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16100,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155763,"queuetimems":0,"class":"HRegionServer","responsesize":7741,"method":"Multi"}
2014-07-13 18:26:11,967 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:11,969 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14714,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157255,"queuetimems":0,"class":"HRegionServer","responsesize":6025,"method":"Multi"}
2014-07-13 18:26:11,969 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159820,"queuetimems":0,"class":"HRegionServer","responsesize":3996,"method":"Multi"}
2014-07-13 18:26:11,969 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14668,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157301,"queuetimems":0,"class":"HRegionServer","responsesize":3872,"method":"Multi"}
2014-07-13 18:26:11,972 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14792,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157180,"queuetimems":2,"class":"HRegionServer","responsesize":6630,"method":"Multi"}
2014-07-13 18:26:11,973 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14143,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157830,"queuetimems":0,"class":"HRegionServer","responsesize":5266,"method":"Multi"}
2014-07-13 18:26:11,977 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159842,"queuetimems":0,"class":"HRegionServer","responsesize":6531,"method":"Multi"}
2014-07-13 18:26:11,992 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70450 synced till here 70415
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14940,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157960,"queuetimems":0,"class":"HRegionServer","responsesize":9536,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12837,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301160063,"queuetimems":1,"class":"HRegionServer","responsesize":11824,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15703,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157198,"queuetimems":0,"class":"HRegionServer","responsesize":4912,"method":"Multi"}
2014-07-13 18:26:12,902 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13006,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159895,"queuetimems":0,"class":"HRegionServer","responsesize":10269,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12872,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301160028,"queuetimems":0,"class":"HRegionServer","responsesize":10615,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14895,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301158005,"queuetimems":0,"class":"HRegionServer","responsesize":4765,"method":"Multi"}
2014-07-13 18:26:12,909 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12994,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159915,"queuetimems":1,"class":"HRegionServer","responsesize":7560,"method":"Multi"}
2014-07-13 18:26:12,910 WARN  [RpcServer.handler=33,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17055,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155855,"queuetimems":0,"class":"HRegionServer","responsesize":7560,"method":"Multi"}
2014-07-13 18:26:12,912 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12945,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159967,"queuetimems":0,"class":"HRegionServer","responsesize":6025,"method":"Multi"}
2014-07-13 18:26:12,912 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":14970,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157942,"queuetimems":0,"class":"HRegionServer","responsesize":10680,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15662,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157239,"queuetimems":1,"class":"HRegionServer","responsesize":6470,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17204,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155697,"queuetimems":0,"class":"HRegionServer","responsesize":9837,"method":"Multi"}
2014-07-13 18:26:12,913 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159873,"queuetimems":0,"class":"HRegionServer","responsesize":10532,"method":"Multi"}
2014-07-13 18:26:12,914 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15751,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157163,"queuetimems":1,"class":"HRegionServer","responsesize":11824,"method":"Multi"}
2014-07-13 18:26:12,901 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17294,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155607,"queuetimems":0,"class":"HRegionServer","responsesize":9032,"method":"Multi"}
2014-07-13 18:26:12,912 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12913,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159999,"queuetimems":0,"class":"HRegionServer","responsesize":11164,"method":"Multi"}
2014-07-13 18:26:12,909 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15720,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157189,"queuetimems":0,"class":"HRegionServer","responsesize":6531,"method":"Multi"}
2014-07-13 18:26:12,925 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15831,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157094,"queuetimems":1,"class":"HRegionServer","responsesize":10615,"method":"Multi"}
2014-07-13 18:26:12,925 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17035,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155890,"queuetimems":1,"class":"HRegionServer","responsesize":10520,"method":"Multi"}
2014-07-13 18:26:13,012 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16467,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301156545,"queuetimems":0,"class":"HRegionServer","responsesize":10532,"method":"Multi"}
2014-07-13 18:26:13,013 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15167,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157846,"queuetimems":1,"class":"HRegionServer","responsesize":7741,"method":"Multi"}
2014-07-13 18:26:13,013 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16507,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301156506,"queuetimems":1,"class":"HRegionServer","responsesize":11164,"method":"Multi"}
2014-07-13 18:26:13,013 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15890,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157123,"queuetimems":0,"class":"HRegionServer","responsesize":10024,"method":"Multi"}
2014-07-13 18:26:13,014 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15149,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157864,"queuetimems":1,"class":"HRegionServer","responsesize":9032,"method":"Multi"}
2014-07-13 18:26:13,012 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17431,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155581,"queuetimems":0,"class":"HRegionServer","responsesize":15776,"method":"Multi"}
2014-07-13 18:26:13,017 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15930,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157087,"queuetimems":0,"class":"HRegionServer","responsesize":10269,"method":"Multi"}
2014-07-13 18:26:13,012 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13059,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159953,"queuetimems":0,"class":"HRegionServer","responsesize":12889,"method":"Multi"}
2014-07-13 18:26:13,020 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15023,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157997,"queuetimems":0,"class":"HRegionServer","responsesize":9636,"method":"Multi"}
2014-07-13 18:26:13,020 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17189,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155831,"queuetimems":0,"class":"HRegionServer","responsesize":10606,"method":"Multi"}
2014-07-13 18:26:13,046 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301155538 with entries=110, filesize=98.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301171967
2014-07-13 18:26:13,459 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16213,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157245,"queuetimems":0,"class":"HRegionServer","responsesize":3996,"method":"Multi"}
2014-07-13 18:26:13,459 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17528,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155930,"queuetimems":0,"class":"HRegionServer","responsesize":12889,"method":"Multi"}
2014-07-13 18:26:13,459 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13666,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159792,"queuetimems":1,"class":"HRegionServer","responsesize":10606,"method":"Multi"}
2014-07-13 18:26:13,459 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":17717,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301155741,"queuetimems":1,"class":"HRegionServer","responsesize":14021,"method":"Multi"}
2014-07-13 18:26:13,461 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13650,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301159811,"queuetimems":1,"class":"HRegionServer","responsesize":6630,"method":"Multi"}
2014-07-13 18:26:13,474 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15495,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157978,"queuetimems":0,"class":"HRegionServer","responsesize":9837,"method":"Multi"}
2014-07-13 18:26:13,629 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15707,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157922,"queuetimems":0,"class":"HRegionServer","responsesize":14021,"method":"Multi"}
2014-07-13 18:26:13,643 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":15748,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157895,"queuetimems":0,"class":"HRegionServer","responsesize":15776,"method":"Multi"}
2014-07-13 18:26:13,645 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":16417,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301157228,"queuetimems":0,"class":"HRegionServer","responsesize":16253,"method":"Multi"}
2014-07-13 18:26:13,992 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:14,482 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70560 synced till here 70536
2014-07-13 18:26:14,680 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301171967 with entries=110, filesize=102.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301173993
2014-07-13 18:26:16,380 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:16,461 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70670 synced till here 70635
2014-07-13 18:26:16,677 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301173993 with entries=110, filesize=101.3m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301176380
2014-07-13 18:26:17,925 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:17,948 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301176380 with entries=124, filesize=61.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301177925
2014-07-13 18:26:18,626 DEBUG [RpcServer.handler=49,port=60020] regionserver.HRegion: Flush requested on usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:26:18,626 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. has too many store files; delaying flush up to 90000ms
2014-07-13 18:26:18,626 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:190), split_queue=0, merge_queue=0
2014-07-13 18:26:18,780 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush thread woke up because memory above low water=3.8g
2014-07-13 18:26:18,781 DEBUG [MemStoreFlusher.0] regionserver.MemStoreFlusher: Under global heap pressure: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files, but is 957.2m vs best flushable region's 0.0. Choosing the bigger.
2014-07-13 18:26:18,781 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Flush of region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. due to global heap pressure
2014-07-13 18:26:18,781 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292., current region memstore size 957.2m
2014-07-13 18:26:19,243 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:19,643 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 70887 synced till here 70886
2014-07-13 18:26:19,684 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301177925 with entries=93, filesize=76.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301179244
2014-07-13 18:26:19,767 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:26:20,663 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,676 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:20,685 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,698 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,712 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,742 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,771 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,788 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,814 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:20,836 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301179244 with entries=59, filesize=63.6m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301180677
2014-07-13 18:26:20,859 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,134 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,141 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,161 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,182 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,203 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,223 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,235 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,258 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,726 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,733 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,831 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:21,940 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,002 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,013 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,036 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,047 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,049 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,073 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,075 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,158 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,161 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,855 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,874 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,898 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,918 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,939 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,959 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,974 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:22,991 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,012 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,034 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,040 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,065 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,085 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,103 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:23,124 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:24,844 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:24,850 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:24,876 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:24,880 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:24,919 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on slave1,60020,1405298890065: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-13 18:26:25,663 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:25,686 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:25,699 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:25,713 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:25,742 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:25,771 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:25,788 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:25,815 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:25,859 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,134 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,141 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,161 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,183 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:26,204 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,223 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,235 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,258 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,726 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:26,733 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,831 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:26,940 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,002 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,013 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,036 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,047 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,049 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,074 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:27,075 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,159 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:27,161 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,856 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:27,874 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,898 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,919 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,939 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,960 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:27,974 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:27,991 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,013 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,034 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,040 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,065 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,085 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,103 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:28,125 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:28,473 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/9593400dc08d43998fe45da32b7a3c3a as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/9593400dc08d43998fe45da32b7a3c3a
2014-07-13 18:26:28,497 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:26:28,510 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/30c123a754ea44938b40767ed9ddc271, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/30c123a754ea44938b40767ed9ddc271
2014-07-13 18:26:28,515 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c48023fecb4745c38d34fa8a87029118, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c48023fecb4745c38d34fa8a87029118
2014-07-13 18:26:28,521 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2bf0f75181494e778adbe35c126b8592, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2bf0f75181494e778adbe35c126b8592
2014-07-13 18:26:28,521 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into 9593400dc08d43998fe45da32b7a3c3a(size=321.2m), total size for store is 4.2g. This selection was in queue for 0sec, and took 52sec to execute.
2014-07-13 18:26:28,522 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=3, fileSize=325.1m, priority=-2, time=255043557024759; duration=52sec
2014-07-13 18:26:28,522 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:191), split_queue=0, merge_queue=0
2014-07-13 18:26:28,522 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:191), split_queue=0, merge_queue=0
2014-07-13 18:26:28,523 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 21 store files, 0 compacting, 21 eligible, 20 blocking
2014-07-13 18:26:28,525 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 3 files of size 341659045 starting at candidate #4 after considering 124 permutations with 112 in ratio
2014-07-13 18:26:28,525 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: ecd2c8d6e263c2e3db5b8717fb22b6df - family: Initiating minor compaction
2014-07-13 18:26:28,525 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:26:28,526 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp, totalSize=325.8m
2014-07-13 18:26:28,526 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/427379afeb9a47979408745cebd4dfad, keycount=88263, bloomtype=ROW, size=62.9m, encoding=NONE, seqNum=6091
2014-07-13 18:26:28,526 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/07bf2fd1db644795b184c60c5ed53c4e, keycount=132005, bloomtype=ROW, size=94.0m, encoding=NONE, seqNum=6528
2014-07-13 18:26:28,526 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2ebe4a4205fc48ca921bb574c5638b2b, keycount=237465, bloomtype=ROW, size=168.9m, encoding=NONE, seqNum=7136
2014-07-13 18:26:28,615 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:26:29,845 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:29,850 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:29,877 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-13 18:26:29,880 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:29,919 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-13 18:26:30,664 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:30,686 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:30,699 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:30,713 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:30,742 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:30,771 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:30,788 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:30,815 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:30,860 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:31,135 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,141 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:31,162 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,183 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,204 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,224 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,235 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:31,258 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:31,727 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,733 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:31,832 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:31,940 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,003 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:32,013 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,036 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,047 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,049 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,074 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:32,075 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,159 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10001ms
2014-07-13 18:26:32,161 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10000ms
2014-07-13 18:26:32,636 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17736, memsize=1.1g, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/77c55744c3fb4b7c80a516cfde61521e
2014-07-13 18:26:32,661 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp/77c55744c3fb4b7c80a516cfde61521e as hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/77c55744c3fb4b7c80a516cfde61521e
2014-07-13 18:26:32,687 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/77c55744c3fb4b7c80a516cfde61521e, entries=4036470, sequenceid=17736, filesize=287.4m
2014-07-13 18:26:32,687 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~1.6g/1696478080, currentsize=326.3m/342129440 for region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. in 41504ms, sequenceid=17736, compaction requested=true
2014-07-13 18:26:32,688 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:191), split_queue=0, merge_queue=0
2014-07-13 18:26:32,688 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10527ms
2014-07-13 18:26:32,688 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,688 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10530ms
2014-07-13 18:26:32,688 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,688 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10613ms
2014-07-13 18:26:32,688 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,691 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10618ms
2014-07-13 18:26:32,691 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,693 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10644ms
2014-07-13 18:26:32,693 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,693 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10646ms
2014-07-13 18:26:32,693 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,693 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10657ms
2014-07-13 18:26:32,693 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,693 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10680ms
2014-07-13 18:26:32,693 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,693 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10691ms
2014-07-13 18:26:32,693 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,697 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10757ms
2014-07-13 18:26:32,697 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,705 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10874ms
2014-07-13 18:26:32,705 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,705 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10972ms
2014-07-13 18:26:32,705 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,705 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 10980ms
2014-07-13 18:26:32,705 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,706 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11448ms
2014-07-13 18:26:32,707 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,707 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11472ms
2014-07-13 18:26:32,707 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,707 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11484ms
2014-07-13 18:26:32,707 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,710 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11507ms
2014-07-13 18:26:32,710 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,710 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11528ms
2014-07-13 18:26:32,710 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,713 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11552ms
2014-07-13 18:26:32,713 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,713 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11572ms
2014-07-13 18:26:32,713 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,713 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11579ms
2014-07-13 18:26:32,713 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,713 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11854ms
2014-07-13 18:26:32,713 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,713 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11899ms
2014-07-13 18:26:32,714 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,714 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11926ms
2014-07-13 18:26:32,714 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,721 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11950ms
2014-07-13 18:26:32,721 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,721 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 11979ms
2014-07-13 18:26:32,721 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,725 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12013ms
2014-07-13 18:26:32,725 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,733 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12035ms
2014-07-13 18:26:32,733 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,733 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12048ms
2014-07-13 18:26:32,733 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,739 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 12076ms
2014-07-13 18:26:32,739 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,739 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7820ms
2014-07-13 18:26:32,739 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,740 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7860ms
2014-07-13 18:26:32,740 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,740 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7864ms
2014-07-13 18:26:32,740 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,740 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7890ms
2014-07-13 18:26:32,740 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,740 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7896ms
2014-07-13 18:26:32,740 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,740 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9616ms
2014-07-13 18:26:32,740 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,740 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9637ms
2014-07-13 18:26:32,740 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,741 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9656ms
2014-07-13 18:26:32,741 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,741 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9676ms
2014-07-13 18:26:32,741 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,741 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9701ms
2014-07-13 18:26:32,742 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,742 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9708ms
2014-07-13 18:26:32,742 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,742 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9730ms
2014-07-13 18:26:32,742 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,742 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9751ms
2014-07-13 18:26:32,742 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,743 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9768ms
2014-07-13 18:26:32,744 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,744 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9785ms
2014-07-13 18:26:32,744 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,744 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9805ms
2014-07-13 18:26:32,744 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,744 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9826ms
2014-07-13 18:26:32,744 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,744 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9846ms
2014-07-13 18:26:32,744 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,744 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9870ms
2014-07-13 18:26:32,745 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,745 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9890ms
2014-07-13 18:26:32,745 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server slave1,60020,1405298890065
2014-07-13 18:26:32,844 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10686,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182158,"queuetimems":0,"class":"HRegionServer","responsesize":378,"method":"Multi"}
2014-07-13 18:26:32,844 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10769,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182075,"queuetimems":1,"class":"HRegionServer","responsesize":196,"method":"Multi"}
2014-07-13 18:26:33,218 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12647,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180570,"queuetimems":0,"class":"HRegionServer","responsesize":10956,"method":"Multi"}
2014-07-13 18:26:33,218 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11169,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182049,"queuetimems":0,"class":"HRegionServer","responsesize":524,"method":"Multi"}
2014-07-13 18:26:33,218 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:26:33,219 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182073,"queuetimems":0,"class":"HRegionServer","responsesize":1355,"method":"Multi"}
2014-07-13 18:26:33,219 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11173,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182046,"queuetimems":0,"class":"HRegionServer","responsesize":1734,"method":"Multi"}
2014-07-13 18:26:33,219 WARN  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. has too many store files; delaying flush up to 90000ms
2014-07-13 18:26:33,219 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:192), split_queue=0, merge_queue=0
2014-07-13 18:26:33,218 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12690,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180528,"queuetimems":0,"class":"HRegionServer","responsesize":8228,"method":"Multi"}
2014-07-13 18:26:33,218 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11216,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182002,"queuetimems":0,"class":"HRegionServer","responsesize":1278,"method":"Multi"}
2014-07-13 18:26:33,219 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11183,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182035,"queuetimems":0,"class":"HRegionServer","responsesize":3515,"method":"Multi"}
2014-07-13 18:26:33,828 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11815,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182012,"queuetimems":1,"class":"HRegionServer","responsesize":3860,"method":"Multi"}
2014-07-13 18:26:33,837 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11898,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181939,"queuetimems":1,"class":"HRegionServer","responsesize":4043,"method":"Multi"}
2014-07-13 18:26:33,828 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12095,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181732,"queuetimems":0,"class":"HRegionServer","responsesize":3395,"method":"Multi"}
2014-07-13 18:26:34,005 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:34,007 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11849,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182158,"queuetimems":0,"class":"HRegionServer","responsesize":12364,"method":"Multi"}
2014-07-13 18:26:34,007 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13350,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180657,"queuetimems":0,"class":"HRegionServer","responsesize":11547,"method":"Multi"}
2014-07-13 18:26:34,007 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13102,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180905,"queuetimems":0,"class":"HRegionServer","responsesize":12106,"method":"Multi"}
2014-07-13 18:26:34,013 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11002,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183010,"queuetimems":1,"class":"HRegionServer","responsesize":10312,"method":"Multi"}
2014-07-13 18:26:34,015 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12291,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181724,"queuetimems":0,"class":"HRegionServer","responsesize":8882,"method":"Multi"}
2014-07-13 18:26:34,016 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181159,"queuetimems":0,"class":"HRegionServer","responsesize":10488,"method":"Multi"}
2014-07-13 18:26:34,015 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12877,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181138,"queuetimems":0,"class":"HRegionServer","responsesize":10428,"method":"Multi"}
2014-07-13 18:26:34,021 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13236,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180785,"queuetimems":0,"class":"HRegionServer","responsesize":4628,"method":"Multi"}
2014-07-13 18:26:34,015 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13247,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180768,"queuetimems":0,"class":"HRegionServer","responsesize":8864,"method":"Multi"}
2014-07-13 18:26:34,015 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13320,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180695,"queuetimems":0,"class":"HRegionServer","responsesize":9291,"method":"Multi"}
2014-07-13 18:26:34,016 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13204,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180811,"queuetimems":0,"class":"HRegionServer","responsesize":7957,"method":"Multi"}
2014-07-13 18:26:34,079 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71065 synced till here 71033
2014-07-13 18:26:34,308 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13053,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181255,"queuetimems":1,"class":"HRegionServer","responsesize":11093,"method":"Multi"}
2014-07-13 18:26:34,308 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13074,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181234,"queuetimems":1,"class":"HRegionServer","responsesize":6227,"method":"Multi"}
2014-07-13 18:26:34,309 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13087,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181221,"queuetimems":0,"class":"HRegionServer","responsesize":10312,"method":"Multi"}
2014-07-13 18:26:34,309 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11269,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183039,"queuetimems":0,"class":"HRegionServer","responsesize":4628,"method":"Multi"}
2014-07-13 18:26:34,308 WARN  [RpcServer.handler=25,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11437,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182871,"queuetimems":0,"class":"HRegionServer","responsesize":10526,"method":"Multi"}
2014-07-13 18:26:34,308 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13128,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181180,"queuetimems":0,"class":"HRegionServer","responsesize":11147,"method":"Multi"}
2014-07-13 18:26:34,308 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13453,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180855,"queuetimems":0,"class":"HRegionServer","responsesize":11178,"method":"Multi"}
2014-07-13 18:26:34,308 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11392,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182916,"queuetimems":0,"class":"HRegionServer","responsesize":10439,"method":"Multi"}
2014-07-13 18:26:34,318 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11381,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182937,"queuetimems":1,"class":"HRegionServer","responsesize":10956,"method":"Multi"}
2014-07-13 18:26:34,321 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11332,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182989,"queuetimems":0,"class":"HRegionServer","responsesize":8864,"method":"Multi"}
2014-07-13 18:26:34,326 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11475,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182851,"queuetimems":0,"class":"HRegionServer","responsesize":8228,"method":"Multi"}
2014-07-13 18:26:34,328 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11244,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183083,"queuetimems":1,"class":"HRegionServer","responsesize":10488,"method":"Multi"}
2014-07-13 18:26:34,318 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11217,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183101,"queuetimems":0,"class":"HRegionServer","responsesize":9291,"method":"Multi"}
2014-07-13 18:26:34,315 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11284,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183031,"queuetimems":0,"class":"HRegionServer","responsesize":11178,"method":"Multi"}
2014-07-13 18:26:34,315 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11420,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182895,"queuetimems":0,"class":"HRegionServer","responsesize":12106,"method":"Multi"}
2014-07-13 18:26:34,315 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11193,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183122,"queuetimems":0,"class":"HRegionServer","responsesize":11147,"method":"Multi"}
2014-07-13 18:26:34,314 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11357,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182957,"queuetimems":0,"class":"HRegionServer","responsesize":10428,"method":"Multi"}
2014-07-13 18:26:34,314 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11251,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301183062,"queuetimems":0,"class":"HRegionServer","responsesize":11547,"method":"Multi"}
2014-07-13 18:26:34,312 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13573,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301180738,"queuetimems":0,"class":"HRegionServer","responsesize":10526,"method":"Multi"}
2014-07-13 18:26:34,312 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11339,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301182972,"queuetimems":0,"class":"HRegionServer","responsesize":7957,"method":"Multi"}
2014-07-13 18:26:34,309 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181829,"queuetimems":0,"class":"HRegionServer","responsesize":10353,"method":"Multi"}
2014-07-13 18:26:34,532 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301180677 with entries=119, filesize=91.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301194006
2014-07-13 18:26:34,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301043859
2014-07-13 18:26:34,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301048303
2014-07-13 18:26:34,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301049796
2014-07-13 18:26:34,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301050697
2014-07-13 18:26:34,532 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301052985
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301054004
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301055709
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301057127
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301058670
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301059955
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301061339
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301062650
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301063908
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301065360
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301066733
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301068481
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301069691
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301071137
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301073453
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301074777
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301075735
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301077211
2014-07-13 18:26:34,533 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301079021
2014-07-13 18:26:34,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301081265
2014-07-13 18:26:34,534 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301082994
2014-07-13 18:26:34,935 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13733,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.53:46719","starttimems":1405301181201,"queuetimems":0,"class":"HRegionServer","responsesize":10439,"method":"Multi"}
2014-07-13 18:26:35,848 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:35,862 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71187 synced till here 71168
2014-07-13 18:26:36,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301194006 with entries=122, filesize=93.9m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301195848
2014-07-13 18:26:37,338 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:37,367 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71272 synced till here 71269
2014-07-13 18:26:37,436 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301195848 with entries=85, filesize=65.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301197338
2014-07-13 18:26:38,414 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:38,429 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71337 synced till here 71335
2014-07-13 18:26:38,454 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301197338 with entries=65, filesize=63.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301198415
2014-07-13 18:26:40,498 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:40,513 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71422 synced till here 71421
2014-07-13 18:26:40,535 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301198415 with entries=85, filesize=64.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301200498
2014-07-13 18:26:41,048 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=17585, memsize=590.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/fae51af4bfa142e28f514ac27829c6d0
2014-07-13 18:26:41,061 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/.tmp/fae51af4bfa142e28f514ac27829c6d0 as hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/fae51af4bfa142e28f514ac27829c6d0
2014-07-13 18:26:41,079 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/c8c427e222de992c0f6302092c0a1292/family/fae51af4bfa142e28f514ac27829c6d0, entries=2148240, sequenceid=17585, filesize=152.9m
2014-07-13 18:26:41,080 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~962.7m/1009509680, currentsize=242.2m/253951600 for region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. in 22299ms, sequenceid=17585, compaction requested=true
2014-07-13 18:26:41,080 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:193), split_queue=0, merge_queue=0
2014-07-13 18:26:41,270 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:41,292 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71491 synced till here 71490
2014-07-13 18:26:41,306 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301200498 with entries=69, filesize=61.8m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301201271
2014-07-13 18:26:41,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301084618
2014-07-13 18:26:41,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301108016
2014-07-13 18:26:41,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301109834
2014-07-13 18:26:41,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301112065
2014-07-13 18:26:41,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301113550
2014-07-13 18:26:41,307 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301115068
2014-07-13 18:26:42,604 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292.
2014-07-13 18:26:42,604 WARN  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Region usertable,user7,1405299268768.c8c427e222de992c0f6302092c0a1292. has too many store files; delaying flush up to 90000ms
2014-07-13 18:26:42,605 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:194), split_queue=0, merge_queue=0
2014-07-13 18:26:43,315 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:43,355 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301201271 with entries=60, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301203316
2014-07-13 18:26:45,052 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: Waited 90651ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df.
2014-07-13 18:26:45,053 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 549.8m
2014-07-13 18:26:45,426 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:26:46,096 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:46,139 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71614 synced till here 71612
2014-07-13 18:26:46,156 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301203316 with entries=63, filesize=63.0m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301206097
2014-07-13 18:26:46,157 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:26:47,796 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:47,831 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301206097 with entries=63, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301207797
2014-07-13 18:26:47,832 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:26:49,885 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:49,913 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 71761 synced till here 71760
2014-07-13 18:26:49,921 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301207797 with entries=84, filesize=62.7m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301209885
2014-07-13 18:26:49,922 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:26:52,416 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:52,461 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301209885 with entries=75, filesize=61.4m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301212416
2014-07-13 18:26:52,461 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:26:54,957 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18097, memsize=279.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/1e025b43fe1e45758ab8cb8d7025ccd7
2014-07-13 18:26:54,970 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/1e025b43fe1e45758ab8cb8d7025ccd7 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1e025b43fe1e45758ab8cb8d7025ccd7
2014-07-13 18:26:54,981 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/1e025b43fe1e45758ab8cb8d7025ccd7, entries=1016110, sequenceid=18097, filesize=72.4m
2014-07-13 18:26:54,982 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~549.8m/576518240, currentsize=128.8m/135088000 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 9929ms, sequenceid=18097, compaction requested=true
2014-07-13 18:26:54,982 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:195), split_queue=0, merge_queue=0
2014-07-13 18:26:55,201 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-13 18:26:55,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301212416 with entries=83, filesize=62.1m; new WAL /hbase/WALs/slave1,60020,1405298890065/slave1%2C60020%2C1405298890065.1405301215202
2014-07-13 18:26:55,228 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): df2b912714c1f15f547c828466aaf923
2014-07-13 18:27:10,267 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: Waited 90366ms on a compaction to clean up 'too many store files'; waited long enough... proceeding with flush of usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923.
2014-07-13 18:27:10,268 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1405299268768.df2b912714c1f15f547c828466aaf923., current region memstore size 1.1g
2014-07-13 18:27:10,985 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:27:14,851 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/c69b5c3742504d77a3bfabd4406bf4b6 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/c69b5c3742504d77a3bfabd4406bf4b6
2014-07-13 18:27:14,868 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Removing store files after compaction...
2014-07-13 18:27:14,887 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/427379afeb9a47979408745cebd4dfad, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/427379afeb9a47979408745cebd4dfad
2014-07-13 18:27:14,891 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/07bf2fd1db644795b184c60c5ed53c4e, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/07bf2fd1db644795b184c60c5ed53c4e
2014-07-13 18:27:14,897 DEBUG [regionserver60020-smallCompactions-1405298926457] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileableStoreFile, file:hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2ebe4a4205fc48ca921bb574c5638b2b, to hdfs://master:54310/hbase/archive/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/2ebe4a4205fc48ca921bb574c5638b2b
2014-07-13 18:27:14,897 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Completed compaction of 3 file(s) in family of usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. into c69b5c3742504d77a3bfabd4406bf4b6(size=322.2m), total size for store is 4.2g. This selection was in queue for 0sec, and took 46sec to execute.
2014-07-13 18:27:14,897 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Completed compaction: Request = regionName=usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., storeName=family, fileCount=3, fileSize=325.8m, priority=-1, time=255095952302137; duration=46sec
2014-07-13 18:27:14,897 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Recursive enqueue; compaction_queue=(0:196), split_queue=0, merge_queue=0
2014-07-13 18:27:14,898 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.CompactSplitThread: CompactSplitThread Status: compaction_queue=(0:196), split_queue=0, merge_queue=0
2014-07-13 18:27:14,898 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.RatioBasedCompactionPolicy: Selecting compaction from 22 store files, 0 compacting, 22 eligible, 20 blocking
2014-07-13 18:27:14,899 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 4 files of size 510136294 starting at candidate #17 after considering 132 permutations with 116 in ratio
2014-07-13 18:27:14,899 DEBUG [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: 60bba508114b247927d755fe2fd7c8ea - family: Initiating minor compaction
2014-07-13 18:27:14,899 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HRegion: Starting compaction on family in region usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea.
2014-07-13 18:27:14,899 INFO  [regionserver60020-smallCompactions-1405298926457] regionserver.HStore: Starting compaction of 4 file(s) in family of usertable,user1,1405299268767.60bba508114b247927d755fe2fd7c8ea. into tmpdir=hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/.tmp, totalSize=486.5m
2014-07-13 18:27:14,899 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/a9db301ed9f44040b940eaee67c8629e, keycount=124570, bloomtype=ROW, size=88.7m, encoding=NONE, seqNum=14211
2014-07-13 18:27:14,900 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/62db1db8de074f4b82607bd502f0d9e4, keycount=266272, bloomtype=ROW, size=189.6m, encoding=NONE, seqNum=15139
2014-07-13 18:27:14,900 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/67a4bf0fceb849a5829d57fcacc38683, keycount=261095, bloomtype=ROW, size=186.0m, encoding=NONE, seqNum=16381
2014-07-13 18:27:14,900 DEBUG [regionserver60020-smallCompactions-1405298926457] compactions.Compactor: Compacting hdfs://master:54310/hbase/data/default/usertable/60bba508114b247927d755fe2fd7c8ea/family/ff8b912051b64a9aba4bb8314f4257c7, keycount=31184, bloomtype=ROW, size=22.2m, encoding=NONE, seqNum=16687
2014-07-13 18:27:14,987 DEBUG [regionserver60020-smallCompactions-1405298926457] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:27:15,671 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df., current region memstore size 141.1m
2014-07-13 18:27:15,728 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-13 18:27:19,668 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=18170, memsize=141.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a7396d9e3f4943429ff5b34764b51db0
2014-07-13 18:27:19,688 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/.tmp/a7396d9e3f4943429ff5b34764b51db0 as hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a7396d9e3f4943429ff5b34764b51db0
2014-07-13 18:27:19,705 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/ecd2c8d6e263c2e3db5b8717fb22b6df/family/a7396d9e3f4943429ff5b34764b51db0, entries=513780, sequenceid=18170, filesize=36.6m
2014-07-13 18:27:19,705 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~141.1m/147964160, currentsize=0.0/0 for region usertable,user5,1405299268767.ecd2c8d6e263c2e3db5b8717fb22b6df. in 4034ms, sequenceid=18170, compaction requested=true
2014-07-13 18:27:19,706 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:196), split_queue=0, merge_queue=0
