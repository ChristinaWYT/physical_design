Mon Jul  7 05:59:58 PDT 2014 Starting master on sceplus-vm48
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-07 05:59:59,258 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-07 05:59:59,259 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-07 05:59:59,259 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-07 05:59:59,414 INFO  [main] util.ServerCommandLine: env:TERM=screen
2014-07-07 05:59:59,414 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:SHLVL=6
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/logs
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/logs -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log -Dhbase.home.dir=/home/hadoop/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hadoop-1.2.1/libexec/../lib/native/Linux-amd64-64:/home/hadoop/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:LESSCLOSE=/usr/bin/lesspipe %s %s
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:HIVE_HOME=/home/hadoop/hive
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.48.100.220 51236 22
2014-07-07 05:59:59,415 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-master.znode
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:TMUX=/tmp/tmux-1001/default,1346,0
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/git/physical_design
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:SSH_TTY=/dev/pts/0
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/home/hadoop/hadoop
2014-07-07 05:59:59,416 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hadoop-1.2.1/libexec/../lib/native/Linux-amd64-64:/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-07 05:59:59,417 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-07 05:59:59,417 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.48.100.220 51236 9.1.143.58 22
2014-07-07 05:59:59,417 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-07 05:59:59,417 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-07 05:59:59,417 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase:/home/hadoop/hbase/lib/activation-1.1.jar:/home/hadoop/hbase/lib/asm-3.1.jar:/home/hadoop/hbase/lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/lib/commons-cli-1.2.jar:/home/hadoop/hbase/lib/commons-codec-1.7.jar:/home/hadoop/hbase/lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/lib/commons-configuration-1.6.jar:/home/hadoop/hbase/lib/commons-digester-1.8.jar:/home/hadoop/hbase/lib/commons-el-1.0.jar:/home/hadoop/hbase/lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/lib/commons-io-2.4.jar:/home/hadoop/hbase/lib/commons-lang-2.6.jar:/home/hadoop/hbase/lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/lib/commons-math-2.1.jar:/home/hadoop/hbase/lib/commons-net-1.4.1.jar:/home/hadoop/hbase/lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/lib/guava-12.0.1.jar:/home/hadoop/hbase/lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/lib/htrace-core-2.04.jar:/home/hadoop/hbase/lib/httpclient-4.1.3.jar:/home/hadoop/hbase/lib/httpcore-4.1.3.jar:/home/hadoop/hbase/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/lib/jersey-core-1.8.jar:/home/hadoop/hbase/lib/jersey-json-1.8.jar:/home/hadoop/hbase/lib/jersey-server-1.8.jar:/home/hadoop/hbase/lib/jettison-1.3.1.jar:/home/hadoop/hbase/lib/jetty-6.1.26.jar:/home/hadoop/hbase/lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/lib/jsr305-1.3.9.jar:/home/hadoop/hbase/lib/junit-4.11.jar:/home/hadoop/hbase/lib/libthrift-0.9.0.jar:/home/hadoop/hbase/lib/log4j-1.2.17.jar:/home/hadoop/hbase/lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/lib/xmlenc-0.52.jar:/home/hadoop/hbase/lib/zookeeper-3.4.6.jar:/home/hadoop/hadoop-1.2.1/libexec/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64/lib/tools.jar:/home/hadoop/hadoop-1.2.1/libexec/..:/home/hadoop/hadoop-1.2.1/libexec/../hadoop-core-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/asm-3.2.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/aspectjrt-1.6.11.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/aspectjtools-1.6.11.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-cli-1.2.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-codec-1.4.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-collections-3.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-configuration-1.6.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-daemon-1.0.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-digester-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-el-1.0.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-httpclient-3.0.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-io-2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-lang-2.4.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-logging-1.1.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-logging-api-1.0.4.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-math-2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-net-3.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/core-3.1.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hadoop-capacity-scheduler-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hadoop-fairscheduler-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hadoop-thriftfs-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hsqldb-1.8.0.10.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jasper-compiler-5.5.12.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jasper-runtime-5.5.12.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jdeb-0.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jersey-core-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jersey-json-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jersey-server-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jets3t-0.6.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jetty-6.1.26.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jetty-util-6.1.26.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jsch-0.1.42.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/junit-4.5.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/kfs-0.2.2.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/log4j-1.2.15.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/mockito-all-1.8.5.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/oro-2.0.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/servlet-api-2.5-20081211.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/slf4j-api-1.4.3.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/slf4j-log4j12-1.4.3.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/xmlenc-0.52.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jsp-2.1/jsp-2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jsp-2.1/jsp-api-2.1.jar
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/hadoop/hadoop/bin:/home/hadoop/hive/bin:/home/hadoop/hbase/bin:/home/hadoop/hadoop/bin:/home/hadoop/hive/bin:/home/hadoop/hbase/bin
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:DISPLAY=localhost:10.0
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-07 05:59:59,420 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:LESSOPEN=| /usr/bin/lesspipe %s
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-master.autorestart
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=1
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-master-sceplus-vm48.log
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:TMUX_PANE=%2
2014-07-07 05:59:59,421 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-07 05:59:59,422 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-07 05:59:59,422 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-master-sceplus-vm48
2014-07-07 05:59:59,422 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-07 05:59:59,424 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-07 05:59:59,424 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/logs, -Dhbase.log.file=hbase-hadoop-master-sceplus-vm48.log, -Dhbase.home.dir=/home/hadoop/hbase, -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hadoop-1.2.1/libexec/../lib/native/Linux-amd64-64:/home/hadoop/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-07 05:59:59,545 DEBUG [main] master.HMaster: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:60000 HConnection server-to-server retries=350
2014-07-07 05:59:59,773 INFO  [main] ipc.RpcServer: master/sceplus-vm48.almaden.ibm.com/9.1.143.58:60000: started 10 reader(s).
2014-07-07 05:59:59,869 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-07 05:59:59,880 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-07 05:59:59,939 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-07 05:59:59,940 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-07 05:59:59,940 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-07 05:59:59,945 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-07 05:59:59,950 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-07 06:00:00,166 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-07 06:00:00,166 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-07 06:00:00,391 INFO  [main] master.HMaster: hbase.rootdir=hdfs://master:54310/hbase, hbase.cluster.distributed=true
2014-07-07 06:00:00,462 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm48.almaden.ibm.com
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase:/home/hadoop/hbase/lib/activation-1.1.jar:/home/hadoop/hbase/lib/asm-3.1.jar:/home/hadoop/hbase/lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/lib/commons-cli-1.2.jar:/home/hadoop/hbase/lib/commons-codec-1.7.jar:/home/hadoop/hbase/lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/lib/commons-configuration-1.6.jar:/home/hadoop/hbase/lib/commons-digester-1.8.jar:/home/hadoop/hbase/lib/commons-el-1.0.jar:/home/hadoop/hbase/lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/lib/commons-io-2.4.jar:/home/hadoop/hbase/lib/commons-lang-2.6.jar:/home/hadoop/hbase/lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/lib/commons-math-2.1.jar:/home/hadoop/hbase/lib/commons-net-1.4.1.jar:/home/hadoop/hbase/lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/lib/guava-12.0.1.jar:/home/hadoop/hbase/lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/lib/htrace-core-2.04.jar:/home/hadoop/hbase/lib/httpclient-4.1.3.jar:/home/hadoop/hbase/lib/httpcore-4.1.3.jar:/home/hadoop/hbase/lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/lib/jersey-core-1.8.jar:/home/hadoop/hbase/lib/jersey-json-1.8.jar:/home/hadoop/hbase/lib/jersey-server-1.8.jar:/home/hadoop/hbase/lib/jettison-1.3.1.jar:/home/hadoop/hbase/lib/jetty-6.1.26.jar:/home/hadoop/hbase/lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/lib/jsr305-1.3.9.jar:/home/hadoop/hbase/lib/junit-4.11.jar:/home/hadoop/hbase/lib/libthrift-0.9.0.jar:/home/hadoop/hbase/lib/log4j-1.2.17.jar:/home/hadoop/hbase/lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/lib/xmlenc-0.52.jar:/home/hadoop/hbase/lib/zookeeper-3.4.6.jar:/home/hadoop/hadoop-1.2.1/libexec/../conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64/lib/tools.jar:/home/hadoop/hadoop-1.2.1/libexec/..:/home/hadoop/hadoop-1.2.1/libexec/../hadoop-core-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/asm-3.2.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/aspectjrt-1.6.11.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/aspectjtools-1.6.11.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-cli-1.2.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-codec-1.4.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-collections-3.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-configuration-1.6.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-daemon-1.0.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-digester-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-el-1.0.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-httpclient-3.0.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-io-2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-lang-2.4.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-logging-1.1.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-logging-api-1.0.4.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-math-2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/commons-net-3.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/core-3.1.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hadoop-capacity-scheduler-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hadoop-fairscheduler-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hadoop-thriftfs-1.2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/hsqldb-1.8.0.10.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jasper-compiler-5.5.12.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jasper-runtime-5.5.12.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jdeb-0.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jersey-core-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jersey-json-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jersey-server-1.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jets3t-0.6.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jetty-6.1.26.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jetty-util-6.1.26.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jsch-0.1.42.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/junit-4.5.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/kfs-0.2.2.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/log4j-1.2.15.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/mockito-all-1.8.5.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/oro-2.0.8.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/servlet-api-2.5-20081211.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/slf4j-api-1.4.3.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/slf4j-log4j12-1.4.3.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/xmlenc-0.52.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jsp-2.1/jsp-2.1.jar:/home/hadoop/hadoop-1.2.1/libexec/../lib/jsp-2.1/jsp-api-2.1.jar
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hadoop-1.2.1/libexec/../lib/native/Linux-amd64-64:/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-07 06:00:00,463 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/git/physical_design
2014-07-07 06:00:00,464 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=master:60000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-07 06:00:00,483 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-07 06:00:00,484 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:00:00,486 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:00:00,493 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:00:00,600 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2014-07-07 06:00:00,600 INFO  [main] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-07-07 06:00:00,646 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:00:00,647 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:00:00,672 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x14710e8d3780000, negotiated timeout = 90000
2014-07-07 06:00:01,641 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-07 06:00:01,641 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2014-07-07 06:00:01,651 INFO  [main] impl.MetricsSourceAdapter: MBean for source Master,sub=Server registered.
2014-07-07 06:00:01,712 INFO  [master:sceplus-vm48:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-07 06:00:01,760 INFO  [master:sceplus-vm48:60000] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-07 06:00:01,768 INFO  [master:sceplus-vm48:60000] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60010
2014-07-07 06:00:01,769 INFO  [master:sceplus-vm48:60000] http.HttpServer: listener.getLocalPort() returned 60010 webServer.getConnectors()[0].getLocalPort() returned 60010
2014-07-07 06:00:01,769 INFO  [master:sceplus-vm48:60000] http.HttpServer: Jetty bound to port 60010
2014-07-07 06:00:01,769 INFO  [master:sceplus-vm48:60000] mortbay.log: jetty-6.1.26
2014-07-07 06:00:02,150 INFO  [master:sceplus-vm48:60000] mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2014-07-07 06:00:02,232 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Node /hbase/master already exists and this is not a retry
2014-07-07 06:00:02,233 INFO  [master:sceplus-vm48:60000] master.ActiveMasterManager: Adding ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,60000,1404738000064 in backup master directory
2014-07-07 06:00:02,252 INFO  [master:sceplus-vm48:60000] master.ActiveMasterManager: Current master has this master's address, sceplus-vm48.almaden.ibm.com,60000,1404671127202; master was restarted? Deleting node.
2014-07-07 06:00:02,253 DEBUG [main-EventThread] master.ActiveMasterManager: No master available. Notifying waiting threads
2014-07-07 06:00:02,257 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2014-07-07 06:00:02,258 INFO  [master:sceplus-vm48:60000] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/sceplus-vm48.almaden.ibm.com,60000,1404738000064 from backup master directory
2014-07-07 06:00:02,261 INFO  [master:sceplus-vm48:60000] master.ActiveMasterManager: Registered Active Master=sceplus-vm48.almaden.ibm.com,60000,1404738000064
2014-07-07 06:00:02,268 INFO  [master:sceplus-vm48:60000] impl.MetricsSourceAdapter: MBean for source Master,sub=FileSystem registered.
2014-07-07 06:00:02,278 INFO  [master:sceplus-vm48:60000] util.FSUtils: Waiting for dfs to exit safe mode...
2014-07-07 06:00:12,282 INFO  [master:sceplus-vm48:60000] util.FSUtils: Waiting for dfs to exit safe mode...
2014-07-07 06:00:22,285 INFO  [master:sceplus-vm48:60000] util.FSUtils: Waiting for dfs to exit safe mode...
2014-07-07 06:00:32,542 DEBUG [master:sceplus-vm48:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://master:54310/hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2014-07-07 06:00:32,612 DEBUG [master:sceplus-vm48:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2014-07-07 06:00:32,650 INFO  [master:sceplus-vm48:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-07 06:00:32,657 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2014-07-07 06:00:32,665 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-07-07 06:00:32,708 INFO  [master:sceplus-vm48:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x61254e91, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-07 06:00:32,709 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x61254e91 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-07 06:00:32,709 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:00:32,710 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:00:32,713 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x4710e8d6be0003, negotiated timeout = 90000
2014-07-07 06:00:32,737 DEBUG [master:sceplus-vm48:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@c2b2bfc
2014-07-07 06:00:32,745 INFO  [master:sceplus-vm48:60000] impl.MetricsSourceAdapter: MBean for source Master,sub=Balancer registered.
2014-07-07 06:00:32,822 INFO  [master:sceplus-vm48:60000] impl.MetricsSourceAdapter: MBean for source Master,sub=AssignmentManger registered.
2014-07-07 06:00:32,831 DEBUG [master:sceplus-vm48:60000] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404671128690 data: PBUF��
2014-07-07 06:00:32,833 DEBUG [master:sceplus-vm48:60000] zookeeper.RegionServerTracker: RS node: /hbase/rs/slave1,60020,1404671128300 data: PBUF��
2014-07-07 06:00:32,835 INFO  [master:sceplus-vm48:60000] master.HMaster: Server active/primary master=sceplus-vm48.almaden.ibm.com,60000,1404738000064, sessionid=0x14710e8d3780000, setting cluster-up flag (Was=true)
2014-07-07 06:00:32,873 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-07 06:00:32,875 INFO  [master:sceplus-vm48:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2014-07-07 06:00:32,878 DEBUG [master:sceplus-vm48:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:sceplus-vm48.almaden.ibm.com,60000,1404738000064
2014-07-07 06:00:32,893 INFO  [master:sceplus-vm48:60000] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-07 06:00:32,895 DEBUG [master:sceplus-vm48:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-sceplus-vm48:60000, corePoolSize=5, maxPoolSize=5
2014-07-07 06:00:32,895 DEBUG [master:sceplus-vm48:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-sceplus-vm48:60000, corePoolSize=5, maxPoolSize=5
2014-07-07 06:00:32,895 DEBUG [master:sceplus-vm48:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-sceplus-vm48:60000, corePoolSize=5, maxPoolSize=5
2014-07-07 06:00:32,895 DEBUG [master:sceplus-vm48:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-sceplus-vm48:60000, corePoolSize=5, maxPoolSize=5
2014-07-07 06:00:32,895 DEBUG [master:sceplus-vm48:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-sceplus-vm48:60000, corePoolSize=10, maxPoolSize=10
2014-07-07 06:00:32,896 DEBUG [master:sceplus-vm48:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-sceplus-vm48:60000, corePoolSize=1, maxPoolSize=1
2014-07-07 06:00:32,898 DEBUG [master:sceplus-vm48:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2014-07-07 06:00:32,900 INFO  [master:sceplus-vm48:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=replicationLogCleaner, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-07 06:00:32,901 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-07 06:00:32,902 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:00:32,902 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:00:32,928 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x14710e8d3780005, negotiated timeout = 90000
2014-07-07 06:00:32,932 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Node /hbase/replication/rs already exists and this is not a retry
2014-07-07 06:00:32,932 DEBUG [master:sceplus-vm48:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2014-07-07 06:00:32,938 DEBUG [master:sceplus-vm48:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2014-07-07 06:00:32,941 DEBUG [master:sceplus-vm48:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2014-07-07 06:00:32,944 DEBUG [master:sceplus-vm48:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2014-07-07 06:00:32,945 DEBUG [master:sceplus-vm48:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2014-07-07 06:00:32,945 INFO  [master:sceplus-vm48:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-07-07 06:00:34,449 INFO  [master:sceplus-vm48:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1504 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-07-07 06:00:35,765 INFO  [FifoRpcScheduler.handler1-thread-23] master.ServerManager: Registering server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:35,766 INFO  [FifoRpcScheduler.handler1-thread-24] master.ServerManager: Registering server=slave1,60020,1404738000727
2014-07-07 06:00:35,793 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404671128690 data: PBUF��
2014-07-07 06:00:35,795 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404738001430 data: PBUF��
2014-07-07 06:00:35,797 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/slave1,60020,1404671128300 data: PBUF��
2014-07-07 06:00:35,803 INFO  [master:sceplus-vm48:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 2858 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-07-07 06:00:35,804 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404671128690 data: PBUF��
2014-07-07 06:00:35,806 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404738001430 data: PBUF��
2014-07-07 06:00:35,807 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/slave1,60020,1404671128300 data: PBUF��
2014-07-07 06:00:35,808 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/slave1,60020,1404738000727 data: PBUF��
2014-07-07 06:00:37,307 INFO  [master:sceplus-vm48:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 2, slept for 4362 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-07-07 06:00:37,458 INFO  [master:sceplus-vm48:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 2, slept for 4513 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2014-07-07 06:00:37,458 INFO  [master:sceplus-vm48:60000] master.ServerManager: Server serverName=sceplus-vm48.almaden.ibm.com,60020,1404671128690 rejected; we already have sceplus-vm48.almaden.ibm.com,60020,1404738001430 registered with same hostname and port
2014-07-07 06:00:37,458 INFO  [master:sceplus-vm48:60000] master.ServerManager: Server serverName=slave1,60020,1404671128300 rejected; we already have slave1,60020,1404738000727 registered with same hostname and port
2014-07-07 06:00:37,465 INFO  [master:sceplus-vm48:60000] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690 doesn't belong to a known region server, splitting
2014-07-07 06:00:37,465 INFO  [master:sceplus-vm48:60000] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404738001430 belongs to an existing region server
2014-07-07 06:00:37,465 INFO  [master:sceplus-vm48:60000] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/slave1,60020,1404671128300 doesn't belong to a known region server, splitting
2014-07-07 06:00:37,465 INFO  [master:sceplus-vm48:60000] master.MasterFileSystem: Log folder hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727 belongs to an existing region server
2014-07-07 06:00:37,476 DEBUG [master:sceplus-vm48:60000] master.MasterFileSystem: Renamed region directory: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting
2014-07-07 06:00:37,477 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,60020,1404671128690]
2014-07-07 06:00:37,480 DEBUG [master:sceplus-vm48:60000] master.SplitLogManager: Scheduling batch of logs to split
2014-07-07 06:00:37,481 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting]
2014-07-07 06:00:37,494 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta
2014-07-07 06:00:37,497 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta ver = 0
2014-07-07 06:00:37,516 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta acquired by slave1,60020,1404738000727
2014-07-07 06:00:37,660 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta=last_update = 1404738037565 last_version = 2 cur_worker_name = slave1,60020,1404738000727 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2014-07-07 06:00:41,749 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta entered state: DONE slave1,60020,1404738000727
2014-07-07 06:00:41,769 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690.1404735969463.meta to hdfs://master:54310/hbase/oldWALs/sceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690.1404735969463.meta
2014-07-07 06:00:41,770 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta
2014-07-07 06:00:41,776 WARN  [master:sceplus-vm48:60000] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting
2014-07-07 06:00:41,776 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting] in 4295ms
2014-07-07 06:00:41,779 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404735969463.meta
2014-07-07 06:00:41,848 INFO  [master:sceplus-vm48:60000] catalog.CatalogTracker: Failed verification of hbase:meta,,1 at address=sceplus-vm48.almaden.ibm.com,60020,1404671128690, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:41,851 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,60020,1404671128690]
2014-07-07 06:00:41,854 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting is empty dir, no logs to split
2014-07-07 06:00:41,854 DEBUG [master:sceplus-vm48:60000] master.SplitLogManager: Scheduling batch of logs to split
2014-07-07 06:00:41,854 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: started splitting 0 logs in [hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting]
2014-07-07 06:00:41,858 WARN  [master:sceplus-vm48:60000] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting
2014-07-07 06:00:41,858 INFO  [master:sceplus-vm48:60000] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting] in 4ms
2014-07-07 06:00:41,859 INFO  [master:sceplus-vm48:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-07-07 06:00:41,863 DEBUG [master:sceplus-vm48:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=sceplus-vm48.almaden.ibm.com,60020,1404738001430; 2 (online=2, available=2) available servers, forceNewPlan=false
2014-07-07 06:00:41,864 DEBUG [master:sceplus-vm48:60000] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2014-07-07 06:00:41,877 INFO  [master:sceplus-vm48:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:41,877 INFO  [master:sceplus-vm48:60000] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1404738041864, server=null} to {1588230740 state=PENDING_OPEN, ts=1404738041877, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:41,877 DEBUG [master:sceplus-vm48:60000] master.ServerManager: New admin connection to sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:42,002 INFO  [master:sceplus-vm48:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-07-07 06:00:42,022 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1404738041877, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:42,022 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1404738041877, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {1588230740 state=OPENING, ts=1404738042022, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:42,338 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=1588230740, current_state={1588230740 state=OPENING, ts=1404738042022, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:42,338 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1404738042022, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {1588230740 state=OPEN, ts=1404738042338, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:42,342 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:00:42,348 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:00:42,350 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1404738042338, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:42,351 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:42,353 INFO  [master:sceplus-vm48:60000] master.HMaster: hbase:meta assigned=1, rit=false, location=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:42,499 INFO  [master:sceplus-vm48:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-07-07 06:00:42,540 INFO  [master:sceplus-vm48:60000] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2014-07-07 06:00:42,564 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] handler.ServerShutdownHandler: Splitting logs for sceplus-vm48.almaden.ibm.com,60020,1404671128690 before assignment.
2014-07-07 06:00:42,567 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] master.SplitLogManager: dead splitlog workers [sceplus-vm48.almaden.ibm.com,60020,1404671128690]
2014-07-07 06:00:42,568 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] handler.ServerShutdownHandler: Splitting logs for slave1,60020,1404671128300 before assignment.
2014-07-07 06:00:42,570 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] master.SplitLogManager: Scheduling batch of logs to split
2014-07-07 06:00:42,570 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting]
2014-07-07 06:00:42,572 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.MasterFileSystem: Renamed region directory: hdfs://master:54310/hbase/WALs/slave1,60020,1404671128300-splitting
2014-07-07 06:00:42,572 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.SplitLogManager: dead splitlog workers [slave1,60020,1404671128300]
2014-07-07 06:00:42,574 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385
2014-07-07 06:00:42,574 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.SplitLogManager: Scheduling batch of logs to split
2014-07-07 06:00:42,574 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.SplitLogManager: started splitting 1 logs in [hdfs://master:54310/hbase/WALs/slave1,60020,1404671128300-splitting]
2014-07-07 06:00:42,576 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385 ver = 0
2014-07-07 06:00:42,578 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345
2014-07-07 06:00:42,579 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345 ver = 0
2014-07-07 06:00:42,585 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385 acquired by slave1,60020,1404738000727
2014-07-07 06:00:42,590 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:43,658 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 2 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345=last_update = 1404738042623 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0, /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385=last_update = 1404738042622 last_version = 2 cur_worker_name = slave1,60020,1404738000727 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2014-07-07 06:00:46,658 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385 entered state: DONE slave1,60020,1404738000727
2014-07-07 06:00:46,668 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting/sceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690.1404734575385 to hdfs://master:54310/hbase/oldWALs/sceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690.1404734575385
2014-07-07 06:00:46,669 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385
2014-07-07 06:00:46,672 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fsceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690-splitting%2Fsceplus-vm48.almaden.ibm.com%252C60020%252C1404671128690.1404734575385
2014-07-07 06:00:46,673 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:46,673 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404671128690-splitting] in 4103ms
2014-07-07 06:00:46,674 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] handler.ServerShutdownHandler: Reassigning 0 region(s) that sceplus-vm48.almaden.ibm.com,60020,1404671128690 was carrying (and 0 regions(s) that were opening on this server)
2014-07-07 06:00:46,674 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] master.DeadServer: Finished processing sceplus-vm48.almaden.ibm.com,60020,1404671128690
2014-07-07 06:00:46,674 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-0] handler.ServerShutdownHandler: Finished processing of shutdown of sceplus-vm48.almaden.ibm.com,60020,1404671128690
2014-07-07 06:00:46,683 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404671128300-splitting/slave1%2C60020%2C1404671128300.1404734575345 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404671128300.1404734575345
2014-07-07 06:00:46,685 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345
2014-07-07 06:00:46,688 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 1 log files in [hdfs://master:54310/hbase/WALs/slave1,60020,1404671128300-splitting] in 4114ms
2014-07-07 06:00:46,688 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] handler.ServerShutdownHandler: Reassigning 1 region(s) that slave1,60020,1404671128300 was carrying (and 0 regions(s) that were opening on this server)
2014-07-07 06:00:46,689 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.AssignmentManager: Assigning 1 region(s) to sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:46,692 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node e5ee55a21ff19d69490518939b0887e0 with OFFLINE state
2014-07-07 06:00:46,696 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404671128300-splitting%2Fslave1%252C60020%252C1404671128300.1404734575345
2014-07-07 06:00:46,698 DEBUG [main-EventThread] master.OfflineCallback: rs={e5ee55a21ff19d69490518939b0887e0 state=OFFLINE, ts=1404738042538, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:46,700 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={e5ee55a21ff19d69490518939b0887e0 state=OFFLINE, ts=1404738042538, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:46,702 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.AssignmentManager: sceplus-vm48.almaden.ibm.com,60020,1404738001430 unassigned znodes=1 of total=1
2014-07-07 06:00:46,702 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.RegionStates: Transitioned {e5ee55a21ff19d69490518939b0887e0 state=OFFLINE, ts=1404738046692, server=null} to {e5ee55a21ff19d69490518939b0887e0 state=PENDING_OPEN, ts=1404738046702, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:46,747 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.AssignmentManager: Bulk assigning done for sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:46,747 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] master.DeadServer: Finished processing slave1,60020,1404671128300
2014-07-07 06:00:46,747 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-1] handler.ServerShutdownHandler: Finished processing of shutdown of slave1,60020,1404671128300
2014-07-07 06:00:46,755 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=e5ee55a21ff19d69490518939b0887e0, current_state={e5ee55a21ff19d69490518939b0887e0 state=PENDING_OPEN, ts=1404738046702, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:46,755 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {e5ee55a21ff19d69490518939b0887e0 state=PENDING_OPEN, ts=1404738046702, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {e5ee55a21ff19d69490518939b0887e0 state=OPENING, ts=1404738046755, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:46,904 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=e5ee55a21ff19d69490518939b0887e0, current_state={e5ee55a21ff19d69490518939b0887e0 state=OPENING, ts=1404738046755, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:46,904 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {e5ee55a21ff19d69490518939b0887e0 state=OPENING, ts=1404738046755, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {e5ee55a21ff19d69490518939b0887e0 state=OPEN, ts=1404738046904, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:46,904 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of e5ee55a21ff19d69490518939b0887e0 from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:00:46,912 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node e5ee55a21ff19d69490518939b0887e0 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:00:46,917 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1402645258293.e5ee55a21ff19d69490518939b0887e0. deleted, state: {e5ee55a21ff19d69490518939b0887e0 state=OPEN, ts=1404738046904, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:00:46,917 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined e5ee55a21ff19d69490518939b0887e0 on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:00:46,998 DEBUG [master:sceplus-vm48:60000] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-07-07 06:00:47,002 DEBUG [master:sceplus-vm48:60000] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2014-07-07 06:00:47,056 DEBUG [master:sceplus-vm48:60000] client.ClientSmallScanner: Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-07-07 06:00:47,079 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Node /hbase/namespace/default already exists and this is not a retry
2014-07-07 06:00:47,088 INFO  [master:sceplus-vm48:60000] zookeeper.RecoverableZooKeeper: Node /hbase/namespace/hbase already exists and this is not a retry
2014-07-07 06:00:47,091 INFO  [master:sceplus-vm48:60000] master.HMaster: Master has completed initialization
2014-07-07 06:01:30,852 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sceplus-vm48.almaden.ibm.com,60020,1404671128690]
2014-07-07 06:01:30,852 WARN  [main-EventThread] zookeeper.RegionServerTracker: sceplus-vm48.almaden.ibm.com,60020,1404671128690 is not online or isn't known to the master.The latter could be caused by a DNS misconfiguration.
2014-07-07 06:01:30,859 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404738001430 data: PBUF��
2014-07-07 06:01:30,861 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/slave1,60020,1404738000727 data: PBUF��
2014-07-07 06:01:30,861 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave1,60020,1404671128300]
2014-07-07 06:01:30,862 WARN  [main-EventThread] zookeeper.RegionServerTracker: slave1,60020,1404671128300 is not online or isn't known to the master.The latter could be caused by a DNS misconfiguration.
2014-07-07 06:05:49,848 INFO  [FifoRpcScheduler.handler1-thread-37] master.HMaster: Client=hadoop//9.1.143.58 create 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}}
2014-07-07 06:05:49,872 DEBUG [FifoRpcScheduler.handler1-thread-37] lock.ZKInterProcessLockBase: Acquired a lock for /hbase/table-lock/usertable/write-master:600000000000000
2014-07-07 06:05:49,897 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] handler.CreateTableHandler: Create table usertable
2014-07-07 06:05:49,963 DEBUG [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://master:54310/hbase/.tmp/data/default/usertable/.tabledesc/.tableinfo.0000000001
2014-07-07 06:05:49,968 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,968 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,968 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,969 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,970 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,972 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,972 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,974 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,974 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:49,974 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: creating HRegion usertable HTD == 'usertable', {NAME => 'family', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true', CONFIGURATION => {'hbase.hregion.majorcompaction' => '0', 'hbase.store.compaction.ratio' => '0.0F'}} RootDir = hdfs://master:54310/hbase/.tmp Table name == usertable
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Instantiated usertable,user3,1404738349844.884013593d7c1f731440aebfc9634f85.
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Instantiated usertable,,1404738349844.5d8adfae065b9614cb337be48a51d0be.
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Instantiated usertable,user6,1404738349844.fcbd4075ff130d4df9edc8f47b10062a.
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Closing usertable,user3,1404738349844.884013593d7c1f731440aebfc9634f85.: disabling compactions & flushes
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Closing usertable,,1404738349844.5d8adfae065b9614cb337be48a51d0be.: disabling compactions & flushes
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Closing usertable,user6,1404738349844.fcbd4075ff130d4df9edc8f47b10062a.: disabling compactions & flushes
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Updates disabled for region usertable,,1404738349844.5d8adfae065b9614cb337be48a51d0be.
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Updates disabled for region usertable,user6,1404738349844.fcbd4075ff130d4df9edc8f47b10062a.
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Instantiated usertable,user1,1404738349844.29d9d3a7d9a498a1add8ab91fc58d5dc.
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Instantiated usertable,user5,1404738349844.21e7aed314fba8f6f1ca20bec59be2ce.
2014-07-07 06:05:50,049 INFO  [RegionOpenAndInitThread-usertable-7] regionserver.HRegion: Closed usertable,user6,1404738349844.fcbd4075ff130d4df9edc8f47b10062a.
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Closing usertable,user5,1404738349844.21e7aed314fba8f6f1ca20bec59be2ce.: disabling compactions & flushes
2014-07-07 06:05:50,049 INFO  [RegionOpenAndInitThread-usertable-1] regionserver.HRegion: Closed usertable,,1404738349844.5d8adfae065b9614cb337be48a51d0be.
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Updates disabled for region usertable,user5,1404738349844.21e7aed314fba8f6f1ca20bec59be2ce.
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Updates disabled for region usertable,user3,1404738349844.884013593d7c1f731440aebfc9634f85.
2014-07-07 06:05:50,048 DEBUG [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Instantiated usertable,user4,1404738349844.3bec2975ff0263b5c766835dbe17a2c9.
2014-07-07 06:05:50,049 INFO  [RegionOpenAndInitThread-usertable-4] regionserver.HRegion: Closed usertable,user3,1404738349844.884013593d7c1f731440aebfc9634f85.
2014-07-07 06:05:50,050 DEBUG [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Closing usertable,user4,1404738349844.3bec2975ff0263b5c766835dbe17a2c9.: disabling compactions & flushes
2014-07-07 06:05:50,049 INFO  [RegionOpenAndInitThread-usertable-6] regionserver.HRegion: Closed usertable,user5,1404738349844.21e7aed314fba8f6f1ca20bec59be2ce.
2014-07-07 06:05:50,050 DEBUG [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Updates disabled for region usertable,user4,1404738349844.3bec2975ff0263b5c766835dbe17a2c9.
2014-07-07 06:05:50,049 DEBUG [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Closing usertable,user1,1404738349844.29d9d3a7d9a498a1add8ab91fc58d5dc.: disabling compactions & flushes
2014-07-07 06:05:50,050 INFO  [RegionOpenAndInitThread-usertable-5] regionserver.HRegion: Closed usertable,user4,1404738349844.3bec2975ff0263b5c766835dbe17a2c9.
2014-07-07 06:05:50,050 DEBUG [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Updates disabled for region usertable,user1,1404738349844.29d9d3a7d9a498a1add8ab91fc58d5dc.
2014-07-07 06:05:50,050 INFO  [RegionOpenAndInitThread-usertable-2] regionserver.HRegion: Closed usertable,user1,1404738349844.29d9d3a7d9a498a1add8ab91fc58d5dc.
2014-07-07 06:05:50,052 DEBUG [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Instantiated usertable,user8,1404738349845.68edfd62a4dd5aa125f431153f0efc00.
2014-07-07 06:05:50,052 DEBUG [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Closing usertable,user8,1404738349845.68edfd62a4dd5aa125f431153f0efc00.: disabling compactions & flushes
2014-07-07 06:05:50,052 DEBUG [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Updates disabled for region usertable,user8,1404738349845.68edfd62a4dd5aa125f431153f0efc00.
2014-07-07 06:05:50,052 INFO  [RegionOpenAndInitThread-usertable-9] regionserver.HRegion: Closed usertable,user8,1404738349845.68edfd62a4dd5aa125f431153f0efc00.
2014-07-07 06:05:50,055 DEBUG [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Instantiated usertable,user2,1404738349844.b0c01fcb10c7886b283cc24243740604.
2014-07-07 06:05:50,055 DEBUG [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Closing usertable,user2,1404738349844.b0c01fcb10c7886b283cc24243740604.: disabling compactions & flushes
2014-07-07 06:05:50,055 DEBUG [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Updates disabled for region usertable,user2,1404738349844.b0c01fcb10c7886b283cc24243740604.
2014-07-07 06:05:50,055 INFO  [RegionOpenAndInitThread-usertable-3] regionserver.HRegion: Closed usertable,user2,1404738349844.b0c01fcb10c7886b283cc24243740604.
2014-07-07 06:05:50,057 DEBUG [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Instantiated usertable,user9,1404738349845.3a8212f6ef51df81d589b0bc9f90839c.
2014-07-07 06:05:50,057 DEBUG [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Closing usertable,user9,1404738349845.3a8212f6ef51df81d589b0bc9f90839c.: disabling compactions & flushes
2014-07-07 06:05:50,057 DEBUG [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Updates disabled for region usertable,user9,1404738349845.3a8212f6ef51df81d589b0bc9f90839c.
2014-07-07 06:05:50,057 INFO  [RegionOpenAndInitThread-usertable-10] regionserver.HRegion: Closed usertable,user9,1404738349845.3a8212f6ef51df81d589b0bc9f90839c.
2014-07-07 06:05:50,096 DEBUG [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Instantiated usertable,user7,1404738349845.75942e420f6ed1740c25c35c5a60554c.
2014-07-07 06:05:50,096 DEBUG [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Closing usertable,user7,1404738349845.75942e420f6ed1740c25c35c5a60554c.: disabling compactions & flushes
2014-07-07 06:05:50,096 DEBUG [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Updates disabled for region usertable,user7,1404738349845.75942e420f6ed1740c25c35c5a60554c.
2014-07-07 06:05:50,096 INFO  [RegionOpenAndInitThread-usertable-8] regionserver.HRegion: Closed usertable,user7,1404738349845.75942e420f6ed1740c25c35c5a60554c.
2014-07-07 06:05:50,178 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] catalog.MetaEditor: Added 10
2014-07-07 06:05:50,180 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] master.AssignmentManager: Bulk assigning 10 region(s) across 2 server(s), round-robin=true
2014-07-07 06:05:50,182 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.AssignmentManager: Assigning 5 region(s) to sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,182 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 5d8adfae065b9614cb337be48a51d0be with OFFLINE state
2014-07-07 06:05:50,182 DEBUG [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] master.GeneralBulkAssigner: Timeout-on-RIT=125000
2014-07-07 06:05:50,182 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.AssignmentManager: Assigning 5 region(s) to slave1,60020,1404738000727
2014-07-07 06:05:50,182 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 21e7aed314fba8f6f1ca20bec59be2ce with OFFLINE state
2014-07-07 06:05:50,183 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node fcbd4075ff130d4df9edc8f47b10062a with OFFLINE state
2014-07-07 06:05:50,183 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 29d9d3a7d9a498a1add8ab91fc58d5dc with OFFLINE state
2014-07-07 06:05:50,183 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 884013593d7c1f731440aebfc9634f85 with OFFLINE state
2014-07-07 06:05:50,183 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node b0c01fcb10c7886b283cc24243740604 with OFFLINE state
2014-07-07 06:05:50,183 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 3bec2975ff0263b5c766835dbe17a2c9 with OFFLINE state
2014-07-07 06:05:50,183 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 75942e420f6ed1740c25c35c5a60554c with OFFLINE state
2014-07-07 06:05:50,184 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 68edfd62a4dd5aa125f431153f0efc00 with OFFLINE state
2014-07-07 06:05:50,184 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 3a8212f6ef51df81d589b0bc9f90839c with OFFLINE state
2014-07-07 06:05:50,186 DEBUG [main-EventThread] master.OfflineCallback: rs={5d8adfae065b9614cb337be48a51d0be state=OFFLINE, ts=1404738350179, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,187 DEBUG [main-EventThread] master.OfflineCallback: rs={21e7aed314fba8f6f1ca20bec59be2ce state=OFFLINE, ts=1404738350179, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,187 DEBUG [main-EventThread] master.OfflineCallback: rs={fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,188 DEBUG [main-EventThread] master.OfflineCallback: rs={29d9d3a7d9a498a1add8ab91fc58d5dc state=OFFLINE, ts=1404738350179, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,188 DEBUG [main-EventThread] master.OfflineCallback: rs={884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,189 DEBUG [main-EventThread] master.OfflineCallback: rs={b0c01fcb10c7886b283cc24243740604 state=OFFLINE, ts=1404738350180, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,190 DEBUG [main-EventThread] master.OfflineCallback: rs={3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,190 DEBUG [main-EventThread] master.OfflineCallback: rs={75942e420f6ed1740c25c35c5a60554c state=OFFLINE, ts=1404738350180, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,191 DEBUG [main-EventThread] master.OfflineCallback: rs={68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,191 DEBUG [main-EventThread] master.OfflineCallback: rs={3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404738350180, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,193 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={5d8adfae065b9614cb337be48a51d0be state=OFFLINE, ts=1404738350179, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,193 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={21e7aed314fba8f6f1ca20bec59be2ce state=OFFLINE, ts=1404738350179, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,193 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,193 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={29d9d3a7d9a498a1add8ab91fc58d5dc state=OFFLINE, ts=1404738350179, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,193 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,194 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={b0c01fcb10c7886b283cc24243740604 state=OFFLINE, ts=1404738350180, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,194 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,194 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.AssignmentManager: sceplus-vm48.almaden.ibm.com,60020,1404738001430 unassigned znodes=4 of total=5
2014-07-07 06:05:50,194 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={75942e420f6ed1740c25c35c5a60554c state=OFFLINE, ts=1404738350180, server=null}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,194 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404738350179, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,194 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404738350180, server=null}, server=slave1,60020,1404738000727
2014-07-07 06:05:50,194 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.AssignmentManager: slave1,60020,1404738000727 unassigned znodes=5 of total=5
2014-07-07 06:05:50,195 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404738350182, server=null} to {fcbd4075ff130d4df9edc8f47b10062a state=PENDING_OPEN, ts=1404738350194, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,195 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404738350183, server=null} to {884013593d7c1f731440aebfc9634f85 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,195 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404738350183, server=null} to {3bec2975ff0263b5c766835dbe17a2c9 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,195 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404738350184, server=null} to {68edfd62a4dd5aa125f431153f0efc00 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,195 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404738350184, server=null} to {3a8212f6ef51df81d589b0bc9f90839c state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,195 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.ServerManager: New admin connection to slave1,60020,1404738000727
2014-07-07 06:05:50,199 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.AssignmentManager: sceplus-vm48.almaden.ibm.com,60020,1404738001430 unassigned znodes=5 of total=5
2014-07-07 06:05:50,199 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.RegionStates: Transitioned {5d8adfae065b9614cb337be48a51d0be state=OFFLINE, ts=1404738350182, server=null} to {5d8adfae065b9614cb337be48a51d0be state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,199 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.RegionStates: Transitioned {21e7aed314fba8f6f1ca20bec59be2ce state=OFFLINE, ts=1404738350182, server=null} to {21e7aed314fba8f6f1ca20bec59be2ce state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,199 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.RegionStates: Transitioned {29d9d3a7d9a498a1add8ab91fc58d5dc state=OFFLINE, ts=1404738350183, server=null} to {29d9d3a7d9a498a1add8ab91fc58d5dc state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,199 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.RegionStates: Transitioned {b0c01fcb10c7886b283cc24243740604 state=OFFLINE, ts=1404738350183, server=null} to {b0c01fcb10c7886b283cc24243740604 state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,199 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.RegionStates: Transitioned {75942e420f6ed1740c25c35c5a60554c state=OFFLINE, ts=1404738350183, server=null} to {75942e420f6ed1740c25c35c5a60554c state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,221 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-0] master.AssignmentManager: Bulk assigning done for sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,226 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=5d8adfae065b9614cb337be48a51d0be, current_state={5d8adfae065b9614cb337be48a51d0be state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,226 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {5d8adfae065b9614cb337be48a51d0be state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {5d8adfae065b9614cb337be48a51d0be state=OPENING, ts=1404738350226, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,227 DEBUG [AM.ZK.Worker-pool2-t11] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=21e7aed314fba8f6f1ca20bec59be2ce, current_state={21e7aed314fba8f6f1ca20bec59be2ce state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,227 INFO  [AM.ZK.Worker-pool2-t11] master.RegionStates: Transitioned {21e7aed314fba8f6f1ca20bec59be2ce state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {21e7aed314fba8f6f1ca20bec59be2ce state=OPENING, ts=1404738350227, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,227 DEBUG [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=29d9d3a7d9a498a1add8ab91fc58d5dc, current_state={29d9d3a7d9a498a1add8ab91fc58d5dc state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,228 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Transitioned {29d9d3a7d9a498a1add8ab91fc58d5dc state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {29d9d3a7d9a498a1add8ab91fc58d5dc state=OPENING, ts=1404738350228, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,265 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=21e7aed314fba8f6f1ca20bec59be2ce, current_state={21e7aed314fba8f6f1ca20bec59be2ce state=OPENING, ts=1404738350227, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,265 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Transitioned {21e7aed314fba8f6f1ca20bec59be2ce state=OPENING, ts=1404738350227, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {21e7aed314fba8f6f1ca20bec59be2ce state=OPEN, ts=1404738350265, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,265 DEBUG [AM.ZK.Worker-pool2-t13] handler.OpenedRegionHandler: Handling OPENED of 21e7aed314fba8f6f1ca20bec59be2ce from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:05:50,266 DEBUG [AM.ZK.Worker-pool2-t14] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=5d8adfae065b9614cb337be48a51d0be, current_state={5d8adfae065b9614cb337be48a51d0be state=OPENING, ts=1404738350226, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,266 INFO  [AM.ZK.Worker-pool2-t14] master.RegionStates: Transitioned {5d8adfae065b9614cb337be48a51d0be state=OPENING, ts=1404738350226, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {5d8adfae065b9614cb337be48a51d0be state=OPEN, ts=1404738350266, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,266 DEBUG [AM.ZK.Worker-pool2-t14] handler.OpenedRegionHandler: Handling OPENED of 5d8adfae065b9614cb337be48a51d0be from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:05:50,269 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=b0c01fcb10c7886b283cc24243740604, current_state={b0c01fcb10c7886b283cc24243740604 state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,269 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Transitioned {b0c01fcb10c7886b283cc24243740604 state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {b0c01fcb10c7886b283cc24243740604 state=OPENING, ts=1404738350269, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,271 DEBUG [AM.ZK.Worker-pool2-t13] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 21e7aed314fba8f6f1ca20bec59be2ce in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,272 DEBUG [AM.ZK.Worker-pool2-t18] master.AssignmentManager: Znode usertable,user5,1404738349844.21e7aed314fba8f6f1ca20bec59be2ce. deleted, state: {21e7aed314fba8f6f1ca20bec59be2ce state=OPEN, ts=1404738350265, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,272 INFO  [AM.ZK.Worker-pool2-t18] master.RegionStates: Onlined 21e7aed314fba8f6f1ca20bec59be2ce on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,272 DEBUG [AM.ZK.Worker-pool2-t14] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 5d8adfae065b9614cb337be48a51d0be in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,273 DEBUG [AM.ZK.Worker-pool2-t16] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=75942e420f6ed1740c25c35c5a60554c, current_state={75942e420f6ed1740c25c35c5a60554c state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,273 INFO  [AM.ZK.Worker-pool2-t16] master.RegionStates: Transitioned {75942e420f6ed1740c25c35c5a60554c state=PENDING_OPEN, ts=1404738350199, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {75942e420f6ed1740c25c35c5a60554c state=OPENING, ts=1404738350273, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,273 DEBUG [AM.ZK.Worker-pool2-t19] master.AssignmentManager: Znode usertable,,1404738349844.5d8adfae065b9614cb337be48a51d0be. deleted, state: {5d8adfae065b9614cb337be48a51d0be state=OPEN, ts=1404738350266, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,273 INFO  [AM.ZK.Worker-pool2-t19] master.RegionStates: Onlined 5d8adfae065b9614cb337be48a51d0be on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,282 DEBUG [AM.ZK.Worker-pool2-t20] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=29d9d3a7d9a498a1add8ab91fc58d5dc, current_state={29d9d3a7d9a498a1add8ab91fc58d5dc state=OPENING, ts=1404738350228, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,282 INFO  [AM.ZK.Worker-pool2-t20] master.RegionStates: Transitioned {29d9d3a7d9a498a1add8ab91fc58d5dc state=OPENING, ts=1404738350228, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {29d9d3a7d9a498a1add8ab91fc58d5dc state=OPEN, ts=1404738350282, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,282 DEBUG [AM.ZK.Worker-pool2-t20] handler.OpenedRegionHandler: Handling OPENED of 29d9d3a7d9a498a1add8ab91fc58d5dc from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:05:50,288 DEBUG [AM.ZK.Worker-pool2-t20] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 29d9d3a7d9a498a1add8ab91fc58d5dc in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,288 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Znode usertable,user1,1404738349844.29d9d3a7d9a498a1add8ab91fc58d5dc. deleted, state: {29d9d3a7d9a498a1add8ab91fc58d5dc state=OPEN, ts=1404738350282, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,289 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Onlined 29d9d3a7d9a498a1add8ab91fc58d5dc on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,307 DEBUG [AM.ZK.Worker-pool2-t23] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=b0c01fcb10c7886b283cc24243740604, current_state={b0c01fcb10c7886b283cc24243740604 state=OPENING, ts=1404738350269, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,308 INFO  [AM.ZK.Worker-pool2-t23] master.RegionStates: Transitioned {b0c01fcb10c7886b283cc24243740604 state=OPENING, ts=1404738350269, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {b0c01fcb10c7886b283cc24243740604 state=OPEN, ts=1404738350308, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,308 DEBUG [AM.ZK.Worker-pool2-t23] handler.OpenedRegionHandler: Handling OPENED of b0c01fcb10c7886b283cc24243740604 from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:05:50,320 DEBUG [AM.ZK.Worker-pool2-t23] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node b0c01fcb10c7886b283cc24243740604 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,321 DEBUG [AM.ZK.Worker-pool2-t25] master.AssignmentManager: Znode usertable,user2,1404738349844.b0c01fcb10c7886b283cc24243740604. deleted, state: {b0c01fcb10c7886b283cc24243740604 state=OPEN, ts=1404738350308, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,321 INFO  [AM.ZK.Worker-pool2-t25] master.RegionStates: Onlined b0c01fcb10c7886b283cc24243740604 on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,352 DEBUG [AM.ZK.Worker-pool2-t26] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=75942e420f6ed1740c25c35c5a60554c, current_state={75942e420f6ed1740c25c35c5a60554c state=OPENING, ts=1404738350273, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,352 INFO  [AM.ZK.Worker-pool2-t26] master.RegionStates: Transitioned {75942e420f6ed1740c25c35c5a60554c state=OPENING, ts=1404738350273, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {75942e420f6ed1740c25c35c5a60554c state=OPEN, ts=1404738350352, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,352 DEBUG [AM.ZK.Worker-pool2-t26] handler.OpenedRegionHandler: Handling OPENED of 75942e420f6ed1740c25c35c5a60554c from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:05:50,357 DEBUG [AM.ZK.Worker-pool2-t26] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 75942e420f6ed1740c25c35c5a60554c in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,358 DEBUG [AM.ZK.Worker-pool2-t28] master.AssignmentManager: Znode usertable,user7,1404738349845.75942e420f6ed1740c25c35c5a60554c. deleted, state: {75942e420f6ed1740c25c35c5a60554c state=OPEN, ts=1404738350352, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:05:50,358 INFO  [AM.ZK.Worker-pool2-t28] master.RegionStates: Onlined 75942e420f6ed1740c25c35c5a60554c on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:05:50,378 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-GeneralBulkAssigner-1] master.AssignmentManager: Bulk assigning done for slave1,60020,1404738000727
2014-07-07 06:05:50,379 DEBUG [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] master.GeneralBulkAssigner: bulk assigning total 10 regions to 2 servers, took 197ms, with 5 regions still in transition
2014-07-07 06:05:50,379 INFO  [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] master.AssignmentManager: Bulk assigning done
2014-07-07 06:05:50,385 DEBUG [AM.ZK.Worker-pool2-t9] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=slave1,60020,1404738000727, region=fcbd4075ff130d4df9edc8f47b10062a, current_state={fcbd4075ff130d4df9edc8f47b10062a state=PENDING_OPEN, ts=1404738350194, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,386 INFO  [AM.ZK.Worker-pool2-t9] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=PENDING_OPEN, ts=1404738350194, server=slave1,60020,1404738000727} to {fcbd4075ff130d4df9edc8f47b10062a state=OPENING, ts=1404738350386, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,386 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=slave1,60020,1404738000727, region=884013593d7c1f731440aebfc9634f85, current_state={884013593d7c1f731440aebfc9634f85 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,386 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727} to {884013593d7c1f731440aebfc9634f85 state=OPENING, ts=1404738350386, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,386 DEBUG [AM.ZK.Worker-pool2-t11] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=slave1,60020,1404738000727, region=3bec2975ff0263b5c766835dbe17a2c9, current_state={3bec2975ff0263b5c766835dbe17a2c9 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,387 INFO  [AM.ZK.Worker-pool2-t11] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727} to {3bec2975ff0263b5c766835dbe17a2c9 state=OPENING, ts=1404738350387, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,389 DEBUG [MASTER_TABLE_OPERATIONS-sceplus-vm48:60000-0] lock.ZKInterProcessLockBase: Released /hbase/table-lock/usertable/write-master:600000000000000
2014-07-07 06:05:50,638 DEBUG [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=slave1,60020,1404738000727, region=884013593d7c1f731440aebfc9634f85, current_state={884013593d7c1f731440aebfc9634f85 state=OPENING, ts=1404738350386, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,638 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=OPENING, ts=1404738350386, server=slave1,60020,1404738000727} to {884013593d7c1f731440aebfc9634f85 state=OPEN, ts=1404738350638, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,638 DEBUG [AM.ZK.Worker-pool2-t12] handler.OpenedRegionHandler: Handling OPENED of 884013593d7c1f731440aebfc9634f85 from slave1,60020,1404738000727; deleting unassigned node
2014-07-07 06:05:50,638 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=slave1,60020,1404738000727, region=3bec2975ff0263b5c766835dbe17a2c9, current_state={3bec2975ff0263b5c766835dbe17a2c9 state=OPENING, ts=1404738350387, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,638 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=OPENING, ts=1404738350387, server=slave1,60020,1404738000727} to {3bec2975ff0263b5c766835dbe17a2c9 state=OPEN, ts=1404738350638, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,638 DEBUG [AM.ZK.Worker-pool2-t15] handler.OpenedRegionHandler: Handling OPENED of 3bec2975ff0263b5c766835dbe17a2c9 from slave1,60020,1404738000727; deleting unassigned node
2014-07-07 06:05:50,639 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=slave1,60020,1404738000727, region=fcbd4075ff130d4df9edc8f47b10062a, current_state={fcbd4075ff130d4df9edc8f47b10062a state=OPENING, ts=1404738350386, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,639 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=OPENING, ts=1404738350386, server=slave1,60020,1404738000727} to {fcbd4075ff130d4df9edc8f47b10062a state=OPEN, ts=1404738350639, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,639 DEBUG [AM.ZK.Worker-pool2-t13] handler.OpenedRegionHandler: Handling OPENED of fcbd4075ff130d4df9edc8f47b10062a from slave1,60020,1404738000727; deleting unassigned node
2014-07-07 06:05:50,645 DEBUG [AM.ZK.Worker-pool2-t18] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=slave1,60020,1404738000727, region=68edfd62a4dd5aa125f431153f0efc00, current_state={68edfd62a4dd5aa125f431153f0efc00 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,645 INFO  [AM.ZK.Worker-pool2-t18] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727} to {68edfd62a4dd5aa125f431153f0efc00 state=OPENING, ts=1404738350645, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,646 DEBUG [AM.ZK.Worker-pool2-t12] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 884013593d7c1f731440aebfc9634f85 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,646 DEBUG [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Znode usertable,user3,1404738349844.884013593d7c1f731440aebfc9634f85. deleted, state: {884013593d7c1f731440aebfc9634f85 state=OPEN, ts=1404738350638, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,646 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Onlined 884013593d7c1f731440aebfc9634f85 on slave1,60020,1404738000727
2014-07-07 06:05:50,647 DEBUG [AM.ZK.Worker-pool2-t14] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=slave1,60020,1404738000727, region=3a8212f6ef51df81d589b0bc9f90839c, current_state={3a8212f6ef51df81d589b0bc9f90839c state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,647 INFO  [AM.ZK.Worker-pool2-t14] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=PENDING_OPEN, ts=1404738350195, server=slave1,60020,1404738000727} to {3a8212f6ef51df81d589b0bc9f90839c state=OPENING, ts=1404738350647, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,647 DEBUG [AM.ZK.Worker-pool2-t15] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 3bec2975ff0263b5c766835dbe17a2c9 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,647 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Znode usertable,user4,1404738349844.3bec2975ff0263b5c766835dbe17a2c9. deleted, state: {3bec2975ff0263b5c766835dbe17a2c9 state=OPEN, ts=1404738350638, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,648 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Onlined 3bec2975ff0263b5c766835dbe17a2c9 on slave1,60020,1404738000727
2014-07-07 06:05:50,648 DEBUG [AM.ZK.Worker-pool2-t13] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node fcbd4075ff130d4df9edc8f47b10062a in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,648 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Znode usertable,user6,1404738349844.fcbd4075ff130d4df9edc8f47b10062a. deleted, state: {fcbd4075ff130d4df9edc8f47b10062a state=OPEN, ts=1404738350639, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,648 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Onlined fcbd4075ff130d4df9edc8f47b10062a on slave1,60020,1404738000727
2014-07-07 06:05:50,699 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=slave1,60020,1404738000727, region=68edfd62a4dd5aa125f431153f0efc00, current_state={68edfd62a4dd5aa125f431153f0efc00 state=OPENING, ts=1404738350645, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,699 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=OPENING, ts=1404738350645, server=slave1,60020,1404738000727} to {68edfd62a4dd5aa125f431153f0efc00 state=OPEN, ts=1404738350699, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,699 DEBUG [AM.ZK.Worker-pool2-t22] handler.OpenedRegionHandler: Handling OPENED of 68edfd62a4dd5aa125f431153f0efc00 from slave1,60020,1404738000727; deleting unassigned node
2014-07-07 06:05:50,699 DEBUG [AM.ZK.Worker-pool2-t21] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=slave1,60020,1404738000727, region=3a8212f6ef51df81d589b0bc9f90839c, current_state={3a8212f6ef51df81d589b0bc9f90839c state=OPENING, ts=1404738350647, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,700 INFO  [AM.ZK.Worker-pool2-t21] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=OPENING, ts=1404738350647, server=slave1,60020,1404738000727} to {3a8212f6ef51df81d589b0bc9f90839c state=OPEN, ts=1404738350700, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,700 DEBUG [AM.ZK.Worker-pool2-t21] handler.OpenedRegionHandler: Handling OPENED of 3a8212f6ef51df81d589b0bc9f90839c from slave1,60020,1404738000727; deleting unassigned node
2014-07-07 06:05:50,705 DEBUG [AM.ZK.Worker-pool2-t22] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 68edfd62a4dd5aa125f431153f0efc00 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,705 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Znode usertable,user8,1404738349845.68edfd62a4dd5aa125f431153f0efc00. deleted, state: {68edfd62a4dd5aa125f431153f0efc00 state=OPEN, ts=1404738350699, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,705 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Onlined 68edfd62a4dd5aa125f431153f0efc00 on slave1,60020,1404738000727
2014-07-07 06:05:50,706 DEBUG [AM.ZK.Worker-pool2-t21] zookeeper.ZKAssign: master:60000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 3a8212f6ef51df81d589b0bc9f90839c in expected state RS_ZK_REGION_OPENED
2014-07-07 06:05:50,706 DEBUG [AM.ZK.Worker-pool2-t21] master.AssignmentManager: Znode usertable,user9,1404738349845.3a8212f6ef51df81d589b0bc9f90839c. deleted, state: {3a8212f6ef51df81d589b0bc9f90839c state=OPEN, ts=1404738350700, server=slave1,60020,1404738000727}
2014-07-07 06:05:50,706 INFO  [AM.ZK.Worker-pool2-t21] master.RegionStates: Onlined 3a8212f6ef51df81d589b0bc9f90839c on slave1,60020,1404738000727
2014-07-07 06:09:05,222 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:05,659 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:05,947 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:06,311 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x4710e8d6be0003, negotiated timeout = 90000
2014-07-07 06:09:08,950 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:08,951 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780005, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:08,952 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780000, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:09,062 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:09,063 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:09,067 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780000, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:09,835 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:09,835 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:09,836 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780005, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:09,891 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:09,891 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:09,892 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:10,256 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:10,267 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:10,276 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780000, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:10,912 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:10,912 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:10,913 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780000, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:11,003 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:11,230 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:11,231 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:11,345 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:12,019 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:12,020 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780005, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:12,179 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:12,182 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:12,193 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780000, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:12,238 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:12,239 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:12,239 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:12,591 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:12,591 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:12,592 INFO  [main-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780000, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:13,055 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:13,056 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:13,056 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14710e8d3780005, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:13,926 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:13,927 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:13,928 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:14,152 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:14,152 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-07 06:09:14,153 INFO  [master:sceplus-vm48:60000-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x4710e8d6be0003, likely server has closed socket, closing socket connection and attempting reconnect
2014-07-07 06:09:14,295 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:14,296 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:14,299 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x14710e8d3780005, negotiated timeout = 90000
2014-07-07 06:09:14,382 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:14,383 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:14,384 INFO  [main-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x14710e8d3780000, negotiated timeout = 90000
2014-07-07 06:09:15,835 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-07 06:09:15,836 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-07 06:09:15,838 INFO  [master:sceplus-vm48:60000-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x4710e8d6be0003, negotiated timeout = 90000
2014-07-07 06:09:40,827 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5967ms
No GCs detected
2014-07-07 06:11:33,000 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690.1404734575385
2014-07-07 06:11:33,751 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404671128690.1404735969463.meta
2014-07-07 06:11:33,754 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404671128300.1404734575345
2014-07-07 06:17:32,969 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738035043
2014-07-07 06:17:32,973 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738368811
2014-07-07 06:17:32,975 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738371497
2014-07-07 06:17:32,978 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738373861
2014-07-07 06:17:32,980 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738375999
2014-07-07 06:17:32,983 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738378960
2014-07-07 06:17:32,985 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738382049
2014-07-07 06:17:32,987 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738383792
2014-07-07 06:17:32,990 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738386187
2014-07-07 06:17:32,993 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738388627
2014-07-07 06:17:32,995 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738391424
2014-07-07 06:17:33,006 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738393007
2014-07-07 06:17:33,009 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738394720
2014-07-07 06:17:33,011 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738396553
2014-07-07 06:17:33,013 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738403865
2014-07-07 06:17:33,015 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738406123
2014-07-07 06:17:33,018 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738408153
2014-07-07 06:17:33,020 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738414368
2014-07-07 06:17:33,025 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738418877
2014-07-07 06:17:33,027 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738420915
2014-07-07 06:17:33,029 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738422911
2014-07-07 06:17:33,032 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738425351
2014-07-07 06:17:33,034 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738426994
2014-07-07 06:18:32,966 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738035881
2014-07-07 06:18:32,973 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738369870
2014-07-07 06:18:32,976 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738404452
2014-07-07 06:18:32,979 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738406127
2014-07-07 06:18:32,981 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738419812
2014-07-07 06:18:32,985 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738425101
2014-07-07 06:18:32,987 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738430297
2014-07-07 06:18:32,989 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738438220
2014-07-07 06:18:32,991 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738441046
2014-07-07 06:18:32,995 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738443236
2014-07-07 06:18:32,998 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738446559
2014-07-07 06:18:33,001 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738449435
2014-07-07 06:18:33,003 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738475052
2014-07-07 06:18:33,008 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738477021
2014-07-07 06:18:33,014 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738479354
2014-07-07 06:18:33,016 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738481844
2014-07-07 06:18:33,018 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738486243
2014-07-07 06:18:33,021 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738429505
2014-07-07 06:18:33,025 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738431673
2014-07-07 06:18:33,027 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738433789
2014-07-07 06:18:33,032 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738437005
2014-07-07 06:19:32,988 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738488274
2014-07-07 06:19:32,991 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738490999
2014-07-07 06:19:32,994 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738493861
2014-07-07 06:19:32,996 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738498182
2014-07-07 06:19:32,998 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738501643
2014-07-07 06:19:33,000 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738504441
2014-07-07 06:19:33,002 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738509556
2014-07-07 06:19:33,004 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738512657
2014-07-07 06:19:33,006 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738438931
2014-07-07 06:19:33,008 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738441171
2014-07-07 06:19:33,010 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738443163
2014-07-07 06:19:33,012 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738445383
2014-07-07 06:19:33,014 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738449946
2014-07-07 06:19:33,017 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738452940
2014-07-07 06:19:33,018 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738455717
2014-07-07 06:19:33,028 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738459109
2014-07-07 06:19:33,030 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738462599
2014-07-07 06:19:33,033 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738465098
2014-07-07 06:19:33,035 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738467013
2014-07-07 06:19:33,037 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738469015
2014-07-07 06:19:33,039 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738471043
2014-07-07 06:19:33,041 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738472622
2014-07-07 06:19:33,043 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738474347
2014-07-07 06:19:33,045 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738476002
2014-07-07 06:19:33,047 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738478569
2014-07-07 06:19:33,049 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738480407
2014-07-07 06:19:33,051 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738482877
2014-07-07 06:19:33,053 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738484988
2014-07-07 06:19:33,055 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738487153
2014-07-07 06:19:33,057 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738489320
2014-07-07 06:19:33,059 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738492605
2014-07-07 06:19:33,064 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738494953
2014-07-07 06:19:33,066 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738497732
2014-07-07 06:19:33,068 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738500582
2014-07-07 06:19:33,070 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738503296
2014-07-07 06:20:32,959 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738506285
2014-07-07 06:20:32,961 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738507995
2014-07-07 06:20:32,964 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738511023
2014-07-07 06:20:32,966 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738512660
2014-07-07 06:20:32,969 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738515319
2014-07-07 06:20:32,971 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738517686
2014-07-07 06:21:32,958 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738514537
2014-07-07 06:21:32,961 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738517007
2014-07-07 06:21:32,963 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738520796
2014-07-07 06:22:32,962 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738526397
2014-07-07 06:22:32,965 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738570100
2014-07-07 06:22:32,968 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738621634
2014-07-07 06:22:32,970 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738629834
2014-07-07 06:22:32,972 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738651825
2014-07-07 06:22:32,974 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738661697
2014-07-07 06:22:32,976 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738665569
2014-07-07 06:22:32,978 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738669688
2014-07-07 06:22:32,980 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738674655
2014-07-07 06:22:32,982 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738686904
2014-07-07 06:22:32,984 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738690859
2014-07-07 06:22:32,986 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738694628
2014-07-07 06:22:32,988 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738698157
2014-07-07 06:22:32,990 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738703639
2014-07-07 06:22:32,992 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738708397
2014-07-07 06:22:32,994 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738520444
2014-07-07 06:22:32,996 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738523183
2014-07-07 06:22:32,999 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738525738
2014-07-07 06:22:33,001 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738529271
2014-07-07 06:22:33,005 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738558984
2014-07-07 06:22:33,007 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738564857
2014-07-07 06:22:33,010 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738568492
2014-07-07 06:22:33,012 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738588074
2014-07-07 06:22:33,014 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738596719
2014-07-07 06:22:33,016 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738606054
2014-07-07 06:22:33,018 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738612817
2014-07-07 06:22:33,021 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738619691
2014-07-07 06:22:33,023 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738624888
2014-07-07 06:22:33,025 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738632040
2014-07-07 06:22:33,027 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738640053
2014-07-07 06:22:33,035 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738644715
2014-07-07 06:22:33,038 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738649429
2014-07-07 06:22:33,039 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738653111
2014-07-07 06:22:33,047 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738657157
2014-07-07 06:22:33,049 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738661657
2014-07-07 06:22:33,051 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738664882
2014-07-07 06:22:33,053 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738669423
2014-07-07 06:22:33,056 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738673117
2014-07-07 06:22:33,058 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738677920
2014-07-07 06:22:33,060 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738681140
2014-07-07 06:22:33,062 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738684596
2014-07-07 06:22:33,064 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738688698
2014-07-07 06:22:33,066 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738692063
2014-07-07 06:22:33,068 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738696117
2014-07-07 06:22:33,070 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738699784
2014-07-07 06:22:33,072 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738702415
2014-07-07 06:22:33,074 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738706811
2014-07-07 06:22:33,076 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738710369
2014-07-07 06:23:32,962 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738711864
2014-07-07 06:23:32,965 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738715924
2014-07-07 06:30:32,972 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738721517
2014-07-07 06:30:32,992 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738724092
2014-07-07 06:30:33,003 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738726555
2014-07-07 06:30:33,010 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738729883
2014-07-07 06:30:33,021 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738736133
2014-07-07 06:30:33,024 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738739311
2014-07-07 06:37:33,184 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738743130
2014-07-07 06:37:33,196 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738746801
2014-07-07 06:37:33,199 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738750073
2014-07-07 06:38:33,122 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404738753885
2014-07-07 06:38:33,130 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739232223
2014-07-07 06:38:33,134 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739322840
2014-07-07 06:38:33,136 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739329883
2014-07-07 06:38:33,138 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739402721
2014-07-07 06:38:33,140 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739488689
2014-07-07 06:40:32,969 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739579032
2014-07-07 06:40:32,983 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739646543
2014-07-07 06:40:32,986 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739658436
2014-07-07 06:41:33,104 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739669034
2014-07-07 06:41:33,146 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739673183
2014-07-07 06:41:33,149 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739684842
2014-07-07 06:41:33,153 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739694941
2014-07-07 06:41:33,155 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739712169
2014-07-07 06:41:33,158 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739728098
2014-07-07 06:41:33,161 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738713955
2014-07-07 06:41:33,163 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738718651
2014-07-07 06:41:33,165 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738721803
2014-07-07 06:41:33,175 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738723885
2014-07-07 06:41:33,177 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738726652
2014-07-07 06:41:33,180 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738730038
2014-07-07 06:41:33,182 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738733499
2014-07-07 06:41:33,185 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738736232
2014-07-07 06:41:33,188 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738739373
2014-07-07 06:41:33,190 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738741989
2014-07-07 06:41:33,192 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738745770
2014-07-07 06:41:33,195 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738748717
2014-07-07 06:41:33,197 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738752431
2014-07-07 06:41:33,199 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404738755763
2014-07-07 06:41:33,206 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739234630
2014-07-07 06:41:33,208 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739326496
2014-07-07 06:41:33,209 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739397927
2014-07-07 06:41:33,211 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739482604
2014-07-07 06:41:33,213 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739489127
2014-07-07 06:41:33,215 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739580432
2014-07-07 06:41:33,218 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739646062
2014-07-07 06:41:33,220 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739657415
2014-07-07 06:41:33,224 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739667386
2014-07-07 06:41:33,226 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739671676
2014-07-07 06:42:32,994 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739683506
2014-07-07 06:42:33,061 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739692660
2014-07-07 06:42:33,063 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739709657
2014-07-07 06:43:32,977 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739723592
2014-07-07 06:43:32,993 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739739938
2014-07-07 06:43:32,995 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739746908
2014-07-07 06:44:33,007 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739745572
2014-07-07 06:44:33,034 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739808142
2014-07-07 06:44:33,035 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739830371
2014-07-07 06:45:33,167 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: slave1%2C60020%2C1404738000727.1404739813680
2014-07-07 06:46:25,060 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [slave1,60020,1404738000727]
2014-07-07 06:46:25,078 DEBUG [main-EventThread] master.AssignmentManager: based on AM, current region=hbase:meta,,1.1588230740 is on server=sceplus-vm48.almaden.ibm.com,60020,1404738001430 server being checked: slave1,60020,1404738000727
2014-07-07 06:46:25,085 DEBUG [main-EventThread] master.ServerManager: Added=slave1,60020,1404738000727 to dead servers, submitted shutdown handler to be executed meta=false
2014-07-07 06:46:25,088 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404738001430 data: PBUF��
2014-07-07 06:46:25,173 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] handler.ServerShutdownHandler: Splitting logs for slave1,60020,1404738000727 before assignment.
2014-07-07 06:46:25,241 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.MasterFileSystem: Renamed region directory: hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting
2014-07-07 06:46:25,241 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.SplitLogManager: dead splitlog workers [slave1,60020,1404738000727]
2014-07-07 06:46:25,254 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.SplitLogManager: Scheduling batch of logs to split
2014-07-07 06:46:25,254 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.SplitLogManager: started splitting 33 logs in [hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting]
2014-07-07 06:46:25,258 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924
2014-07-07 06:46:25,272 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908
2014-07-07 06:46:25,277 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156
2014-07-07 06:46:25,277 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198
2014-07-07 06:46:25,278 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497
2014-07-07 06:46:25,278 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046
2014-07-07 06:46:25,278 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555
2014-07-07 06:46:25,278 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212
2014-07-07 06:46:25,288 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219
2014-07-07 06:46:25,293 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925
2014-07-07 06:46:25,293 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708
2014-07-07 06:46:25,294 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648
2014-07-07 06:46:25,307 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963
2014-07-07 06:46:25,308 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924 ver = 0
2014-07-07 06:46:25,308 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645
2014-07-07 06:46:25,308 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860
2014-07-07 06:46:25,323 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872
2014-07-07 06:46:25,324 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798
2014-07-07 06:46:25,325 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189
2014-07-07 06:46:25,325 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966
2014-07-07 06:46:25,325 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756
2014-07-07 06:46:25,325 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792
2014-07-07 06:46:25,326 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483
2014-07-07 06:46:25,326 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591
2014-07-07 06:46:25,326 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522
2014-07-07 06:46:25,326 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070
2014-07-07 06:46:25,326 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367
2014-07-07 06:46:25,327 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350
2014-07-07 06:46:25,327 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196
2014-07-07 06:46:25,327 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057
2014-07-07 06:46:25,327 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259
2014-07-07 06:46:25,327 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629
2014-07-07 06:46:25,327 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862
2014-07-07 06:46:25,328 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937
2014-07-07 06:46:25,340 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908 ver = 0
2014-07-07 06:46:25,340 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156 ver = 0
2014-07-07 06:46:25,340 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198 ver = 0
2014-07-07 06:46:25,340 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497 ver = 0
2014-07-07 06:46:25,341 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046 ver = 0
2014-07-07 06:46:25,341 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555 ver = 0
2014-07-07 06:46:25,341 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212 ver = 0
2014-07-07 06:46:25,341 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219 ver = 0
2014-07-07 06:46:25,341 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925 ver = 0
2014-07-07 06:46:25,341 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708 ver = 0
2014-07-07 06:46:25,351 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648 ver = 0
2014-07-07 06:46:25,351 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963 ver = 0
2014-07-07 06:46:25,351 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645 ver = 0
2014-07-07 06:46:25,351 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860 ver = 0
2014-07-07 06:46:25,356 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872 ver = 0
2014-07-07 06:46:25,362 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798 ver = 0
2014-07-07 06:46:25,362 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189 ver = 0
2014-07-07 06:46:25,362 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966 ver = 0
2014-07-07 06:46:25,362 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756 ver = 0
2014-07-07 06:46:25,362 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792 ver = 0
2014-07-07 06:46:25,363 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483 ver = 0
2014-07-07 06:46:25,363 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591 ver = 0
2014-07-07 06:46:25,363 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522 ver = 0
2014-07-07 06:46:25,363 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070 ver = 0
2014-07-07 06:46:25,363 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367 ver = 0
2014-07-07 06:46:25,367 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350 ver = 0
2014-07-07 06:46:25,367 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196 ver = 0
2014-07-07 06:46:25,367 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057 ver = 0
2014-07-07 06:46:25,368 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259 ver = 0
2014-07-07 06:46:25,368 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629 ver = 0
2014-07-07 06:46:25,368 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862 ver = 0
2014-07-07 06:46:25,368 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937 ver = 0
2014-07-07 06:46:25,370 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:25,617 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 33 unassigned = 32 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046=last_update = 1404740785370 last_version = 1 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 0 error = 0}
2014-07-07 06:46:26,368 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:28,202 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:28,218 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739911046 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739911046
2014-07-07 06:46:28,223 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046
2014-07-07 06:46:28,249 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739911046
2014-07-07 06:46:28,298 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:28,678 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:28,685 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739979219 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739979219
2014-07-07 06:46:28,686 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219
2014-07-07 06:46:28,733 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739979219
2014-07-07 06:46:29,183 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:29,314 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:29,320 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740567070 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740567070
2014-07-07 06:46:29,321 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070
2014-07-07 06:46:29,328 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740567070
2014-07-07 06:46:29,982 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:30,621 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 30 unassigned = 28 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924=last_update = 1404740789207 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645=last_update = 1404740790073 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 3 error = 0}
2014-07-07 06:46:30,660 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:30,678 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739830924 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739830924
2014-07-07 06:46:30,683 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924
2014-07-07 06:46:30,697 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739830924
2014-07-07 06:46:30,698 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:32,014 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:32,035 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740094648 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740094648
2014-07-07 06:46:32,044 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648
2014-07-07 06:46:32,046 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740094648
2014-07-07 06:46:32,061 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:32,070 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740179645 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740179645
2014-07-07 06:46:32,070 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645
2014-07-07 06:46:32,125 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740179645
2014-07-07 06:46:32,126 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:32,742 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:33,215 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739846572
2014-07-07 06:46:33,286 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739866425
2014-07-07 06:46:33,315 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739887849
2014-07-07 06:46:33,324 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739906406
2014-07-07 06:46:33,361 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739913544
2014-07-07 06:46:33,365 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739936548
2014-07-07 06:46:33,685 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:33,698 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739957212 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739957212
2014-07-07 06:46:33,699 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212
2014-07-07 06:46:33,702 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739957212
2014-07-07 06:46:33,729 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:33,888 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:33,900 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739867156 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739867156
2014-07-07 06:46:33,901 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156
2014-07-07 06:46:33,911 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739867156
2014-07-07 06:46:34,612 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:35,649 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 25 unassigned = 23 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925=last_update = 1404740793759 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259=last_update = 1404740794667 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 8 error = 0}
2014-07-07 06:46:35,757 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:35,791 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740044925 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740044925
2014-07-07 06:46:35,792 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925
2014-07-07 06:46:35,795 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740044925
2014-07-07 06:46:35,839 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:35,905 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:35,914 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740643259 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740643259
2014-07-07 06:46:35,915 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259
2014-07-07 06:46:35,924 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740643259
2014-07-07 06:46:36,676 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:36,707 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:36,714 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740554591 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740554591
2014-07-07 06:46:36,715 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591
2014-07-07 06:46:36,721 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740554591
2014-07-07 06:46:37,332 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:37,823 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:37,831 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740605196 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740605196
2014-07-07 06:46:37,832 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196
2014-07-07 06:46:37,838 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740605196
2014-07-07 06:46:38,330 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:38,614 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:38,625 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739887198 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739887198
2014-07-07 06:46:38,626 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198
2014-07-07 06:46:38,654 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739887198
2014-07-07 06:46:38,913 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:40,133 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:40,145 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740499756 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740499756
2014-07-07 06:46:40,145 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756
2014-07-07 06:46:40,155 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740499756
2014-07-07 06:46:40,166 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:40,954 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:41,046 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739904497 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739904497
2014-07-07 06:46:41,047 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497
2014-07-07 06:46:41,105 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739904497
2014-07-07 06:46:41,106 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:41,398 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:41,406 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740397189 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740397189
2014-07-07 06:46:41,407 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189
2014-07-07 06:46:41,409 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740397189
2014-07-07 06:46:41,630 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 17 unassigned = 16 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629=last_update = 1404740801130 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 16 error = 0}
2014-07-07 06:46:42,019 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:42,029 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740664629 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740664629
2014-07-07 06:46:42,032 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629
2014-07-07 06:46:42,035 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740664629
2014-07-07 06:46:42,063 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:42,944 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:43,400 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:43,407 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739846908 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739846908
2014-07-07 06:46:43,408 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908
2014-07-07 06:46:43,422 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739846908
2014-07-07 06:46:43,776 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:45,581 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:45,615 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740548483 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740548483
2014-07-07 06:46:45,617 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483
2014-07-07 06:46:45,621 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740548483
2014-07-07 06:46:45,637 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:46,619 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 14 unassigned = 12 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937=last_update = 1404740802979 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350=last_update = 1404740805664 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 19 error = 0}
2014-07-07 06:46:46,724 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:46,735 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740582350 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740582350
2014-07-07 06:46:46,736 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350
2014-07-07 06:46:46,738 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740582350
2014-07-07 06:46:46,789 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:47,820 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:47,830 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740690937 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740690937
2014-07-07 06:46:47,831 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937
2014-07-07 06:46:47,838 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740690937
2014-07-07 06:46:47,852 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:47,852 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:47,860 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740372798 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740372798
2014-07-07 06:46:47,860 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798
2014-07-07 06:46:47,863 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740372798
2014-07-07 06:46:48,770 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:48,798 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:48,805 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740521792 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740521792
2014-07-07 06:46:48,806 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792
2014-07-07 06:46:48,810 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740521792
2014-07-07 06:46:49,609 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:49,775 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:49,792 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740230860 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740230860
2014-07-07 06:46:49,793 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860
2014-07-07 06:46:49,795 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740230860
2014-07-07 06:46:50,381 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:51,209 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:51,216 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740561522 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740561522
2014-07-07 06:46:51,217 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522
2014-07-07 06:46:51,224 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740561522
2014-07-07 06:46:51,264 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:51,629 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 8 unassigned = 6 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367=last_update = 1404740811286 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966=last_update = 1404740810407 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 25 error = 0}
2014-07-07 06:46:51,719 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:51,733 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740452966 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740452966
2014-07-07 06:46:51,734 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966
2014-07-07 06:46:51,738 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740452966
2014-07-07 06:46:52,195 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:52,568 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:52,575 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740574367 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740574367
2014-07-07 06:46:52,576 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367
2014-07-07 06:46:52,579 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740574367
2014-07-07 06:46:53,181 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:53,206 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:53,214 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740682862 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740682862
2014-07-07 06:46:53,214 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862
2014-07-07 06:46:53,217 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740682862
2014-07-07 06:46:53,740 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:54,167 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:54,184 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740147963 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740147963
2014-07-07 06:46:54,185 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963
2014-07-07 06:46:54,190 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740147963
2014-07-07 06:46:54,487 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:54,935 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:54,977 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404739934555 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404739934555
2014-07-07 06:46:54,979 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555
2014-07-07 06:46:55,110 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404739934555
2014-07-07 06:46:55,333 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:55,809 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:55,824 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740630057 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740630057
2014-07-07 06:46:55,825 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057
2014-07-07 06:46:55,828 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740630057
2014-07-07 06:46:55,861 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872 acquired by sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:56,623 INFO  [sceplus-vm48.almaden.ibm.com,60000,1404738000064.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 2 unassigned = 0 tasks={/hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708=last_update = 1404740815355 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 31 error = 0, /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872=last_update = 1404740815881 last_version = 2 cur_worker_name = sceplus-vm48.almaden.ibm.com,60020,1404738001430 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 33 done = 31 error = 0}
2014-07-07 06:46:56,743 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:56,752 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740078708 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740078708
2014-07-07 06:46:56,753 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708
2014-07-07 06:46:56,757 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740078708
2014-07-07 06:46:57,241 INFO  [main-EventThread] master.SplitLogManager: task /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872 entered state: DONE sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,257 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting/slave1%2C60020%2C1404738000727.1404740315872 to hdfs://master:54310/hbase/oldWALs/slave1%2C60020%2C1404738000727.1404740315872
2014-07-07 06:46:57,264 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872
2014-07-07 06:46:57,266 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.SplitLogManager: finished splitting (more than or equal to) 2085158154 bytes in 33 log files in [hdfs://master:54310/hbase/WALs/slave1,60020,1404738000727-splitting] in 32012ms
2014-07-07 06:46:57,270 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase/splitWAL/WALs%2Fslave1%2C60020%2C1404738000727-splitting%2Fslave1%252C60020%252C1404738000727.1404740315872
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=OPEN, ts=1404738350705, server=slave1,60020,1404738000727} to {68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Offlined 68edfd62a4dd5aa125f431153f0efc00 from slave1,60020,1404738000727
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=OPEN, ts=1404738350648, server=slave1,60020,1404738000727} to {3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Offlined 3bec2975ff0263b5c766835dbe17a2c9 from slave1,60020,1404738000727
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=OPEN, ts=1404738350706, server=slave1,60020,1404738000727} to {3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Offlined 3a8212f6ef51df81d589b0bc9f90839c from slave1,60020,1404738000727
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=OPEN, ts=1404738350646, server=slave1,60020,1404738000727} to {884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Offlined 884013593d7c1f731440aebfc9634f85 from slave1,60020,1404738000727
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=OPEN, ts=1404738350648, server=slave1,60020,1404738000727} to {fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Offlined fcbd4075ff130d4df9edc8f47b10062a from slave1,60020,1404738000727
2014-07-07 06:46:57,271 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] handler.ServerShutdownHandler: Reassigning 5 region(s) that slave1,60020,1404738000727 was carrying (and 0 regions(s) that were opening on this server)
2014-07-07 06:46:57,273 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.AssignmentManager: Assigning 5 region(s) to sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,274 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 884013593d7c1f731440aebfc9634f85 with OFFLINE state
2014-07-07 06:46:57,274 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 3bec2975ff0263b5c766835dbe17a2c9 with OFFLINE state
2014-07-07 06:46:57,274 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node fcbd4075ff130d4df9edc8f47b10062a with OFFLINE state
2014-07-07 06:46:57,274 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 68edfd62a4dd5aa125f431153f0efc00 with OFFLINE state
2014-07-07 06:46:57,275 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Async create of unassigned node 3a8212f6ef51df81d589b0bc9f90839c with OFFLINE state
2014-07-07 06:46:57,278 DEBUG [main-EventThread] master.OfflineCallback: rs={884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,278 DEBUG [main-EventThread] master.OfflineCallback: rs={3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,278 DEBUG [main-EventThread] master.OfflineCallback: rs={fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,284 DEBUG [main-EventThread] master.OfflineCallback: rs={68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,287 DEBUG [main-EventThread] master.OfflineCallback: rs={3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,287 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,288 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,288 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,288 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,288 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404740817271, server=slave1,60020,1404738000727}, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,290 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.AssignmentManager: sceplus-vm48.almaden.ibm.com,60020,1404738001430 unassigned znodes=5 of total=5
2014-07-07 06:46:57,291 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=OFFLINE, ts=1404740817274, server=slave1,60020,1404738000727} to {884013593d7c1f731440aebfc9634f85 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,291 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=OFFLINE, ts=1404740817274, server=slave1,60020,1404738000727} to {3bec2975ff0263b5c766835dbe17a2c9 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,291 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=OFFLINE, ts=1404740817274, server=slave1,60020,1404738000727} to {fcbd4075ff130d4df9edc8f47b10062a state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,291 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=OFFLINE, ts=1404740817274, server=slave1,60020,1404738000727} to {68edfd62a4dd5aa125f431153f0efc00 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,291 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=OFFLINE, ts=1404740817275, server=slave1,60020,1404738000727} to {3a8212f6ef51df81d589b0bc9f90839c state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,373 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.AssignmentManager: Bulk assigning done for sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:46:57,374 DEBUG [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] master.DeadServer: Finished processing slave1,60020,1404738000727
2014-07-07 06:46:57,374 INFO  [MASTER_SERVER_OPERATIONS-sceplus-vm48:60000-2] handler.ServerShutdownHandler: Finished processing of shutdown of slave1,60020,1404738000727
2014-07-07 06:46:57,432 DEBUG [AM.ZK.Worker-pool2-t30] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=884013593d7c1f731440aebfc9634f85, current_state={884013593d7c1f731440aebfc9634f85 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,432 INFO  [AM.ZK.Worker-pool2-t30] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {884013593d7c1f731440aebfc9634f85 state=OPENING, ts=1404740817432, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,432 DEBUG [AM.ZK.Worker-pool2-t31] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=3bec2975ff0263b5c766835dbe17a2c9, current_state={3bec2975ff0263b5c766835dbe17a2c9 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,432 INFO  [AM.ZK.Worker-pool2-t31] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {3bec2975ff0263b5c766835dbe17a2c9 state=OPENING, ts=1404740817432, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,439 DEBUG [AM.ZK.Worker-pool2-t32] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=fcbd4075ff130d4df9edc8f47b10062a, current_state={fcbd4075ff130d4df9edc8f47b10062a state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:46:57,439 INFO  [AM.ZK.Worker-pool2-t32] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {fcbd4075ff130d4df9edc8f47b10062a state=OPENING, ts=1404740817439, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:01,177 DEBUG [AM.ZK.Worker-pool2-t33] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=fcbd4075ff130d4df9edc8f47b10062a, current_state={fcbd4075ff130d4df9edc8f47b10062a state=OPENING, ts=1404740817439, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:01,177 INFO  [AM.ZK.Worker-pool2-t33] master.RegionStates: Transitioned {fcbd4075ff130d4df9edc8f47b10062a state=OPENING, ts=1404740817439, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {fcbd4075ff130d4df9edc8f47b10062a state=OPEN, ts=1404740821177, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:01,177 DEBUG [AM.ZK.Worker-pool2-t33] handler.OpenedRegionHandler: Handling OPENED of fcbd4075ff130d4df9edc8f47b10062a from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:47:01,201 DEBUG [AM.ZK.Worker-pool2-t33] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node fcbd4075ff130d4df9edc8f47b10062a in expected state RS_ZK_REGION_OPENED
2014-07-07 06:47:01,201 DEBUG [AM.ZK.Worker-pool2-t34] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=68edfd62a4dd5aa125f431153f0efc00, current_state={68edfd62a4dd5aa125f431153f0efc00 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:01,201 INFO  [AM.ZK.Worker-pool2-t34] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {68edfd62a4dd5aa125f431153f0efc00 state=OPENING, ts=1404740821201, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:01,215 DEBUG [AM.ZK.Worker-pool2-t36] master.AssignmentManager: Znode usertable,user6,1404738349844.fcbd4075ff130d4df9edc8f47b10062a. deleted, state: {fcbd4075ff130d4df9edc8f47b10062a state=OPEN, ts=1404740821177, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:01,215 INFO  [AM.ZK.Worker-pool2-t36] master.RegionStates: Onlined fcbd4075ff130d4df9edc8f47b10062a on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:47:12,252 DEBUG [AM.ZK.Worker-pool2-t37] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=3bec2975ff0263b5c766835dbe17a2c9, current_state={3bec2975ff0263b5c766835dbe17a2c9 state=OPENING, ts=1404740817432, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:12,253 INFO  [AM.ZK.Worker-pool2-t37] master.RegionStates: Transitioned {3bec2975ff0263b5c766835dbe17a2c9 state=OPENING, ts=1404740817432, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {3bec2975ff0263b5c766835dbe17a2c9 state=OPEN, ts=1404740832253, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:12,253 DEBUG [AM.ZK.Worker-pool2-t37] handler.OpenedRegionHandler: Handling OPENED of 3bec2975ff0263b5c766835dbe17a2c9 from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:47:12,258 DEBUG [AM.ZK.Worker-pool2-t38] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=3a8212f6ef51df81d589b0bc9f90839c, current_state={3a8212f6ef51df81d589b0bc9f90839c state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:12,258 INFO  [AM.ZK.Worker-pool2-t38] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=PENDING_OPEN, ts=1404740817291, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {3a8212f6ef51df81d589b0bc9f90839c state=OPENING, ts=1404740832258, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:12,302 DEBUG [AM.ZK.Worker-pool2-t37] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 3bec2975ff0263b5c766835dbe17a2c9 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:47:12,303 DEBUG [AM.ZK.Worker-pool2-t39] master.AssignmentManager: Znode usertable,user4,1404738349844.3bec2975ff0263b5c766835dbe17a2c9. deleted, state: {3bec2975ff0263b5c766835dbe17a2c9 state=OPEN, ts=1404740832253, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:12,303 INFO  [AM.ZK.Worker-pool2-t39] master.RegionStates: Onlined 3bec2975ff0263b5c766835dbe17a2c9 on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:47:18,713 DEBUG [AM.ZK.Worker-pool2-t41] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=884013593d7c1f731440aebfc9634f85, current_state={884013593d7c1f731440aebfc9634f85 state=OPENING, ts=1404740817432, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:18,714 INFO  [AM.ZK.Worker-pool2-t41] master.RegionStates: Transitioned {884013593d7c1f731440aebfc9634f85 state=OPENING, ts=1404740817432, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {884013593d7c1f731440aebfc9634f85 state=OPEN, ts=1404740838714, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:18,714 DEBUG [AM.ZK.Worker-pool2-t41] handler.OpenedRegionHandler: Handling OPENED of 884013593d7c1f731440aebfc9634f85 from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:47:18,719 DEBUG [AM.ZK.Worker-pool2-t41] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 884013593d7c1f731440aebfc9634f85 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:47:18,721 DEBUG [AM.ZK.Worker-pool2-t43] master.AssignmentManager: Znode usertable,user3,1404738349844.884013593d7c1f731440aebfc9634f85. deleted, state: {884013593d7c1f731440aebfc9634f85 state=OPEN, ts=1404740838714, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:18,721 INFO  [AM.ZK.Worker-pool2-t43] master.RegionStates: Onlined 884013593d7c1f731440aebfc9634f85 on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:47:26,591 DEBUG [AM.ZK.Worker-pool2-t44] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=68edfd62a4dd5aa125f431153f0efc00, current_state={68edfd62a4dd5aa125f431153f0efc00 state=OPENING, ts=1404740821201, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:26,591 INFO  [AM.ZK.Worker-pool2-t44] master.RegionStates: Transitioned {68edfd62a4dd5aa125f431153f0efc00 state=OPENING, ts=1404740821201, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {68edfd62a4dd5aa125f431153f0efc00 state=OPEN, ts=1404740846591, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:26,591 DEBUG [AM.ZK.Worker-pool2-t44] handler.OpenedRegionHandler: Handling OPENED of 68edfd62a4dd5aa125f431153f0efc00 from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:47:26,597 DEBUG [AM.ZK.Worker-pool2-t44] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 68edfd62a4dd5aa125f431153f0efc00 in expected state RS_ZK_REGION_OPENED
2014-07-07 06:47:26,620 DEBUG [AM.ZK.Worker-pool2-t45] master.AssignmentManager: Znode usertable,user8,1404738349845.68edfd62a4dd5aa125f431153f0efc00. deleted, state: {68edfd62a4dd5aa125f431153f0efc00 state=OPEN, ts=1404740846591, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:26,620 INFO  [AM.ZK.Worker-pool2-t45] master.RegionStates: Onlined 68edfd62a4dd5aa125f431153f0efc00 on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:47:31,791 DEBUG [AM.ZK.Worker-pool2-t47] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430, region=3a8212f6ef51df81d589b0bc9f90839c, current_state={3a8212f6ef51df81d589b0bc9f90839c state=OPENING, ts=1404740832258, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:31,809 INFO  [AM.ZK.Worker-pool2-t47] master.RegionStates: Transitioned {3a8212f6ef51df81d589b0bc9f90839c state=OPENING, ts=1404740832258, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430} to {3a8212f6ef51df81d589b0bc9f90839c state=OPEN, ts=1404740851809, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:31,809 DEBUG [AM.ZK.Worker-pool2-t47] handler.OpenedRegionHandler: Handling OPENED of 3a8212f6ef51df81d589b0bc9f90839c from sceplus-vm48.almaden.ibm.com,60020,1404738001430; deleting unassigned node
2014-07-07 06:47:31,813 DEBUG [AM.ZK.Worker-pool2-t47] zookeeper.ZKAssign: master:60000-0x14710e8d3780000-0x14710e8d3780000, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Deleted unassigned node 3a8212f6ef51df81d589b0bc9f90839c in expected state RS_ZK_REGION_OPENED
2014-07-07 06:47:31,814 DEBUG [AM.ZK.Worker-pool2-t47] master.AssignmentManager: Znode usertable,user9,1404738349845.3a8212f6ef51df81d589b0bc9f90839c. deleted, state: {3a8212f6ef51df81d589b0bc9f90839c state=OPEN, ts=1404740851809, server=sceplus-vm48.almaden.ibm.com,60020,1404738001430}
2014-07-07 06:47:31,814 INFO  [AM.ZK.Worker-pool2-t47] master.RegionStates: Onlined 3a8212f6ef51df81d589b0bc9f90839c on sceplus-vm48.almaden.ibm.com,60020,1404738001430
2014-07-07 06:47:46,095 DEBUG [FifoRpcScheduler.handler1-thread-38] master.ServerManager: Server REPORT rejected; currently processing slave1,60020,1404738000727 as dead server
2014-07-07 06:47:47,438 ERROR [FifoRpcScheduler.handler1-thread-40] master.HMaster: Region server slave1,60020,1404738000727 reported a fatal error:
ABORTING region server slave1,60020,1404738000727: regionserver:60020-0x14710e8d3780002-0x14710e8d3780002-0x14710e8d3780002, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase regionserver:60020-0x14710e8d3780002-0x14710e8d3780002-0x14710e8d3780002 received expired from ZooKeeper, aborting
Cause:
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)

2014-07-07 06:47:47,447 ERROR [FifoRpcScheduler.handler1-thread-39] master.HMaster: Region server slave1,60020,1404738000727 reported a fatal error:
ABORTING region server slave1,60020,1404738000727: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing slave1,60020,1404738000727 as dead server
Cause:
org.apache.hadoop.hbase.YouAreDeadException: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing slave1,60020,1404738000727 as dead server
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:79)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:285)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1065)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:901)
	at java.lang.Thread.run(Thread.java:701)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing slave1,60020,1404738000727 as dead server
	at org.apache.hadoop.hbase.master.ServerManager.checkIsDead(ServerManager.java:369)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:274)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:1357)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:5087)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2012)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:73)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1453)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1657)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1715)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerReport(RegionServerStatusProtos.java:5414)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1063)
	... 2 more

2014-07-07 06:50:42,567 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-07-07 06:52:33,076 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739959893
2014-07-07 06:52:33,098 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404739980880
2014-07-07 06:52:33,104 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740059100
2014-07-07 06:53:33,002 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740084189
2014-07-07 06:53:33,028 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740143245
2014-07-07 06:53:33,030 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740172807
2014-07-07 06:53:33,032 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740219532
2014-07-07 06:53:33,035 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740313410
2014-07-07 06:53:33,047 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740328542
2014-07-07 06:54:32,996 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740396724
2014-07-07 06:54:33,137 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740453967
2014-07-07 06:54:33,144 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740500877
2014-07-07 06:55:33,062 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740522978
2014-07-07 06:55:33,074 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740549406
2014-07-07 06:55:33,076 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740557210
2014-07-07 06:55:33,078 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740562650
2014-07-07 06:55:33,080 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740571569
2014-07-07 06:55:33,083 DEBUG [master:sceplus-vm48:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sceplus-vm48.almaden.ibm.com%2C60020%2C1404738001430.1404740578921
2014-07-07 06:55:42,573 DEBUG [sceplus-vm48.almaden.ibm.com,60000,1404738000064-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
