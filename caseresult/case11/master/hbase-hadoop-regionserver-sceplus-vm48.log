Wed Jul  2 21:51:45 PDT 2014 Starting regionserver on sceplus-vm48
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 128203
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 32768
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 128203
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-07-02 21:51:45,733 INFO  [main] util.VersionInfo: HBase 0.98.3-hadoop1
2014-07-02 21:51:45,733 INFO  [main] util.VersionInfo: Subversion git://acer/usr/src/Hadoop/hbase -r d5e65a9144e315bb0a964e7730871af32f5018d5
2014-07-02 21:51:45,734 INFO  [main] util.VersionInfo: Compiled by apurtell on Sat May 31 19:34:57 PDT 2014
2014-07-02 21:51:45,945 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.6.0-openjdk-amd64/
2014-07-02 21:51:45,945 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-07-02 21:51:45,945 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/home/hadoop/hbase/bin/../logs
2014-07-02 21:51:45,945 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/home/hadoop/hbase/bin/..
2014-07-02 21:51:45,945 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm48.log -Dhbase.home.dir=/home/hadoop/hbase/bin/.. -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,RFA -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:SSH_CLIENT=9.1.143.58 43193 22
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:HBASE_HEAPSIZE=10240
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hadoop
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.znode
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:PWD=/home/hadoop/hbase
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:LOGNAME=hadoop
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=true
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-07-02 21:51:45,946 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-6-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-6-openjdk-amd64/jre/../lib/amd64::/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-02 21:51:45,947 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-07-02 21:51:45,947 INFO  [main] util.ServerCommandLine: env:SSH_CONNECTION=9.1.143.58 43193 9.1.143.58 22
2014-07-02 21:51:45,947 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-07-02 21:51:45,947 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/hadoop/pids
2014-07-02 21:51:45,947 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-07-02 21:51:45,949 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-02 21:51:45,949 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-07-02 21:51:45,949 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2014-07-02 21:51:45,949 INFO  [main] util.ServerCommandLine: env:USER=hadoop
2014-07-02 21:51:45,949 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-07-02 21:51:45,949 INFO  [main] util.ServerCommandLine: env:HOME=/home/hadoop
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:HBASE_LIBRARY_PATH=/home/hadoop/hbase/lib/native/Linux-amd64-64
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/hadoop/pids/hbase-hadoop-regionserver.autorestart
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=6
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hadoop-regionserver-sceplus-vm48.log
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/1001
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hadoop-regionserver-sceplus-vm48
2014-07-02 21:51:45,950 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hadoop
2014-07-02 21:51:45,952 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Sun Microsystems Inc., vmVersion=23.25-b01
2014-07-02 21:51:45,952 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx10240m, -XX:+UseConcMarkSweepGC, -Dhbase.log.dir=/home/hadoop/hbase/bin/../logs, -Dhbase.log.file=hbase-hadoop-regionserver-sceplus-vm48.log, -Dhbase.home.dir=/home/hadoop/hbase/bin/.., -Dhbase.id.str=hadoop, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2014-07-02 21:51:46,148 DEBUG [main] regionserver.HRegionServer: regionserver/sceplus-vm48.almaden.ibm.com/9.1.143.58:60020 HConnection server-to-server retries=350
2014-07-02 21:51:46,501 INFO  [main] ipc.RpcServer: regionserver/sceplus-vm48.almaden.ibm.com/9.1.143.58:60020: started 10 reader(s).
2014-07-02 21:51:46,574 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-07-02 21:51:46,585 INFO  [main] impl.MetricsSinkAdapter: Sink file-all started
2014-07-02 21:51:46,642 INFO  [main] impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-07-02 21:51:46,643 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-07-02 21:51:46,643 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-07-02 21:51:46,647 INFO  [main] impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-07-02 21:51:46,651 INFO  [main] impl.MetricsSourceAdapter: MBean for source IPC,sub=IPC registered.
2014-07-02 21:51:46,723 INFO  [main] impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-07-02 21:51:46,724 WARN  [main] impl.MetricsSystemImpl: Source name ugi already exists!
2014-07-02 21:51:46,727 DEBUG [main] util.DirectMemoryUtils: Failed to retrieve nio.BufferPool direct MemoryUsed attribute.
javax.management.InstanceNotFoundException: java.nio:type=BufferPool,name=direct
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1117)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:678)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:682)
	at org.apache.hadoop.hbase.util.DirectMemoryUtils.<clinit>(DirectMemoryUtils.java:72)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.instantiateBlockCache(CacheConfig.java:396)
	at org.apache.hadoop.hbase.io.hfile.CacheConfig.<init>(CacheConfig.java:179)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.<init>(HRegionServer.java:621)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.constructRegionServer(HRegionServer.java:2393)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:61)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-02 21:51:46,730 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 4.0g
2014-07-02 21:51:46,797 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-07-02 21:51:46,853 INFO  [main] http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-07-02 21:51:46,861 INFO  [main] http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 60030
2014-07-02 21:51:46,863 INFO  [main] http.HttpServer: listener.getLocalPort() returned 60030 webServer.getConnectors()[0].getLocalPort() returned 60030
2014-07-02 21:51:46,863 INFO  [main] http.HttpServer: Jetty bound to port 60030
2014-07-02 21:51:46,863 INFO  [main] mortbay.log: jetty-6.1.26
2014-07-02 21:51:47,153 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-07-02 21:51:47,194 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2014-07-02 21:51:47,194 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=sceplus-vm48.almaden.ibm.com
2014-07-02 21:51:47,194 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.6.0_31
2014-07-02 21:51:47,194 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
2014-07-02 21:51:47,194 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-6-openjdk-amd64/jre
2014-07-02 21:51:47,194 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2014-07-02 21:51:47,194 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/home/hadoop/hbase/conf:/usr/lib/jvm/java-1.6.0-openjdk-amd64//lib/tools.jar:/home/hadoop/hbase/bin/..:/home/hadoop/hbase/bin/../lib/activation-1.1.jar:/home/hadoop/hbase/bin/../lib/asm-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/home/hadoop/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/hbase/bin/../lib/commons-cli-1.2.jar:/home/hadoop/hbase/bin/../lib/commons-codec-1.7.jar:/home/hadoop/hbase/bin/../lib/commons-collections-3.2.1.jar:/home/hadoop/hbase/bin/../lib/commons-configuration-1.6.jar:/home/hadoop/hbase/bin/../lib/commons-digester-1.8.jar:/home/hadoop/hbase/bin/../lib/commons-el-1.0.jar:/home/hadoop/hbase/bin/../lib/commons-httpclient-3.1.jar:/home/hadoop/hbase/bin/../lib/commons-io-2.4.jar:/home/hadoop/hbase/bin/../lib/commons-lang-2.6.jar:/home/hadoop/hbase/bin/../lib/commons-logging-1.1.1.jar:/home/hadoop/hbase/bin/../lib/commons-math-2.1.jar:/home/hadoop/hbase/bin/../lib/commons-net-1.4.1.jar:/home/hadoop/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/hadoop/hbase/bin/../lib/guava-12.0.1.jar:/home/hadoop/hbase/bin/../lib/hadoop-core-1.2.1.jar:/home/hadoop/hbase/bin/../lib/hamcrest-core-1.3.jar:/home/hadoop/hbase/bin/../lib/hbase-client-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-common-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-examples-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop1-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-hadoop-compat-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-it-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-prefix-tree-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-protocol-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-server-0.98.3-hadoop1-tests.jar:/home/hadoop/hbase/bin/../lib/hbase-shell-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-testing-util-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/hbase-thrift-0.98.3-hadoop1.jar:/home/hadoop/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/home/hadoop/hbase/bin/../lib/htrace-core-2.04.jar:/home/hadoop/hbase/bin/../lib/httpclient-4.1.3.jar:/home/hadoop/hbase/bin/../lib/httpcore-4.1.3.jar:/home/hadoop/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jackson-xc-1.8.8.jar:/home/hadoop/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/home/hadoop/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/home/hadoop/hbase/bin/../lib/jaxb-api-2.2.2.jar:/home/hadoop/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/hbase/bin/../lib/jersey-core-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-json-1.8.jar:/home/hadoop/hbase/bin/../lib/jersey-server-1.8.jar:/home/hadoop/hbase/bin/../lib/jettison-1.3.1.jar:/home/hadoop/hbase/bin/../lib/jetty-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-sslengine-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jetty-util-6.1.26.jar:/home/hadoop/hbase/bin/../lib/jruby-complete-1.6.8.jar:/home/hadoop/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/hadoop/hbase/bin/../lib/jsr305-1.3.9.jar:/home/hadoop/hbase/bin/../lib/junit-4.11.jar:/home/hadoop/hbase/bin/../lib/libthrift-0.9.0.jar:/home/hadoop/hbase/bin/../lib/log4j-1.2.17.jar:/home/hadoop/hbase/bin/../lib/metrics-core-2.1.2.jar:/home/hadoop/hbase/bin/../lib/netty-3.6.6.Final.jar:/home/hadoop/hbase/bin/../lib/protobuf-java-2.5.0.jar:/home/hadoop/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/hadoop/hbase/bin/../lib/slf4j-api-1.6.4.jar:/home/hadoop/hbase/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/hadoop/hbase/bin/../lib/xmlenc-0.52.jar:/home/hadoop/hbase/bin/../lib/zookeeper-3.4.6.jar:
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/home/hadoop/hbase/bin/../lib/native/Linux-amd64-64
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=3.13.0-24-generic
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hadoop
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/home/hadoop
2014-07-02 21:51:47,195 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/home/hadoop/hbase-0.98.3-hadoop1
2014-07-02 21:51:47,196 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-02 21:51:47,215 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-02 21:51:47,217 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 21:51:47,221 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-02 21:51:47,231 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x146fa9060fe0001, negotiated timeout = 90000
2014-07-02 21:52:17,999 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x53c01def, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-02 21:52:18,001 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x53c01def connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-02 21:52:18,001 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 21:52:18,001 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-02 21:52:18,011 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, sessionid = 0x46fa9065850004, negotiated timeout = 90000
2014-07-02 21:52:18,224 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@289278d5
2014-07-02 21:52:18,228 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 3b61b992-e8ee-43f8-b0c6-14cd23a8afbe
2014-07-02 21:52:18,233 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2014-07-02 21:52:18,246 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-07-02 21:52:18,271 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2014-07-02 21:52:18,276 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=4.0g, globalMemStoreLimitLowMark=3.8g, maxHeap=9.9g
2014-07-02 21:52:18,280 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-07-02 21:52:18,293 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=sceplus-vm48.almaden.ibm.com,60000,1404363105252 with port=60020, startcode=1404363106660
2014-07-02 21:52:18,616 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://master:54310/hbase
2014-07-02 21:52:18,616 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://master:54310
2014-07-02 21:52:18,637 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-07-02 21:52:18,644 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:18,673 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2014-07-02 21:52:18,684 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=64 MB, rollsize=60.8 MB, enabled=true
2014-07-02 21:52:18,778 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363138690
2014-07-02 21:52:18,793 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=WAL registered.
2014-07-02 21:52:18,797 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-07-02 21:52:18,800 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Server registered.
2014-07-02 21:52:18,804 INFO  [regionserver60020] trace.SpanReceiverHost: SpanReceiver org.cloudera.htrace.impl.LocalFileSpanReceiver was loaded successfully.
2014-07-02 21:52:18,806 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-sceplus-vm48:60020, corePoolSize=3, maxPoolSize=3
2014-07-02 21:52:18,807 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-sceplus-vm48:60020, corePoolSize=1, maxPoolSize=1
2014-07-02 21:52:18,807 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-sceplus-vm48:60020, corePoolSize=3, maxPoolSize=3
2014-07-02 21:52:18,807 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-sceplus-vm48:60020, corePoolSize=1, maxPoolSize=1
2014-07-02 21:52:18,807 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-sceplus-vm48:60020, corePoolSize=2, maxPoolSize=2
2014-07-02 21:52:18,814 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [slave1,60020,1404363105763, sceplus-vm48.almaden.ibm.com,60020,1404363106660] other RSs: [slave1,60020,1404363105763, sceplus-vm48.almaden.ibm.com,60020,1404363106660]
2014-07-02 21:52:18,833 INFO  [regionserver60020] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Replication registered.
2014-07-02 21:52:18,835 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181 sessionTimeout=90000 watcher=hconnection-0x3f437b82, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase
2014-07-02 21:52:18,836 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3f437b82 connecting to ZooKeeper ensemble=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181
2014-07-02 21:52:18,837 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 21:52:18,838 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-02 21:52:18,841 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Session establishment complete on server slave1/9.1.143.59:2181, sessionid = 0x146fa9060fe0003, negotiated timeout = 90000
2014-07-02 21:52:18,846 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-07-02 21:52:18,846 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2014-07-02 21:52:18,889 INFO  [regionserver60020] regionserver.HRegionServer: Serving as sceplus-vm48.almaden.ibm.com,60020,1404363106660, RpcServer on sceplus-vm48.almaden.ibm.com/9.1.143.58:60020, sessionid=0x146fa9060fe0001
2014-07-02 21:52:18,889 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,60020,1404363106660] regionserver.SplitLogWorker: SplitLogWorker sceplus-vm48.almaden.ibm.com,60020,1404363106660 starting
2014-07-02 21:52:18,889 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2014-07-02 21:52:18,889 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:18,889 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'sceplus-vm48.almaden.ibm.com,60020,1404363106660'
2014-07-02 21:52:18,889 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-07-02 21:52:18,891 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-07-02 21:52:18,892 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2014-07-02 21:52:23,583 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:23,739 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:23,739 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e566d5de950d9b05d65bb241664e9bd from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:23,740 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:23,741 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cc2dabb2c2f461f6df7fda50e1fa996d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:23,742 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:23,743 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 864ed997ce8762419ee7842a34c8c1fc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:23,743 INFO  [Priority.RpcServer.handler=0,port=60020] regionserver.HRegionServer: Open usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:23,764 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 864ed997ce8762419ee7842a34c8c1fc from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:23,764 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e566d5de950d9b05d65bb241664e9bd from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:23,765 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cc2dabb2c2f461f6df7fda50e1fa996d from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:23,777 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => 864ed997ce8762419ee7842a34c8c1fc, NAME => 'usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-02 21:52:23,777 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Opening region: {ENCODED => cc2dabb2c2f461f6df7fda50e1fa996d, NAME => 'usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.', STARTKEY => 'user4', ENDKEY => 'user5'}
2014-07-02 21:52:23,778 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => 0e566d5de950d9b05d65bb241664e9bd, NAME => 'usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-02 21:52:23,802 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] impl.MetricsSourceAdapter: MBean for source RegionServer,sub=Regions registered.
2014-07-02 21:52:23,802 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable cc2dabb2c2f461f6df7fda50e1fa996d
2014-07-02 21:52:23,802 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 864ed997ce8762419ee7842a34c8c1fc
2014-07-02 21:52:23,802 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 0e566d5de950d9b05d65bb241664e9bd
2014-07-02 21:52:23,803 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Instantiated usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:23,803 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:23,803 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:23,810 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] util.NativeCodeLoader: Loaded the native-hadoop library
2014-07-02 21:52:23,811 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2014-07-02 21:52:23,813 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] compress.CodecPool: Got brand-new compressor
2014-07-02 21:52:23,813 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] compress.CodecPool: Got brand-new compressor
2014-07-02 21:52:23,814 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] compress.CodecPool: Got brand-new compressor
2014-07-02 21:52:23,880 INFO  [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:52:23,880 INFO  [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:52:23,886 INFO  [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:52:23,920 INFO  [StoreFileOpenerThread-family-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-07-02 21:52:23,960 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-02 21:52:23,960 INFO  [StoreFileOpenerThread-family-1] compress.CodecPool: Got brand-new decompressor
2014-07-02 21:52:23,973 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/1040f2686bf54cabb3a4a1bfcea10909, isReference=false, isBulkLoadResult=false, seqid=1268, majorCompaction=false
2014-07-02 21:52:23,973 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/2521d7080fb047cd94f2800376aabae0, isReference=false, isBulkLoadResult=false, seqid=215, majorCompaction=false
2014-07-02 21:52:24,007 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/6861bb97d9494aa3960f233e698a63f2, isReference=false, isBulkLoadResult=false, seqid=1587, majorCompaction=false
2014-07-02 21:52:24,030 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/2b03349383fb4f46bd09d97b45567a12, isReference=false, isBulkLoadResult=false, seqid=1592, majorCompaction=false
2014-07-02 21:52:24,031 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/060741e3550b4d64843a6fa2075efb9c, isReference=false, isBulkLoadResult=false, seqid=1872, majorCompaction=false
2014-07-02 21:52:24,052 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/0a09ffe6b73d43a880ecea655a5907f7, isReference=false, isBulkLoadResult=false, seqid=1546, majorCompaction=false
2014-07-02 21:52:24,073 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/589918494b7d4883957a7a9df1b4d536, isReference=false, isBulkLoadResult=false, seqid=1772, majorCompaction=false
2014-07-02 21:52:24,075 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/93f3836b6d464fe7ad4505bf3fe5eeb2, isReference=false, isBulkLoadResult=false, seqid=516, majorCompaction=false
2014-07-02 21:52:24,083 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/1076b53e5c1c4d378f855e270fa7ab19, isReference=false, isBulkLoadResult=false, seqid=331, majorCompaction=false
2014-07-02 21:52:24,109 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/702d74b25bdb49d19321d19ff5633155, isReference=false, isBulkLoadResult=false, seqid=1718, majorCompaction=false
2014-07-02 21:52:24,115 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/9916f50813f24b489ef90ff326b951d7, isReference=false, isBulkLoadResult=false, seqid=371, majorCompaction=false
2014-07-02 21:52:24,116 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/5e4c59d7d6dd4f27a4c66715835e9d16, isReference=false, isBulkLoadResult=false, seqid=511, majorCompaction=false
2014-07-02 21:52:24,121 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/c227134de561457a837c73101bf42b37, isReference=false, isBulkLoadResult=false, seqid=1074, majorCompaction=false
2014-07-02 21:52:24,138 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/b4ef18f342724bed8a12d319aa0a5b06, isReference=false, isBulkLoadResult=false, seqid=1869, majorCompaction=false
2014-07-02 21:52:24,142 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/c3f5a82ffd15492086bcffeb4a6bfe19, isReference=false, isBulkLoadResult=false, seqid=477, majorCompaction=false
2014-07-02 21:52:24,151 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/b795ad36b9e1437a83df4f0dfd35ebeb, isReference=false, isBulkLoadResult=false, seqid=1306, majorCompaction=false
2014-07-02 21:52:24,154 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/b63e1302a5c04873a24877bbe5e6b435, isReference=false, isBulkLoadResult=false, seqid=366, majorCompaction=false
2014-07-02 21:52:24,169 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/c761dc77af264642a72b04586c972541, isReference=false, isBulkLoadResult=false, seqid=176, majorCompaction=false
2014-07-02 21:52:24,185 DEBUG [StoreOpener-cc2dabb2c2f461f6df7fda50e1fa996d-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d/family/d814d70e7f4545bcad188ac1624bfd76, isReference=false, isBulkLoadResult=false, seqid=633, majorCompaction=false
2014-07-02 21:52:24,189 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/d6620fe049dd4c20a5c4a743b987ff2c, isReference=false, isBulkLoadResult=false, seqid=1767, majorCompaction=false
2014-07-02 21:52:24,191 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/ca956afb184c42d08d78eebeff0a6f7c, isReference=false, isBulkLoadResult=false, seqid=1874, majorCompaction=false
2014-07-02 21:52:24,241 DEBUG [StoreOpener-864ed997ce8762419ee7842a34c8c1fc-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc/family/e92313159b1641d883502843bd5ec539, isReference=false, isBulkLoadResult=false, seqid=765, majorCompaction=false
2014-07-02 21:52:24,241 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/ddc2222dded747d09e06a13c7f96ddcb, isReference=false, isBulkLoadResult=false, seqid=738, majorCompaction=false
2014-07-02 21:52:24,243 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/cc2dabb2c2f461f6df7fda50e1fa996d
2014-07-02 21:52:24,243 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/864ed997ce8762419ee7842a34c8c1fc
2014-07-02 21:52:24,248 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Onlined cc2dabb2c2f461f6df7fda50e1fa996d; next sequenceid=1873
2014-07-02 21:52:24,248 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined 864ed997ce8762419ee7842a34c8c1fc; next sequenceid=1870
2014-07-02 21:52:24,248 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node cc2dabb2c2f461f6df7fda50e1fa996d
2014-07-02 21:52:24,248 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 864ed997ce8762419ee7842a34c8c1fc
2014-07-02 21:52:24,252 INFO  [PostOpenDeployTasks:cc2dabb2c2f461f6df7fda50e1fa996d] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:24,252 INFO  [PostOpenDeployTasks:864ed997ce8762419ee7842a34c8c1fc] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:24,254 DEBUG [PostOpenDeployTasks:cc2dabb2c2f461f6df7fda50e1fa996d] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 21:52:24,254 DEBUG [PostOpenDeployTasks:864ed997ce8762419ee7842a34c8c1fc] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:1), split_queue=0, merge_queue=0
2014-07-02 21:52:24,256 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-02 21:52:24,256 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-02 21:52:24,259 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:52:24,259 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:52:24,263 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d. because compaction request was cancelled
2014-07-02 21:52:24,264 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-02 21:52:24,264 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-02 21:52:24,264 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:52:24,264 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:52:24,265 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc. because compaction request was cancelled
2014-07-02 21:52:24,276 DEBUG [StoreOpener-0e566d5de950d9b05d65bb241664e9bd-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd/family/e486f113581e42eba17e56b81fce736a, isReference=false, isBulkLoadResult=false, seqid=194, majorCompaction=false
2014-07-02 21:52:24,279 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/0e566d5de950d9b05d65bb241664e9bd
2014-07-02 21:52:24,282 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined 0e566d5de950d9b05d65bb241664e9bd; next sequenceid=1875
2014-07-02 21:52:24,282 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 0e566d5de950d9b05d65bb241664e9bd
2014-07-02 21:52:24,285 INFO  [PostOpenDeployTasks:0e566d5de950d9b05d65bb241664e9bd] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:24,285 DEBUG [PostOpenDeployTasks:0e566d5de950d9b05d65bb241664e9bd] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 21:52:24,287 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 8 store files, 0 compacting, 8 eligible, 20 blocking
2014-07-02 21:52:24,287 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 8 files from compaction candidates
2014-07-02 21:52:24,287 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:52:24,287 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:52:24,287 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd. because compaction request was cancelled
2014-07-02 21:52:24,367 INFO  [PostOpenDeployTasks:0e566d5de950d9b05d65bb241664e9bd] catalog.MetaEditor: Updated row usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,367 INFO  [PostOpenDeployTasks:0e566d5de950d9b05d65bb241664e9bd] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:24,367 INFO  [PostOpenDeployTasks:864ed997ce8762419ee7842a34c8c1fc] catalog.MetaEditor: Updated row usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,367 INFO  [PostOpenDeployTasks:cc2dabb2c2f461f6df7fda50e1fa996d] catalog.MetaEditor: Updated row usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,368 INFO  [PostOpenDeployTasks:864ed997ce8762419ee7842a34c8c1fc] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:24,368 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e566d5de950d9b05d65bb241664e9bd from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,368 INFO  [PostOpenDeployTasks:cc2dabb2c2f461f6df7fda50e1fa996d] regionserver.HRegionServer: Finished post open deploy task for usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:24,369 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 864ed997ce8762419ee7842a34c8c1fc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,369 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cc2dabb2c2f461f6df7fda50e1fa996d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,375 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e566d5de950d9b05d65bb241664e9bd from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,375 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned 0e566d5de950d9b05d65bb241664e9bd to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,375 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,375 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 864ed997ce8762419ee7842a34c8c1fc from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,376 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cc2dabb2c2f461f6df7fda50e1fa996d from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,375 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned 864ed997ce8762419ee7842a34c8c1fc to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,376 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d4105ca8a3053390fb540605331344b4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:24,376 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Transitioned cc2dabb2c2f461f6df7fda50e1fa996d to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,376 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,376 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Opened usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,377 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning af910ebb080e56f205be06fa740f19fe from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:24,381 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d4105ca8a3053390fb540605331344b4 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:24,382 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => d4105ca8a3053390fb540605331344b4, NAME => 'usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.', STARTKEY => 'user5', ENDKEY => 'user6'}
2014-07-02 21:52:24,383 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d4105ca8a3053390fb540605331344b4
2014-07-02 21:52:24,383 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:24,386 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node af910ebb080e56f205be06fa740f19fe from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:52:24,386 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => af910ebb080e56f205be06fa740f19fe, NAME => 'usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-02 21:52:24,387 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable af910ebb080e56f205be06fa740f19fe
2014-07-02 21:52:24,387 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:24,390 INFO  [StoreOpener-d4105ca8a3053390fb540605331344b4-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:52:24,396 INFO  [StoreOpener-af910ebb080e56f205be06fa740f19fe-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:52:24,428 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/326704c81e844bd69c0e3477dab7c9ff, isReference=false, isBulkLoadResult=false, seqid=1036, majorCompaction=false
2014-07-02 21:52:24,438 DEBUG [StoreOpener-af910ebb080e56f205be06fa740f19fe-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/af910ebb080e56f205be06fa740f19fe/family/7d27db5f35c84e04b3a8043fec109ca9, isReference=false, isBulkLoadResult=false, seqid=903, majorCompaction=false
2014-07-02 21:52:24,455 DEBUG [StoreOpener-af910ebb080e56f205be06fa740f19fe-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/af910ebb080e56f205be06fa740f19fe/family/bb2006897417432b88b9b7836b03fbbd, isReference=false, isBulkLoadResult=false, seqid=2243, majorCompaction=false
2014-07-02 21:52:24,474 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/44cb023a0ae74a05a84a0d56fce90850, isReference=false, isBulkLoadResult=false, seqid=322, majorCompaction=false
2014-07-02 21:52:24,507 DEBUG [StoreOpener-af910ebb080e56f205be06fa740f19fe-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/af910ebb080e56f205be06fa740f19fe/family/fc37262c21144f95a21167ad83698f06, isReference=false, isBulkLoadResult=false, seqid=2968, majorCompaction=false
2014-07-02 21:52:24,513 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/5e6f113b8b334b0fab92faff24e0c514, isReference=false, isBulkLoadResult=false, seqid=466, majorCompaction=false
2014-07-02 21:52:24,526 DEBUG [StoreOpener-af910ebb080e56f205be06fa740f19fe-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/af910ebb080e56f205be06fa740f19fe/family/fe1446137d774ca4a4fddc87d819db1e, isReference=false, isBulkLoadResult=false, seqid=3092, majorCompaction=false
2014-07-02 21:52:24,530 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/af910ebb080e56f205be06fa740f19fe
2014-07-02 21:52:24,533 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined af910ebb080e56f205be06fa740f19fe; next sequenceid=3093
2014-07-02 21:52:24,534 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node af910ebb080e56f205be06fa740f19fe
2014-07-02 21:52:24,536 INFO  [PostOpenDeployTasks:af910ebb080e56f205be06fa740f19fe] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:24,537 DEBUG [PostOpenDeployTasks:af910ebb080e56f205be06fa740f19fe] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 21:52:24,537 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 21:52:24,537 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-02 21:52:24,537 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:52:24,537 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:52:24,538 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe. because compaction request was cancelled
2014-07-02 21:52:24,547 INFO  [PostOpenDeployTasks:af910ebb080e56f205be06fa740f19fe] catalog.MetaEditor: Updated row usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,547 INFO  [PostOpenDeployTasks:af910ebb080e56f205be06fa740f19fe] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:24,548 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning af910ebb080e56f205be06fa740f19fe from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,554 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node af910ebb080e56f205be06fa740f19fe from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,555 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned af910ebb080e56f205be06fa740f19fe to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,555 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,567 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/6641fba7a76a4073b8a994d2da3b226c, isReference=false, isBulkLoadResult=false, seqid=1870, majorCompaction=false
2014-07-02 21:52:24,611 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/693a4864f671451e88c7b4b90142d996, isReference=false, isBulkLoadResult=false, seqid=171, majorCompaction=false
2014-07-02 21:52:24,632 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/6db3d2a253f54a289c40c76dde049466, isReference=false, isBulkLoadResult=false, seqid=609, majorCompaction=false
2014-07-02 21:52:24,669 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/da1f25e1bb8f49fd91fd653ca03dbfb2, isReference=false, isBulkLoadResult=false, seqid=1439, majorCompaction=false
2014-07-02 21:52:24,697 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/eea352d3ba9a497f8849a8c7bc5fef5e, isReference=false, isBulkLoadResult=false, seqid=1589, majorCompaction=false
2014-07-02 21:52:24,733 DEBUG [StoreOpener-d4105ca8a3053390fb540605331344b4-1] regionserver.HStore: loaded hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4/family/f74b9478b7d84368baf2e997a6e90a8f, isReference=false, isBulkLoadResult=false, seqid=1769, majorCompaction=false
2014-07-02 21:52:24,737 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d4105ca8a3053390fb540605331344b4
2014-07-02 21:52:24,740 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined d4105ca8a3053390fb540605331344b4; next sequenceid=1871
2014-07-02 21:52:24,740 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d4105ca8a3053390fb540605331344b4
2014-07-02 21:52:24,743 INFO  [PostOpenDeployTasks:d4105ca8a3053390fb540605331344b4] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:24,743 DEBUG [PostOpenDeployTasks:d4105ca8a3053390fb540605331344b4] regionserver.CompactSplitThread: Small Compaction requested: system; Because: Opening Region; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 21:52:24,744 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 9 store files, 0 compacting, 9 eligible, 20 blocking
2014-07-02 21:52:24,744 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 9 files from compaction candidates
2014-07-02 21:52:24,744 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:52:24,744 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:52:24,744 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4. because compaction request was cancelled
2014-07-02 21:52:24,754 INFO  [PostOpenDeployTasks:d4105ca8a3053390fb540605331344b4] catalog.MetaEditor: Updated row usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,754 INFO  [PostOpenDeployTasks:d4105ca8a3053390fb540605331344b4] regionserver.HRegionServer: Finished post open deploy task for usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:24,755 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d4105ca8a3053390fb540605331344b4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d4105ca8a3053390fb540605331344b4 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:52:24,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned d4105ca8a3053390fb540605331344b4 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:24,760 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:27,562 INFO  [Priority.RpcServer.handler=1,port=60020] regionserver.HRegionServer: Close 0e566d5de950d9b05d65bb241664e9bd, via zk=yes, znode version=0, on null
2014-07-02 21:52:27,563 INFO  [Priority.RpcServer.handler=2,port=60020] regionserver.HRegionServer: Close d4105ca8a3053390fb540605331344b4, via zk=yes, znode version=0, on null
2014-07-02 21:52:27,563 INFO  [Priority.RpcServer.handler=3,port=60020] regionserver.HRegionServer: Close cc2dabb2c2f461f6df7fda50e1fa996d, via zk=yes, znode version=0, on null
2014-07-02 21:52:27,563 INFO  [Priority.RpcServer.handler=4,port=60020] regionserver.HRegionServer: Close 864ed997ce8762419ee7842a34c8c1fc, via zk=yes, znode version=0, on null
2014-07-02 21:52:27,563 INFO  [Priority.RpcServer.handler=5,port=60020] regionserver.HRegionServer: Close af910ebb080e56f205be06fa740f19fe, via zk=yes, znode version=0, on null
2014-07-02 21:52:27,565 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Processing close of usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:27,567 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closing usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.: disabling compactions & flushes
2014-07-02 21:52:27,566 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Processing close of usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:27,567 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Processing close of usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:27,567 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Updates disabled for region usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:27,568 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closing usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.: disabling compactions & flushes
2014-07-02 21:52:27,568 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Updates disabled for region usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:27,568 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closing usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.: disabling compactions & flushes
2014-07-02 21:52:27,569 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Updates disabled for region usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:27,604 INFO  [StoreCloserThread-usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.-1] regionserver.HStore: Closed family
2014-07-02 21:52:27,606 INFO  [StoreCloserThread-usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.-1] regionserver.HStore: Closed family
2014-07-02 21:52:27,607 INFO  [StoreCloserThread-usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.-1] regionserver.HStore: Closed family
2014-07-02 21:52:27,608 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closed usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:27,608 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closed usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:27,608 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning af910ebb080e56f205be06fa740f19fe from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,608 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closed usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:27,608 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d4105ca8a3053390fb540605331344b4 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,608 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 0e566d5de950d9b05d65bb241664e9bd from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node af910ebb080e56f205be06fa740f19fe from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Closed usertable,user9,1404360839130.af910ebb080e56f205be06fa740f19fe.
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Processing close of usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d4105ca8a3053390fb540605331344b4 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Closed usertable,user5,1404360839129.d4105ca8a3053390fb540605331344b4.
2014-07-02 21:52:27,615 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 0e566d5de950d9b05d65bb241664e9bd from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,616 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Set closed state in zk for usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:27,616 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Processing close of usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:27,616 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Closed usertable,user1,1404360839129.0e566d5de950d9b05d65bb241664e9bd.
2014-07-02 21:52:27,617 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closing usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.: disabling compactions & flushes
2014-07-02 21:52:27,617 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Updates disabled for region usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:27,617 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closing usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.: disabling compactions & flushes
2014-07-02 21:52:27,617 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Updates disabled for region usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:27,619 INFO  [StoreCloserThread-usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.-1] regionserver.HStore: Closed family
2014-07-02 21:52:27,619 INFO  [StoreCloserThread-usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.-1] regionserver.HStore: Closed family
2014-07-02 21:52:27,619 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closed usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:27,620 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning cc2dabb2c2f461f6df7fda50e1fa996d from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,621 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closed usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:52:27,621 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 864ed997ce8762419ee7842a34c8c1fc from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node cc2dabb2c2f461f6df7fda50e1fa996d from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Set closed state in zk for usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:27,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Closed usertable,user4,1404360839129.cc2dabb2c2f461f6df7fda50e1fa996d.
2014-07-02 21:52:27,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 864ed997ce8762419ee7842a34c8c1fc from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2014-07-02 21:52:27,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Set closed state in zk for usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:52:27,625 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Closed usertable,user6,1404360839129.864ed997ce8762419ee7842a34c8c1fc.
2014-07-02 21:56:46,739 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=0, evicted=0, evictedPerRun=NaN
2014-07-02 21:57:35,667 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:57:35,676 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:57:35,677 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning da30d076a3fb986c27f5ec576fd4dbc3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,677 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:57:35,678 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 21:57:35,679 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2c36a3fcd1790e62fe374a1c93881d35 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,679 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d229cf2ba6e2c3756ac8f1655f75a182 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,680 INFO  [Priority.RpcServer.handler=6,port=60020] regionserver.HRegionServer: Open usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:57:35,684 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node da30d076a3fb986c27f5ec576fd4dbc3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,685 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Opening region: {ENCODED => da30d076a3fb986c27f5ec576fd4dbc3, NAME => 'usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.', STARTKEY => 'user1', ENDKEY => 'user2'}
2014-07-02 21:57:35,685 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2c36a3fcd1790e62fe374a1c93881d35 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,686 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable da30d076a3fb986c27f5ec576fd4dbc3
2014-07-02 21:57:35,686 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => 2c36a3fcd1790e62fe374a1c93881d35, NAME => 'usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.', STARTKEY => 'user3', ENDKEY => 'user4'}
2014-07-02 21:57:35,686 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Instantiated usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:57:35,687 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 2c36a3fcd1790e62fe374a1c93881d35
2014-07-02 21:57:35,687 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:57:35,688 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d229cf2ba6e2c3756ac8f1655f75a182 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,690 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Opening region: {ENCODED => d229cf2ba6e2c3756ac8f1655f75a182, NAME => 'usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.', STARTKEY => 'user8', ENDKEY => 'user9'}
2014-07-02 21:57:35,690 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable d229cf2ba6e2c3756ac8f1655f75a182
2014-07-02 21:57:35,690 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Instantiated usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:57:35,696 INFO  [StoreOpener-da30d076a3fb986c27f5ec576fd4dbc3-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:57:35,697 INFO  [StoreOpener-2c36a3fcd1790e62fe374a1c93881d35-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:57:35,698 INFO  [StoreOpener-d229cf2ba6e2c3756ac8f1655f75a182-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:57:35,699 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3
2014-07-02 21:57:35,700 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35
2014-07-02 21:57:35,701 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182
2014-07-02 21:57:35,702 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Onlined da30d076a3fb986c27f5ec576fd4dbc3; next sequenceid=1
2014-07-02 21:57:35,702 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined 2c36a3fcd1790e62fe374a1c93881d35; next sequenceid=1
2014-07-02 21:57:35,702 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 2c36a3fcd1790e62fe374a1c93881d35
2014-07-02 21:57:35,702 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node da30d076a3fb986c27f5ec576fd4dbc3
2014-07-02 21:57:35,704 INFO  [PostOpenDeployTasks:2c36a3fcd1790e62fe374a1c93881d35] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:57:35,705 INFO  [PostOpenDeployTasks:da30d076a3fb986c27f5ec576fd4dbc3] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:57:35,717 INFO  [PostOpenDeployTasks:2c36a3fcd1790e62fe374a1c93881d35] catalog.MetaEditor: Updated row usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,717 INFO  [PostOpenDeployTasks:2c36a3fcd1790e62fe374a1c93881d35] regionserver.HRegionServer: Finished post open deploy task for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:57:35,718 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 2c36a3fcd1790e62fe374a1c93881d35 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,719 INFO  [PostOpenDeployTasks:da30d076a3fb986c27f5ec576fd4dbc3] catalog.MetaEditor: Updated row usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,719 INFO  [PostOpenDeployTasks:da30d076a3fb986c27f5ec576fd4dbc3] regionserver.HRegionServer: Finished post open deploy task for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:57:35,720 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning da30d076a3fb986c27f5ec576fd4dbc3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,721 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 2c36a3fcd1790e62fe374a1c93881d35 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,721 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned 2c36a3fcd1790e62fe374a1c93881d35 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,721 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,722 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 59a882e2ecb917452809632a4eb8d27e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,724 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node da30d076a3fb986c27f5ec576fd4dbc3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,724 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Transitioned da30d076a3fb986c27f5ec576fd4dbc3 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,724 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Opened usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,724 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 22b32dbac98aa0b38d3435a0ebdfe229 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,727 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 59a882e2ecb917452809632a4eb8d27e from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,727 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Opening region: {ENCODED => 59a882e2ecb917452809632a4eb8d27e, NAME => 'usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.', STARTKEY => 'user9', ENDKEY => ''}
2014-07-02 21:57:35,728 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:57:35,728 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Instantiated usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 21:57:35,730 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Onlined d229cf2ba6e2c3756ac8f1655f75a182; next sequenceid=1
2014-07-02 21:57:35,730 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node d229cf2ba6e2c3756ac8f1655f75a182
2014-07-02 21:57:35,735 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 22b32dbac98aa0b38d3435a0ebdfe229 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-07-02 21:57:35,736 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Opening region: {ENCODED => 22b32dbac98aa0b38d3435a0ebdfe229, NAME => 'usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.', STARTKEY => 'user6', ENDKEY => 'user7'}
2014-07-02 21:57:35,736 INFO  [PostOpenDeployTasks:d229cf2ba6e2c3756ac8f1655f75a182] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:57:35,736 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table usertable 22b32dbac98aa0b38d3435a0ebdfe229
2014-07-02 21:57:35,736 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Instantiated usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:57:35,741 INFO  [StoreOpener-59a882e2ecb917452809632a4eb8d27e-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:57:35,744 INFO  [PostOpenDeployTasks:d229cf2ba6e2c3756ac8f1655f75a182] catalog.MetaEditor: Updated row usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,744 INFO  [PostOpenDeployTasks:d229cf2ba6e2c3756ac8f1655f75a182] regionserver.HRegionServer: Finished post open deploy task for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:57:35,745 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning d229cf2ba6e2c3756ac8f1655f75a182 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,745 INFO  [StoreOpener-22b32dbac98aa0b38d3435a0ebdfe229-1] compactions.CompactionConfiguration: size [268435456, 128); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 5368709120; delete expired; major period 0, major jitter 0.500000
2014-07-02 21:57:35,746 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:57:35,748 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229
2014-07-02 21:57:35,749 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Onlined 59a882e2ecb917452809632a4eb8d27e; next sequenceid=1
2014-07-02 21:57:35,749 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:57:35,751 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node d229cf2ba6e2c3756ac8f1655f75a182 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,751 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Transitioned d229cf2ba6e2c3756ac8f1655f75a182 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,751 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-0] handler.OpenRegionHandler: Opened usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,751 INFO  [PostOpenDeployTasks:59a882e2ecb917452809632a4eb8d27e] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 21:57:35,759 INFO  [PostOpenDeployTasks:59a882e2ecb917452809632a4eb8d27e] catalog.MetaEditor: Updated row usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,759 INFO  [PostOpenDeployTasks:59a882e2ecb917452809632a4eb8d27e] regionserver.HRegionServer: Finished post open deploy task for usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 21:57:35,759 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 59a882e2ecb917452809632a4eb8d27e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,767 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 59a882e2ecb917452809632a4eb8d27e from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,767 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Transitioned 59a882e2ecb917452809632a4eb8d27e to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,767 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-2] handler.OpenRegionHandler: Opened usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,789 INFO  [RS_OPEN_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Onlined 22b32dbac98aa0b38d3435a0ebdfe229; next sequenceid=1
2014-07-02 21:57:35,789 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Attempting to retransition opening state of node 22b32dbac98aa0b38d3435a0ebdfe229
2014-07-02 21:57:35,792 INFO  [PostOpenDeployTasks:22b32dbac98aa0b38d3435a0ebdfe229] regionserver.HRegionServer: Post open deploy tasks for region=usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:57:35,801 INFO  [PostOpenDeployTasks:22b32dbac98aa0b38d3435a0ebdfe229] catalog.MetaEditor: Updated row usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. with server=sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,801 INFO  [PostOpenDeployTasks:22b32dbac98aa0b38d3435a0ebdfe229] regionserver.HRegionServer: Finished post open deploy task for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:57:35,802 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioning 22b32dbac98aa0b38d3435a0ebdfe229 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,807 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] zookeeper.ZKAssign: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase Transitioned node 22b32dbac98aa0b38d3435a0ebdfe229 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-07-02 21:57:35,807 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Transitioned 22b32dbac98aa0b38d3435a0ebdfe229 to OPENED in zk on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:35,807 DEBUG [RS_OPEN_REGION-sceplus-vm48:60020-1] handler.OpenRegionHandler: Opened usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. on sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 21:57:54,332 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:57:54,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 108 synced till here 98
2014-07-02 21:57:55,238 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363138690 with entries=108, filesize=90.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363474332
2014-07-02 21:57:56,826 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:57:57,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 225 synced till here 196
2014-07-02 21:57:57,292 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363474332 with entries=117, filesize=83.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363476826
2014-07-02 21:57:59,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:57:59,302 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 329 synced till here 300
2014-07-02 21:57:59,538 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363476826 with entries=104, filesize=77.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363479069
2014-07-02 21:58:01,680 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:01,843 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 458 synced till here 437
2014-07-02 21:58:02,056 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363479069 with entries=129, filesize=93.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363481680
2014-07-02 21:58:03,374 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:03,394 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 558 synced till here 535
2014-07-02 21:58:03,788 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363481680 with entries=100, filesize=78.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363483374
2014-07-02 21:58:05,419 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:05,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 686 synced till here 668
2014-07-02 21:58:06,543 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363483374 with entries=128, filesize=90.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363485419
2014-07-02 21:58:07,262 DEBUG [RpcServer.handler=13,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:58:07,282 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 266.5m
2014-07-02 21:58:09,095 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:09,205 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:09,296 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 815 synced till here 798
2014-07-02 21:58:09,344 DEBUG [RpcServer.handler=24,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:58:09,344 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 260.7m
2014-07-02 21:58:09,530 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363485419 with entries=129, filesize=96.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363489206
2014-07-02 21:58:10,313 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:58:10,476 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:10,630 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-02 21:58:11,039 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:11,044 DEBUG [RpcServer.handler=26,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:58:11,167 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 939 synced till here 898
2014-07-02 21:58:11,671 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363489206 with entries=124, filesize=89.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363491039
2014-07-02 21:58:12,985 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:13,050 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1043 synced till here 1035
2014-07-02 21:58:13,298 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363491039 with entries=104, filesize=80.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363492986
2014-07-02 21:58:14,353 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:14,377 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1137 synced till here 1134
2014-07-02 21:58:14,394 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363492986 with entries=94, filesize=68.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363494354
2014-07-02 21:58:15,291 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=187, memsize=51.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/7bea9b18a8884e118c7d62fe06bec371
2014-07-02 21:58:15,303 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/7bea9b18a8884e118c7d62fe06bec371 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/7bea9b18a8884e118c7d62fe06bec371
2014-07-02 21:58:15,316 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/7bea9b18a8884e118c7d62fe06bec371, entries=186410, sequenceid=187, filesize=13.3m
2014-07-02 21:58:15,316 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~287.0m/300975760, currentsize=86.9m/91155440 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 5972ms, sequenceid=187, compaction requested=false
2014-07-02 21:58:15,324 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 368.2m
2014-07-02 21:58:15,369 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=174, memsize=51.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/3b060d18b26d44709154506ac49182ad
2014-07-02 21:58:15,380 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/3b060d18b26d44709154506ac49182ad as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/3b060d18b26d44709154506ac49182ad
2014-07-02 21:58:15,436 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/3b060d18b26d44709154506ac49182ad, entries=186120, sequenceid=174, filesize=13.3m
2014-07-02 21:58:15,436 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~266.5m/279481520, currentsize=106.8m/112008640 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 8154ms, sequenceid=174, compaction requested=false
2014-07-02 21:58:15,437 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182., current region memstore size 365.0m
2014-07-02 21:58:15,808 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:15,977 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:16,294 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:16,321 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363494354 with entries=99, filesize=61.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363496294
2014-07-02 21:58:18,638 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:18,733 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1345 synced till here 1325
2014-07-02 21:58:18,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363496294 with entries=109, filesize=85.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363498639
2014-07-02 21:58:19,910 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:20,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1438 synced till here 1432
2014-07-02 21:58:20,057 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363498639 with entries=93, filesize=67.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363499910
2014-07-02 21:58:21,775 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:22,978 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=244, memsize=56.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/9eb49e6d61b943c4933a69f0d406f856
2014-07-02 21:58:22,978 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1575 synced till here 1572
2014-07-02 21:58:23,000 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/9eb49e6d61b943c4933a69f0d406f856 as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/9eb49e6d61b943c4933a69f0d406f856
2014-07-02 21:58:23,014 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/9eb49e6d61b943c4933a69f0d406f856, entries=203810, sequenceid=244, filesize=14.5m
2014-07-02 21:58:23,014 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~374.4m/392636720, currentsize=116.3m/121986480 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 7690ms, sequenceid=244, compaction requested=false
2014-07-02 21:58:23,034 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363499910 with entries=137, filesize=98.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363501775
2014-07-02 21:58:23,048 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=243, memsize=56.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/ff6bda3eec804ac0b88aa958275aca32
2014-07-02 21:58:23,062 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/ff6bda3eec804ac0b88aa958275aca32 as hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/ff6bda3eec804ac0b88aa958275aca32
2014-07-02 21:58:23,078 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/ff6bda3eec804ac0b88aa958275aca32, entries=203920, sequenceid=243, filesize=14.5m
2014-07-02 21:58:23,078 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~374.5m/392644880, currentsize=114.9m/120458960 for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. in 7642ms, sequenceid=243, compaction requested=false
2014-07-02 21:58:24,712 DEBUG [RpcServer.handler=35,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:58:24,713 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 257.5m
2014-07-02 21:58:25,189 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:25,210 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1670 synced till here 1659
2014-07-02 21:58:25,234 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:25,257 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363501775 with entries=95, filesize=71.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363505190
2014-07-02 21:58:26,896 DEBUG [RpcServer.handler=19,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:58:26,897 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 256.1m
2014-07-02 21:58:27,069 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:27,092 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1758 synced till here 1755
2014-07-02 21:58:27,110 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363505190 with entries=88, filesize=63.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363507070
2014-07-02 21:58:27,336 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:29,064 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:29,328 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1856 synced till here 1840
2014-07-02 21:58:29,849 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363507070 with entries=98, filesize=73.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363509065
2014-07-02 21:58:32,680 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:32,763 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 1971 synced till here 1943
2014-07-02 21:58:33,075 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363509065 with entries=115, filesize=95.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363512680
2014-07-02 21:58:34,351 DEBUG [RpcServer.handler=14,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:58:35,197 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:35,233 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2084 synced till here 2063
2014-07-02 21:58:35,382 DEBUG [RpcServer.handler=34,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:58:35,566 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363512680 with entries=113, filesize=76.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363515199
2014-07-02 21:58:36,901 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:37,087 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2176 synced till here 2174
2014-07-02 21:58:37,333 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363515199 with entries=92, filesize=61.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363516902
2014-07-02 21:58:39,672 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:39,726 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2266 synced till here 2259
2014-07-02 21:58:39,971 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363516902 with entries=90, filesize=69.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363519672
2014-07-02 21:58:42,988 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=341, memsize=153.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/1ca000fc847d4c508d27f885a6bead7d
2014-07-02 21:58:43,008 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/1ca000fc847d4c508d27f885a6bead7d as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/1ca000fc847d4c508d27f885a6bead7d
2014-07-02 21:58:43,031 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/1ca000fc847d4c508d27f885a6bead7d, entries=559750, sequenceid=341, filesize=39.9m
2014-07-02 21:58:43,032 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.5m/269967360, currentsize=222.4m/233254160 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 18319ms, sequenceid=341, compaction requested=false
2014-07-02 21:58:43,032 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 347.7m
2014-07-02 21:58:43,210 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:43,382 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2376 synced till here 2353
2014-07-02 21:58:44,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363519672 with entries=110, filesize=84.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363523211
2014-07-02 21:58:45,071 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:45,227 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:58:46,109 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:46,266 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2485 synced till here 2457
2014-07-02 21:58:46,808 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=354, memsize=161.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/df4e0f135fc348c0b7fbfa3b9bbbdb33
2014-07-02 21:58:46,833 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/df4e0f135fc348c0b7fbfa3b9bbbdb33 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/df4e0f135fc348c0b7fbfa3b9bbbdb33
2014-07-02 21:58:47,027 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363523211 with entries=109, filesize=81.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363526110
2014-07-02 21:58:47,466 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/df4e0f135fc348c0b7fbfa3b9bbbdb33, entries=588750, sequenceid=354, filesize=42.0m
2014-07-02 21:58:47,466 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~258.0m/270495520, currentsize=247.7m/259772480 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 20569ms, sequenceid=354, compaction requested=false
2014-07-02 21:58:47,467 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182., current region memstore size 372.9m
2014-07-02 21:58:48,695 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:48,696 DEBUG [RpcServer.handler=22,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:58:48,910 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363526110 with entries=103, filesize=77.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363528696
2014-07-02 21:58:48,951 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:58:50,691 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:50,721 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2692 synced till here 2683
2014-07-02 21:58:50,774 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363528696 with entries=104, filesize=69.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363530692
2014-07-02 21:58:51,793 DEBUG [RpcServer.handler=40,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 21:58:53,127 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:58:53,305 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2789 synced till here 2778
2014-07-02 21:58:53,820 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363530692 with entries=97, filesize=71.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363533128
2014-07-02 21:59:15,124 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 26042ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 21:59:15,124 WARN  [regionserver60020] util.Sleeper: We slept 22153ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 21:59:15,124 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 26042ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 21:59:15,207 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20164ms
GC pool 'ParNew' had collection(s): count=3 time=238ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20206ms
2014-07-02 21:59:15,333 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23096,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532176,"queuetimems":208,"class":"HRegionServer","responsesize":16880,"method":"Multi"}
2014-07-02 21:59:15,333 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532203,"queuetimems":1,"class":"HRegionServer","responsesize":17123,"method":"Multi"}
2014-07-02 21:59:15,333 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.respondercallId: 827 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,335 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23084,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532188,"queuetimems":1,"class":"HRegionServer","responsesize":17555,"method":"Multi"}
2014-07-02 21:59:15,335 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: RpcServer.handler=8,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,335 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.respondercallId: 825 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,336 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: RpcServer.handler=47,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,336 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.respondercallId: 826 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,336 WARN  [RpcServer.handler=49,port=60020] ipc.RpcServer: RpcServer.handler=49,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,429 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23215,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532213,"queuetimems":0,"class":"HRegionServer","responsesize":16459,"method":"Multi"}
2014-07-02 21:59:15,430 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.respondercallId: 824 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,430 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: RpcServer.handler=34,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,596 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:15,597 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23164,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532432,"queuetimems":2,"class":"HRegionServer","responsesize":17137,"method":"Multi"}
2014-07-02 21:59:15,597 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23145,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532452,"queuetimems":1,"class":"HRegionServer","responsesize":16640,"method":"Multi"}
2014-07-02 21:59:15,597 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23135,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532462,"queuetimems":0,"class":"HRegionServer","responsesize":17041,"method":"Multi"}
2014-07-02 21:59:15,597 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.respondercallId: 823 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,598 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: RpcServer.handler=48,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,598 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 821 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,598 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,598 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 835 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,598 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,598 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23156,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532442,"queuetimems":1,"class":"HRegionServer","responsesize":17232,"method":"Multi"}
2014-07-02 21:59:15,599 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.respondercallId: 822 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,599 WARN  [RpcServer.handler=15,port=60020] ipc.RpcServer: RpcServer.handler=15,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,599 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22924,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532674,"queuetimems":0,"class":"HRegionServer","responsesize":17303,"method":"Multi"}
2014-07-02 21:59:15,600 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.respondercallId: 830 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,600 WARN  [RpcServer.handler=17,port=60020] ipc.RpcServer: RpcServer.handler=17,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,622 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22957,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532665,"queuetimems":1,"class":"HRegionServer","responsesize":16522,"method":"Multi"}
2014-07-02 21:59:15,622 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.respondercallId: 832 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,622 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: RpcServer.handler=46,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,647 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2890 synced till here 2872
2014-07-02 21:59:15,717 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":23062,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363532654,"queuetimems":1,"class":"HRegionServer","responsesize":17206,"method":"Multi"}
2014-07-02 21:59:15,717 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.respondercallId: 833 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,717 WARN  [RpcServer.handler=9,port=60020] ipc.RpcServer: RpcServer.handler=9,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,804 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363533128 with entries=101, filesize=79.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363555596
2014-07-02 21:59:15,979 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22674,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533305,"queuetimems":3,"class":"HRegionServer","responsesize":16656,"method":"Multi"}
2014-07-02 21:59:15,980 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.respondercallId: 836 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,980 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: RpcServer.handler=45,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,980 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22645,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533335,"queuetimems":0,"class":"HRegionServer","responsesize":17115,"method":"Multi"}
2014-07-02 21:59:15,981 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.respondercallId: 843 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,981 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: RpcServer.handler=27,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:15,995 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22675,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533320,"queuetimems":1,"class":"HRegionServer","responsesize":16472,"method":"Multi"}
2014-07-02 21:59:15,996 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.respondercallId: 837 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:15,996 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: RpcServer.handler=13,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,114 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22073,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534040,"queuetimems":0,"class":"HRegionServer","responsesize":16831,"method":"Multi"}
2014-07-02 21:59:16,114 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22584,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533529,"queuetimems":0,"class":"HRegionServer","responsesize":16944,"method":"Multi"}
2014-07-02 21:59:16,114 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.respondercallId: 844 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,114 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: RpcServer.handler=18,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,114 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.respondercallId: 842 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,114 WARN  [RpcServer.handler=32,port=60020] ipc.RpcServer: RpcServer.handler=32,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533565,"queuetimems":0,"class":"HRegionServer","responsesize":17046,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22087,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534027,"queuetimems":0,"class":"HRegionServer","responsesize":16903,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22283,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533831,"queuetimems":0,"class":"HRegionServer","responsesize":17043,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21856,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534258,"queuetimems":0,"class":"HRegionServer","responsesize":16844,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.respondercallId: 839 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: RpcServer.handler=26,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21886,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534229,"queuetimems":1,"class":"HRegionServer","responsesize":16950,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534007,"queuetimems":1,"class":"HRegionServer","responsesize":17285,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22572,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533542,"queuetimems":1,"class":"HRegionServer","responsesize":16974,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533565,"queuetimems":11,"class":"HRegionServer","responsesize":16686,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":22295,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363533819,"queuetimems":1,"class":"HRegionServer","responsesize":17205,"method":"Multi"}
2014-07-02 21:59:16,115 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.respondercallId: 849 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: RpcServer.handler=38,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.respondercallId: 840 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: RpcServer.handler=23,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.respondercallId: 846 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: RpcServer.handler=4,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.respondercallId: 838 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: RpcServer.handler=22,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.respondercallId: 841 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: RpcServer.handler=30,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,116 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 847 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,117 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: RpcServer.handler=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,117 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.respondercallId: 851 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,117 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: RpcServer.handler=2,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,117 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 856 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,117 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,133 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21664,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534468,"queuetimems":2,"class":"HRegionServer","responsesize":17083,"method":"Multi"}
2014-07-02 21:59:16,133 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21889,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534243,"queuetimems":0,"class":"HRegionServer","responsesize":17460,"method":"Multi"}
2014-07-02 21:59:16,133 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.respondercallId: 855 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,133 WARN  [RpcServer.handler=6,port=60020] ipc.RpcServer: RpcServer.handler=6,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,133 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.respondercallId: 854 service: ClientService methodName: Multi size: 3.1m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,133 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: RpcServer.handler=29,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,174 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.respondercallId: 862 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,174 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: RpcServer.handler=11,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,174 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21683,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534491,"queuetimems":1,"class":"HRegionServer","responsesize":16983,"method":"Multi"}
2014-07-02 21:59:16,174 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 860 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,175 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,204 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21724,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534479,"queuetimems":0,"class":"HRegionServer","responsesize":17001,"method":"Multi"}
2014-07-02 21:59:16,204 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.respondercallId: 863 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,204 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: RpcServer.handler=36,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,204 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.respondercallId: 858 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,204 WARN  [RpcServer.handler=24,port=60020] ipc.RpcServer: RpcServer.handler=24,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,220 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":21312,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40206","starttimems":1404363534908,"queuetimems":11,"class":"HRegionServer","responsesize":16640,"method":"Multi"}
2014-07-02 21:59:16,221 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.respondercallId: 985 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40348: output error
2014-07-02 21:59:16,221 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.respondercallId: 866 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,222 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: RpcServer.handler=28,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,222 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: RpcServer.handler=19,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,222 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.respondercallId: 861 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40206: output error
2014-07-02 21:59:16,221 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.respondercallId: 945 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:40347: output error
2014-07-02 21:59:16,222 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: RpcServer.handler=37,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,223 WARN  [RpcServer.handler=44,port=60020] ipc.RpcServer: RpcServer.handler=44,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:16,246 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.respondercallId: 921 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:40346: output error
2014-07-02 21:59:16,247 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: RpcServer.handler=3,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 21:59:17,569 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:17,584 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 2982 synced till here 2980
2014-07-02 21:59:17,596 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363555596 with entries=92, filesize=61.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363557569
2014-07-02 21:59:19,650 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:19,675 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363557569 with entries=86, filesize=61.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363559651
2014-07-02 21:59:20,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:20,761 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3155 synced till here 3149
2014-07-02 21:59:20,808 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363559651 with entries=87, filesize=65.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363560748
2014-07-02 21:59:21,585 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=473, memsize=225.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/c372b05553ff42cc881c82cae4a96cba
2014-07-02 21:59:21,612 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/c372b05553ff42cc881c82cae4a96cba as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/c372b05553ff42cc881c82cae4a96cba
2014-07-02 21:59:21,626 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/c372b05553ff42cc881c82cae4a96cba, entries=819500, sequenceid=473, filesize=58.4m
2014-07-02 21:59:21,626 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~354.1m/371255920, currentsize=265.5m/278414800 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 38594ms, sequenceid=473, compaction requested=false
2014-07-02 21:59:21,627 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 469.9m
2014-07-02 21:59:21,686 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 21:59:22,084 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:59:22,090 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:22,278 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363560748 with entries=100, filesize=71.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363562090
2014-07-02 21:59:23,748 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:23,827 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3344 synced till here 3341
2014-07-02 21:59:23,858 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363562090 with entries=89, filesize=66.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363563749
2014-07-02 21:59:23,960 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=499, memsize=238.1m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/c72e2c4267ca49219027225c1e66ae2a
2014-07-02 21:59:23,972 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/c72e2c4267ca49219027225c1e66ae2a as hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/c72e2c4267ca49219027225c1e66ae2a
2014-07-02 21:59:23,993 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/c72e2c4267ca49219027225c1e66ae2a, entries=866820, sequenceid=499, filesize=61.8m
2014-07-02 21:59:23,994 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~394.4m/413596240, currentsize=270.8m/283905040 for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. in 36526ms, sequenceid=499, compaction requested=false
2014-07-02 21:59:23,994 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 497.0m
2014-07-02 21:59:24,210 DEBUG [RpcServer.handler=23,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 21:59:24,733 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:59:25,350 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:25,720 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363563749 with entries=101, filesize=74.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363565351
2014-07-02 21:59:25,721 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:59:26,969 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:27,088 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3541 synced till here 3528
2014-07-02 21:59:27,159 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363565351 with entries=96, filesize=73.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363566970
2014-07-02 21:59:27,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:59:28,410 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:28,648 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3657 synced till here 3644
2014-07-02 21:59:28,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363566970 with entries=116, filesize=86.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363568410
2014-07-02 21:59:28,807 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:59:30,308 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:30,440 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3755 synced till here 3743
2014-07-02 21:59:30,511 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363568410 with entries=98, filesize=69.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363570308
2014-07-02 21:59:30,512 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:59:32,932 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:33,000 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3847 synced till here 3833
2014-07-02 21:59:33,104 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363570308 with entries=92, filesize=70.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363572933
2014-07-02 21:59:33,106 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:59:34,946 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:35,003 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 3963 synced till here 3937
2014-07-02 21:59:35,047 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=647, memsize=223.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/ec272a4327b84db19d2640838ef01019
2014-07-02 21:59:35,061 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/ec272a4327b84db19d2640838ef01019 as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/ec272a4327b84db19d2640838ef01019
2014-07-02 21:59:36,154 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/ec272a4327b84db19d2640838ef01019, entries=812500, sequenceid=647, filesize=58.0m
2014-07-02 21:59:36,154 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~471.5m/494450560, currentsize=253.8m/266155440 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 14527ms, sequenceid=647, compaction requested=true
2014-07-02 21:59:36,161 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 21:59:36,168 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 21:59:36,168 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 21:59:36,168 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-02 21:59:36,168 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:59:36,168 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e., current region memstore size 364.2m
2014-07-02 21:59:36,168 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:59:36,168 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. because compaction request was cancelled
2014-07-02 21:59:36,176 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363572933 with entries=116, filesize=89.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363574947
2014-07-02 21:59:36,180 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 21:59:36,740 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:36,959 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:59:38,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4086 synced till here 4081
2014-07-02 21:59:38,161 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363574947 with entries=123, filesize=93.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363576740
2014-07-02 21:59:38,810 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:38,846 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4199 synced till here 4188
2014-07-02 21:59:39,825 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363576740 with entries=113, filesize=76.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363578810
2014-07-02 21:59:40,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:41,801 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4321 synced till here 4303
2014-07-02 21:59:41,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363578810 with entries=122, filesize=90.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363580509
2014-07-02 21:59:42,252 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=675, memsize=247.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0951060c59614af9be6f3b879834e1a3
2014-07-02 21:59:42,309 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0951060c59614af9be6f3b879834e1a3 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/0951060c59614af9be6f3b879834e1a3
2014-07-02 21:59:42,331 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/0951060c59614af9be6f3b879834e1a3, entries=901180, sequenceid=675, filesize=64.3m
2014-07-02 21:59:42,331 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~497.0m/521161200, currentsize=317.6m/333019040 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 18337ms, sequenceid=675, compaction requested=true
2014-07-02 21:59:42,332 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 21:59:42,332 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 21:59:42,332 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-02 21:59:42,332 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 21:59:42,332 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 21:59:42,332 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. because compaction request was cancelled
2014-07-02 21:59:42,332 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 620.0m
2014-07-02 21:59:42,348 DEBUG [RpcServer.handler=36,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 21:59:43,997 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:44,052 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4442 synced till here 4417
2014-07-02 21:59:44,145 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:59:44,179 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363580509 with entries=121, filesize=88.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363583998
2014-07-02 21:59:44,798 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:44,829 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4540 synced till here 4527
2014-07-02 21:59:44,900 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363583998 with entries=98, filesize=67.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363584799
2014-07-02 21:59:46,749 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:47,850 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4644 synced till here 4628
2014-07-02 21:59:47,950 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363584799 with entries=104, filesize=82.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363586750
2014-07-02 21:59:48,563 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:48,580 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4742 synced till here 4730
2014-07-02 21:59:48,674 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363586750 with entries=98, filesize=73.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363588563
2014-07-02 21:59:50,216 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:50,241 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363588563 with entries=94, filesize=61.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363590217
2014-07-02 21:59:50,332 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=784, memsize=150.0m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/.tmp/37aca2d3b34b4db0b0dd98bd3f7b8e9b
2014-07-02 21:59:50,356 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/.tmp/37aca2d3b34b4db0b0dd98bd3f7b8e9b as hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/family/37aca2d3b34b4db0b0dd98bd3f7b8e9b
2014-07-02 21:59:50,369 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/family/37aca2d3b34b4db0b0dd98bd3f7b8e9b, entries=546310, sequenceid=784, filesize=38.9m
2014-07-02 21:59:50,370 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~366.2m/384002320, currentsize=85.1m/89229280 for region usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e. in 14202ms, sequenceid=784, compaction requested=false
2014-07-02 21:59:50,371 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182., current region memstore size 729.0m
2014-07-02 21:59:52,582 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1683ms
GC pool 'ParNew' had collection(s): count=1 time=1780ms
2014-07-02 21:59:52,860 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 21:59:53,060 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:53,115 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 4941 synced till here 4923
2014-07-02 21:59:53,211 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363590217 with entries=105, filesize=84.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363593061
2014-07-02 21:59:53,211 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363138690
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363474332
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363476826
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363479069
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363481680
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363483374
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363485419
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363489206
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363491039
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363492986
2014-07-02 21:59:53,212 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363494354
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363496294
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363498639
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363499910
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363501775
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363505190
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363507070
2014-07-02 21:59:53,213 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363509065
2014-07-02 21:59:53,215 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363512680
2014-07-02 21:59:53,215 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363515199
2014-07-02 21:59:53,215 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363516902
2014-07-02 21:59:55,588 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1454ms
GC pool 'ParNew' had collection(s): count=1 time=1832ms
2014-07-02 21:59:56,271 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:56,346 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5064 synced till here 5042
2014-07-02 21:59:57,388 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363593061 with entries=123, filesize=89.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363596271
2014-07-02 21:59:58,140 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 21:59:59,112 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5197 synced till here 5176
2014-07-02 21:59:59,250 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363596271 with entries=133, filesize=100.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363598140
2014-07-02 21:59:59,866 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:00,598 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363598140 with entries=121, filesize=81.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363599866
2014-07-02 22:00:01,774 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:01,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363599866 with entries=96, filesize=67.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363601774
2014-07-02 22:00:03,166 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:03,240 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5501 synced till here 5500
2014-07-02 22:00:03,320 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363601774 with entries=87, filesize=64.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363603167
2014-07-02 22:00:05,557 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:05,644 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363603167 with entries=89, filesize=62.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363605558
2014-07-02 22:00:07,146 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:07,169 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=880, memsize=321.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/58d4ecb721ac49059f7a01e2eae6226b
2014-07-02 22:00:07,200 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5674 synced till here 5673
2014-07-02 22:00:07,216 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/58d4ecb721ac49059f7a01e2eae6226b as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/58d4ecb721ac49059f7a01e2eae6226b
2014-07-02 22:00:07,248 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363605558 with entries=84, filesize=61.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363607147
2014-07-02 22:00:07,257 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/58d4ecb721ac49059f7a01e2eae6226b, entries=1171650, sequenceid=880, filesize=83.5m
2014-07-02 22:00:07,257 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~632.7m/663391760, currentsize=400.7m/420113760 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 24925ms, sequenceid=880, compaction requested=true
2014-07-02 22:00:07,258 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 22:00:07,258 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-02 22:00:07,259 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:00:07,259 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:00:07,259 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. because compaction request was cancelled
2014-07-02 22:00:07,259 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:00:07,259 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 761.5m
2014-07-02 22:00:07,325 DEBUG [RpcServer.handler=39,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:00:07,925 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:00:09,003 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:09,024 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5758 synced till here 5756
2014-07-02 22:00:09,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363607147 with entries=84, filesize=62.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363609003
2014-07-02 22:00:09,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363519672
2014-07-02 22:00:09,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363523211
2014-07-02 22:00:10,808 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:10,865 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5852 synced till here 5840
2014-07-02 22:00:11,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363609003 with entries=94, filesize=72.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363610808
2014-07-02 22:00:12,840 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:12,870 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 5947 synced till here 5940
2014-07-02 22:00:12,911 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363610808 with entries=95, filesize=67.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363612841
2014-07-02 22:00:13,711 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:13,731 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6034 synced till here 6033
2014-07-02 22:00:13,746 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363612841 with entries=87, filesize=63.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363613711
2014-07-02 22:00:15,481 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:15,916 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=971, memsize=355.7m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/de6bae118c0a41eaaea27db27c3a5789
2014-07-02 22:00:15,920 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6123 synced till here 6121
2014-07-02 22:00:15,944 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/de6bae118c0a41eaaea27db27c3a5789 as hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/de6bae118c0a41eaaea27db27c3a5789
2014-07-02 22:00:15,952 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363613711 with entries=89, filesize=64.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363615482
2014-07-02 22:00:16,004 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/de6bae118c0a41eaaea27db27c3a5789, entries=1295090, sequenceid=971, filesize=92.2m
2014-07-02 22:00:16,005 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~729.0m/764397840, currentsize=397.4m/416656880 for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. in 25633ms, sequenceid=971, compaction requested=true
2014-07-02 22:00:16,005 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 22:00:16,006 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-02 22:00:16,006 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:00:16,006 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:00:16,006 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. because compaction request was cancelled
2014-07-02 22:00:16,008 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:00:16,008 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e., current region memstore size 205.7m
2014-07-02 22:00:16,081 DEBUG [RpcServer.handler=15,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:00:16,191 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:00:17,895 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:17,925 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6210 synced till here 6203
2014-07-02 22:00:17,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363615482 with entries=87, filesize=66.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363617896
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363526110
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363528696
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363530692
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363533128
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363555596
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363557569
2014-07-02 22:00:17,990 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363559651
2014-07-02 22:00:19,426 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:19,460 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6301 synced till here 6300
2014-07-02 22:00:19,513 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363617896 with entries=91, filesize=64.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363619427
2014-07-02 22:00:21,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:21,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363619427 with entries=90, filesize=63.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363621189
2014-07-02 22:00:21,795 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1227, memsize=105.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/.tmp/60ed9f2590e64a479ea33870b286a1b9
2014-07-02 22:00:21,810 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/.tmp/60ed9f2590e64a479ea33870b286a1b9 as hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/family/60ed9f2590e64a479ea33870b286a1b9
2014-07-02 22:00:21,884 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/family/60ed9f2590e64a479ea33870b286a1b9, entries=385560, sequenceid=1227, filesize=27.5m
2014-07-02 22:00:21,885 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~205.7m/215649280, currentsize=25.5m/26701440 for region usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e. in 5877ms, sequenceid=1227, compaction requested=false
2014-07-02 22:00:21,885 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 950.0m
2014-07-02 22:00:23,314 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1062ms
GC pool 'ParNew' had collection(s): count=1 time=1068ms
2014-07-02 22:00:23,389 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:23,438 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6483 synced till here 6473
2014-07-02 22:00:23,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363621189 with entries=92, filesize=72.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363623389
2014-07-02 22:00:24,104 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:00:25,459 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:25,770 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363623389 with entries=108, filesize=82.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363625460
2014-07-02 22:00:27,589 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:27,631 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6695 synced till here 6683
2014-07-02 22:00:27,758 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363625460 with entries=104, filesize=73.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363627590
2014-07-02 22:00:28,319 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:28,975 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363627590 with entries=103, filesize=71.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363628319
2014-07-02 22:00:29,724 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:30,987 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 6902 synced till here 6896
2014-07-02 22:00:31,043 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363628319 with entries=104, filesize=79.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363629725
2014-07-02 22:00:31,855 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:31,919 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363629725 with entries=89, filesize=63.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363631856
2014-07-02 22:00:33,360 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1142, memsize=405.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/359a1e5c46d14091a56eb2fd0493e369
2014-07-02 22:00:33,404 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/359a1e5c46d14091a56eb2fd0493e369 as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/359a1e5c46d14091a56eb2fd0493e369
2014-07-02 22:00:33,438 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/359a1e5c46d14091a56eb2fd0493e369, entries=1478010, sequenceid=1142, filesize=105.3m
2014-07-02 22:00:33,439 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~763.0m/800085200, currentsize=427.2m/447973760 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 26180ms, sequenceid=1142, compaction requested=true
2014-07-02 22:00:33,439 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:00:33,439 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 22:00:33,439 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-02 22:00:33,440 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:00:33,440 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:00:33,440 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 830.9m
2014-07-02 22:00:33,440 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. because compaction request was cancelled
2014-07-02 22:00:33,792 DEBUG [RpcServer.handler=25,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:00:33,898 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:34,016 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7088 synced till here 7085
2014-07-02 22:00:34,049 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363631856 with entries=97, filesize=69.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363633898
2014-07-02 22:00:34,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363560748
2014-07-02 22:00:34,049 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363562090
2014-07-02 22:00:34,243 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:00:36,107 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:36,277 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7186 synced till here 7178
2014-07-02 22:00:36,356 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363633898 with entries=98, filesize=70.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363636107
2014-07-02 22:00:38,022 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:38,157 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7286 synced till here 7274
2014-07-02 22:00:38,264 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363636107 with entries=100, filesize=76.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363638023
2014-07-02 22:00:40,184 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:40,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7388 synced till here 7375
2014-07-02 22:00:40,268 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363638023 with entries=102, filesize=75.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363640184
2014-07-02 22:00:41,708 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:41,810 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7490 synced till here 7475
2014-07-02 22:00:41,997 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363640184 with entries=102, filesize=75.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363641709
2014-07-02 22:00:43,662 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:43,692 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7587 synced till here 7578
2014-07-02 22:00:43,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363641709 with entries=97, filesize=71.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363643662
2014-07-02 22:00:45,235 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:45,295 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363643662 with entries=87, filesize=61.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363645236
2014-07-02 22:00:45,747 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,747 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,748 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,749 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,749 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,749 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,778 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,778 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,778 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,778 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,796 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,800 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,827 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,847 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:45,875 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:46,218 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:46,647 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:46,798 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:47,013 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:47,105 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:47,924 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,001 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,040 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,056 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,079 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,109 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,130 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,153 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,171 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,190 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,208 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,228 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,247 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,266 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,286 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,309 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:48,334 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,052 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,067 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,092 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,109 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,146 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,165 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:50,747 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:50,748 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-02 22:00:50,749 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5002ms
2014-07-02 22:00:50,749 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,749 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,749 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,778 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,778 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,778 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,778 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,797 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:50,801 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:50,827 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,848 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:50,875 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:51,218 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:51,647 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:51,798 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:52,014 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:52,061 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:52,106 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:52,114 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:52,139 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:52,149 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:52,165 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:52,185 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:52,203 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:00:53,959 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5625ms
2014-07-02 22:00:53,960 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5830ms
2014-07-02 22:00:53,960 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1162ms
GC pool 'ParNew' had collection(s): count=1 time=1250ms
2014-07-02 22:00:53,960 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5807ms
2014-07-02 22:00:53,960 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5752ms
2014-07-02 22:00:53,961 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5770ms
2014-07-02 22:00:53,961 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5733ms
2014-07-02 22:00:53,961 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5714ms
2014-07-02 22:00:53,961 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5790ms
2014-07-02 22:00:53,962 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5697ms
2014-07-02 22:00:53,962 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5676ms
2014-07-02 22:00:53,962 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5653ms
2014-07-02 22:00:53,962 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5961ms
2014-07-02 22:00:53,962 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 6038ms
2014-07-02 22:00:53,963 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5923ms
2014-07-02 22:00:53,963 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5907ms
2014-07-02 22:00:53,963 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5884ms
2014-07-02 22:00:53,963 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5854ms
2014-07-02 22:00:55,053 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:55,068 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:55,092 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:55,110 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:00:55,146 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:55,165 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:00:55,415 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1298, memsize=571.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/a5da3f364a274dd9a417ffbdd899bca1
2014-07-02 22:00:55,428 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/a5da3f364a274dd9a417ffbdd899bca1 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/a5da3f364a274dd9a417ffbdd899bca1
2014-07-02 22:00:55,437 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/a5da3f364a274dd9a417ffbdd899bca1, entries=2079830, sequenceid=1298, filesize=148.1m
2014-07-02 22:00:55,438 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~962.3m/1009081040, currentsize=394.2m/413369280 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 33553ms, sequenceid=1298, compaction requested=true
2014-07-02 22:00:55,438 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:00:55,438 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 22:00:55,438 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-02 22:00:55,438 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5273ms
2014-07-02 22:00:55,438 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:00:55,438 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,439 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182., current region memstore size 891.8m
2014-07-02 22:00:55,439 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:00:55,439 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5293ms
2014-07-02 22:00:55,439 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,439 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. because compaction request was cancelled
2014-07-02 22:00:55,439 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5330ms
2014-07-02 22:00:55,439 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,439 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5347ms
2014-07-02 22:00:55,439 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,439 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5372ms
2014-07-02 22:00:55,439 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,440 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5388ms
2014-07-02 22:00:55,440 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,440 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7331ms
2014-07-02 22:00:55,440 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,440 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7361ms
2014-07-02 22:00:55,440 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,445 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7389ms
2014-07-02 22:00:55,445 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,445 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7405ms
2014-07-02 22:00:55,446 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,446 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7522ms
2014-07-02 22:00:55,446 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,456 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7455ms
2014-07-02 22:00:55,456 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,456 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7147ms
2014-07-02 22:00:55,456 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,456 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7170ms
2014-07-02 22:00:55,456 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,461 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7195ms
2014-07-02 22:00:55,461 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,461 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7290ms
2014-07-02 22:00:55,461 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,464 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7217ms
2014-07-02 22:00:55,464 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,464 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7236ms
2014-07-02 22:00:55,464 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,465 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7275ms
2014-07-02 22:00:55,465 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,465 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7257ms
2014-07-02 22:00:55,465 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,465 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7312ms
2014-07-02 22:00:55,465 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,469 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7339ms
2014-07-02 22:00:55,469 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,469 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7135ms
2014-07-02 22:00:55,469 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,473 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3270ms
2014-07-02 22:00:55,473 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,473 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3288ms
2014-07-02 22:00:55,473 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,473 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3308ms
2014-07-02 22:00:55,473 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,473 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3324ms
2014-07-02 22:00:55,474 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,474 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3335ms
2014-07-02 22:00:55,474 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,474 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3360ms
2014-07-02 22:00:55,474 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,474 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8369ms
2014-07-02 22:00:55,474 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,474 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3413ms
2014-07-02 22:00:55,474 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,475 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8462ms
2014-07-02 22:00:55,475 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,476 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8678ms
2014-07-02 22:00:55,476 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,476 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8830ms
2014-07-02 22:00:55,476 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,476 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9258ms
2014-07-02 22:00:55,476 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,477 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9602ms
2014-07-02 22:00:55,477 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,477 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9630ms
2014-07-02 22:00:55,477 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,477 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9650ms
2014-07-02 22:00:55,477 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,478 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9677ms
2014-07-02 22:00:55,478 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,478 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9682ms
2014-07-02 22:00:55,478 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,479 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9701ms
2014-07-02 22:00:55,479 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,480 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9701ms
2014-07-02 22:00:55,480 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,480 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9702ms
2014-07-02 22:00:55,480 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,492 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9714ms
2014-07-02 22:00:55,492 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,496 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9747ms
2014-07-02 22:00:55,496 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,504 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9755ms
2014-07-02 22:00:55,504 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,504 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9755ms
2014-07-02 22:00:55,504 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,509 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9763ms
2014-07-02 22:00:55,509 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,510 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9763ms
2014-07-02 22:00:55,510 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,511 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9764ms
2014-07-02 22:00:55,511 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:00:55,549 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10271,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645278,"queuetimems":1,"class":"HRegionServer","responsesize":16663,"method":"Multi"}
2014-07-02 22:00:55,549 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10196,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645353,"queuetimems":1,"class":"HRegionServer","responsesize":16945,"method":"Multi"}
2014-07-02 22:00:55,549 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10218,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645331,"queuetimems":0,"class":"HRegionServer","responsesize":17007,"method":"Multi"}
2014-07-02 22:00:55,550 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10572,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363644977,"queuetimems":0,"class":"HRegionServer","responsesize":16984,"method":"Multi"}
2014-07-02 22:00:55,552 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10237,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645311,"queuetimems":1,"class":"HRegionServer","responsesize":16833,"method":"Multi"}
2014-07-02 22:00:55,553 WARN  [RpcServer.handler=23,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10538,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645010,"queuetimems":0,"class":"HRegionServer","responsesize":17100,"method":"Multi"}
2014-07-02 22:00:55,555 WARN  [RpcServer.handler=14,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10478,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645077,"queuetimems":0,"class":"HRegionServer","responsesize":17042,"method":"Multi"}
2014-07-02 22:00:55,582 DEBUG [RpcServer.handler=10,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:00:55,611 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10226,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645375,"queuetimems":1,"class":"HRegionServer","responsesize":16986,"method":"Multi"}
2014-07-02 22:00:55,729 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:55,771 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7784 synced till here 7762
2014-07-02 22:00:55,902 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10451,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645450,"queuetimems":0,"class":"HRegionServer","responsesize":16934,"method":"Multi"}
2014-07-02 22:00:55,906 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10479,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645427,"queuetimems":0,"class":"HRegionServer","responsesize":17265,"method":"Multi"}
2014-07-02 22:00:55,940 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363645236 with entries=110, filesize=80.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363655729
2014-07-02 22:00:55,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363563749
2014-07-02 22:00:55,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363565351
2014-07-02 22:00:55,940 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363566970
2014-07-02 22:00:55,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363568410
2014-07-02 22:00:55,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363570308
2014-07-02 22:00:55,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363572933
2014-07-02 22:00:55,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363574947
2014-07-02 22:00:55,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363576740
2014-07-02 22:00:55,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363578810
2014-07-02 22:00:56,096 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10366,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645730,"queuetimems":0,"class":"HRegionServer","responsesize":16841,"method":"Multi"}
2014-07-02 22:00:57,131 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:00:57,488 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:57,527 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 7899 synced till here 7874
2014-07-02 22:00:57,694 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363655729 with entries=115, filesize=92.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363657488
2014-07-02 22:00:58,185 WARN  [RpcServer.handler=13,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10107,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648077,"queuetimems":0,"class":"HRegionServer","responsesize":17058,"method":"Multi"}
2014-07-02 22:00:58,193 WARN  [RpcServer.handler=16,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10040,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648152,"queuetimems":0,"class":"HRegionServer","responsesize":16934,"method":"Multi"}
2014-07-02 22:00:58,195 WARN  [RpcServer.handler=18,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11184,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363647011,"queuetimems":0,"class":"HRegionServer","responsesize":17108,"method":"Multi"}
2014-07-02 22:00:58,204 WARN  [RpcServer.handler=37,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10016,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648188,"queuetimems":0,"class":"HRegionServer","responsesize":16833,"method":"Multi"}
2014-07-02 22:00:58,208 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10038,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648169,"queuetimems":0,"class":"HRegionServer","responsesize":17042,"method":"Multi"}
2014-07-02 22:00:58,208 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10001,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648207,"queuetimems":1,"class":"HRegionServer","responsesize":16945,"method":"Multi"}
2014-07-02 22:00:58,209 WARN  [RpcServer.handler=46,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11412,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363646796,"queuetimems":1,"class":"HRegionServer","responsesize":17136,"method":"Multi"}
2014-07-02 22:00:58,209 WARN  [RpcServer.handler=4,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10153,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648055,"queuetimems":1,"class":"HRegionServer","responsesize":16986,"method":"Multi"}
2014-07-02 22:00:58,210 WARN  [RpcServer.handler=47,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10171,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648038,"queuetimems":0,"class":"HRegionServer","responsesize":17084,"method":"Multi"}
2014-07-02 22:00:58,210 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12414,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645796,"queuetimems":0,"class":"HRegionServer","responsesize":3993,"method":"Multi"}
2014-07-02 22:00:58,211 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11567,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363646644,"queuetimems":0,"class":"HRegionServer","responsesize":16697,"method":"Multi"}
2014-07-02 22:00:58,669 WARN  [RpcServer.handler=27,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11566,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363647103,"queuetimems":1,"class":"HRegionServer","responsesize":17065,"method":"Multi"}
2014-07-02 22:00:58,763 WARN  [RpcServer.handler=36,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10499,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648264,"queuetimems":0,"class":"HRegionServer","responsesize":16663,"method":"Multi"}
2014-07-02 22:00:58,767 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12921,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645845,"queuetimems":1,"class":"HRegionServer","responsesize":17084,"method":"Multi"}
2014-07-02 22:00:58,767 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12552,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363646215,"queuetimems":0,"class":"HRegionServer","responsesize":17241,"method":"Multi"}
2014-07-02 22:00:58,839 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:00:58,845 WARN  [RpcServer.handler=31,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12971,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645873,"queuetimems":0,"class":"HRegionServer","responsesize":17058,"method":"Multi"}
2014-07-02 22:00:58,935 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8030 synced till here 8008
2014-07-02 22:00:59,000 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13174,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363645825,"queuetimems":1,"class":"HRegionServer","responsesize":16894,"method":"Multi"}
2014-07-02 22:00:59,002 WARN  [RpcServer.handler=2,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11080,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363647922,"queuetimems":0,"class":"HRegionServer","responsesize":16975,"method":"Multi"}
2014-07-02 22:00:59,003 WARN  [RpcServer.handler=48,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11003,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363648000,"queuetimems":1,"class":"HRegionServer","responsesize":3993,"method":"Multi"}
2014-07-02 22:00:59,037 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363657488 with entries=131, filesize=76.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363658840
2014-07-02 22:01:00,690 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:00,749 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8119 synced till here 8104
2014-07-02 22:01:00,907 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363658840 with entries=89, filesize=73.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363660690
2014-07-02 22:01:01,747 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:01,783 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363660690 with entries=104, filesize=62.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363661748
2014-07-02 22:01:02,929 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:03,128 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8328 synced till here 8326
2014-07-02 22:01:03,155 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363661748 with entries=105, filesize=74.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363662930
2014-07-02 22:01:03,712 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1420, memsize=561.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/cbd9a3d3373f4f848718da9b3811bc3a
2014-07-02 22:01:03,737 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/cbd9a3d3373f4f848718da9b3811bc3a as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/cbd9a3d3373f4f848718da9b3811bc3a
2014-07-02 22:01:03,759 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/cbd9a3d3373f4f848718da9b3811bc3a, entries=2044400, sequenceid=1420, filesize=145.5m
2014-07-02 22:01:03,760 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~832.5m/872892480, currentsize=381.8m/400364560 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 30320ms, sequenceid=1420, compaction requested=true
2014-07-02 22:01:03,760 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:01:03,761 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 22:01:03,761 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 823.3m
2014-07-02 22:01:03,761 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-02 22:01:03,761 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:01:03,761 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:01:03,761 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. because compaction request was cancelled
2014-07-02 22:01:03,790 DEBUG [RpcServer.handler=27,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:01:04,810 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:04,924 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8432 synced till here 8415
2014-07-02 22:01:05,012 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:01:05,038 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363662930 with entries=104, filesize=74.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363664811
2014-07-02 22:01:05,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363580509
2014-07-02 22:01:05,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363583998
2014-07-02 22:01:05,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363584799
2014-07-02 22:01:05,038 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363586750
2014-07-02 22:01:05,039 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363588563
2014-07-02 22:01:06,619 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:06,645 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8536 synced till here 8534
2014-07-02 22:01:06,667 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363664811 with entries=104, filesize=68.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363666619
2014-07-02 22:01:08,357 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:08,384 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8625 synced till here 8624
2014-07-02 22:01:08,404 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363666619 with entries=89, filesize=62.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363668357
2014-07-02 22:01:10,651 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:10,774 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8726 synced till here 8719
2014-07-02 22:01:10,886 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363668357 with entries=101, filesize=75.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363670652
2014-07-02 22:01:12,438 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:12,466 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8815 synced till here 8811
2014-07-02 22:01:12,495 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363670652 with entries=89, filesize=64.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363672439
2014-07-02 22:01:13,623 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:13,656 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363672439 with entries=88, filesize=61.2m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363673623
2014-07-02 22:01:14,490 DEBUG [RpcServer.handler=0,port=60020] regionserver.HRegion: Flush requested on usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 22:01:15,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:15,122 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 8987 synced till here 8986
2014-07-02 22:01:15,130 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363673623 with entries=84, filesize=62.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363675107
2014-07-02 22:01:16,667 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:16,685 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9071 synced till here 9070
2014-07-02 22:01:16,705 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363675107 with entries=84, filesize=62.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363676668
2014-07-02 22:01:17,936 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:17,939 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:17,943 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:17,950 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:17,982 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,027 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,053 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,081 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,307 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,523 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,557 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,583 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,685 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,925 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,951 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:18,983 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:19,268 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:19,521 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:19,762 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:20,015 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:20,026 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:20,047 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:20,068 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:20,091 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,186 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,199 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,211 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,234 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,245 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,263 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,275 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,294 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,313 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,332 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,352 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,371 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:22,397 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:23,238 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5157ms
2014-07-02 22:01:23,238 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5302ms
2014-07-02 22:01:23,238 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5299ms
2014-07-02 22:01:23,239 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5289ms
2014-07-02 22:01:23,239 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5212ms
2014-07-02 22:01:23,239 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5257ms
2014-07-02 22:01:23,240 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5297ms
2014-07-02 22:01:23,240 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5187ms
2014-07-02 22:01:23,245 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:23,307 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:23,523 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:23,558 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:23,583 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:23,685 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:23,925 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:23,952 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:23,984 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:24,116 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:24,131 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:24,147 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:24,165 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:24,183 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:24,268 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:24,521 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:24,763 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:25,016 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:25,026 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:25,048 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:25,069 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:25,092 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:26,131 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:26,151 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:26,171 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:26,197 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:26,218 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:26,242 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:26,265 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Blocking updates on sceplus-vm48.almaden.ibm.com,60020,1404363106660: the global memstore size 4.0g is >= than blocking 4.0g size
2014-07-02 22:01:27,186 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,200 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,211 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,235 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:27,245 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,263 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,276 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:27,294 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,313 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,332 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,352 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,371 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5001ms
2014-07-02 22:01:27,398 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5000ms
2014-07-02 22:01:27,635 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1550, memsize=668.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/451c40bfa0d149a4bb8d24d32476822a
2014-07-02 22:01:27,683 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/451c40bfa0d149a4bb8d24d32476822a as hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/451c40bfa0d149a4bb8d24d32476822a
2014-07-02 22:01:27,696 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/451c40bfa0d149a4bb8d24d32476822a, entries=2433420, sequenceid=1550, filesize=173.2m
2014-07-02 22:01:27,696 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~891.8m/935087600, currentsize=415.7m/435872080 for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. in 32258ms, sequenceid=1550, compaction requested=true
2014-07-02 22:01:27,697 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:01:27,697 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 4 store files, 0 compacting, 4 eligible, 20 blocking
2014-07-02 22:01:27,697 WARN  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5300ms
2014-07-02 22:01:27,697 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 4 files from compaction candidates
2014-07-02 22:01:27,697 INFO  [RpcServer.handler=44,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,697 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:01:27,697 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 807.9m
2014-07-02 22:01:27,697 WARN  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5327ms
2014-07-02 22:01:27,697 INFO  [RpcServer.handler=16,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,697 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:01:27,697 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. because compaction request was cancelled
2014-07-02 22:01:27,700 WARN  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5348ms
2014-07-02 22:01:27,700 INFO  [RpcServer.handler=15,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,700 WARN  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5368ms
2014-07-02 22:01:27,700 INFO  [RpcServer.handler=25,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,700 WARN  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5387ms
2014-07-02 22:01:27,700 INFO  [RpcServer.handler=6,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,703 WARN  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5409ms
2014-07-02 22:01:27,703 INFO  [RpcServer.handler=20,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,703 WARN  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5428ms
2014-07-02 22:01:27,703 INFO  [RpcServer.handler=48,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,704 WARN  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5440ms
2014-07-02 22:01:27,704 INFO  [RpcServer.handler=33,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,704 WARN  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5459ms
2014-07-02 22:01:27,704 INFO  [RpcServer.handler=17,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,708 WARN  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5474ms
2014-07-02 22:01:27,708 INFO  [RpcServer.handler=14,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,708 WARN  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5497ms
2014-07-02 22:01:27,708 INFO  [RpcServer.handler=2,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,708 WARN  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5509ms
2014-07-02 22:01:27,708 INFO  [RpcServer.handler=36,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,709 WARN  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 5523ms
2014-07-02 22:01:27,709 INFO  [RpcServer.handler=31,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,713 WARN  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1447ms
2014-07-02 22:01:27,713 INFO  [RpcServer.handler=13,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,713 WARN  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1471ms
2014-07-02 22:01:27,713 INFO  [RpcServer.handler=1,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,713 WARN  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1495ms
2014-07-02 22:01:27,713 INFO  [RpcServer.handler=47,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,713 WARN  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1516ms
2014-07-02 22:01:27,713 INFO  [RpcServer.handler=27,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,713 WARN  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1542ms
2014-07-02 22:01:27,713 INFO  [RpcServer.handler=18,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,713 WARN  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1562ms
2014-07-02 22:01:27,713 INFO  [RpcServer.handler=49,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,714 WARN  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 1583ms
2014-07-02 22:01:27,714 INFO  [RpcServer.handler=37,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,714 WARN  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7623ms
2014-07-02 22:01:27,714 INFO  [RpcServer.handler=22,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,715 WARN  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7647ms
2014-07-02 22:01:27,715 INFO  [RpcServer.handler=45,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,715 WARN  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7668ms
2014-07-02 22:01:27,715 INFO  [RpcServer.handler=10,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,715 WARN  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7689ms
2014-07-02 22:01:27,715 INFO  [RpcServer.handler=26,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,717 WARN  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7702ms
2014-07-02 22:01:27,717 INFO  [RpcServer.handler=42,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,720 WARN  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 7958ms
2014-07-02 22:01:27,720 INFO  [RpcServer.handler=12,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,720 WARN  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8200ms
2014-07-02 22:01:27,720 INFO  [RpcServer.handler=40,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,720 WARN  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8452ms
2014-07-02 22:01:27,721 INFO  [RpcServer.handler=38,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,721 WARN  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3538ms
2014-07-02 22:01:27,721 INFO  [RpcServer.handler=23,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,721 WARN  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3557ms
2014-07-02 22:01:27,721 INFO  [RpcServer.handler=46,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,723 WARN  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3576ms
2014-07-02 22:01:27,723 INFO  [RpcServer.handler=9,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,723 WARN  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3592ms
2014-07-02 22:01:27,723 INFO  [RpcServer.handler=4,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,724 WARN  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 3607ms
2014-07-02 22:01:27,724 INFO  [RpcServer.handler=32,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,726 WARN  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8743ms
2014-07-02 22:01:27,726 INFO  [RpcServer.handler=0,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,726 WARN  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8775ms
2014-07-02 22:01:27,727 INFO  [RpcServer.handler=21,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,727 WARN  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 8803ms
2014-07-02 22:01:27,727 INFO  [RpcServer.handler=35,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,727 WARN  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9043ms
2014-07-02 22:01:27,727 INFO  [RpcServer.handler=5,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,727 WARN  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9144ms
2014-07-02 22:01:27,727 INFO  [RpcServer.handler=11,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,728 WARN  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9170ms
2014-07-02 22:01:27,728 INFO  [RpcServer.handler=3,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,728 WARN  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9205ms
2014-07-02 22:01:27,728 INFO  [RpcServer.handler=19,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,728 WARN  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9421ms
2014-07-02 22:01:27,728 INFO  [RpcServer.handler=30,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,729 WARN  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 4484ms
2014-07-02 22:01:27,729 INFO  [RpcServer.handler=24,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,730 WARN  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9676ms
2014-07-02 22:01:27,730 INFO  [RpcServer.handler=29,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,730 WARN  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9787ms
2014-07-02 22:01:27,730 INFO  [RpcServer.handler=7,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,730 WARN  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9748ms
2014-07-02 22:01:27,730 INFO  [RpcServer.handler=8,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,730 WARN  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9703ms
2014-07-02 22:01:27,730 INFO  [RpcServer.handler=43,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,731 WARN  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9780ms
2014-07-02 22:01:27,731 INFO  [RpcServer.handler=34,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,731 WARN  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9792ms
2014-07-02 22:01:27,731 INFO  [RpcServer.handler=28,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,732 WARN  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9795ms
2014-07-02 22:01:27,732 INFO  [RpcServer.handler=41,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,734 WARN  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Memstore is above high water mark and block 9653ms
2014-07-02 22:01:27,734 INFO  [RpcServer.handler=39,port=60020] regionserver.MemStoreFlusher: Unblocking updates for server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:01:27,879 DEBUG [RpcServer.handler=7,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:01:28,155 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:28,157 WARN  [RpcServer.handler=7,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10875,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363677281,"queuetimems":1,"class":"HRegionServer","responsesize":17113,"method":"Multi"}
2014-07-02 22:01:28,815 WARN  [RpcServer.handler=34,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":10928,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363677236,"queuetimems":1,"class":"HRegionServer","responsesize":17019,"method":"Multi"}
2014-07-02 22:01:28,824 WARN  [RpcServer.handler=8,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11492,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363677332,"queuetimems":0,"class":"HRegionServer","responsesize":16992,"method":"Multi"}
2014-07-02 22:01:28,878 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9186 synced till here 9176
2014-07-02 22:01:28,943 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363676668 with entries=115, filesize=87.3m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363688156
2014-07-02 22:01:28,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363590217
2014-07-02 22:01:28,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363593061
2014-07-02 22:01:28,943 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363596271
2014-07-02 22:01:28,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363598140
2014-07-02 22:01:28,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363599866
2014-07-02 22:01:28,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363601774
2014-07-02 22:01:28,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363603167
2014-07-02 22:01:28,944 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363605558
2014-07-02 22:01:28,957 WARN  [RpcServer.handler=41,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11177,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363677780,"queuetimems":0,"class":"HRegionServer","responsesize":16793,"method":"Multi"}
2014-07-02 22:01:29,095 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:01:29,310 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1690, memsize=561.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/f5f27bfc022c4d53a579cf63c90692b1
2014-07-02 22:01:29,321 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/f5f27bfc022c4d53a579cf63c90692b1 as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/f5f27bfc022c4d53a579cf63c90692b1
2014-07-02 22:01:29,343 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/f5f27bfc022c4d53a579cf63c90692b1, entries=2044240, sequenceid=1690, filesize=145.4m
2014-07-02 22:01:29,343 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~828.8m/869083200, currentsize=295.2m/309517760 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 25582ms, sequenceid=1690, compaction requested=true
2014-07-02 22:01:29,344 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:01:29,344 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 22:01:29,344 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-02 22:01:29,344 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:01:29,344 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:01:29,344 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. because compaction request was cancelled
2014-07-02 22:01:29,344 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 626.7m
2014-07-02 22:01:29,361 DEBUG [RpcServer.handler=21,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:01:29,362 WARN  [RpcServer.handler=28,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11512,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363677849,"queuetimems":0,"class":"HRegionServer","responsesize":17083,"method":"Multi"}
2014-07-02 22:01:30,723 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:30,753 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9304 synced till here 9273
2014-07-02 22:01:30,917 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363688156 with entries=118, filesize=93.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363690724
2014-07-02 22:01:30,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363607147
2014-07-02 22:01:30,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363609003
2014-07-02 22:01:30,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363610808
2014-07-02 22:01:30,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363612841
2014-07-02 22:01:30,953 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363613711
2014-07-02 22:01:31,037 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11022,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363680014,"queuetimems":0,"class":"HRegionServer","responsesize":17083,"method":"Multi"}
2014-07-02 22:01:31,037 WARN  [RpcServer.handler=5,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12353,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678683,"queuetimems":0,"class":"HRegionServer","responsesize":17011,"method":"Multi"}
2014-07-02 22:01:31,118 WARN  [RpcServer.handler=10,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11071,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363680046,"queuetimems":0,"class":"HRegionServer","responsesize":17113,"method":"Multi"}
2014-07-02 22:01:31,118 WARN  [RpcServer.handler=45,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11050,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363680067,"queuetimems":0,"class":"HRegionServer","responsesize":16992,"method":"Multi"}
2014-07-02 22:01:31,118 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:01:31,261 WARN  [RpcServer.handler=12,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11500,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363679760,"queuetimems":0,"class":"HRegionServer","responsesize":17044,"method":"Multi"}
2014-07-02 22:01:31,508 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:31,513 WARN  [RpcServer.handler=3,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12957,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678555,"queuetimems":0,"class":"HRegionServer","responsesize":16918,"method":"Multi"}
2014-07-02 22:01:31,520 WARN  [RpcServer.handler=11,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12939,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678581,"queuetimems":0,"class":"HRegionServer","responsesize":16903,"method":"Multi"}
2014-07-02 22:01:31,521 WARN  [RpcServer.handler=39,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13442,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678079,"queuetimems":1,"class":"HRegionServer","responsesize":16860,"method":"Multi"}
2014-07-02 22:01:31,522 WARN  [RpcServer.handler=26,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11498,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363680024,"queuetimems":0,"class":"HRegionServer","responsesize":16793,"method":"Multi"}
2014-07-02 22:01:31,524 WARN  [RpcServer.handler=29,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13473,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678051,"queuetimems":1,"class":"HRegionServer","responsesize":17025,"method":"Multi"}
2014-07-02 22:01:31,525 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13500,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678025,"queuetimems":0,"class":"HRegionServer","responsesize":16802,"method":"Multi"}
2014-07-02 22:01:31,529 WARN  [RpcServer.handler=30,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13223,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678305,"queuetimems":0,"class":"HRegionServer","responsesize":17213,"method":"Multi"}
2014-07-02 22:01:31,531 WARN  [RpcServer.handler=22,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":11440,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363680090,"queuetimems":0,"class":"HRegionServer","responsesize":17019,"method":"Multi"}
2014-07-02 22:01:31,531 WARN  [RpcServer.handler=0,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12549,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678981,"queuetimems":0,"class":"HRegionServer","responsesize":16855,"method":"Multi"}
2014-07-02 22:01:31,531 WARN  [RpcServer.handler=19,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13009,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678521,"queuetimems":1,"class":"HRegionServer","responsesize":16711,"method":"Multi"}
2014-07-02 22:01:31,532 WARN  [RpcServer.handler=35,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12608,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678923,"queuetimems":1,"class":"HRegionServer","responsesize":16980,"method":"Multi"}
2014-07-02 22:01:31,557 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9428 synced till here 9409
2014-07-02 22:01:31,570 WARN  [RpcServer.handler=21,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12621,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363678949,"queuetimems":0,"class":"HRegionServer","responsesize":17119,"method":"Multi"}
2014-07-02 22:01:31,580 WARN  [RpcServer.handler=40,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":12061,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363679519,"queuetimems":1,"class":"HRegionServer","responsesize":17094,"method":"Multi"}
2014-07-02 22:01:31,633 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363690724 with entries=124, filesize=79.7m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363691509
2014-07-02 22:01:31,634 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=33, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:32,487 WARN  [RpcServer.handler=38,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":13220,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:40349","starttimems":1404363679266,"queuetimems":0,"class":"HRegionServer","responsesize":17111,"method":"Multi"}
2014-07-02 22:01:33,079 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:33,092 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9539 synced till here 9524
2014-07-02 22:01:33,217 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363691509 with entries=111, filesize=84.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363693080
2014-07-02 22:01:33,218 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=34, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:35,085 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:35,108 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9636 synced till here 9634
2014-07-02 22:01:35,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363693080 with entries=97, filesize=63.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363695085
2014-07-02 22:01:35,153 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=35, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:36,935 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:36,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363695085 with entries=88, filesize=61.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363696935
2014-07-02 22:01:36,957 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=36, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:38,415 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:38,442 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9813 synced till here 9811
2014-07-02 22:01:38,456 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363696935 with entries=89, filesize=63.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363698415
2014-07-02 22:01:38,457 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=37, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:40,400 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:40,415 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9903 synced till here 9901
2014-07-02 22:01:40,429 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363698415 with entries=90, filesize=63.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363700401
2014-07-02 22:01:40,429 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=38, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:41,860 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:41,916 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 9993 synced till here 9991
2014-07-02 22:01:41,958 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363700401 with entries=90, filesize=65.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363701861
2014-07-02 22:01:41,961 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=39, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:43,580 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:43,730 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363701861 with entries=88, filesize=61.9m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363703581
2014-07-02 22:01:43,732 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=40, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:45,854 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:01:46,151 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363703581 with entries=102, filesize=69.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363705854
2014-07-02 22:01:46,160 INFO  [regionserver60020.logRoller] wal.FSHLog: Too many hlogs: logs=41, maxlogs=32; forcing flush of 1 regions(s): 59a882e2ecb917452809632a4eb8d27e
2014-07-02 22:01:46,737 DEBUG [LruStats #0] hfile.LruBlockCache: Total=4.16 MB, free=3.95 GB, max=3.96 GB, blocks=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=0, evicted=0, evictedPerRun=NaN
2014-07-02 22:01:50,725 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1845, memsize=456.9m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/26373c3af8c0499583682dcd70709458
2014-07-02 22:01:50,736 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/26373c3af8c0499583682dcd70709458 as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/26373c3af8c0499583682dcd70709458
2014-07-02 22:01:50,750 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/26373c3af8c0499583682dcd70709458, entries=1663440, sequenceid=1845, filesize=118.5m
2014-07-02 22:01:50,750 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~643.7m/675008240, currentsize=307.5m/322476160 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 21406ms, sequenceid=1845, compaction requested=true
2014-07-02 22:01:50,750 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:01:50,751 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 22:01:50,751 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-02 22:01:50,751 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e., current region memstore size 372.1m
2014-07-02 22:01:50,751 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:01:50,751 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:01:50,751 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. because compaction request was cancelled
2014-07-02 22:01:51,037 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:01:54,081 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1831, memsize=565.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/a0552c04085e492f8245d1b851cd60c3
2014-07-02 22:01:54,092 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/a0552c04085e492f8245d1b851cd60c3 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/a0552c04085e492f8245d1b851cd60c3
2014-07-02 22:01:54,103 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/a0552c04085e492f8245d1b851cd60c3, entries=2059300, sequenceid=1831, filesize=146.6m
2014-07-02 22:01:54,104 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~807.9m/847100240, currentsize=329.4m/345416320 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 26407ms, sequenceid=1831, compaction requested=true
2014-07-02 22:01:54,104 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:01:54,104 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 22:01:54,105 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-02 22:01:54,105 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:01:54,105 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:01:54,105 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. because compaction request was cancelled
2014-07-02 22:01:54,105 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182., current region memstore size 751.6m
2014-07-02 22:01:54,618 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:01:58,879 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2047, memsize=255.3m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/.tmp/f277936dcbcb4541837af153442c89e7
2014-07-02 22:01:58,890 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/.tmp/f277936dcbcb4541837af153442c89e7 as hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/family/f277936dcbcb4541837af153442c89e7
2014-07-02 22:01:58,907 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/59a882e2ecb917452809632a4eb8d27e/family/f277936dcbcb4541837af153442c89e7, entries=929600, sequenceid=2047, filesize=66.2m
2014-07-02 22:01:58,908 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~372.1m/390181520, currentsize=0.0/0 for region usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e. in 8156ms, sequenceid=2047, compaction requested=true
2014-07-02 22:01:58,908 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:01:58,908 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 3 store files, 0 compacting, 3 eligible, 20 blocking
2014-07-02 22:01:58,908 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 3 files from compaction candidates
2014-07-02 22:01:58,908 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 549.9m
2014-07-02 22:01:58,908 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:01:58,908 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:01:58,908 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e. because compaction request was cancelled
2014-07-02 22:01:59,283 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:02:02,459 INFO  [RpcServer.handler=24,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,459 INFO  [RpcServer.handler=0,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,459 INFO  [RpcServer.handler=19,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,460 INFO  [RpcServer.handler=29,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,459 INFO  [RpcServer.handler=47,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,460 INFO  [RpcServer.handler=21,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,460 INFO  [RpcServer.handler=14,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:02,464 INFO  [RpcServer.handler=22,port=60020] compress.CodecPool: Got brand-new decompressor
2014-07-02 22:02:10,376 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2051, memsize=459.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/418911634e244efea51545093295f228
2014-07-02 22:02:10,388 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/418911634e244efea51545093295f228 as hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/418911634e244efea51545093295f228
2014-07-02 22:02:10,398 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/418911634e244efea51545093295f228, entries=1672560, sequenceid=2051, filesize=119.2m
2014-07-02 22:02:10,399 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~751.6m/788111520, currentsize=0.0/0 for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. in 16293ms, sequenceid=2051, compaction requested=true
2014-07-02 22:02:10,399 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:02:10,399 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 5 store files, 0 compacting, 5 eligible, 20 blocking
2014-07-02 22:02:10,400 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 5 files from compaction candidates
2014-07-02 22:02:10,400 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:02:10,400 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:02:10,400 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. because compaction request was cancelled
2014-07-02 22:02:13,840 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2058, memsize=403.8m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/bdfbd71903df4fe38ca112ba2d19c4f6
2014-07-02 22:02:13,888 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/bdfbd71903df4fe38ca112ba2d19c4f6 as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/bdfbd71903df4fe38ca112ba2d19c4f6
2014-07-02 22:02:13,911 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/bdfbd71903df4fe38ca112ba2d19c4f6, entries=1470260, sequenceid=2058, filesize=104.8m
2014-07-02 22:02:13,921 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~549.9m/576625040, currentsize=0.0/0 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 15013ms, sequenceid=2058, compaction requested=true
2014-07-02 22:02:13,940 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:02:13,940 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-02 22:02:13,940 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-02 22:02:13,940 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:02:13,940 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:02:13,941 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. because compaction request was cancelled
2014-07-02 22:06:46,738 DEBUG [LruStats #0] hfile.LruBlockCache: Total=76.44 MB, free=3.88 GB, max=3.96 GB, blocks=1120, accesses=21293773, hits=21292499, hitRatio=99.99%, , cachingAccesses=21293865, cachingHits=21292591, cachingHitsRatio=99.99%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-02 22:07:24,065 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1324ms
GC pool 'ParNew' had collection(s): count=1 time=1728ms
2014-07-02 22:07:30,935 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2364ms
GC pool 'ParNew' had collection(s): count=1 time=2721ms
2014-07-02 22:07:35,906 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1468ms
GC pool 'ParNew' had collection(s): count=1 time=1552ms
2014-07-02 22:07:45,740 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1723ms
GC pool 'ParNew' had collection(s): count=1 time=1775ms
2014-07-02 22:08:25,323 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:08:25,323 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 331.0m
2014-07-02 22:08:25,428 DEBUG [RpcServer.handler=46,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:08:25,429 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 309.1m
2014-07-02 22:08:25,814 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:08:25,815 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:08:28,156 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:08:28,226 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10277 synced till here 10275
2014-07-02 22:08:28,328 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363705854 with entries=94, filesize=64.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364108157
2014-07-02 22:08:28,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363615482
2014-07-02 22:08:28,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363617896
2014-07-02 22:08:28,333 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363619427
2014-07-02 22:08:28,356 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363621189
2014-07-02 22:08:28,360 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363623389
2014-07-02 22:08:28,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363625460
2014-07-02 22:08:28,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363627590
2014-07-02 22:08:28,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363628319
2014-07-02 22:08:28,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363629725
2014-07-02 22:08:28,371 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363631856
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363633898
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363636107
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363638023
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363640184
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363641709
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363643662
2014-07-02 22:08:28,380 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363645236
2014-07-02 22:08:28,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363655729
2014-07-02 22:08:28,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363657488
2014-07-02 22:08:28,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363658840
2014-07-02 22:08:28,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363660690
2014-07-02 22:08:28,381 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363661748
2014-07-02 22:08:28,389 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363662930
2014-07-02 22:08:28,390 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363664811
2014-07-02 22:08:28,483 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363666619
2014-07-02 22:08:28,484 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363668357
2014-07-02 22:08:28,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363670652
2014-07-02 22:08:28,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363672439
2014-07-02 22:08:28,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363673623
2014-07-02 22:08:28,492 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363675107
2014-07-02 22:08:32,681 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1824ms
GC pool 'ParNew' had collection(s): count=1 time=1839ms
2014-07-02 22:08:35,186 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2053, memsize=190.6m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/2bd98e9b794b48faadeeea20287f81c1
2014-07-02 22:08:35,196 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/2bd98e9b794b48faadeeea20287f81c1 as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/2bd98e9b794b48faadeeea20287f81c1
2014-07-02 22:08:35,204 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/2bd98e9b794b48faadeeea20287f81c1, entries=693810, sequenceid=2053, filesize=49.5m
2014-07-02 22:08:35,204 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~309.1m/324083120, currentsize=29.4m/30824160 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 9775ms, sequenceid=2053, compaction requested=true
2014-07-02 22:08:35,206 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-02 22:08:35,206 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-02 22:08:35,206 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:08:35,206 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:08:35,206 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:08:35,206 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. because compaction request was cancelled
2014-07-02 22:08:37,781 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1097ms
GC pool 'ParNew' had collection(s): count=1 time=1383ms
2014-07-02 22:08:38,286 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2053, memsize=191.4m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/c5b625b26e0640f7ab6c8f5090684822
2014-07-02 22:08:38,296 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/c5b625b26e0640f7ab6c8f5090684822 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/c5b625b26e0640f7ab6c8f5090684822
2014-07-02 22:08:38,304 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/c5b625b26e0640f7ab6c8f5090684822, entries=696830, sequenceid=2053, filesize=49.7m
2014-07-02 22:08:38,305 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~331.0m/347046400, currentsize=29.5m/30938960 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 12981ms, sequenceid=2053, compaction requested=true
2014-07-02 22:08:38,306 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:08:38,306 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-02 22:08:38,306 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-02 22:08:38,307 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:08:38,307 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:08:38,307 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. because compaction request was cancelled
2014-07-02 22:09:30,087 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:09:30,109 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364108157 with entries=85, filesize=62.0m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364170087
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363676668
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363688156
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363690724
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363691509
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363693080
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363695085
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363696935
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363698415
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363700401
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363701861
2014-07-02 22:09:30,110 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404363703581
2014-07-02 22:10:32,163 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:10:32,189 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364170087 with entries=83, filesize=60.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364232163
2014-07-02 22:10:38,622 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:10:38,633 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10529 synced till here 10528
2014-07-02 22:10:38,641 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364232163 with entries=84, filesize=61.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364238622
2014-07-02 22:11:33,007 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:11:33,041 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364238622 with entries=83, filesize=61.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364293008
2014-07-02 22:11:46,737 DEBUG [LruStats #0] hfile.LruBlockCache: Total=2.44 GB, free=1.52 GB, max=3.96 GB, blocks=39467, accesses=40240721, hits=40200960, hitRatio=99.90%, , cachingAccesses=40240723, cachingHits=40200962, cachingHitsRatio=99.90%, evictions=0, evicted=0, evictedPerRun=NaN
2014-07-02 22:12:24,431 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:12:24,460 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364293008 with entries=84, filesize=61.8m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364344431
2014-07-02 22:13:13,456 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:13:13,512 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 10851 synced till here 10848
2014-07-02 22:13:13,556 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364344431 with entries=155, filesize=66.4m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364393456
2014-07-02 22:13:21,540 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:13:21,989 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364393456 with entries=86, filesize=61.6m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364401541
2014-07-02 22:13:23,771 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:13:23,790 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364401541 with entries=83, filesize=61.1m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364403771
2014-07-02 22:13:28,447 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2458ms
GC pool 'ParNew' had collection(s): count=1 time=2600ms
2014-07-02 22:13:34,813 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2014-07-02 22:13:34,844 DEBUG [regionserver60020.logRoller] wal.FSHLog: cleanupCurrentWriter  waiting for transactions to get synced  total 11103 synced till here 11102
2014-07-02 22:13:34,867 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364403771 with entries=83, filesize=61.5m; new WAL /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814
2014-07-02 22:13:35,230 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:13:35,241 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., current region memstore size 257.3m
2014-07-02 22:13:35,407 DEBUG [RpcServer.handler=16,port=60020] regionserver.HRegion: Flush requested on usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:13:35,407 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182., current region memstore size 257.2m
2014-07-02 22:13:35,451 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:13:35,571 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:13:35,612 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:13:35,627 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: Flush requested on usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:13:41,449 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2238, memsize=165.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/f2403f831387436fa5bdbcfb34d1c30b
2014-07-02 22:13:41,473 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/.tmp/f2403f831387436fa5bdbcfb34d1c30b as hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/f2403f831387436fa5bdbcfb34d1c30b
2014-07-02 22:13:41,494 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/da30d076a3fb986c27f5ec576fd4dbc3/family/f2403f831387436fa5bdbcfb34d1c30b, entries=602550, sequenceid=2238, filesize=43.0m
2014-07-02 22:13:41,494 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.3m/269771440, currentsize=1.5m/1586880 for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. in 6253ms, sequenceid=2238, compaction requested=true
2014-07-02 22:13:41,496 DEBUG [MemStoreFlusher.0] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.0; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:13:41,496 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 7 store files, 0 compacting, 7 eligible, 20 blocking
2014-07-02 22:13:41,496 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 7 files from compaction candidates
2014-07-02 22:13:41,496 DEBUG [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., current region memstore size 257.1m
2014-07-02 22:13:41,496 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:13:41,496 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:13:41,496 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3. because compaction request was cancelled
2014-07-02 22:13:41,538 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2231, memsize=165.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/4036b0b8674946208366b82a46ac1b1f
2014-07-02 22:13:41,549 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/.tmp/4036b0b8674946208366b82a46ac1b1f as hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/4036b0b8674946208366b82a46ac1b1f
2014-07-02 22:13:41,557 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/d229cf2ba6e2c3756ac8f1655f75a182/family/4036b0b8674946208366b82a46ac1b1f, entries=602550, sequenceid=2231, filesize=43.0m
2014-07-02 22:13:41,560 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~257.2m/269660880, currentsize=1.6m/1664640 for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. in 6153ms, sequenceid=2231, compaction requested=true
2014-07-02 22:13:41,562 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Selecting compaction from 6 store files, 0 compacting, 6 eligible, 20 blocking
2014-07-02 22:13:41,562 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Some files are too large. Excluding 6 files from compaction candidates
2014-07-02 22:13:41,562 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.ExploringCompactionPolicy: Exploring compaction algorithm has selected 0 files of size 0 starting at candidate #-1 after considering 0 permutations with 0 in ratio
2014-07-02 22:13:41,562 DEBUG [regionserver60020-smallCompactions-1404363144254] compactions.RatioBasedCompactionPolicy: Not compacting files because we only have 0 files ready for compaction. Need 3 to initiate.
2014-07-02 22:13:41,562 DEBUG [regionserver60020-smallCompactions-1404363144254] regionserver.CompactSplitThread: Not compacting usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182. because compaction request was cancelled
2014-07-02 22:13:41,563 DEBUG [MemStoreFlusher.1] regionserver.CompactSplitThread: Small Compaction requested: system; Because: MemStoreFlusher.1; compaction_queue=(0:0), split_queue=0, merge_queue=0
2014-07-02 22:13:41,567 DEBUG [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., current region memstore size 256.8m
2014-07-02 22:13:41,686 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:13:41,753 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:15:06,368 WARN  [regionserver60020] util.Sleeper: We slept 82411ms instead of 3000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 22:15:06,375 WARN  [regionserver60020.periodicFlusher] util.Sleeper: We slept 87923ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 22:15:06,371 WARN  [regionserver60020.compactionChecker] util.Sleeper: We slept 87924ms instead of 10000ms, this is likely due to a long garbage collecting pause and it's usually bad, see http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired
2014-07-02 22:15:06,369 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 80535ms
GC pool 'ParNew' had collection(s): count=1 time=1150ms
GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=79741ms
2014-07-02 22:15:06,394 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 105723ms for sessionid 0x146fa9060fe0003, closing socket connection and attempting reconnect
2014-07-02 22:15:06,394 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 109709ms for sessionid 0x46fa9065850004, closing socket connection and attempting reconnect
2014-07-02 22:15:06,394 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 109749ms for sessionid 0x146fa9060fe0001, closing socket connection and attempting reconnect
2014-07-02 22:15:06,593 WARN  [ResponseProcessor for block blk_5840423534092117012_42286] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_5840423534092117012_42286java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.58:59165 remote=/9.1.143.58:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-02 22:15:06,596 WARN  [ResponseProcessor for block blk_-7647615952713483253_42287] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_-7647615952713483253_42287java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.58:59257 remote=/9.1.143.58:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-02 22:15:06,596 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for blk_5840423534092117012_42286 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,622 WARN  [ResponseProcessor for block blk_6079498091110961410_42283] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block blk_6079498091110961410_42283java.net.SocketTimeoutException: 66000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/9.1.143.58:58898 remote=/9.1.143.58:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readLong(DataInputStream.java:416)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:124)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3161)

2014-07-02 22:15:06,626 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for blk_6079498091110961410_42283 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,622 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for blk_-7647615952713483253_42287 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,626 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:06,626 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:06,632 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:06,796 FATAL [regionserver60020] regionserver.HRegionServer: ABORTING region server sceplus-vm48.almaden.ibm.com,60020,1404363106660: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing sceplus-vm48.almaden.ibm.com,60020,1404363106660 as dead server
org.apache.hadoop.hbase.YouAreDeadException: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing sceplus-vm48.almaden.ibm.com,60020,1404363106660 as dead server
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:534)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:95)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:79)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRemoteException(ProtobufUtil.java:285)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1065)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:901)
	at java.lang.Thread.run(Thread.java:701)
Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing sceplus-vm48.almaden.ibm.com,60020,1404363106660 as dead server
	at org.apache.hadoop.hbase.master.ServerManager.checkIsDead(ServerManager.java:369)
	at org.apache.hadoop.hbase.master.ServerManager.regionServerReport(ServerManager.java:274)
	at org.apache.hadoop.hbase.master.HMaster.regionServerReport(HMaster.java:1357)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$2.callBlockingMethod(RegionServerStatusProtos.java:5087)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2012)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:98)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:73)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1146)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:701)

	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1453)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1657)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1715)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.regionServerReport(RegionServerStatusProtos.java:5414)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1063)
	... 2 more
2014-07-02 22:15:06,826 FATAL [regionserver60020] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: []
2014-07-02 22:15:06,888 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 22:15:06,888 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-02 22:15:06,908 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #0 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:06,930 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x146fa9060fe0003 has expired, closing socket connection
2014-07-02 22:15:06,930 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #0 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:06,930 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.59:50010 failed 1 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:06,922 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #0 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:06,930 WARN  [regionserver60020-EventThread] client.HConnectionManager$HConnectionImplementation: This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2014-07-02 22:15:06,930 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.59:50010 failed 1 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:06,931 INFO  [regionserver60020-EventThread] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x146fa9060fe0003
2014-07-02 22:15:06,931 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.59:50010 failed 1 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:06,932 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-02 22:15:06,933 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for blk_6079498091110961410_42283 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,933 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:06,973 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #1 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:06,973 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.59:50010 failed 2 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:06,974 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for blk_6079498091110961410_42283 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,974 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:06,980 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for blk_-7647615952713483253_42287 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,980 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:06,983 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for blk_5840423534092117012_42286 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:06,984 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,010 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #2 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,022 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.59:50010 failed 3 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,027 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for blk_6079498091110961410_42283 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,027 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,054 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Opening socket connection to server slave1/9.1.143.59:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 22:15:07,055 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Socket connection established to slave1/9.1.143.59:2181, initiating session
2014-07-02 22:15:07,074 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #1 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,074 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.59:50010 failed 2 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,075 INFO  [regionserver60020-SendThread(slave1:2181)] zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x46fa9065850004 has expired, closing socket connection
2014-07-02 22:15:07,075 WARN  [regionserver60020-EventThread] client.HConnectionManager$HConnectionImplementation: This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2014-07-02 22:15:07,099 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #1 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,091 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for blk_-7647615952713483253_42287 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,100 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.59:50010 failed 2 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,100 INFO  [regionserver60020-EventThread] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x46fa9065850004
2014-07-02 22:15:07,100 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,100 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-02 22:15:07,112 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #3 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,118 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.59:50010 failed 4 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,118 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for blk_6079498091110961410_42283 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,119 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,131 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #4 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,138 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #2 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,138 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.59:50010 failed 5 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,138 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.59:50010 failed 3 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,139 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for blk_6079498091110961410_42283 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,139 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,141 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for blk_5840423534092117012_42286 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,141 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,158 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for blk_-7647615952713483253_42287 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,158 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,186 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,186 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.59:50010 failed 6 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Marking primary datanode as bad.
2014-07-02 22:15:07,199 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sceplus-vm48.almaden.ibm.com/9.1.143.58:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-02 22:15:07,203 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #2 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,204 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.59:50010 failed 3 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,203 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #3 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,204 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Socket connection established to sceplus-vm48.almaden.ibm.com/9.1.143.58:2181, initiating session
2014-07-02 22:15:07,204 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.59:50010 failed 4 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,223 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for blk_-7647615952713483253_42287 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,223 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,223 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for blk_5840423534092117012_42286 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,224 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,242 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #4 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,244 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #3 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,245 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.59:50010 failed 4 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,244 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.59:50010 failed 5 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,254 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for blk_-7647615952713483253_42287 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,254 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,272 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,272 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.59:50010 failed 6 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Marking primary datanode as bad.
2014-07-02 22:15:07,276 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for blk_5840423534092117012_42286 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,276 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,298 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #0 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,304 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 1 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,313 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #4 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,316 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.59:50010 failed 5 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Will retry...
2014-07-02 22:15:07,339 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #1 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,348 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #0 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,349 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 1 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,348 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 2 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,354 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for blk_5840423534092117012_42286 bad datanode[0] 9.1.143.58:50010
2014-07-02 22:15:07,354 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 in pipeline 9.1.143.58:50010, 9.1.143.59:50010: bad datanode 9.1.143.58:50010
2014-07-02 22:15:07,361 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 9.1.143.59:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,361 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.59:50010 failed 6 times.  Pipeline was 9.1.143.58:50010, 9.1.143.59:50010. Marking primary datanode as bad.
2014-07-02 22:15:07,372 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #2 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,372 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 3 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,387 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #0 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,387 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 1 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,404 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #3 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,405 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 4 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,411 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #1 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,412 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 2 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,414 INFO  [regionserver60020-SendThread(sceplus-vm48.almaden.ibm.com:2181)] zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x146fa9060fe0001 has expired, closing socket connection
2014-07-02 22:15:07,416 FATAL [regionserver60020-EventThread] regionserver.HRegionServer: ABORTING region server sceplus-vm48.almaden.ibm.com,60020,1404363106660: regionserver:60020-0x146fa9060fe0001, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, baseZNode=/hbase regionserver:60020-0x146fa9060fe0001 received expired from ZooKeeper, aborting
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:401)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:319)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
2014-07-02 22:15:07,425 FATAL [regionserver60020-EventThread] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: []
2014-07-02 22:15:07,435 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #4 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,435 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 5 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,492 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_6079498091110961410_42283 has out of date GS 42283 found 42319, may already be committed
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,500 INFO  [regionserver60020] regionserver.HRegionServer: STOPPED: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing sceplus-vm48.almaden.ibm.com,60020,1404363106660 as dead server
2014-07-02 22:15:07,494 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-07-02 22:15:07,501 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2014-07-02 22:15:07,500 WARN  [DataStreamer for file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814 block blk_6079498091110961410_42283] hdfs.DFSClient: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
2014-07-02 22:15:07,501 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,505 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2014-07-02 22:15:07,505 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,505 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:07,519 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #2 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,519 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2014-07-02 22:15:07,520 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 2 replicas.  Requesting close of hlog.
2014-07-02 22:15:07,520 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 3 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,530 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #1 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,531 FATAL [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:07,532 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 2 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,532 WARN  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 2 replicas.  Requesting close of hlog.
2014-07-02 22:15:07,548 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2014-07-02 22:15:07,549 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2014-07-02 22:15:07,588 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2014-07-02 22:15:07,588 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2014-07-02 22:15:07,628 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #3 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,628 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #2 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,590 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,60020,1404363106660] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2014-07-02 22:15:07,629 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 3 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,629 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 4 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,629 INFO  [SplitLogWorker-sceplus-vm48.almaden.ibm.com,60020,1404363106660] regionserver.SplitLogWorker: SplitLogWorker sceplus-vm48.almaden.ibm.com,60020,1404363106660 exiting
2014-07-02 22:15:07,636 INFO  [regionserver60020] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:60030
2014-07-02 22:15:07,656 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #3 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,657 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 4 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,674 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #4 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,674 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 5 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,710 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_-7647615952713483253_42287 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,711 WARN  [DataStreamer for file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d block blk_-7647615952713483253_42287] hdfs.DFSClient: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
2014-07-02 22:15:07,720 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #4 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,721 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 5 times.  Pipeline was 9.1.143.58:50010. Will retry...
2014-07-02 22:15:07,730 WARN  [MemStoreFlusher.1] regionserver.HStore: Failed flushing store file, retrying num=0
java.io.IOException: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,752 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Failed recovery attempt #5 from primary datanode 9.1.143.58:50010
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5840423534092117012_42286 is missing
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:5943)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:835)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:2127)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2095)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2175)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:622)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)

	at org.apache.hadoop.ipc.Client.call(Client.java:1113)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy13.recoverBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3319)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,753 WARN  [DataStreamer for file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639 block blk_5840423534092117012_42286] hdfs.DFSClient: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
2014-07-02 22:15:07,767 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5530 keyvalues from start:0 to end:553
2014-07-02 22:15:07,811 WARN  [MemStoreFlusher.0] regionserver.HStore: Failed flushing store file, retrying num=0
java.io.IOException: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:07,818 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5360 keyvalues from start:0 to end:536
2014-07-02 22:15:07,828 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5360 keyvalues from start:0 to end:536
2014-07-02 22:15:07,860 INFO  [RpcServer.handler=43,port=60020] regionserver.HRegion: Interrupted while waiting for a lock
2014-07-02 22:15:07,866 INFO  [RpcServer.handler=1,port=60020] regionserver.HRegion: Interrupted while waiting for a lock
2014-07-02 22:15:07,871 INFO  [RpcServer.handler=42,port=60020] regionserver.HRegion: Interrupted while waiting for a lock
2014-07-02 22:15:07,988 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5340 keyvalues from start:0 to end:534
2014-07-02 22:15:08,101 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,101 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,101 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 2 replicas.  Requesting close of hlog.
2014-07-02 22:15:08,117 INFO  [RpcServer.handler=20,port=60020] regionserver.HRegion: Interrupted while waiting for a lock
2014-07-02 22:15:08,154 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,154 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,154 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 2 replicas.  Requesting close of hlog.
2014-07-02 22:15:08,156 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,156 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,156 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 2 replicas.  Requesting close of hlog.
2014-07-02 22:15:08,234 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,234 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,235 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Too many consecutive RollWriter requests, it's a sign of the total number of live datanodes is lower than the tolerable replicas.
2014-07-02 22:15:08,247 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5650 keyvalues from start:0 to end:565
2014-07-02 22:15:08,247 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5690 keyvalues from start:0 to end:569
2014-07-02 22:15:08,247 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5650 keyvalues from start:0 to end:565
2014-07-02 22:15:08,273 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5770 keyvalues from start:0 to end:577
2014-07-02 22:15:08,342 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,342 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,347 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,347 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,349 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,349 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,357 DEBUG [RpcServer.handler=20,port=60020] regionserver.HRegion: rollbackMemstore rolled back 1580 keyvalues from start:0 to end:158
2014-07-02 22:15:08,370 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":83012,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:52895","starttimems":1404364425351,"queuetimems":0,"class":"HRegionServer","responsesize":1540440,"method":"Multi"}
2014-07-02 22:15:08,373 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.respondercallId: 376433 service: ClientService methodName: Multi size: 2.9m connection: 9.1.143.58:52895: output error
2014-07-02 22:15:08,378 WARN  [RpcServer.handler=20,port=60020] ipc.RpcServer: RpcServer.handler=20,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 22:15:08,383 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,383 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,388 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5710 keyvalues from start:0 to end:571
2014-07-02 22:15:08,396 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5820 keyvalues from start:0 to end:582
2014-07-02 22:15:08,421 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: rollbackMemstore rolled back 5820 keyvalues from start:0 to end:582
2014-07-02 22:15:08,456 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,456 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,465 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,465 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,471 DEBUG [RpcServer.handler=43,port=60020] regionserver.HRegion: rollbackMemstore rolled back 1600 keyvalues from start:0 to end:160
2014-07-02 22:15:08,482 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: (responseTooSlow): {"processingtimems":83063,"call":"Multi(org.apache.hadoop.hbase.protobuf.generated.ClientProtos$MultiRequest)","client":"9.1.143.58:52895","starttimems":1404364425416,"queuetimems":0,"class":"HRegionServer","responsesize":1859175,"method":"Multi"}
2014-07-02 22:15:08,484 DEBUG [RpcServer.handler=1,port=60020] regionserver.HRegion: rollbackMemstore rolled back 1720 keyvalues from start:0 to end:172
2014-07-02 22:15:08,492 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.respondercallId: 376687 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:52895: output error
2014-07-02 22:15:08,492 WARN  [RpcServer.handler=43,port=60020] ipc.RpcServer: RpcServer.handler=43,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 22:15:08,493 ERROR [regionserver60020-WAL.AsyncWriter] wal.FSHLog: Error while AsyncWriter write, request close of hlog 
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:08,493 FATAL [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: Error while AsyncSyncer sync, request close of hlog 
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.sync(DFSClient.java:3879)
	at org.apache.hadoop.fs.FSDataOutputStream.sync(FSDataOutputStream.java:97)
	at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.sync(ProtobufLogWriter.java:158)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$AsyncSyncer.run(FSHLog.java:1240)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:08,498 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.respondercallId: 376710 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:52895: output error
2014-07-02 22:15:08,498 WARN  [RpcServer.handler=1,port=60020] ipc.RpcServer: RpcServer.handler=1,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 22:15:08,507 DEBUG [RpcServer.handler=42,port=60020] regionserver.HRegion: rollbackMemstore rolled back 1720 keyvalues from start:0 to end:172
2014-07-02 22:15:08,522 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.respondercallId: 376734 service: ClientService methodName: Multi size: 3.0m connection: 9.1.143.58:52895: output error
2014-07-02 22:15:08,522 WARN  [RpcServer.handler=42,port=60020] ipc.RpcServer: RpcServer.handler=42,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-07-02 22:15:08,902 DEBUG [MemStoreFlusher.1] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:15:08,910 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-02 22:15:08,911 INFO  [MemStoreFlusher.1] compress.CodecPool: Got brand-new compressor
2014-07-02 22:15:08,968 DEBUG [MemStoreFlusher.0] util.FSUtils: DFS Client does not support most favored nodes create; using default create
2014-07-02 22:15:08,978 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-02 22:15:08,979 INFO  [MemStoreFlusher.0] compress.CodecPool: Got brand-new compressor
2014-07-02 22:15:15,242 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2233, memsize=165.2m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/3f48ed81a1de4150b449ba331c8251d0
2014-07-02 22:15:15,252 DEBUG [MemStoreFlusher.1] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/3f48ed81a1de4150b449ba331c8251d0 as hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/3f48ed81a1de4150b449ba331c8251d0
2014-07-02 22:15:15,265 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/family/3f48ed81a1de4150b449ba331c8251d0, entries=601660, sequenceid=2233, filesize=42.9m
2014-07-02 22:15:15,265 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~256.8m/269264480, currentsize=17.0m/17856000 for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229. in 93698ms, sequenceid=2233, compaction requested=true
2014-07-02 22:15:15,266 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2014-07-02 22:15:15,318 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=2233, memsize=165.5m, hasBloomFilter=true, into tmp file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/f195122fabb24a7f8834461307d29405
2014-07-02 22:15:15,326 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/f195122fabb24a7f8834461307d29405 as hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/f195122fabb24a7f8834461307d29405
2014-07-02 22:15:15,333 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://master:54310/hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/family/f195122fabb24a7f8834461307d29405, entries=602640, sequenceid=2233, filesize=43.0m
2014-07-02 22:15:15,333 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~257.1m/269623360, currentsize=17.2m/18030960 for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35. in 93837ms, sequenceid=2233, compaction requested=true
2014-07-02 22:15:15,334 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2014-07-02 22:15:15,334 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager abruptly.
2014-07-02 22:15:15,334 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2014-07-02 22:15:15,334 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2014-07-02 22:15:15,335 INFO  [regionserver60020] regionserver.HRegionServer: aborting server sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:15,336 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@289278d5
2014-07-02 22:15:15,345 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Processing close of usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 22:15:15,345 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closing usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.: disabling compactions & flushes
2014-07-02 22:15:15,345 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Updates disabled for region usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 22:15:15,375 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Processing close of usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:15:15,375 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Processing close of usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:15:15,375 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closing usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.: disabling compactions & flushes
2014-07-02 22:15:15,375 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Updates disabled for region usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:15:15,375 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closing usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.: disabling compactions & flushes
2014-07-02 22:15:15,375 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 5 regions to close
2014-07-02 22:15:15,375 DEBUG [regionserver60020] regionserver.HRegionServer: {59a882e2ecb917452809632a4eb8d27e=usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e., 22b32dbac98aa0b38d3435a0ebdfe229=usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229., da30d076a3fb986c27f5ec576fd4dbc3=usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3., 2c36a3fcd1790e62fe374a1c93881d35=usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35., d229cf2ba6e2c3756ac8f1655f75a182=usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.}
2014-07-02 22:15:15,375 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Updates disabled for region usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:15:15,436 INFO  [StoreCloserThread-usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.-1] regionserver.HStore: Closed family
2014-07-02 22:15:15,441 ERROR [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Memstore size is 87141920
2014-07-02 22:15:15,446 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closed usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 22:15:15,446 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Closed usertable,user9,1404363455394.59a882e2ecb917452809632a4eb8d27e.
2014-07-02 22:15:15,446 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Processing close of usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:15:15,446 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closing usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.: disabling compactions & flushes
2014-07-02 22:15:15,446 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Updates disabled for region usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:15:15,461 INFO  [StoreCloserThread-usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.-1] regionserver.HStore: Closed family
2014-07-02 22:15:15,463 ERROR [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Memstore size is 17856000
2014-07-02 22:15:15,463 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closed usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:15:15,464 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Closed usertable,user6,1404363455394.22b32dbac98aa0b38d3435a0ebdfe229.
2014-07-02 22:15:15,464 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Processing close of usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:15:15,464 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closing usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.: disabling compactions & flushes
2014-07-02 22:15:15,464 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Updates disabled for region usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:15:15,465 INFO  [StoreCloserThread-usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.-1] regionserver.HStore: Closed family
2014-07-02 22:15:15,471 ERROR [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Memstore size is 21239440
2014-07-02 22:15:15,476 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-2] regionserver.HRegion: Closed usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:15:15,476 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-2] handler.CloseRegionHandler: Closed usertable,user1,1404363455394.da30d076a3fb986c27f5ec576fd4dbc3.
2014-07-02 22:15:15,482 INFO  [StoreCloserThread-usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.-1] regionserver.HStore: Closed family
2014-07-02 22:15:15,498 ERROR [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Memstore size is 18030960
2014-07-02 22:15:15,501 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-1] regionserver.HRegion: Closed usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:15:15,501 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-1] handler.CloseRegionHandler: Closed usertable,user3,1404363455394.2c36a3fcd1790e62fe374a1c93881d35.
2014-07-02 22:15:15,502 INFO  [StoreCloserThread-usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.-1] regionserver.HStore: Closed family
2014-07-02 22:15:15,503 ERROR [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Memstore size is 19370320
2014-07-02 22:15:15,503 INFO  [RS_CLOSE_REGION-sceplus-vm48:60020-0] regionserver.HRegion: Closed usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:15:15,504 DEBUG [RS_CLOSE_REGION-sceplus-vm48:60020-0] handler.CloseRegionHandler: Closed usertable,user8,1404363455394.d229cf2ba6e2c3756ac8f1655f75a182.
2014-07-02 22:15:15,576 INFO  [regionserver60020] regionserver.HRegionServer: stopping server sceplus-vm48.almaden.ibm.com,60020,1404363106660; all regions closed.
2014-07-02 22:15:15,576 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2014-07-02 22:15:15,576 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2014-07-02 22:15:15,577 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2014-07-02 22:15:15,577 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2014-07-02 22:15:15,577 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2014-07-02 22:15:15,577 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2014-07-02 22:15:15,578 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2014-07-02 22:15:15,578 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2014-07-02 22:15:15,583 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2014-07-02 22:15:15,583 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2014-07-02 22:15:15,584 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2014-07-02 22:15:15,584 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2014-07-02 22:15:15,584 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2014-07-02 22:15:15,584 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2014-07-02 22:15:15,584 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://master:54310/hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:15,586 ERROR [regionserver60020] regionserver.HRegionServer: Close and delete failed
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:15,686 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2014-07-02 22:15:15,686 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2014-07-02 22:15:16,368 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2014-07-02 22:15:16,380 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2014-07-02 22:15:16,384 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2014-07-02 22:15:16,384 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2014-07-02 22:15:16,384 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2014-07-02 22:15:16,384 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2014-07-02 22:15:16,385 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2014-07-02 22:15:16,385 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/replication/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:16,389 INFO  [regionserver60020] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-07-02 22:15:17,390 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/replication/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:17,391 INFO  [regionserver60020] util.RetryCounter: Sleeping 2000ms before retry #1...
2014-07-02 22:15:19,391 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/replication/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:19,391 INFO  [regionserver60020] util.RetryCounter: Sleeping 4000ms before retry #2...
2014-07-02 22:15:23,392 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/replication/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:23,392 INFO  [regionserver60020] util.RetryCounter: Sleeping 8000ms before retry #3...
2014-07-02 22:15:31,396 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/replication/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:31,396 ERROR [regionserver60020] zookeeper.RecoverableZooKeeper: ZooKeeper getChildren failed after 4 attempts
2014-07-02 22:15:31,432 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:31,432 INFO  [regionserver60020] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-07-02 22:15:32,432 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:32,433 INFO  [regionserver60020] util.RetryCounter: Sleeping 2000ms before retry #1...
2014-07-02 22:15:34,433 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:34,433 INFO  [regionserver60020] util.RetryCounter: Sleeping 4000ms before retry #2...
2014-07-02 22:15:38,434 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:38,434 INFO  [regionserver60020] util.RetryCounter: Sleeping 8000ms before retry #3...
2014-07-02 22:15:46,434 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=sceplus-vm49.almaden.ibm.com:2181,sceplus-vm48.almaden.ibm.com:2181, exception=org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
2014-07-02 22:15:46,434 ERROR [regionserver60020] zookeeper.RecoverableZooKeeper: ZooKeeper delete failed after 4 attempts
2014-07-02 22:15:46,435 WARN  [regionserver60020] regionserver.HRegionServer: Failed deleting my ephemeral node
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/rs/sceplus-vm48.almaden.ibm.com,60020,1404363106660
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:127)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.delete(RecoverableZooKeeper.java:156)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1273)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1262)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.deleteMyEphemeralNode(HRegionServer.java:1292)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1008)
	at java.lang.Thread.run(Thread.java:701)
2014-07-02 22:15:46,450 INFO  [regionserver60020] regionserver.HRegionServer: stopping server sceplus-vm48.almaden.ibm.com,60020,1404363106660; zookeeper connection closed.
2014-07-02 22:15:46,450 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2014-07-02 22:15:46,452 ERROR [main] regionserver.HRegionServerCommandLine: Region server exiting
java.lang.RuntimeException: HRegionServer Aborted
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:66)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2410)
2014-07-02 22:15:46,456 INFO  [Shutdownhook:regionserver60020] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=Thread[Thread-9,5,main]
2014-07-02 22:15:46,457 INFO  [Shutdownhook:regionserver60020] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2014-07-02 22:15:46,457 ERROR [Thread-9] hdfs.DFSClient: Failed to close file /hbase/WALs/sceplus-vm48.almaden.ibm.com,60020,1404363106660/sceplus-vm48.almaden.ibm.com%2C60020%2C1404363106660.1404364414814
java.io.IOException: Error Recovery for block blk_6079498091110961410_42283 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:46,458 ERROR [Thread-9] hdfs.DFSClient: Failed to close file /hbase/data/default/usertable/2c36a3fcd1790e62fe374a1c93881d35/.tmp/0ffa59256e0d45d390e62a4011109639
java.io.IOException: Error Recovery for block blk_5840423534092117012_42286 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:46,458 ERROR [Thread-9] hdfs.DFSClient: Failed to close file /hbase/data/default/usertable/22b32dbac98aa0b38d3435a0ebdfe229/.tmp/b57d3e4481e24804baac0e369e53947d
java.io.IOException: Error Recovery for block blk_-7647615952713483253_42287 failed  because recovery from primary datanode 9.1.143.58:50010 failed 6 times.  Pipeline was 9.1.143.58:50010. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3355)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2200(DFSClient.java:2783)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2987)
2014-07-02 22:15:46,458 INFO  [Shutdownhook:regionserver60020] regionserver.ShutdownHook: Shutdown hook finished.
